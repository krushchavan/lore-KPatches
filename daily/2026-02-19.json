{
  "date": "2026-02-19",
  "report_file": "2026-02-19_ollama_llama3.1-8b.html",
  "llm_backends": [
    [
      "ollama",
      "llama3.1:8b"
    ]
  ],
  "generation_time_seconds": 18777.805493354797,
  "developer_reports": [
    {
      "name": "Alexandre Ghiti",
      "primary_email": "alexghiti@rivosinc.com",
      "patches_submitted": [],
      "patches_reviewed": [],
      "patches_acked": [],
      "discussions_posted": [],
      "errors": []
    },
    {
      "name": "Boris Burkov",
      "primary_email": "boris@bur.io",
      "patches_submitted": [
        {
          "activity_type": "patch_submitted",
          "subject": "[PATCH 1/1] btrfs: set BTRFS_ROOT_ORPHAN_CLEANUP during subvol create",
          "message_id": "718a3b0c2275324b9e287af7e4434f55a4a45901.1771529877.git.boris@bur.io",
          "url": "https://lore.kernel.org/all/718a3b0c2275324b9e287af7e4434f55a4a45901.1771529877.git.boris@bur.io/",
          "date": "2026-02-19T19:38:30Z",
          "in_reply_to": null,
          "ack_type": null,
          "is_ongoing": false,
          "submitted_date": null,
          "patch_summary": "This patch sets the BTRFS_ROOT_ORPHAN_CLEANUP flag during subvolume creation to prevent orphan cleanup issues. The problem arises when a subvolume is created and later orphan cleanup fails, leading to ENOENT errors and file system inconsistencies. The patch addresses two concurrent races that can occur between writeback and unlink operations, as well as lookup and delayed iputs. By setting the flag during subvolume creation, it ensures that orphan cleanup is performed before other operations can interfere with it, resolving the issue and allowing for successful deletion of the subvolume.",
          "analysis_source": "llm-per-reviewer",
          "review_comments": [
            {
              "author": "Filipe Manana",
              "summary": "Reviewer questioned the phrase 'first does' and requested the use of full function names in the patch description.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "clarification_request",
                "grammatical_correction"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "What do you mean by \"first does\"? The first call to btrfs_orphan_cleanup()?\n\nAlso please use full function name, orphan_cleanup() -> btrfs_orphan_cleanup()",
              "reply_to": "Boris Burkov",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Filipe Manana",
              "summary": "Reviewer questioned the patch's explanation of how delayed iputs can lead to a race condition between lookup and eviction, pointing out that igrab() increases i_count from 1 to 2, not 1 -> 1 + N.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "questioning the patch's explanation"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I find this confusing:   1 -> 1 + N ?\n\nShouldn't it be 1 -> 2, meaning the igrab() increased i_count from 1 to 2?",
              "reply_to": "Boris Burkov",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Filipe Manana",
              "summary": "Reviewer Filipe Manana asked for a detailed explanation of where the decrement of parent->d_lockref.count happens, specifically requesting the full call chain from iput() or iput_final().",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "request_for_clarity"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Where does this decrement of parent->d_lockref.count happens exactly?\nI don't see it immediately in iput(), or iput_final(). Please put the\nfull call chain.",
              "reply_to": "Boris Burkov",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Filipe Manana",
              "summary": "Reviewer noted that the patch is reasonable and looks good, but did not provide any specific technical feedback or suggestions.",
              "sentiment": "POSITIVE",
              "sentiment_signals": [],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Looks reasonable to me.\n\nThanks!",
              "reply_to": "Boris Burkov",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            }
          ]
        }
      ],
      "patches_reviewed": [],
      "patches_acked": [],
      "discussions_posted": [],
      "errors": []
    },
    {
      "name": "Dmitry Ilvokhin",
      "primary_email": "d@ilvokhin.com",
      "patches_submitted": [],
      "patches_reviewed": [],
      "patches_acked": [],
      "discussions_posted": [],
      "errors": []
    },
    {
      "name": "Gregory Price",
      "primary_email": "gourry@gourry.net",
      "patches_submitted": [
        {
          "activity_type": "patch_submitted",
          "subject": "[PATCH] mm: name the anonymous MMOP enum as enum mmop",
          "message_id": "20260211215447.2194189-1-gourry@gourry.net",
          "url": "https://lore.kernel.org/all/20260211215447.2194189-1-gourry@gourry.net/",
          "date": "2026-02-11T21:54:56Z",
          "in_reply_to": null,
          "ack_type": null,
          "is_ongoing": true,
          "submitted_date": "2026-02-11",
          "patch_summary": "This patch renames the anonymous MMOP enum to 'enum mmop' to allow the compiler to catch invalid assignments of values to variables of this type. The existing functions returning int are left unchanged, and the uint8_t buffer in offline_and_remove_memory() is kept as-is for space efficiency. The enum definition is moved before the CONFIG_MEMORY_HOTPLUG guard to ensure it's available for struct memory_block in memory.h. This patch makes no functional changes.",
          "analysis_source": "llm-per-reviewer",
          "review_comments": [
            {
              "author": "Cheatham, Benjamin",
              "summary": "Reviewer noted that the patch was already reviewed and improved upon in another set of patches, but still requested a Reviewed-by tag",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "reviewer appreciated previous review and improvement",
                "request for formal acknowledgement"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I saw this when reviewing another set of yours and thought about mentioning it, glad you cleaned it up!\n\nOne small nit below, otherwise:\nReviewed-by: Ben Cheatham <benjamin.cheatham@amd.com>",
              "reply_to": "Gregory Price",
              "message_date": "2026-02-11",
              "analysis_source": "llm"
            },
            {
              "author": "Cheatham, Benjamin",
              "summary": "Reviewer noted that the comment 'Comment looks unaligned' is not relevant to the patch's technical content and does not provide any specific feedback on the code changes.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "lack of technical feedback"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Comment looks unaligned.\n\nThanks,\nBen",
              "reply_to": "Gregory Price",
              "message_date": "2026-02-11",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Gave Acked-by",
              "sentiment": "POSITIVE",
              "sentiment_signals": [],
              "has_inline_review": false,
              "tags_given": [
                "Acked-by"
              ],
              "raw_body": "",
              "reply_to": "Gregory Price",
              "message_date": "2026-02-12",
              "analysis_source": "heuristic"
            },
            {
              "author": "Dave Jiang",
              "summary": "Gave Reviewed-by",
              "sentiment": "POSITIVE",
              "sentiment_signals": [],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "",
              "reply_to": "Gregory Price",
              "message_date": "2026-02-12",
              "analysis_source": "heuristic"
            },
            {
              "author": "Gregory Price (author)",
              "summary": "Author acknowledges that the enum definition is already unaligned, but suggests it might not be worth reordering in a new version (v2) unless reviewer Andrew prefers it.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "acknowledgment",
                "conditional response"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Ah yeah was already unaligned. Bleh.\n\nProbably not worth a full v2 unless Andrew prefers that.\n\n~Gregory",
              "reply_to": "Cheatham, Benjamin",
              "message_date": "2026-02-12",
              "analysis_source": "llm"
            },
            {
              "author": "Davidlohr Bueso",
              "summary": "Gave Reviewed-by",
              "sentiment": "POSITIVE",
              "sentiment_signals": [],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "",
              "reply_to": "Gregory Price",
              "message_date": "2026-02-12",
              "analysis_source": "heuristic"
            },
            {
              "author": "Jonathan Cameron",
              "summary": "Reviewer Jonathan Cameron noted that the patch does not address the issue of the MMOP enum being anonymous, which can lead to compiler warnings about implicit conversions between enums and integers.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "compiler warning",
                "implicit conversion"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "On Wed, 11 Feb 2026 16:54:47 -0500\nGregory Price <gourry@gourry.net> wrote:",
              "reply_to": "Gregory Price",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Jonathan Cameron",
              "summary": "Reviewer noted that the patch does not contain any functional changes and is a clean-up effort, thus no further review or testing is required.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "no functional change"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Reviewed-by: Jonathan Cameron <jonathan.cameron@huawei.com>\n\nThanks for cleaning this up!\n\nJ",
              "reply_to": "Gregory Price",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            }
          ]
        }
      ],
      "patches_reviewed": [],
      "patches_acked": [],
      "discussions_posted": [],
      "errors": []
    },
    {
      "name": "Jeff Layton",
      "primary_email": "jlayton@kernel.org",
      "patches_submitted": [],
      "patches_reviewed": [],
      "patches_acked": [],
      "discussions_posted": [],
      "errors": []
    },
    {
      "name": "Joanne Koong",
      "primary_email": "joannelkoong@gmail.com",
      "patches_submitted": [
        {
          "activity_type": "patch_submitted",
          "subject": "[PATCH v1 0/1] iomap: don't mark folio uptodate if read IO has bytes pending",
          "message_id": "20260219003911.344478-1-joannelkoong@gmail.com",
          "url": "https://lore.kernel.org/all/20260219003911.344478-1-joannelkoong@gmail.com/",
          "date": "2026-02-19T00:41:04Z",
          "in_reply_to": null,
          "ack_type": null,
          "is_ongoing": false,
          "submitted_date": null,
          "patch_summary": "This patch fixes a bug where a folio is incorrectly marked as uptodate after a read operation has bytes pending. The issue occurs when the read operation completes, but there are still unread bytes in the buffer cache. To fix this, the patch prevents iomap from marking the folio uptodate if there are still bytes pending to be read. This approach addresses a specific scenario where the folio is marked uptodate prematurely, leading to incorrect behavior.",
          "analysis_source": "llm-per-reviewer",
          "review_comments": [
            {
              "author": "Joanne Koong (author)",
              "summary": "The author acknowledged that the read completion path must not mark a folio uptodate if there are bytes pending from an async IO helper, and agreed to modify the code in iomap_set_range_uptodate() to prevent this issue.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "If a folio has ifs metadata attached to it and the folio is partially\nread in through an async IO helper with the rest of it then being read\nin through post-EOF zeroing or as inline data, and the helper\nsuccessfully finishes the read first, then post-EOF zeroing / reading\ninline will mark the folio as uptodate in iomap_set_range_uptodate().\n\nThis is a problem because when the read completion path later calls\niomap_read_end(), it will call folio_end_read(), which sets the uptodate\nbit using XOR semantics. Calling folio_end_read() on a folio that was\nalready marked uptodate clears the uptodate bit.\n\nFix this by not marking the folio as uptodate if the read IO has bytes\npending. The folio uptodate state will be set in the read completion\npath through iomap_end_read() -> folio_end_read().\n\nReported-by: Wei Gao <wegao@suse.com>\nSuggested-by: Sasha Levin <sashal@kernel.org>\nTested-by: Wei Gao <wegao@suse.com>\nSigned-off-by: Joanne Koong <joannelkoong@gmail.com>\nFixes: b2f35ac4146d (\"iomap: add caller-provided callbacks for read and readahead\")\n---\n fs/iomap/buffered-io.c | 15 ++++++++++++---\n 1 file changed, 12 insertions(+), 3 deletions(-)\n\ndiff --git a/fs/iomap/buffered-io.c b/fs/iomap/buffered-io.c\nindex 58887513b894..4fc5ce963feb 100644\n--- a/fs/iomap/buffered-io.c\n+++ b/fs/iomap/buffered-io.c\n@@ -80,18 +80,27 @@ static void iomap_set_range_uptodate(struct folio *folio, size_t off,\n {\n \tstruct iomap_folio_state *ifs = folio->private;\n \tunsigned long flags;\n-\tbool uptodate = true;\n+\tbool mark_uptodate = true;\n \n \tif (folio_test_uptodate(folio))\n \t\treturn;\n \n \tif (ifs) {\n \t\tspin_lock_irqsave(&ifs->state_lock, flags);\n-\t\tuptodate = ifs_set_range_uptodate(folio, ifs, off, len);\n+\t\t/*\n+\t\t * If a read with bytes pending is in progress, we must not call\n+\t\t * folio_mark_uptodate(). The read completion path\n+\t\t * (iomap_read_end()) will call folio_end_read(), which uses XOR\n+\t\t * semantics to set the uptodate bit. If we set it here, the XOR\n+\t\t * in folio_end_read() will clear it, leaving the folio not\n+\t\t * uptodate.\n+\t\t */\n+\t\tmark_uptodate = ifs_set_range_uptodate(folio, ifs, off, len) &&\n+\t\t\t\t!ifs->read_bytes_pending;\n \t\tspin_unlock_irqrestore(&ifs->state_lock, flags);\n \t}\n \n-\tif (uptodate)\n+\tif (mark_uptodate)\n \t\tfolio_mark_uptodate(folio);\n }\n \n-- \n2.47.3",
              "reply_to": "",
              "message_date": "2026-02-18",
              "analysis_source": "llm"
            },
            {
              "author": "Darrick Wong",
              "summary": "Reviewer Darrick Wong suggested adding a link to a relevant discussion on linux-fsdevel mailing list and CC'ing stable@vger.kernel.org for the v6.19 release, indicating that the original patch is now in a released kernel.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "requested additional information",
                "acknowledged the patch's inclusion in a released kernel"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I would add:\n\nLink: https://lore.kernel.org/linux-fsdevel/aYbmy8JdgXwsGaPP@autotest-wegao.qe.prg2.suse.org/\nCc: <stable@vger.kernel.org> # v6.19\n\nsince the recent discussion around this was sort of buried in a\ndifferent thread, and the original patch is now in a released kernel.",
              "reply_to": "Joanne Koong",
              "message_date": "2026-02-18",
              "analysis_source": "llm"
            },
            {
              "author": "Darrick Wong",
              "summary": "Reviewer asked how difficult it would be to write a test for this patch, indicating no technical concerns",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Yeah, that makes sense.  How difficult is this to write up as an fstest?\n\nReviewed-by: \"Darrick J. Wong\" <djwong@kernel.org>\n\n--D",
              "reply_to": "Joanne Koong",
              "message_date": "2026-02-18",
              "analysis_source": "llm"
            },
            {
              "author": "Matthew Wilcox",
              "summary": "Matthew Wilcox expressed frustration that the iomap code has become overly complex, making it difficult for him to understand and explain a simple solution to Joanne Koong.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "frustration",
                "difficulty understanding"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "This isn't \"the xor thing has come back to bite us\".  This is \"the iomap\ncode is now too complicated and I cannot figure out how to explain to\nJoanne that there's really a simple way to do this\".\n\nI'm going to have to set aside my current projects and redo the iomap\nreadahead/read_folio code myself, aren't I?",
              "reply_to": "Darrick Wong",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Darrick Wong",
              "summary": "Reviewer Darrick Wong expressed confusion about an alternative approach mentioned in a previous discussion, and requested clarification on what that simpler way is.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "confusion",
                "lack of clarity"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Well you could try explaining to me what that simpler way is?\n\n/me gets the sense he's missing a discussion somewhere...\n\n--D",
              "reply_to": "Matthew Wilcox",
              "message_date": "2026-02-18",
              "analysis_source": "llm"
            },
            {
              "author": "Joanne Koong (author)",
              "summary": "Author acknowledged that the swapoff path needs to drop the per-vswap spinlock before calling try_to_unmap(), but instead of addressing the specific concern, she provided a link to an unrelated prior discussion.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "lack of direct response",
                "unrelated link"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "This is the link to the prior discussion\nhttps://lore.kernel.org/linux-fsdevel/20251223223018.3295372-1-sashal@kernel.org/T/#mbd61eaa5fd1e8922caa479720232628e39b8c9da\n\nThanks,\nJoanne",
              "reply_to": "Darrick Wong",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Darrick Wong",
              "summary": "Reviewer Darrick Wong noted that the read_bytes_pending field in iomap has inconsistent behavior across different IO paths, and suggested consolidating the read code into a single function to simplify the logic.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes",
                "suggested improvements"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "<willy and I had a chat; this is a clumsy non-AI summary of it>\n\nI started looking at folio read state management in iomap, and made a\nfew observations that (I hope) match what willy's grumpy about.\n\nThere are three ways that iomap can be reading into the pagecache:\na) async ->readahead,\nb) synchronous ->read_folio (page faults), and\nc) synchronous ->read_folio_range (pagecache write).\n\n(Note that (b) can call a different ->read_folio_range than (c), though\nall implementations seem to have the same function)\n\nAll three of these IO paths share the behavior that they try to fill out\nthe folio's contents and set the corresponding folio/ifs uptodate bits\nif that succeeds.  Folio contents can come from anywhere, whether it's:\n\ni) zeroing memory,\nii) copying from an inlinedata buffer, or\niii) asynchronously fetching the contents from somewhere\n\nIn the case of (c) above, if the read fails then we fail the write, and\nif the read succeeds then we start copying to the pagecache.\n\nHowever, (a) and (b) have this additional read_bytes_pending field in\nthe ifs that implements some extra tracking.  AFAICT the purpose of this\nfield is to ensure that we don't call folio_end_read prematurely if\nthere's an async read in progress.  This can happen if iomap_iter\nreturns a negative errno on a partially processed folio, I think?\n\nread_bytes_pending is initialized to the folio_size() at the start of a\nread and subtracted from when parts of the folio are supplied, whether\nthat's synchronous zeroing or asynchronous read ioend completion.  When\nthe field reaches zero, we can then call folio_end_read().\n\nBut then there are twists, like the fact that we only call\niomap_read_init() to set read_bytes_pending if we decide to do an\nasynchronous read.  Or that iomap_read_end and iomap_finish_folio_read\nhave awfully similar code.  I think in the case of (i) and (ii) we also\ndon't touch read_pending_bytes at all, and merely set the uptodate bits?\n\nThis is confusing to me.  It would be more straightforward (I think) if\nwe just did it for all cases instead of adding more conditionals.  IOWs,\nhow hard would it be to consolidate the read code so that there's one\nfunction that iomap calls when it has filled out part of a folio.  Is\nthat possible, even though we shouldn't be calling folio_end_read during\na pagecache write?\n\nAt the end of the day, however, there's a bug in Linus' tree and we need\nto fix it, so Joanne's patch is a sufficient bandaid until we can go\nclean this up.\n\n--D",
              "reply_to": "Matthew Wilcox",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            }
          ]
        }
      ],
      "patches_reviewed": [],
      "patches_acked": [],
      "discussions_posted": [],
      "errors": []
    },
    {
      "name": "Johannes Weiner",
      "primary_email": "hannes@cmpxchg.org",
      "patches_submitted": [],
      "patches_reviewed": [
        {
          "activity_type": "patch_reviewed",
          "subject": "Re: [LSF/MM/BPF TOPIC] Beyond 2MB: Why Terabyte-Scale Machines Need 1GB Transparent Huge Pages",
          "message_id": "aZdDjA16yQYV9csN@cmpxchg.org",
          "url": "https://lore.kernel.org/all/aZdDjA16yQYV9csN@cmpxchg.org/",
          "date": "2026-02-19T17:08:34Z",
          "in_reply_to": null,
          "ack_type": null,
          "is_ongoing": false,
          "submitted_date": null,
          "patch_summary": "",
          "analysis_source": "llm-per-reviewer",
          "review_comments": [
            {
              "author": "David (Arm)",
              "summary": "Reviewer David noted that migrating all memory away from a 1 GiB THP instead of splitting it could be an interesting approach, but this method does not work when remapping the THP to be mapped by PMDs or other cases where it's not desired.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": true,
              "tags_given": [],
              "raw_body": "There once was this proposal where we would, instead of splitting a THP, \nmigrate all memory away instead. That means, instead of splitting the 1 \nGiB THP, you would instead return it to the page allocator where \nsomebody else could use it.\n\nHowever, we cannot easily do the same when remapping a 1 GiB THP to be \nmapped by PMDs etc. I think there are examples where that just doesn't \nwork or is not desired.\n\nBut I considered that in general (avoid folio_split()) an interesting \napproach. The remapping part is a bit different though.\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Usama Arif",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Johannes Weiner",
              "summary": "The reviewer noted that preserving contiguity in TLB coalescing is beneficial and suggested doing this lazily when huge pages are scarce, by scanning deferred split lists for potential migrations.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": true,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "With TLB coalescing, there is benefit in preserving contiguity. If you\nlop off the last 4k of a 2M-backed range, a split still gives you 511\ncontiguously mapped pfns that can be coalesced.\n\nIt would be unfortunate to lose that for pure virtual memory splits,\nwhile there is no demand or no shortage of huge pages. But it might be\npossible to do this lazily, e.g. when somebody has trouble getting a\nlarger page, scan the deferred split lists for candidates to migrate.",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Zi Yan",
              "summary": "Reviewer Zi Yan suggested using non-uniform splitting for folios larger than the PMD size to keep after-split folios as large as possible.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "request for clarification",
                "technical suggestion"
              ],
              "has_inline_review": true,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "With mapping of folios > PMD with PMDs, you can use non uniform split to keep\nafter-split folios as large as possible.",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Zi Yan",
              "summary": "Reviewer Yan suggested a possible solution to avoid splitting the PUD THP by proposing hardware support for multiple TLB entries translating to the same physical frame and translation priority of TLB entries.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "possible solution",
                "no clear objection"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "If HW can support multiple TLB entries translating to the same physical frame\nand allow translation priority of TLB entries, this remapping would be easy\nand we can still keep the 1GB PUD mapping. Basically, we can have 1GB TLB entry\npointing to the 1GB folio and another 4KB TLB entry pointing to the remapped\nregion and overriding the part in the original 1GB vaddr region.\n\nWithout that, SW will need to split the PUD into PMDs and PTEs.\n\n\nBest Regards,\nYan, Zi",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Zi Yan",
              "summary": "Reviewer Zi Yan questioned the relevance of CPU-specific features (PTE coalescing and contig PTE) to the proposed 1GB Transparent Huge Pages, asking about PMD level ARM contiguous bit support",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "questioning",
                "request for clarification"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Which CPU are you referring to? AMD\\u2019s PTE coalescing works up to 32KB\nand ARM\\u2019s contig PTE supports larger sizes. BTW, do we have PMD level\nARM contiguous bit support?",
              "reply_to": "Johannes Weiner",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Zi Yan",
              "summary": "Reviewer noted that the patch's handling of hugetlbfs and PUD THP is not properly synchronized, leading to potential issues with memory accounting and reclaim paths.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "potential synchronization issue",
                "memory accounting"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Best Regards,\nYan, Zi",
              "reply_to": "Johannes Weiner",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Johannes Weiner",
              "summary": "Reviewer noted that any potential coalescing benefits of 1GB THPs would be lost due to the pages being split into discontiguous 4K pagelets, which could lead to performance issues.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "potential performance issue",
                "concern about effectiveness"
              ],
              "has_inline_review": true,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I'm not aware of a CPU that will coalesce the 511 entries into a\nsingle one. But *any* coalescing effects will be lost when the range\nis scattered into discontiguous 4k pagelets.",
              "reply_to": "Zi Yan",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Matthew Wilcox",
              "summary": "Reviewer Matthew Wilcox expressed concern about the feasibility of implementing 1GB transparent huge pages due to potential hardware compatibility issues, citing notes from various CPU vendors that suggest attempting this would lead to significant problems.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Uh, do you know any hardware that supports that?  Every CPU I'm familiar\nwith has notes suggesting that trying to do this will cause you to Have\nA Very Bad Day.",
              "reply_to": "Zi Yan",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Zi Yan",
              "summary": "Reviewer Yan noted that the TLB would need to handle sub-range translations for >PTE TLB hits, which could be resolved by either a per-sub-range bitmap or rewalking each sub-range.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "NEUTRAL"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "No. I was imagining it. :)\n\nBut thinking about it more, that means for every >PTE TLB hit, HW needs to know\nwhether any sub-range has an additional translation. It is easy if all sub-range\ntranslations are present in the TLB. Otherwise, a per sub range bitmap or rewalks\nof each sub range is needed. Never mind, thank you for waking me up in my\ndaydream.\n\nBest Regards,\nYan, Zi",
              "reply_to": "Matthew Wilcox",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Rik Riel",
              "summary": "Reviewer Rik Riel questioned whether the current approach to handling large memory allocations is suitable for future-proofing against 1TB pages, suggesting that a more fundamental rethinking of physical memory handling is needed.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes",
                "suggested new direction"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "While I agree with the idea of starting simple, I think\nwe should ask the question of what we want physical memory\nhandling to look like if 1TB pages become more common,\nand applications start to rely on them to meet their\nperformance goals.\n\nWe have CMA balancing code today. It seems to work, but\nit likely is not the long term direction we want to go,\nmostly due to the way CMA does allocations.\n\nIt seems clear that in order to prevent memory fragmentation,\nwe need to split up system memory in some way between an area\nthat is used only for movable allocations, and an area where\nany kind of allocation can go.\n\nThis would need something similar to CMA balancing to prevent\nfalse OOMs for non-movable allocations.\n\nHowever, beyond that I really do not have any idea of what\nthings should look like.\n\nWhat do we want the kernel to do here?\n\n\n-- \nAll Rights Reversed.",
              "reply_to": "Usama Arif",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David (Arm) suggested that teaching the buddy to manage pages larger than the current maximum buddy order and modifying compaction to compact/group on a larger granularity could be potential solutions for managing large memory, but noted that these would require significant work and potentially introduce new complexities.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "This subtopic is certainly worth a separate session as it's quite \ninvolved, but I assume the right (tm) thing to do will be\n\n(a) Teaching the buddy to manage pages larger than the current maximum\n     buddy order. There will certainly be some work required to get to\n     that point (and Zi Yan already did some work). It might also be\n     fair to say that order > current  buddy order might behave different\n     at least to some degree (thinking about relation to zone alignment,\n     section sizes etc).\n\n     If we require vmemmap for these larger orders, maybe the buddy order\n     could more easily exceed the section size; I don't remember all of\n     the details why that limitation was in place (but one of them was\n     memmap continuity within a high-order buddy page, which is only\n     guaranteed within a memory section with CONFIG_SPARSEMEM).\n\n(b) Teaching compaction etc. to *also* compact/group on a larger\n     granularity (in addition to current sized pageblocks). When we\n     discussed that in the past we used the term superblock, that\n     Zi Yan just brought up again in another thread [1].\n\n\n\nThere was a proposal a while ago to internally separate zones into \nchunks of memory (I think the proposal used DRAM banks, such that you \ncould more easily power down unused DRAM banks). I'm not saying we \nshould do that, but maybe something like sub-zones could be something to \nexplore. Maybe not.\n\nBig, more complex topic :)\n\n\n[1] \nhttps://lore.kernel.org/r/34730030-48F6-4D0C-91EA-998A5AF93F5F@nvidia.com\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Rik Riel",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            }
          ]
        },
        {
          "activity_type": "patch_reviewed",
          "subject": "Re: [LSF/MM/BPF TOPIC] Beyond 2MB: Why Terabyte-Scale Machines Need 1GB Transparent Huge Pages",
          "message_id": "aZc-8dMBz1XCJI3n@cmpxchg.org",
          "url": "https://lore.kernel.org/all/aZc-8dMBz1XCJI3n@cmpxchg.org/",
          "date": "2026-02-19T16:48:58Z",
          "in_reply_to": null,
          "ack_type": null,
          "is_ongoing": false,
          "submitted_date": null,
          "patch_summary": "",
          "analysis_source": "llm-per-reviewer",
          "review_comments": [
            {
              "author": "David (Arm)",
              "summary": "Reviewer noted that migrating all memory away from a 1 GiB THP instead of splitting it could be an interesting approach, but this does not apply to remapping a 1 GiB THP for use by PMDs, which can lead to issues or undesired behavior.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "There once was this proposal where we would, instead of splitting a THP, \nmigrate all memory away instead. That means, instead of splitting the 1 \nGiB THP, you would instead return it to the page allocator where \nsomebody else could use it.\n\nHowever, we cannot easily do the same when remapping a 1 GiB THP to be \nmapped by PMDs etc. I think there are examples where that just doesn't \nwork or is not desired.\n\nBut I considered that in general (avoid folio_split()) an interesting \napproach. The remapping part is a bit different though.\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Usama Arif",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Johannes Weiner",
              "summary": "The reviewer noted that preserving contiguity in TLB coalescing is beneficial and suggested doing this lazily when huge pages are scarce, by scanning deferred split lists for migration candidates.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": true,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "With TLB coalescing, there is benefit in preserving contiguity. If you\nlop off the last 4k of a 2M-backed range, a split still gives you 511\ncontiguously mapped pfns that can be coalesced.\n\nIt would be unfortunate to lose that for pure virtual memory splits,\nwhile there is no demand or no shortage of huge pages. But it might be\npossible to do this lazily, e.g. when somebody has trouble getting a\nlarger page, scan the deferred split lists for candidates to migrate.",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Zi Yan",
              "summary": "Reviewer Zi Yan suggested using non-uniform splitting to keep after-split folios as large as possible when mapping folios larger than PMD size.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "suggestion",
                "technical detail"
              ],
              "has_inline_review": true,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "With mapping of folios > PMD with PMDs, you can use non uniform split to keep\nafter-split folios as large as possible.",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Zi Yan",
              "summary": "Reviewer Yan suggested a possible solution to avoid splitting the PUD THP by proposing hardware support for multiple TLB entries translating to the same physical frame and translation priority of TLB entries, which would allow keeping the 1GB PUD mapping intact.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "suggested a possible solution",
                "did not express strong opinion"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "If HW can support multiple TLB entries translating to the same physical frame\nand allow translation priority of TLB entries, this remapping would be easy\nand we can still keep the 1GB PUD mapping. Basically, we can have 1GB TLB entry\npointing to the 1GB folio and another 4KB TLB entry pointing to the remapped\nregion and overriding the part in the original 1GB vaddr region.\n\nWithout that, SW will need to split the PUD into PMDs and PTEs.\n\n\nBest Regards,\nYan, Zi",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Zi Yan",
              "summary": "Reviewer Zi Yan questioned the CPU-specific assumptions in the patch, specifically asking about AMD's and ARM's PTE coalescing capabilities and whether there is PMD level ARM contiguous bit support.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "questioning",
                "request for clarification"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Which CPU are you referring to? AMD\\u2019s PTE coalescing works up to 32KB\nand ARM\\u2019s contig PTE supports larger sizes. BTW, do we have PMD level\nARM contiguous bit support?",
              "reply_to": "Johannes Weiner",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Zi Yan",
              "summary": "Reviewer noted that the patch does not handle the case where a 1GB huge page is split into smaller pages, which would lead to memory waste and prevent partial reclaim.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "memory accounting",
                "partial reclaim"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Best Regards,\nYan, Zi",
              "reply_to": "Johannes Weiner",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Johannes Weiner",
              "summary": "Reviewer noted that any potential benefits of coalescing 511 entries into a single one would be lost due to the range being scattered into discontiguous 4k pagelets, raising concerns about the effectiveness of this approach.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "concerns",
                "potential issue"
              ],
              "has_inline_review": true,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I'm not aware of a CPU that will coalesce the 511 entries into a\nsingle one. But *any* coalescing effects will be lost when the range\nis scattered into discontiguous 4k pagelets.",
              "reply_to": "Zi Yan",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Matthew Wilcox",
              "summary": "Reviewer Matthew Wilcox expressed concern about the feasibility of implementing 1GB transparent huge pages, citing potential hardware compatibility issues and warning that attempting to do so could lead to significant problems.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Uh, do you know any hardware that supports that?  Every CPU I'm familiar\nwith has notes suggesting that trying to do this will cause you to Have\nA Very Bad Day.",
              "reply_to": "Zi Yan",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Zi Yan",
              "summary": "Reviewer Yan noted that the TLB would need to handle additional translations for sub-ranges of a 1GB page, potentially requiring per-sub-range bitmaps or rewalks of each sub-range",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "raised a new consideration",
                "acknowledged the reviewer's comment with 'thank you'"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "No. I was imagining it. :)\n\nBut thinking about it more, that means for every >PTE TLB hit, HW needs to know\nwhether any sub-range has an additional translation. It is easy if all sub-range\ntranslations are present in the TLB. Otherwise, a per sub range bitmap or rewalks\nof each sub range is needed. Never mind, thank you for waking me up in my\ndaydream.\n\nBest Regards,\nYan, Zi",
              "reply_to": "Matthew Wilcox",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Rik Riel",
              "summary": "Reviewer Rik Riel questioned whether the current approach to handling large memory allocations is sustainable and suggested exploring a new direction for physical memory handling, specifically considering the implications of 1TB pages on performance goals and memory fragmentation.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes",
                "suggested exploration"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "While I agree with the idea of starting simple, I think\nwe should ask the question of what we want physical memory\nhandling to look like if 1TB pages become more common,\nand applications start to rely on them to meet their\nperformance goals.\n\nWe have CMA balancing code today. It seems to work, but\nit likely is not the long term direction we want to go,\nmostly due to the way CMA does allocations.\n\nIt seems clear that in order to prevent memory fragmentation,\nwe need to split up system memory in some way between an area\nthat is used only for movable allocations, and an area where\nany kind of allocation can go.\n\nThis would need something similar to CMA balancing to prevent\nfalse OOMs for non-movable allocations.\n\nHowever, beyond that I really do not have any idea of what\nthings should look like.\n\nWhat do we want the kernel to do here?\n\n\n-- \nAll Rights Reversed.",
              "reply_to": "Usama Arif",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "The reviewer suggests that teaching the buddy to manage pages larger than the current maximum buddy order and modifying compaction to compact/group on a larger granularity are necessary steps for implementing 1GB transparent huge pages.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes",
                "necessary work required"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "This subtopic is certainly worth a separate session as it's quite \ninvolved, but I assume the right (tm) thing to do will be\n\n(a) Teaching the buddy to manage pages larger than the current maximum\n     buddy order. There will certainly be some work required to get to\n     that point (and Zi Yan already did some work). It might also be\n     fair to say that order > current  buddy order might behave different\n     at least to some degree (thinking about relation to zone alignment,\n     section sizes etc).\n\n     If we require vmemmap for these larger orders, maybe the buddy order\n     could more easily exceed the section size; I don't remember all of\n     the details why that limitation was in place (but one of them was\n     memmap continuity within a high-order buddy page, which is only\n     guaranteed within a memory section with CONFIG_SPARSEMEM).\n\n(b) Teaching compaction etc. to *also* compact/group on a larger\n     granularity (in addition to current sized pageblocks). When we\n     discussed that in the past we used the term superblock, that\n     Zi Yan just brought up again in another thread [1].\n\n\n\nThere was a proposal a while ago to internally separate zones into \nchunks of memory (I think the proposal used DRAM banks, such that you \ncould more easily power down unused DRAM banks). I'm not saying we \nshould do that, but maybe something like sub-zones could be something to \nexplore. Maybe not.\n\nBig, more complex topic :)\n\n\n[1] \nhttps://lore.kernel.org/r/34730030-48F6-4D0C-91EA-998A5AF93F5F@nvidia.com\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Rik Riel",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            }
          ]
        }
      ],
      "patches_acked": [],
      "discussions_posted": [],
      "errors": []
    },
    {
      "name": "Joshua Hahn",
      "primary_email": "joshua.hahnjy@gmail.com",
      "patches_submitted": [],
      "patches_reviewed": [],
      "patches_acked": [],
      "discussions_posted": [],
      "errors": []
    },
    {
      "name": "JP Kobryn",
      "primary_email": "inwardvessel@gmail.com",
      "patches_submitted": [
        {
          "activity_type": "patch_submitted",
          "subject": "[PATCH v5] mm: move pgscan, pgsteal, pgrefill to node stats",
          "message_id": "20260219235846.161910-1-jp.kobryn@linux.dev",
          "url": "https://lore.kernel.org/all/20260219235846.161910-1-jp.kobryn@linux.dev/",
          "date": "2026-02-19T23:59:27Z",
          "in_reply_to": null,
          "ack_type": null,
          "is_ongoing": false,
          "submitted_date": null,
          "patch_summary": "This patch moves the pgscan, pgsteal, and pgrefill counters from vm_event_item to node_stat_item to provide per-node reclaim visibility. This allows for easier identification of nodes under pressure due to NUMA imbalance scenarios. The counters are now displayed in /proc/zoneinfo's per-node section, while still being aggregated across all nodes in /proc/vmstat. Memcg accounting is preserved, and the virtio_balloon driver has been updated to use global_node_page_state() to fetch the counters.",
          "analysis_source": "llm-per-reviewer",
          "review_comments": [
            {
              "author": "Zi Yan",
              "summary": "Reviewer Zi Yan pointed out that the patch does not handle the case where a node is being drained and its pgscan counter is being updated concurrently by multiple CPUs, which could lead to incorrect statistics.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "concurrency issue",
                "potential for incorrect statistics"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Acked-by"
              ],
              "raw_body": "Acked-by: Zi Yan <ziy@nvidia.com>\n\nBest Regards,\nYan, Zi",
              "reply_to": "JP (Meta)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Johannes Weiner",
              "summary": "Gave Acked-by",
              "sentiment": "POSITIVE",
              "sentiment_signals": [],
              "has_inline_review": false,
              "tags_given": [
                "Acked-by"
              ],
              "raw_body": "",
              "reply_to": "JP (Meta)",
              "message_date": "2026-02-20",
              "analysis_source": "heuristic"
            },
            {
              "author": "Shakeel Butt",
              "summary": "Gave Acked-by",
              "sentiment": "POSITIVE",
              "sentiment_signals": [],
              "has_inline_review": false,
              "tags_given": [
                "Acked-by"
              ],
              "raw_body": "",
              "reply_to": "JP (Meta)",
              "message_date": "2026-02-20",
              "analysis_source": "heuristic"
            }
          ]
        },
        {
          "activity_type": "patch_submitted",
          "subject": "[PATCH v3] mm: move pgscan, pgsteal, pgrefill to node stats",
          "message_id": "20260218222652.108411-1-jp.kobryn@linux.dev",
          "url": "https://lore.kernel.org/all/20260218222652.108411-1-jp.kobryn@linux.dev/",
          "date": "2026-02-18T22:27:32Z",
          "in_reply_to": null,
          "ack_type": null,
          "is_ongoing": true,
          "submitted_date": "2026-02-18",
          "patch_summary": "This patch moves three memory reclaim counters (pgscan, pgsteal, and pgrefill) from the global vm_event_item to node_stat_item, allowing for per-node visibility of these metrics in /proc/zoneinfo. The counters are still aggregated across all nodes in /proc/vmstat, but their ordering changes. Memcg accounting is preserved, and the virtio_balloon driver is updated to use the new node-based counters.",
          "analysis_source": "llm-per-reviewer",
          "review_comments": [
            {
              "author": "Vlastimil (SUSE)",
              "summary": "Gave Reviewed-by",
              "sentiment": "POSITIVE",
              "sentiment_signals": [],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "",
              "reply_to": "JP (Meta)",
              "message_date": "2026-02-19",
              "analysis_source": "heuristic"
            }
          ]
        }
      ],
      "patches_reviewed": [],
      "patches_acked": [],
      "discussions_posted": [],
      "errors": []
    },
    {
      "name": "Kiryl Shutsemau",
      "primary_email": "kas@kernel.org",
      "patches_submitted": [
        {
          "activity_type": "patch_submitted",
          "subject": "[PATCHv2 0/2] efi: Fix alignenment issues in unaccepted memory code",
          "message_id": "20260217104957.249340-1-kas@kernel.org",
          "url": "https://lore.kernel.org/all/20260217104957.249340-1-kas@kernel.org/",
          "date": "2026-02-17T10:50:15Z",
          "in_reply_to": null,
          "ack_type": null,
          "is_ongoing": true,
          "submitted_date": "2026-02-17",
          "patch_summary": "This patch series addresses two issues related to unaligned physical addresses and sizes in EFI unaccepted memory handling, which can cause kernel panics in Intel TDX environments. The patches fix the reservation of the unaccepted memory table itself and ensure that memory acceptance requests are page-aligned before performing unit_size alignment checks, preventing crashes due to missing 'guard page' extensions.",
          "analysis_source": "llm-per-reviewer",
          "review_comments": [
            {
              "author": "Kiryl (Meta) (author)",
              "summary": "The author addressed a concern about the reserve_unaccepted() function incorrectly calculating the size of the memblock reservation for the unaccepted memory table, acknowledged that this can lead to kernel panics in accept_memory(), and agreed to fix it by recalculating the end address first (including the unaligned start) and then aligning it up.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "acknowledged a bug",
                "agreed to fix"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "The reserve_unaccepted() function incorrectly calculates the size of the\nmemblock reservation for the unaccepted memory table. It aligns the\nsize of the table, but fails to account for cases where the table's\nstarting physical address (efi.unaccepted) is not page-aligned.\n\nIf the table starts at an offset within a page and its end crosses into\na subsequent page that the aligned size does not cover, the end of the\ntable will not be reserved. This can lead to the table being overwritten\nor inaccessible, causing a kernel panic in accept_memory().\n\nThis issue was observed when starting Intel TDX VMs with specific memory\nsizes (e.g., > 64GB).\n\nFix this by calculating the end address first (including the unaligned\nstart) and then aligning it up, ensuring the entire range is covered\nby the reservation.\n\nFixes: 8dbe33956d96 (\"efi/unaccepted: Make sure unaccepted table is mapped\")\nReported-by: Moritz Sanft <ms@edgeless.systems>\nSigned-off-by: Kiryl Shutsemau (Meta) <kas@kernel.org>\n---\n drivers/firmware/efi/efi.c | 8 ++++----\n 1 file changed, 4 insertions(+), 4 deletions(-)\n\ndiff --git a/drivers/firmware/efi/efi.c b/drivers/firmware/efi/efi.c\nindex 111e87a618e5..56e9d73412fa 100644\n--- a/drivers/firmware/efi/efi.c\n+++ b/drivers/firmware/efi/efi.c\n@@ -692,13 +692,13 @@ static __init int match_config_table(const efi_guid_t *guid,\n \n static __init void reserve_unaccepted(struct efi_unaccepted_memory *unaccepted)\n {\n-\tphys_addr_t start, size;\n+\tphys_addr_t start, end;\n \n \tstart = PAGE_ALIGN_DOWN(efi.unaccepted);\n-\tsize = PAGE_ALIGN(sizeof(*unaccepted) + unaccepted->size);\n+\tend = PAGE_ALIGN(efi.unaccepted + sizeof(*unaccepted) + unaccepted->size);\n \n-\tmemblock_add(start, size);\n-\tmemblock_reserve(start, size);\n+\tmemblock_add(start, end - start);\n+\tmemblock_reserve(start, end - start);\n }\n \n int __init efi_config_parse_tables(const efi_config_table_t *config_tables,\n-- \n2.51.2",
              "reply_to": "",
              "message_date": "2026-02-17",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl (Meta) (author)",
              "summary": "The author addressed a concern about the alignment check in accept_memory() and range_contains_unaccepted_memory() functions, explaining that if the caller passes a non-page-aligned range, the 'end' of the range might not be numerically aligned to unit_size. The author proposed aligning the start address down and the size up to the nearest page boundary before performing the unit_size alignment check.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "clarification",
                "explanation"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "The accept_memory() and range_contains_unaccepted_memory() functions\nemploy a \"guard page\" logic to prevent crashes with load_unaligned_zeropad().\nThis logic extends the range to be accepted (or checked) by one unit_size\nif the end of the range is aligned to a unit_size boundary.\n\nHowever, if the caller passes a range that is not page-aligned, the\n'end' of the range might not be numerically aligned to unit_size, even\nif it covers the last page of a unit. This causes the \"if (!(end % unit_size))\"\ncheck to fail, skipping the necessary extension and leaving the next\nunit unaccepted, which can lead to a kernel panic when accessed by\nload_unaligned_zeropad().\n\nAlign the start address down and the size up to the nearest page\nboundary before performing the unit_size alignment check. This ensures\nthat the guard unit is correctly added when the range effectively ends\non a unit boundary.\n\nSigned-off-by: Kiryl Shutsemau (Meta) <kas@kernel.org>\n---\n drivers/firmware/efi/unaccepted_memory.c | 10 ++++++++--\n 1 file changed, 8 insertions(+), 2 deletions(-)\n\ndiff --git a/drivers/firmware/efi/unaccepted_memory.c b/drivers/firmware/efi/unaccepted_memory.c\nindex c2c067eff634..4a8ec8d6a571 100644\n--- a/drivers/firmware/efi/unaccepted_memory.c\n+++ b/drivers/firmware/efi/unaccepted_memory.c\n@@ -35,14 +35,17 @@ void accept_memory(phys_addr_t start, unsigned long size)\n \tstruct efi_unaccepted_memory *unaccepted;\n \tunsigned long range_start, range_end;\n \tstruct accept_range range, *entry;\n-\tphys_addr_t end = start + size;\n \tunsigned long flags;\n+\tphys_addr_t end;\n \tu64 unit_size;\n \n \tunaccepted = efi_get_unaccepted_table();\n \tif (!unaccepted)\n \t\treturn;\n \n+\tend = PAGE_ALIGN(start + size);\n+\tstart = PAGE_ALIGN_DOWN(start);\n+\n \tunit_size = unaccepted->unit_size;\n \n \t/*\n@@ -160,15 +163,18 @@ void accept_memory(phys_addr_t start, unsigned long size)\n bool range_contains_unaccepted_memory(phys_addr_t start, unsigned long size)\n {\n \tstruct efi_unaccepted_memory *unaccepted;\n-\tphys_addr_t end = start + size;\n \tunsigned long flags;\n \tbool ret = false;\n+\tphys_addr_t end;\n \tu64 unit_size;\n \n \tunaccepted = efi_get_unaccepted_table();\n \tif (!unaccepted)\n \t\treturn false;\n \n+\tend = PAGE_ALIGN(start + size);\n+\tstart = PAGE_ALIGN_DOWN(start);\n+\n \tunit_size = unaccepted->unit_size;\n \n \t/*\n-- \n2.51.2",
              "reply_to": "",
              "message_date": "2026-02-17",
              "analysis_source": "llm"
            },
            {
              "author": "Mike Rapoport",
              "summary": "Gave Acked-by",
              "sentiment": "POSITIVE",
              "sentiment_signals": [],
              "has_inline_review": false,
              "tags_given": [
                "Acked-by"
              ],
              "raw_body": "",
              "reply_to": "Kiryl (Meta)",
              "message_date": "2026-02-17",
              "analysis_source": "heuristic"
            },
            {
              "author": "Tom Lendacky",
              "summary": "Gave Reviewed-by",
              "sentiment": "POSITIVE",
              "sentiment_signals": [],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "",
              "reply_to": "Kiryl (Meta)",
              "message_date": "2026-02-17",
              "analysis_source": "heuristic"
            }
          ]
        }
      ],
      "patches_reviewed": [
        {
          "activity_type": "patch_reviewed",
          "subject": "Re: [LSF/MM/BPF TOPIC] 64k (or 16k) base page size on x86",
          "message_id": "aZeJP-GhoqeTtjRe@thinkstation",
          "url": "https://lore.kernel.org/all/aZeJP-GhoqeTtjRe@thinkstation/",
          "date": "2026-02-19T22:14:27Z",
          "in_reply_to": null,
          "ack_type": null,
          "is_ongoing": false,
          "submitted_date": null,
          "patch_summary": "",
          "analysis_source": "llm-per-reviewer",
          "review_comments": [
            {
              "author": "Pedro Falcato",
              "summary": "Reviewer Pedro Falcato questioned the relevance of the patch's idea, given the existence of mTHP (multi-THP) which can be toggled via a sysfs entry to achieve similar benefits.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Doesn't this idea make less sense these days, with mTHP? Simply by toggling one\nof the entries in /sys/kernel/mm/transparent_hugepage.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Pedro Falcato",
              "summary": "Reviewer Pedro Falcato suggested adding a global minimum page cache order to address scalability concerns, noting that some points are not addressed by existing work (1G THPs) and others are being addressed separately (memdesc work).",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "We could perhaps add a way to enforce a min_order globally on the page cache,\nas a way to address it.\n\nThere are some points there which aren't addressed by mTHP work in any way\n(1G THPs for one), others which are being addressed separately (memdesc work\ntrying to cut down on struct page overhead).\n\n(I also don't understand your point about order-5 allocation, AFAIK pcp will\ncache up to COSTLY_ORDER (3) and PMD order, but I'm probably not seeing the\nfull picture)\n\n\n-- \nPedro",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer suggested emulating a larger page size (64k) for user space while still using 4k pages in the OS, reducing zone lock contention and other issues.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "When discussing per-process page sizes with Ryan and Dev, I mentioned \nthat having a larger emulated page size could be interesting for other \narchitectures as well.\n\nThat is, we would emulate a 64K page size on Intel for user space as \nwell, but let the OS work with 4K pages.\n\nWe'd only allocate+map large folios into user space + pagecache, but \nstill allow for page tables etc. to not waste memory.\n\nSo \"most\" of your allocations in the system would actually be at least \n64k, reducing zone lock contention etc.\n\n\nIt doesn't solve all the problems you wanted to tackle on your list \n(e.g., \"struct page\" overhead, which will be sorted out by memdescs).\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "The author addressed a concern that the mTHP (madvise transparent huge pages) implementation is not guaranteed to provide 64k pages, and clarified that it's still best effort, meaning users don't need to worry about fragmentation.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "clarification",
                "no clear resolution"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "mTHP is still best effort. This is way you don't need to care about\nfragmentation, you will get your 64k page as long as you have free\nmemory.",
              "reply_to": "Pedro Falcato",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "The author addressed Pedro's concern that the page allocator would need to do more work to merge/split buddy pages, explaining that it is actually cheaper for higher base page sizes.",
              "sentiment": "POSITIVE",
              "sentiment_signals": [
                "acknowledged a specific technical point",
                "provided an explanation"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "With higher base page size, page allocator doesn't need to do as much\nwork to merge/split buddy pages. So serving the same 2M as order-5 is\ncheaper than order-9.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "Pedro Falcato",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David noted that the proposed change would lead to reduced page table merging and splitting due to larger allocation sizes, which is expected to result in improved performance.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "no clear signal"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I think the idea is that if most of your allocations (anon + pagecache) \nare 64k instead of 4k, on average, you'll just naturally do less merging \nsplitting.\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "The author is addressing David's concern that emulation of 64k pages would help reduce zone lock contention, but instead expects contention to increase due to mixing 4k and 64k requests.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "neutral explanation",
                "no clear resolution"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I am not convinced emulation would help zone lock contention. I expect\ncontention to be higher if page allocator would see a mix of 4k and 64k\nrequests. It sounds like constant split/merge under the lock.",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author acknowledged that the current implementation of serving 1G pages from the buddy allocator is not viable, and expressed uncertainty about how to achieve a viable 1G THPs without it.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "uncertainty",
                "acknowledgment of limitation"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I don't think we can serve 1G pages out of buddy allocator with 4k\norder-0. And without it, I don't see how to get to a viable 1G THPs.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David (Arm) noted that if most allocations are larger than 64k, the benefits of splitting PAGE_SIZE into PTE_SIZE and PG_SIZE may be diminished, as there would be less need for splitting/merging smaller allocations.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "If most your allocations are larger, then there isn't that much \nsplitting/merging.\n\nThere will be some for the < 64k allocations of course, but when all \nuser space+page cache is >= 64 then the split/merge + zone lock should \nbe heavily reduced.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David expressed skepticism about the proposed changes, suggesting that previous work by Zi Yan could be leveraged to address the issue of larger page sizes on x86.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "suggested alternative approach",
                "implied lack of confidence in current patch"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Zi Yan was one working on this, and I think we had ideas on how to make \nthat work in the long run.\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Dave Hansen",
              "summary": "Reviewer Dave Hansen questioned the memory savings of splitting PAGE_SIZE into PTE_SIZE and PG_SIZE, citing a kernel tree analysis that showed a 64k page cache would consume ~5GB of extra memory, suggesting that the benefits may not outweigh the costs.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes",
                "questioned assumptions"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "First of all, this looks like fun. Nice work! I'm not opposed at all in\nconcept to cleaning up things and doing the logical separation you\ndescribed to split buddy granularity and mapping granularity. That seems\nlike a worthy endeavor and some of the union/#define tricks look like a\nlikely viable way to do it incrementally.\n\nBut I don't think there's going to be a lot of memory savings in the\nend. Maybe this would bring the mem= hyperscalers back into the fold and\nhave them actually start using 'struct page' again for their VM memory.\nDunno.\n\nBut, let's look at my kernel directory and round the file sizes up to\n4k, 16k and 64k:\n\nfind .  -printf '%s\\n' | while read size; do echo\t\\\n\t\t$(((size + 0x0fff) & 0xfffff000))\t\\\n\t\t$(((size + 0x3fff) & 0xffffc000))\t\\\n\t\t$(((size + 0xffff) & 0xffff0000));\ndone\n\n... and add them all up:\n\n11,297,648 KB - on disk\n11,297,712 KB - in a 4k page cache\n12,223,488 KB - in a 16k page cache\n16,623,296 KB - in a 64k page cache\n\nSo a 64k page cache eats ~5GB of extra memory for a kernel tree (well,\n_my_ kernel tree). In other words, if you are looking for memory savings\non my laptop, you'll need ~300GB of RAM before 'struct page' overhead\noverwhelms the page cache bloat from a single kernel tree.\n\nThe whole kernel obviously isn't in the page cache all at the same time.\nThe page cache across the system is also obviously different than a\nkernel tree, but you get the point.\n\nThat's not to diminish how useful something like this might be,\nespecially for folks that are sensitive to 'struct page' overhead or\nallocator performance.\n\nBut, it will mostly be getting better performance at the _cost_ of\nconsuming more RAM, not saving RAM.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author asks for clarification on whether the proposed page size change should enforce alignment of user-space mappings.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "clarifying question"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Just to clarify, do you want it to be enforced on userspace ABI.\nLike, all mappings are 64k aligned?",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "The author acknowledges that memory waste due to page table overhead is a solvable issue, suggesting that switching to slab allocation can address it.",
              "sentiment": "POSITIVE",
              "sentiment_signals": [
                "acknowledged fix needed",
                "proposed solution"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Waste of memory for page table is solvable and pretty straight forward.\nMost of such cases can be solve mechanically by switching to slab.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Dave Hansen",
              "summary": "Reviewer Dave Hansen pointed out that the patch does not address the complexity of handling page faults into file mappings when PTE_SIZE is larger than PG_SIZE, and requested a solution to this problem.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "complexity",
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "On 2/19/26 07:08, Kiryl Shutsemau wrote:\n...",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Dave Hansen",
              "summary": "Reviewer noted that the patch introduces a significant number of changes across multiple files, primarily due to renaming and refactoring efforts, but did not raise any specific technical concerns or objections.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "no specific technical issues raised"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "A few notes about the diffstats:\n\n$ git diff v6.17..HEAD arch/x86 | diffstat | tail -1\n 105 files changed, 874 insertions(+), 843 deletions(-)\n$ git diff v6.17..HEAD mm | diffstat | tail -1\n 53 files changed, 1136 insertions(+), 1069 deletions(-)\n\nThe vast, vast majority of this seems to be the renames. Stuff like:",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Dave Hansen",
              "summary": "Reviewer Dave Hansen noted that the patch requires auditing for logic changes and requested a clear separation between mechanical and logical updates.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested_changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "That stuff obviously needs to be audited but it's far less concerning\nthan the logic changes.\n\nSo just for review sanity, if you go forward with this, I'd very much\nappreciate a strong separation of the purely mechanical bits from any\nlogic changes.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Dave Hansen",
              "summary": "Reviewer Dave Hansen noted that the patch's changes to separate page size for virtual address space mapping (PTE_SIZE) and order-0 buddy allocation (PG_SIZE) are contingent on a full tree conversion to ptdescs, which is a prerequisite for this change.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Others mentioned this, but I think this essentially gates what you are\ndoing behind a full tree conversion over to ptdescs.\n\nThe most useful thing we can do with this series is look at it and\ndecide what _other_ things need to get done before the tree could\npossibly go in that direction, like ptdesc or a the disambiguation\nbetween PTE_SIZE and PG_SIZE that you've kicked off here.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Matthew Wilcox",
              "summary": "Reviewer Matthew Wilcox suggested an alternative approach to allocating larger page sizes by using a single allocation of the larger size and then splitting it into multiple smaller entries, expressing skepticism about the slab approach.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "skepticism",
                "alternative suggestion"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Have you looked at the s390/ppc implementations (yes, they're different,\nno, that sucks)?  slab seems like the wrong approach to me.\n\nThere's a third approach that I've never looked at which is to allocate\nthe larger size, then just use it for N consecutive entries.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Pedro Falcato",
              "summary": "The reviewer notes that the proposed patch, if combined with slab_min_order changes, could lead to a system where 90%+ of allocations are 64k, and suggests this as a potential outcome.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "no clear opinion or request"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Yep. That plus slab_min_order would hopefully yield a system where 90%+\n(depending on how your filesystem's buffer cache works) allocations are 64K.\n\n-- \nPedro",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author acknowledges that struct page memory consumption is a problem, but notes that it's static and cannot be reclaimed, whereas page cache rounding overhead can be controlled by userspace",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "acknowledges the issue",
                "provides explanation"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "That's fair.\n\nThe problem with struct page memory consumption is that it is static and\ncannot be reclaimed. You pay the struct page tax no matter what.\n\nPage cache rounding overhead can be large, but a motivated userspace can\nkeep it under control by avoiding splitting a dataset into many small\nfiles. And this memory is reclaimable.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "Dave Hansen",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author acknowledged a concern about packing of page tables and decided to simplify the proof-of-concept (PoC) by wasting full order-0 pages instead, indicating no immediate plan to address this issue.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "acknowledged a concern",
                "decided to simplify"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I have not followed ptdescs closely. Need to catch up.\n\nFor PoC, I will just waste full order-0 page for page table. Packing is\nnot required for correctness.",
              "reply_to": "Dave Hansen",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Dave Hansen",
              "summary": "Reviewer noted that the proposed change to use a larger page size would not cause issues with the KPTI pgd because its allocation size is smaller than the new page size, making it 'weird but functional'.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "NEUTRAL"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Yeah, I guess padding it out is ugly but effective.\n\nI was trying to figure out how it would apply to the KPTI pgd because we\njust flip bit 12 to switch between user and kernel PGDs. But I guess the\n8k of PGDs in the current allocation will fit fine in 128k, so it's\nweird but functional.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author acknowledges a concern about performance and scalability, but hasn't put much time into addressing it yet",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "acknowledges a problem",
                "haven't addressed it"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I was the first thing that came to mind. I have not put much time into\nit",
              "reply_to": "Matthew Wilcox",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author responded to a concern about fragmentation in page tables, explaining that it's not an issue since the parent page table only needs to be populated with 16 entries.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "clarification",
                "explanation"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Yeah, that's a possible way. We would need to populate 16 page table\nentries of the parent page table. But you don't need to care about\nfragmentation within the page.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "Matthew Wilcox",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kalesh Singh",
              "summary": "Reviewer Kalesh Singh pointed out that the patch does not handle page faults into file mappings correctly when PTE_SIZE is larger than PG_SIZE, as it assumes the page cache always has a valid mapping for the entire page.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "On Thu, Feb 19, 2026 at 7:39AM David Hildenbrand (Arm)\n<david@kernel.org> wrote:",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kalesh Singh",
              "summary": "Reviewer Kalesh Singh noted that the current design does not enforce a larger granularity on VMAs to emulate a userspace page size, which is necessary for Android's compatibility testing of apps for 16KB devices, and requested discussion on extending the design to cover this use case.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Hi Kiryl,\n\nI'd be interested to discuss this at LSFMM.\n\nOn Android, we have a separate but related use case: we emulate the\nuserspace page size on x86, primarily to enable app developers to\nconduct compatibility testing of their apps for 16KB Android devices.\n[1]\n\nIt mainly works by enforcing a larger granularity on the VMAs to\nemulate a userspace page size, somewhat similar to what David\nmentioned, while the underlying kernel still operates on a 4KB\ngranularity. [2]\n\nIIUC the current design would not enfore the larger granularity /\nalignment for VMAs to avoid breaking ABI. However, I'd be interest to\ndiscuss whether it can be extended to cover this usecase as well.\n\n[1]  https://developer.android.com/guide/practices/page-sizes#16kb-emulator\n[2] https://source.android.com/docs/core/architecture/16kb-page-size/getting-started-cf-x86-64-pgagnostic\n\nThanks,\nKalesh",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Zi Yan",
              "summary": "Reviewer suggested adding a super pageblock that consists of N consecutive pageblocks, allowing anti-fragmentation to work at larger granularity (e.g., 1GB) and creating free pages.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "debatable"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Right. The idea is to add super pageblock (or whatever name), which consists of N consecutive\npageblocks, so that anti fragmentation can work at larger granularity, e.g., 1GB, to create\nfree pages. Whether 1GB free pages from memory compaction need to go into buddy allocator\nor not is debatable.\n\n--\nBest Regards,\nYan, Zi",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Liam Howlett",
              "summary": "Reviewer Liam Howlett noted that increasing page size may not be beneficial for systems under memory pressure, as it can lead to increased CPU usage and degradation of primary workloads, and suggested that the solution is only useful for systems with a lot of memory.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "But we are in reclaim a lot more these days.  As I'm sure you are aware,\nwe are trying to maximize the resources (both cpu and ram) of any\nmachine powered on.  Entering reclaim will consume the cpu time and will\naffect other tasks.\n\nEspecially with multiple workload machines, the tendency is to have a\nprimary focus with the lower desired work being killed, if necessary.\nReducing the overhead just means more secondary tasks, or a bigger\nfootprint of the ones already executing.\n\nIncreasing the memory pressure will degrade the primary workload more\nfrequently, even if we recover enough to avoid OOMing the secondary.\n\nWhile in the struct page tax world, the secondary task would be killed\nafter a shorter (and less frequently executed) reclaim comes up short.\nSo, I would think that we would be degrading the primary workload in an\nattempt to keep the secondary alive?  Maybe I'm over-simplifying here?\n\nNear the other end of the spectrum, we have chromebooks that are\nconstantly in reclaim, even with 4k pages.  I guess these machines would\nbe destine to maintain the same page size they use today.  That is, this\nsolution for the struct page tax is only useful if you have a lot of\nmemory.  But then again, that's where the bookkeeping costs become hard\nto take.\n\nThanks,\nLiam",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "David Laight",
              "summary": "Reviewer David Laight noted that the patch's approach to separating PAGE_SIZE into PTE_SIZE and PG_SIZE may not be suitable for architectures other than x86, as it relies on specific properties of the x86 page table structure.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "architecture-specific concerns"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "On Thu, 19 Feb 2026 15:08:51 +0000\nKiryl Shutsemau <kas@kernel.org> wrote:",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David Laight",
              "summary": "Reviewer questioned the impact on 'random' buffers, mmap of kernel memory, and PCIe window alignment",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "requested clarification",
                "raised questions"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Also the 'random' buffers that are PAGE_SIZE rather than 4k.\n\nI also wonder how is affects mmap of kernel memory and the alignement\nof PCIe windows (etc).\n\n\tDavid",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer noted that allowing 64k page size for emulated processes would enable running such processes alongside 4k processes on the same machine, eliminating the need for 'vma crosses base pages' handling.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Right, see the proposal from Dev on the list.\n\n From user-space POV, the pagesize would be 64K for these emulated \nprocesses. That is, VMAs must be suitable aligned etc.\n\nOne key thing I think is that you could run such emulated-64k process \n(that actually support it!) with 4k processes on the same machine, like \nArm is considering.\n\nYou would have no weird \"vma crosses base pages\" handling, which is just \nrather nasty and makes my head hurt.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David (Arm) expressed concerns that the proposed patch would reintroduce memory waste issues on x86, similar to those experienced by Arm users when they switched from 64k to 4k page sizes. He noted that achieving native 64k performance is hard and suggested exploring per-process page sizes instead.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Well, yes, like Willy says, there are already similar custom solutions \nfor s390x and ppc.\n\nPasha talked recently about the memory waste of 16k kernel stacks and \nhow we would want to reduce that to 4k. In your proposal, it would be \n64k, unless you somehow manage to allocate multiple kernel stacks from \nthe same 64k page. My head hurts thinking about whether that could work, \nmaybe it could (no idea about guard pages in there, though).\n\n\nLet's take a look at the history of page size usage on Arm (people can \nfeel free to correct me):\n\n(1) Most distros were using 64k on Arm.\n\n(2) People realized that 64k was suboptimal many use cases (memory\n     waste for stacks, pagecache, etc) and started to switch to 4k. I\n     remember that mostly HPC-centric users sticked to 64k, but there was\n     also demand from others to be able to stay on 64k.\n\n(3) Arm improved performance on a 4k kernel by adding cont-pte support,\n     trying to get closer to 64k native performance.\n\n(4) Achieving 64k native performance is hard, which is why per-process\n     page sizes are being explored to get the best out of both worlds\n     (use 64k page size only where it really matters for performance).\n\nArm clearly has the added benefit of actually benefiting from hardware \nsupport for 64k.\n\nIIUC, what you are proposing feels a bit like traveling back in time \nwhen it comes to the memory waste problem that Arm users encountered.\n\nWhere do you see the big difference to 64k on Arm in your proposal? \nWould you currently also be running 64k Arm in production and the memory \nwaste etc is acceptable?\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "The author acknowledges that increasing the base page size to 64k or 16k would limit the patch's adoption due to existing legacy code on x86, but does not indicate a plan for addressing this issue.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "acknowledges limitation",
                "no fix planned"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Well, it will drastically limit the adoption. We have too much legacy\nstuff on x86.",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author responded to a concern about kernel stack allocation and suggested that slab-allocated stacks could work for large base page sizes, but did not address the specific issue of alignment.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "clarifying question",
                "explaining reasoning"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Kernel stack is allocated from vmalloc. I think mapping them with\nsub-page granularity should be doable.\n\nBTW, do you see any reason why slab-allocated stack wouldn't work for\nlarge base page sizes? There's no requirement for it be aligned to page\nor PTE, right?",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author responded to reviewer's concern about the similarity between 64k page size on x86 and existing 64k Arm architecture, stating that he wants to bring this option to x86 for machines with over 2TiB of RAM, citing scalability benefits.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "acknowledging reviewer's point",
                "explaining his goals"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "That's the point. I don't see a big difference to 64k Arm. I want to\nbring this option to x86: at some machine size it makes sense trade\nmemory consumption for scalability. I am targeting it to machines with\nover 2TiB of RAM.\n\nBTW, we do run 64k Arm in our fleet. There's some growing pains, but it\nlooks good in general We have no plans to switch to 4k (or 16k) at the\nmoment. 512M THPs also look good on some workloads.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author acknowledges the need for ABI preservation and proposes adding a knob or personality(2) flag to enforce a preferred virtual address space granularity, indicating no immediate fix but a potential solution.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "acknowledges need for ABI preservation",
                "proposes potential solution"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I don't want to break ABI, but might add a knob (maybe personality(2) ?)\nfor enforcement to see what breaks.\n\nIn general, I would prefer to advertise a new value to userspace that\nwould mean preferred virtual address space granularity.",
              "reply_to": "Kalesh Singh",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author responded to Liam's point about balancing struct page overhead and page cache rounding overhead, stating he doesn't think this balance will be the primary factor in sizing tasks between machines.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "clarification",
                "questioning"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I am not sure I fully follow your point.\n\nSizing tasks and scheduling tasks between machines is hard in general.\nI don't think the balance between struct page tax and page cache\nrounding overhead is going to be the primary factor.",
              "reply_to": "Liam Howlett",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "The author is addressing a concern about the applicability of 64k pages to smaller machines, stating that they will not benefit from this feature.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "acknowledging feedback",
                "clarifying scope"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Smaller machines are not target for 64k pages. They will not benefit\nfrom them.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "Liam Howlett",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Liam Howlett",
              "summary": "Reviewer Liam Howlett noted that the proposed change may cause an increase in reclaim time due to the potential for more frequent reclaim penalties, which is a trade-off not previously considered.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "trade-offs",
                "reclaim penalty"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I think there are more trade offs than what you listed.  It's still\nprobably worth doing, but I wanted to know if you though that this would\ncause us to spend more time in reclaim, which seems to be implied above.\nSo, another trade-off might be all the reclaim penalty being paid more\nfrequently?\n\n...\n\nThanks,\nLiam",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author is unsure about the benefits of reducing allocation events and reclaim work, considering it too speculative at this stage.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "uncertainty",
                "speculation"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I am not sure.\n\nKernel would need to do less work in reclaim per unit of memory.\nDepending on workloads you might see less allocation events and\ntherefore less frequent reclaim.\n\nIt's all too hand-wavy at the stage.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "Liam Howlett",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David (Arm) expressed interest in exploring how much conversion would be needed for Meta's fleet to adapt to a larger page size, and suggested that legacy applications could still run on the same system with the default 4k pagesize.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "requested information",
                "acknowledged potential issues"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I'd assume that many applications nowadays can deal with differing page \nsizes (thanks to some other architectures paving the way).\n\nBut yes, some real legacy stuff, or stuff that ever only cared about \nintel still hardcodes pagesize=4k.\n\nIn Meta's fleet, I'd be quite interesting how much conversion there \nwould have to be done.\n\nFor legacy apps, you could still run them as 4k pagesize on the same \nsystem, of course.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David expressed concern about the sub-page mapping mechanism, specifically how to handle partial page mappings and their impact on mapcount, describing it as 'scary'.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I still have to wrap my head around the sub-page mapping here as well. \nIt's scary.\n\nRe mapcount: I think if any part of the page is mapped, it would be \nconsidered mapped -> mapcount += 1.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David raised concerns about the potential complexity of implementing a new page size, specifically citing the need for detailed consideration of metadata storage in page tables and kernel stacks.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "complexity",
                "metadata storage"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I'd assume that would work. Devil is in the detail with these things \nbefore we have memdescs.\n\nE.g., page table have a dedicated type (PGTY_table) and store separate \nmetadata in the ptdesc. For kernel stack there was once a proposal to \nhave a type but it is not upstream.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David suggested simplifying the patch by removing or hiding sub-page mapping details, which are currently scattered throughout the code and making it hard to understand.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Okay, that's valuable information, thanks!\n\nBeing able to remove the sub-page mapping part (or being able to just \nhide it somewhere deep down in arch code) would make this a lot easier \nto digest.\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kalesh Singh",
              "summary": "Reviewer Kalesh Singh noted that the personality(2) system call may be too late to enforce larger VMA alignment, as initial userspace mappings are already established by then, and suggested using an early_param for global enforcement and a prctl/personality flag for per-process opt-in.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I think personality(2) may be too late? By the time a process invokes\nit, the initial userspace mappings (executable, linker for init, etc)\nare already established with the default granularity.\n\nTo handle this, I've been using an early_param to enforce the larger\nVMA alignment system-wide right from boot.\n\nPerhaps, something for global enforcement (Kconfig/early param) and a\nprctl/personality flag for per-process opt in?",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kalesh Singh",
              "summary": "Reviewer noted that userspace allocators may benefit from optimizing their layouts to match the new PG_SIZE, allowing them to take advantage of larger allocations while still being able to operate at PTE_SIZE when needed.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "no clear signal",
                "acknowledging benefits"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "This makes sense for maintaining ABI compatibility. Userspace\nallocators might want to optimize their layouts to match PG_SIZE while\nstill being able to operate at PTE_SIZE when needed.\n\n-- Kalesh",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kalesh Singh",
              "summary": "Reviewer noted that the patch's design may not be suitable for architectures other than x86, and requested clarification on how PTE_SIZE and PG_SIZE would be handled in non-x86 contexts.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes",
                "clarification needed"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "On Fri, Feb 20, 2026 at 8:30AM David Hildenbrand (Arm)\n<david@kernel.org> wrote:",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kalesh Singh",
              "summary": "Reviewer noted that ELF segment alignment set by linkers would be incompatible with the proposed 64k page size, potentially causing issues with loading of binaries compiled for 4k granularity",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "incompatibility issue",
                "potential breakage"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I think most issues will stem from linkers setting the default ELF\nsegment alignment (max-page-size) for x86 to 4096. So those ELFs will\nnot load correctly or at all on the larger emulated granularity.\n\n-- Kalesh",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            }
          ]
        },
        {
          "activity_type": "patch_reviewed",
          "subject": "Re: [LSF/MM/BPF TOPIC] 64k (or 16k) base page size on x86",
          "message_id": "aZdCl8byz51Q1-v6@thinkstation",
          "url": "https://lore.kernel.org/all/aZdCl8byz51Q1-v6@thinkstation/",
          "date": "2026-02-19T17:09:24Z",
          "in_reply_to": null,
          "ack_type": null,
          "is_ongoing": false,
          "submitted_date": null,
          "patch_summary": "",
          "analysis_source": "llm-per-reviewer",
          "review_comments": [
            {
              "author": "Pedro Falcato",
              "summary": "Reviewer Pedro Falcato questioned the relevance of the proposed patch given the existence of mTHP, suggesting that toggling a sysfs entry is sufficient to achieve similar benefits.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "questioning relevance",
                "suggested alternative solution"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Doesn't this idea make less sense these days, with mTHP? Simply by toggling one\nof the entries in /sys/kernel/mm/transparent_hugepage.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Pedro Falcato",
              "summary": "Reviewer Pedro Falcato suggested adding a way to enforce a minimum allocation order globally on the page cache as an alternative solution, and also questioned the reviewer's point about order-5 allocation.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "suggested alternative solution",
                "questioned specific claim"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "We could perhaps add a way to enforce a min_order globally on the page cache,\nas a way to address it.\n\nThere are some points there which aren't addressed by mTHP work in any way\n(1G THPs for one), others which are being addressed separately (memdesc work\ntrying to cut down on struct page overhead).\n\n(I also don't understand your point about order-5 allocation, AFAIK pcp will\ncache up to COSTLY_ORDER (3) and PMD order, but I'm probably not seeing the\nfull picture)\n\n\n-- \nPedro",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer suggested emulating a larger page size (64K) for user space on x86 while still using 4K pages internally, reducing zone lock contention and other issues.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "When discussing per-process page sizes with Ryan and Dev, I mentioned \nthat having a larger emulated page size could be interesting for other \narchitectures as well.\n\nThat is, we would emulate a 64K page size on Intel for user space as \nwell, but let the OS work with 4K pages.\n\nWe'd only allocate+map large folios into user space + pagecache, but \nstill allow for page tables etc. to not waste memory.\n\nSo \"most\" of your allocations in the system would actually be at least \n64k, reducing zone lock contention etc.\n\n\nIt doesn't solve all the problems you wanted to tackle on your list \n(e.g., \"struct page\" overhead, which will be sorted out by memdescs).\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "The author addressed Pedro's concern that mTHP (multi-THP) is not guaranteed to work correctly, explaining that it's a best-effort mechanism and fragmentation isn't an issue as long as there's free memory.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "clarification",
                "explanation"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "mTHP is still best effort. This is way you don't need to care about\nfragmentation, you will get your 64k page as long as you have free\nmemory.",
              "reply_to": "Pedro Falcato",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "The author addressed Pedro Falcato's concern about the efficiency of page allocation, explaining that a higher base page size reduces the work needed to merge/split buddy pages, making it cheaper to serve large allocations.",
              "sentiment": "POSITIVE",
              "sentiment_signals": [
                "acknowledged the benefit",
                "explained reasoning"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "With higher base page size, page allocator doesn't need to do as much\nwork to merge/split buddy pages. So serving the same 2M as order-5 is\ncheaper than order-9.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "Pedro Falcato",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David noted that the proposed change would lead to reduced page table merging and splitting due to larger allocation sizes, which is expected to naturally reduce the need for these operations.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "no clear technical objection or suggestion"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I think the idea is that if most of your allocations (anon + pagecache) \nare 64k instead of 4k, on average, you'll just naturally do less merging \nsplitting.\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "The author is addressing David's concern about zone lock contention, stating that emulation would not help and expects contention to be higher if the page allocator sees a mix of 4k and 64k requests.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "neutral explanation",
                "no clear resolution"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I am not convinced emulation would help zone lock contention. I expect\ncontention to be higher if page allocator would see a mix of 4k and 64k\nrequests. It sounds like constant split/merge under the lock.",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author acknowledged that the current implementation of the buddy allocator cannot serve 1G pages, and expressed uncertainty about how to achieve viable 1G THPs without this capability.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "acknowledged limitation",
                "expressed uncertainty"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I don't think we can serve 1G pages out of buddy allocator with 4k\norder-0. And without it, I don't see how to get to a viable 1G THPs.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David (Arm) noted that if most allocations are larger than 64k, the benefits of splitting page size into PTE_SIZE and PG_SIZE may be diminished, as there would be less need for splitting/merging smaller allocations.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "If most your allocations are larger, then there isn't that much \nsplitting/merging.\n\nThere will be some for the < 64k allocations of course, but when all \nuser space+page cache is >= 64 then the split/merge + zone lock should \nbe heavily reduced.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David (Arm) expressed skepticism about the feasibility of implementing a separate page size for order-0 buddy allocations, citing previous discussions and ideas from Zi Yan.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "skepticism",
                "previous discussion"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Zi Yan was one working on this, and I think we had ideas on how to make \nthat work in the long run.\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Dave Hansen",
              "summary": "Reviewer Dave Hansen noted that a 64k page cache would consume significantly more memory than expected, estimating an additional ~5GB for a kernel tree, and suggested that the benefits of reducing 'struct page' overhead may be outweighed by increased RAM usage.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes",
                "questioning the effectiveness of the proposed solution"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "First of all, this looks like fun. Nice work! I'm not opposed at all in\nconcept to cleaning up things and doing the logical separation you\ndescribed to split buddy granularity and mapping granularity. That seems\nlike a worthy endeavor and some of the union/#define tricks look like a\nlikely viable way to do it incrementally.\n\nBut I don't think there's going to be a lot of memory savings in the\nend. Maybe this would bring the mem= hyperscalers back into the fold and\nhave them actually start using 'struct page' again for their VM memory.\nDunno.\n\nBut, let's look at my kernel directory and round the file sizes up to\n4k, 16k and 64k:\n\nfind .  -printf '%s\\n' | while read size; do echo\t\\\n\t\t$(((size + 0x0fff) & 0xfffff000))\t\\\n\t\t$(((size + 0x3fff) & 0xffffc000))\t\\\n\t\t$(((size + 0xffff) & 0xffff0000));\ndone\n\n... and add them all up:\n\n11,297,648 KB - on disk\n11,297,712 KB - in a 4k page cache\n12,223,488 KB - in a 16k page cache\n16,623,296 KB - in a 64k page cache\n\nSo a 64k page cache eats ~5GB of extra memory for a kernel tree (well,\n_my_ kernel tree). In other words, if you are looking for memory savings\non my laptop, you'll need ~300GB of RAM before 'struct page' overhead\noverwhelms the page cache bloat from a single kernel tree.\n\nThe whole kernel obviously isn't in the page cache all at the same time.\nThe page cache across the system is also obviously different than a\nkernel tree, but you get the point.\n\nThat's not to diminish how useful something like this might be,\nespecially for folks that are sensitive to 'struct page' overhead or\nallocator performance.\n\nBut, it will mostly be getting better performance at the _cost_ of\nconsuming more RAM, not saving RAM.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author asks for clarification on whether the proposed page size change should also enforce alignment of user-space mappings.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "clarifying question"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Just to clarify, do you want it to be enforced on userspace ABI.\nLike, all mappings are 64k aligned?",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "The author acknowledges that memory waste due to page table overhead is a solvable issue, suggesting that switching to slab allocation can address it.",
              "sentiment": "POSITIVE",
              "sentiment_signals": [
                "acknowledgment of a problem",
                "proposed solution"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Waste of memory for page table is solvable and pretty straight forward.\nMost of such cases can be solve mechanically by switching to slab.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Dave Hansen",
              "summary": "Reviewer Dave Hansen noted that the patch does not handle the case where PTE_SIZE is less than PG_SIZE, including misaligned cases, and requested that the page fault handler be updated to handle this scenario.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "On 2/19/26 07:08, Kiryl Shutsemau wrote:\n...",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Dave Hansen",
              "summary": "Reviewer noted that the patch introduces a large number of changes across multiple files, primarily due to renaming, and requested further analysis on the actual code modifications.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "large number of changes",
                "primarily due to renaming"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "A few notes about the diffstats:\n\n$ git diff v6.17..HEAD arch/x86 | diffstat | tail -1\n 105 files changed, 874 insertions(+), 843 deletions(-)\n$ git diff v6.17..HEAD mm | diffstat | tail -1\n 53 files changed, 1136 insertions(+), 1069 deletions(-)\n\nThe vast, vast majority of this seems to be the renames. Stuff like:",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Dave Hansen",
              "summary": "Reviewer Dave Hansen noted that the patch requires careful auditing to separate logic changes from mechanical updates, and requested a clear distinction between these two types of modifications.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested_changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "That stuff obviously needs to be audited but it's far less concerning\nthan the logic changes.\n\nSo just for review sanity, if you go forward with this, I'd very much\nappreciate a strong separation of the purely mechanical bits from any\nlogic changes.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Dave Hansen",
              "summary": "Reviewer Dave Hansen suggested that the patch should be gated behind a full tree conversion to ptdescs, as it introduces new complexities between PTE_SIZE and PG_SIZE",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "gating",
                "complexity"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Others mentioned this, but I think this essentially gates what you are\ndoing behind a full tree conversion over to ptdescs.\n\nThe most useful thing we can do with this series is look at it and\ndecide what _other_ things need to get done before the tree could\npossibly go in that direction, like ptdesc or a the disambiguation\nbetween PTE_SIZE and PG_SIZE that you've kicked off here.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Matthew Wilcox",
              "summary": "Reviewer Matthew Wilcox suggested an alternative approach to implementing larger page sizes by allocating the larger size and using it for multiple entries, expressing skepticism about the slab approach used in other architectures.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "suggested alternative",
                "expressed skepticism"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Have you looked at the s390/ppc implementations (yes, they're different,\nno, that sucks)?  slab seems like the wrong approach to me.\n\nThere's a third approach that I've never looked at which is to allocate\nthe larger size, then just use it for N consecutive entries.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Pedro Falcato",
              "summary": "Reviewer Pedro Falcato noted that the proposed patch could result in 90%+ of allocations being 64k, and suggested that this would be beneficial if combined with adjusting slab_min_order.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "potential benefit",
                "no clear objection"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Yep. That plus slab_min_order would hopefully yield a system where 90%+\n(depending on how your filesystem's buffer cache works) allocations are 64K.\n\n-- \nPedro",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author acknowledged that struct page memory consumption is a problem, but noted it's static and can't be reclaimed, whereas page cache rounding overhead is reclaimable and can be controlled by userspace",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "acknowledged the issue",
                "provided explanation"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "That's fair.\n\nThe problem with struct page memory consumption is that it is static and\ncannot be reclaimed. You pay the struct page tax no matter what.\n\nPage cache rounding overhead can be large, but a motivated userspace can\nkeep it under control by avoiding splitting a dataset into many small\nfiles. And this memory is reclaimable.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "Dave Hansen",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author acknowledged that packing of page tables is not required for correctness and plans to implement a PoC without it, but will need to catch up on ptdescs first.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "acknowledged a limitation",
                "needs further research"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I have not followed ptdescs closely. Need to catch up.\n\nFor PoC, I will just waste full order-0 page for page table. Packing is\nnot required for correctness.",
              "reply_to": "Dave Hansen",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Dave Hansen",
              "summary": "Reviewer noted that the proposed change to use a larger page size would not cause issues with the KPTI pgd allocation due to its current size fitting within the new allocation, and considered it 'weird but functional'.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "NEUTRAL"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Yeah, I guess padding it out is ugly but effective.\n\nI was trying to figure out how it would apply to the KPTI pgd because we\njust flip bit 12 to switch between user and kernel PGDs. But I guess the\n8k of PGDs in the current allocation will fit fine in 128k, so it's\nweird but functional.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author acknowledges a need for further work on handling PTE_SIZE < PG_SIZE, including misaligned cases in page fault handler",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "acknowledges need for fix",
                "further work required"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I was the first thing that came to mind. I have not put much time into\nit",
              "reply_to": "Matthew Wilcox",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author addressed Matthew Wilcox's concern about fragmentation when using 16k base pages, explaining that it is not an issue because only 16 page table entries of the parent page table need to be populated.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "clarification",
                "explanation"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Yeah, that's a possible way. We would need to populate 16 page table\nentries of the parent page table. But you don't need to care about\nfragmentation within the page.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "Matthew Wilcox",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kalesh Singh",
              "summary": "Reviewer noted that the patch's design may not be suitable for architectures other than x86, and requested more information on how to handle page size variations across different platforms.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes",
                "concern about portability"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "On Thu, Feb 19, 2026 at 7:39AM David Hildenbrand (Arm)\n<david@kernel.org> wrote:",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kalesh Singh",
              "summary": "Reviewer Kalesh Singh noted that the current design does not enforce a larger granularity on VMAs to emulate a userspace page size, which is necessary for Android's use case of emulating 16KB devices on x86, and expressed interest in discussing whether this can be extended to cover their use case.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes",
                "interested in discussion"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Hi Kiryl,\n\nI'd be interested to discuss this at LSFMM.\n\nOn Android, we have a separate but related use case: we emulate the\nuserspace page size on x86, primarily to enable app developers to\nconduct compatibility testing of their apps for 16KB Android devices.\n[1]\n\nIt mainly works by enforcing a larger granularity on the VMAs to\nemulate a userspace page size, somewhat similar to what David\nmentioned, while the underlying kernel still operates on a 4KB\ngranularity. [2]\n\nIIUC the current design would not enfore the larger granularity /\nalignment for VMAs to avoid breaking ABI. However, I'd be interest to\ndiscuss whether it can be extended to cover this usecase as well.\n\n[1]  https://developer.android.com/guide/practices/page-sizes#16kb-emulator\n[2] https://source.android.com/docs/core/architecture/16kb-page-size/getting-started-cf-x86-64-pgagnostic\n\nThanks,\nKalesh",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Zi Yan",
              "summary": "Reviewer suggested adding a super pageblock concept that consists of N consecutive pageblocks to enable anti-fragmentation at larger granularity, such as 1GB, and questioned whether free pages from memory compaction should be added to the buddy allocator.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "questioning",
                "debating"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Right. The idea is to add super pageblock (or whatever name), which consists of N consecutive\npageblocks, so that anti fragmentation can work at larger granularity, e.g., 1GB, to create\nfree pages. Whether 1GB free pages from memory compaction need to go into buddy allocator\nor not is debatable.\n\n--\nBest Regards,\nYan, Zi",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Liam Howlett",
              "summary": "Reviewer Liam Howlett expressed concern that increasing page size would increase memory pressure and degrade primary workloads on multi-workload machines, potentially leading to more frequent OOMs of secondary tasks.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "But we are in reclaim a lot more these days.  As I'm sure you are aware,\nwe are trying to maximize the resources (both cpu and ram) of any\nmachine powered on.  Entering reclaim will consume the cpu time and will\naffect other tasks.\n\nEspecially with multiple workload machines, the tendency is to have a\nprimary focus with the lower desired work being killed, if necessary.\nReducing the overhead just means more secondary tasks, or a bigger\nfootprint of the ones already executing.\n\nIncreasing the memory pressure will degrade the primary workload more\nfrequently, even if we recover enough to avoid OOMing the secondary.\n\nWhile in the struct page tax world, the secondary task would be killed\nafter a shorter (and less frequently executed) reclaim comes up short.\nSo, I would think that we would be degrading the primary workload in an\nattempt to keep the secondary alive?  Maybe I'm over-simplifying here?\n\nNear the other end of the spectrum, we have chromebooks that are\nconstantly in reclaim, even with 4k pages.  I guess these machines would\nbe destine to maintain the same page size they use today.  That is, this\nsolution for the struct page tax is only useful if you have a lot of\nmemory.  But then again, that's where the bookkeeping costs become hard\nto take.\n\nThanks,\nLiam",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "David Laight",
              "summary": "Reviewer David Laight pointed out that the patch does not handle the case where PTE_SIZE is less than PG_SIZE, including misaligned cases, which would require changes to the page fault handler.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "On Thu, 19 Feb 2026 15:08:51 +0000\nKiryl Shutsemau <kas@kernel.org> wrote:",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David Laight",
              "summary": "Reviewer questioned whether changing page size would affect alignment of PCIe windows, as well as mmap of kernel memory",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "requested clarification",
                "raised questions"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Also the 'random' buffers that are PAGE_SIZE rather than 4k.\n\nI also wonder how is affects mmap of kernel memory and the alignement\nof PCIe windows (etc).\n\n\tDavid",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer noted that the proposed change allows for running emulated 64k processes alongside 4k processes on the same machine, eliminating the need for 'vma crosses base pages' handling and making it easier to implement.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "no clear signal",
                "neutral tone"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Right, see the proposal from Dev on the list.\n\n From user-space POV, the pagesize would be 64K for these emulated \nprocesses. That is, VMAs must be suitable aligned etc.\n\nOne key thing I think is that you could run such emulated-64k process \n(that actually support it!) with 4k processes on the same machine, like \nArm is considering.\n\nYou would have no weird \"vma crosses base pages\" handling, which is just \nrather nasty and makes my head hurt.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David (Arm) expressed concerns that the proposed patch would reintroduce memory waste issues seen on ARM when using 64k page size, citing previous experiences and improvements made to achieve 4k performance.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "Requested changes",
                "Concerns about memory waste"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Well, yes, like Willy says, there are already similar custom solutions \nfor s390x and ppc.\n\nPasha talked recently about the memory waste of 16k kernel stacks and \nhow we would want to reduce that to 4k. In your proposal, it would be \n64k, unless you somehow manage to allocate multiple kernel stacks from \nthe same 64k page. My head hurts thinking about whether that could work, \nmaybe it could (no idea about guard pages in there, though).\n\n\nLet's take a look at the history of page size usage on Arm (people can \nfeel free to correct me):\n\n(1) Most distros were using 64k on Arm.\n\n(2) People realized that 64k was suboptimal many use cases (memory\n     waste for stacks, pagecache, etc) and started to switch to 4k. I\n     remember that mostly HPC-centric users sticked to 64k, but there was\n     also demand from others to be able to stay on 64k.\n\n(3) Arm improved performance on a 4k kernel by adding cont-pte support,\n     trying to get closer to 64k native performance.\n\n(4) Achieving 64k native performance is hard, which is why per-process\n     page sizes are being explored to get the best out of both worlds\n     (use 64k page size only where it really matters for performance).\n\nArm clearly has the added benefit of actually benefiting from hardware \nsupport for 64k.\n\nIIUC, what you are proposing feels a bit like traveling back in time \nwhen it comes to the memory waste problem that Arm users encountered.\n\nWhere do you see the big difference to 64k on Arm in your proposal? \nWould you currently also be running 64k Arm in production and the memory \nwaste etc is acceptable?\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "The author acknowledges that increasing the base page size to 64k or 16k would limit the patch's adoption due to existing legacy code on x86, but no specific fix is planned.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "acknowledges limitation",
                "no plan for fix"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Well, it will drastically limit the adoption. We have too much legacy\nstuff on x86.",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author responded to a concern about kernel stack allocation and suggested that slab-allocated stacks could work for large base page sizes, but didn't address the specific issue of alignment.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "clarifying question",
                "explaining reasoning"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Kernel stack is allocated from vmalloc. I think mapping them with\nsub-page granularity should be doable.\n\nBTW, do you see any reason why slab-allocated stack wouldn't work for\nlarge base page sizes? There's no requirement for it be aligned to page\nor PTE, right?",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author responded to reviewer's concern about the similarity between the proposed 64k page size on x86 and existing 64k Arm architecture, stating that he wants to bring this option to x86 for machines with over 2TiB of RAM, citing scalability benefits.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "acknowledging a valid concern",
                "explaining the motivation"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "That's the point. I don't see a big difference to 64k Arm. I want to\nbring this option to x86: at some machine size it makes sense trade\nmemory consumption for scalability. I am targeting it to machines with\nover 2TiB of RAM.\n\nBTW, we do run 64k Arm in our fleet. There's some growing pains, but it\nlooks good in general We have no plans to switch to 4k (or 16k) at the\nmoment. 512M THPs also look good on some workloads.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author acknowledges the need for ABI preservation and proposes adding a knob (personality(2)) or advertising a new value to userspace, indicating a willingness to revisit the design to ensure compatibility.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "acknowledges need for ABI preservation",
                "proposes revisiting design"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I don't want to break ABI, but might add a knob (maybe personality(2) ?)\nfor enforcement to see what breaks.\n\nIn general, I would prefer to advertise a new value to userspace that\nwould mean preferred virtual address space granularity.",
              "reply_to": "Kalesh Singh",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author responded to Liam's feedback by expressing uncertainty about the importance of balancing struct page size and page cache rounding overhead, indicating that this may not be a primary concern.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "uncertainty",
                "lack of clear resolution"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I am not sure I fully follow your point.\n\nSizing tasks and scheduling tasks between machines is hard in general.\nI don't think the balance between struct page tax and page cache\nrounding overhead is going to be the primary factor.",
              "reply_to": "Liam Howlett",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "The author acknowledged that smaller machines are not a target for 64k pages, implying they will not benefit from the change.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "acknowledged a specific limitation",
                "did not commit to addressing it"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Smaller machines are not target for 64k pages. They will not benefit\nfrom them.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "Liam Howlett",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Liam Howlett",
              "summary": "Reviewer Liam Howlett noted that the proposed change may introduce additional reclaim penalties due to increased frequency of reclaim operations, which could be a significant trade-off.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "trade-offs",
                "reclaim penalty"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I think there are more trade offs than what you listed.  It's still\nprobably worth doing, but I wanted to know if you though that this would\ncause us to spend more time in reclaim, which seems to be implied above.\nSo, another trade-off might be all the reclaim penalty being paid more\nfrequently?\n\n...\n\nThanks,\nLiam",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author is unsure about the benefits of larger page sizes, citing that it's too early to make claims and more analysis is needed.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "uncertainty",
                "need_for_further_analysis"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I am not sure.\n\nKernel would need to do less work in reclaim per unit of memory.\nDepending on workloads you might see less allocation events and\ntherefore less frequent reclaim.\n\nIt's all too hand-wavy at the stage.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "Liam Howlett",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David (Arm) expressed skepticism about the need for a larger page size, citing that many modern applications can already handle differing page sizes due to other architectures' influence, and questioned the amount of conversion required for legacy apps in his fleet.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "skepticism",
                "questioning"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I'd assume that many applications nowadays can deal with differing page \nsizes (thanks to some other architectures paving the way).\n\nBut yes, some real legacy stuff, or stuff that ever only cared about \nintel still hardcodes pagesize=4k.\n\nIn Meta's fleet, I'd be quite interesting how much conversion there \nwould have to be done.\n\nFor legacy apps, you could still run them as 4k pagesize on the same \nsystem, of course.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David (Arm) expressed concerns about the sub-page mapping approach, finding it 'scary', and questioned how to handle page re-mapping when only part of a page is mapped.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested clarification",
                "expressed uncertainty"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I still have to wrap my head around the sub-page mapping here as well. \nIt's scary.\n\nRe mapcount: I think if any part of the page is mapped, it would be \nconsidered mapped -> mapcount += 1.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David raised concerns that splitting PAGE_SIZE into PTE_SIZE and PG_SIZE may require additional metadata in page tables, specifically mentioning the use of ptdesc for kernel stack pages",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I'd assume that would work. Devil is in the detail with these things \nbefore we have memdescs.\n\nE.g., page table have a dedicated type (PGTY_table) and store separate \nmetadata in the ptdesc. For kernel stack there was once a proposal to \nhave a type but it is not upstream.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David suggested simplifying the patch by removing or hiding sub-page mapping details, making it more palatable to understand and review.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Okay, that's valuable information, thanks!\n\nBeing able to remove the sub-page mapping part (or being able to just \nhide it somewhere deep down in arch code) would make this a lot easier \nto digest.\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kalesh Singh",
              "summary": "Reviewer Kalesh Singh noted that the personality(2) system call may be too late to enforce larger VMA alignment, as initial userspace mappings are already established by the time it is invoked, and suggested using an early_param for global enforcement and a prctl/personality flag for per-process opt-in.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I think personality(2) may be too late? By the time a process invokes\nit, the initial userspace mappings (executable, linker for init, etc)\nare already established with the default granularity.\n\nTo handle this, I've been using an early_param to enforce the larger\nVMA alignment system-wide right from boot.\n\nPerhaps, something for global enforcement (Kconfig/early param) and a\nprctl/personality flag for per-process opt in?",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kalesh Singh",
              "summary": "Reviewer noted that userspace allocators may benefit from knowing the value of PG_SIZE, allowing them to optimize their layouts for better performance",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "no clear opinion",
                "acknowledges the patch's purpose"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "This makes sense for maintaining ABI compatibility. Userspace\nallocators might want to optimize their layouts to match PG_SIZE while\nstill being able to operate at PTE_SIZE when needed.\n\n-- Kalesh",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kalesh Singh",
              "summary": "Reviewer noted that the patch does not handle the case where PTE_SIZE is less than PG_SIZE, including misaligned cases in page faults, and requested that the page fault handler be modified to handle this scenario.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "On Fri, Feb 20, 2026 at 8:30AM David Hildenbrand (Arm)\n<david@kernel.org> wrote:",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kalesh Singh",
              "summary": "Reviewer noted that ELF segment alignment is set to 4096 by linkers, which could cause issues when loading binaries on systems with a larger page size",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "potential compatibility issue",
                "linker setting"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I think most issues will stem from linkers setting the default ELF\nsegment alignment (max-page-size) for x86 to 4096. So those ELFs will\nnot load correctly or at all on the larger emulated granularity.\n\n-- Kalesh",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            }
          ]
        },
        {
          "activity_type": "patch_reviewed",
          "subject": "Re: [LSF/MM/BPF TOPIC] 64k (or 16k) base page size on x86",
          "message_id": "aZcxWsWO7AxQW6JC@thinkstation",
          "url": "https://lore.kernel.org/all/aZcxWsWO7AxQW6JC@thinkstation/",
          "date": "2026-02-19T15:55:06Z",
          "in_reply_to": null,
          "ack_type": null,
          "is_ongoing": false,
          "submitted_date": null,
          "patch_summary": "",
          "analysis_source": "llm-per-reviewer",
          "review_comments": [
            {
              "author": "Pedro Falcato",
              "summary": "Reviewer Pedro Falcato questioned the relevance of the proposed patch, citing that memory transparency can be achieved through mTHP without modifying the kernel.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Doesn't this idea make less sense these days, with mTHP? Simply by toggling one\nof the entries in /sys/kernel/mm/transparent_hugepage.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Pedro Falcato",
              "summary": "Reviewer Pedro Falcato suggested adding a global minimum page cache order to address scalability issues, noting that some points are not addressed by existing work (1G THPs) and others are being handled separately (memdesc work).",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes",
                "suggested improvement"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "We could perhaps add a way to enforce a min_order globally on the page cache,\nas a way to address it.\n\nThere are some points there which aren't addressed by mTHP work in any way\n(1G THPs for one), others which are being addressed separately (memdesc work\ntrying to cut down on struct page overhead).\n\n(I also don't understand your point about order-5 allocation, AFAIK pcp will\ncache up to COSTLY_ORDER (3) and PMD order, but I'm probably not seeing the\nfull picture)\n\n\n-- \nPedro",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer suggested emulating a larger page size (64k) for user space on x86 while still using 4k pages internally, reducing zone lock contention and other issues.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "When discussing per-process page sizes with Ryan and Dev, I mentioned \nthat having a larger emulated page size could be interesting for other \narchitectures as well.\n\nThat is, we would emulate a 64K page size on Intel for user space as \nwell, but let the OS work with 4K pages.\n\nWe'd only allocate+map large folios into user space + pagecache, but \nstill allow for page tables etc. to not waste memory.\n\nSo \"most\" of your allocations in the system would actually be at least \n64k, reducing zone lock contention etc.\n\n\nIt doesn't solve all the problems you wanted to tackle on your list \n(e.g., \"struct page\" overhead, which will be sorted out by memdescs).\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "The author addressed a concern that the mTHP (madvise transparent huge pages) approach would be affected by fragmentation, and responded that mTHP is still best effort, meaning it will attempt to allocate 64k pages as long as there's free memory.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "clarification",
                "explanation"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "mTHP is still best effort. This is way you don't need to care about\nfragmentation, you will get your 64k page as long as you have free\nmemory.",
              "reply_to": "Pedro Falcato",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "The author addressed Pedro Falcato's concern about the efficiency of the page allocator by explaining that a higher base page size reduces the work required to merge/split buddy pages, making it cheaper for the allocator to serve large allocations.",
              "sentiment": "POSITIVE",
              "sentiment_signals": [
                "acknowledged the benefit of higher base page size",
                "provided technical explanation"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "With higher base page size, page allocator doesn't need to do as much\nwork to merge/split buddy pages. So serving the same 2M as order-5 is\ncheaper than order-9.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "Pedro Falcato",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David noted that the proposed change would lead to reduced page table merging and splitting due to larger allocation sizes, which is a natural consequence of using 64k pages instead of 4k",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "no clear technical objection or suggestion"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I think the idea is that if most of your allocations (anon + pagecache) \nare 64k instead of 4k, on average, you'll just naturally do less merging \nsplitting.\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "The author is addressing David's concern about zone lock contention, stating that emulation would not help and that contention would likely increase if the page allocator sees a mix of 4k and 64k requests.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "neutral explanation",
                "no clear resolution"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I am not convinced emulation would help zone lock contention. I expect\ncontention to be higher if page allocator would see a mix of 4k and 64k\nrequests. It sounds like constant split/merge under the lock.",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author acknowledged that the current implementation of the buddy allocator cannot serve 1G pages, and expressed uncertainty about how to achieve viable 1G THPs without it.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "acknowledged a limitation",
                "expressed uncertainty"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I don't think we can serve 1G pages out of buddy allocator with 4k\norder-0. And without it, I don't see how to get to a viable 1G THPs.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer noted that if most allocations are larger than 64k, the benefits of splitting PAGE_SIZE into PTE_SIZE and PG_SIZE may be diminished, as there would be less need for splitting/merging smaller allocations.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "If most your allocations are larger, then there isn't that much \nsplitting/merging.\n\nThere will be some for the < 64k allocations of course, but when all \nuser space+page cache is >= 64 then the split/merge + zone lock should \nbe heavily reduced.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David expressed skepticism about the proposed change, suggesting that previous work by Zi Yan could be leveraged to address the issue of larger page sizes on x86.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "skepticism",
                "lack of clear objection"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Zi Yan was one working on this, and I think we had ideas on how to make \nthat work in the long run.\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Dave Hansen",
              "summary": "Reviewer Dave Hansen noted that a 64k page cache would consume around 5GB of extra memory for a kernel tree, and questioned whether the proposed changes would result in significant memory savings.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "questioning the effectiveness of the proposal",
                "highlighting potential drawbacks"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "First of all, this looks like fun. Nice work! I'm not opposed at all in\nconcept to cleaning up things and doing the logical separation you\ndescribed to split buddy granularity and mapping granularity. That seems\nlike a worthy endeavor and some of the union/#define tricks look like a\nlikely viable way to do it incrementally.\n\nBut I don't think there's going to be a lot of memory savings in the\nend. Maybe this would bring the mem= hyperscalers back into the fold and\nhave them actually start using 'struct page' again for their VM memory.\nDunno.\n\nBut, let's look at my kernel directory and round the file sizes up to\n4k, 16k and 64k:\n\nfind .  -printf '%s\\n' | while read size; do echo\t\\\n\t\t$(((size + 0x0fff) & 0xfffff000))\t\\\n\t\t$(((size + 0x3fff) & 0xffffc000))\t\\\n\t\t$(((size + 0xffff) & 0xffff0000));\ndone\n\n... and add them all up:\n\n11,297,648 KB - on disk\n11,297,712 KB - in a 4k page cache\n12,223,488 KB - in a 16k page cache\n16,623,296 KB - in a 64k page cache\n\nSo a 64k page cache eats ~5GB of extra memory for a kernel tree (well,\n_my_ kernel tree). In other words, if you are looking for memory savings\non my laptop, you'll need ~300GB of RAM before 'struct page' overhead\noverwhelms the page cache bloat from a single kernel tree.\n\nThe whole kernel obviously isn't in the page cache all at the same time.\nThe page cache across the system is also obviously different than a\nkernel tree, but you get the point.\n\nThat's not to diminish how useful something like this might be,\nespecially for folks that are sensitive to 'struct page' overhead or\nallocator performance.\n\nBut, it will mostly be getting better performance at the _cost_ of\nconsuming more RAM, not saving RAM.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author clarifies whether the proposed page size change should also apply to user-space mappings, specifically asking if they want all mappings to be 64k aligned.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "clarifying question",
                "no clear resolution signal"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Just to clarify, do you want it to be enforced on userspace ABI.\nLike, all mappings are 64k aligned?",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "The author acknowledges that memory waste due to page table size is a solvable issue, suggesting it can be addressed by switching to slab allocation.",
              "sentiment": "POSITIVE",
              "sentiment_signals": [
                "acknowledgment of fixability",
                "proposed solution"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Waste of memory for page table is solvable and pretty straight forward.\nMost of such cases can be solve mechanically by switching to slab.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Dave Hansen",
              "summary": "Reviewer Dave Hansen noted that the patch does not address how to handle page faults into file mappings when PTE_SIZE is larger than PG_SIZE, and requested a solution for this case.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "On 2/19/26 07:08, Kiryl Shutsemau wrote:\n...",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Dave Hansen",
              "summary": "Reviewer noted that the patch introduces a significant number of changes across multiple files, primarily due to renaming and reorganization efforts, rather than new functionality.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "large number of changes",
                "renames"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "A few notes about the diffstats:\n\n$ git diff v6.17..HEAD arch/x86 | diffstat | tail -1\n 105 files changed, 874 insertions(+), 843 deletions(-)\n$ git diff v6.17..HEAD mm | diffstat | tail -1\n 53 files changed, 1136 insertions(+), 1069 deletions(-)\n\nThe vast, vast majority of this seems to be the renames. Stuff like:",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Dave Hansen",
              "summary": "Reviewer Dave Hansen expressed concern that the patch's logic changes need to be clearly separated from its mechanical changes, and requested a clear distinction between the two for review sanity.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "That stuff obviously needs to be audited but it's far less concerning\nthan the logic changes.\n\nSo just for review sanity, if you go forward with this, I'd very much\nappreciate a strong separation of the purely mechanical bits from any\nlogic changes.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Dave Hansen",
              "summary": "Reviewer Dave Hansen noted that the proposed patch essentially requires a full tree conversion to ptdescs, which is a prerequisite for implementing the new page size scheme.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "prerequisite",
                "additional work needed"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Others mentioned this, but I think this essentially gates what you are\ndoing behind a full tree conversion over to ptdescs.\n\nThe most useful thing we can do with this series is look at it and\ndecide what _other_ things need to get done before the tree could\npossibly go in that direction, like ptdesc or a the disambiguation\nbetween PTE_SIZE and PG_SIZE that you've kicked off here.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Matthew Wilcox",
              "summary": "Reviewer Matthew Wilcox suggested an alternative approach to implementing larger page sizes by allocating the larger size and using it for multiple consecutive entries, expressing skepticism about the slab approach.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "suggested alternative",
                "expressed skepticism"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Have you looked at the s390/ppc implementations (yes, they're different,\nno, that sucks)?  slab seems like the wrong approach to me.\n\nThere's a third approach that I've never looked at which is to allocate\nthe larger size, then just use it for N consecutive entries.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Pedro Falcato",
              "summary": "Reviewer Pedro Falcato noted that the proposed patch would allow for 90%+ of allocations to be 64K, which he believes could yield a system where most allocations are 64K.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "no clear signal"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Yep. That plus slab_min_order would hopefully yield a system where 90%+\n(depending on how your filesystem's buffer cache works) allocations are 64K.\n\n-- \nPedro",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author acknowledges that struct page memory consumption is a problem, but notes it's static and cannot be reclaimed, whereas page cache rounding overhead can be controlled by userspace",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "acknowledged a concern",
                "pushed back on the severity of the issue"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "That's fair.\n\nThe problem with struct page memory consumption is that it is static and\ncannot be reclaimed. You pay the struct page tax no matter what.\n\nPage cache rounding overhead can be large, but a motivated userspace can\nkeep it under control by avoiding splitting a dataset into many small\nfiles. And this memory is reclaimable.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "Dave Hansen",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author acknowledged a concern about packing of page tables and decided to simplify the proof-of-concept (PoC) by wasting full order-0 pages, deferring detailed handling until later.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "acknowledged a concern",
                "deferred detailed handling"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I have not followed ptdescs closely. Need to catch up.\n\nFor PoC, I will just waste full order-0 page for page table. Packing is\nnot required for correctness.",
              "reply_to": "Dave Hansen",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Dave Hansen",
              "summary": "Reviewer noted that the proposed change to use a larger page size would not cause issues with the KPTI pgd, as the current allocation of 8k PGDs would fit within the new 128k allocation.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "no clear technical objection or suggestion"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Yeah, I guess padding it out is ugly but effective.\n\nI was trying to figure out how it would apply to the KPTI pgd because we\njust flip bit 12 to switch between user and kernel PGDs. But I guess the\n8k of PGDs in the current allocation will fit fine in 128k, so it's\nweird but functional.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author acknowledges a need for more work on handling page faults and VMA alignment, but does not commit to a specific fix or timeline.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "acknowledges need for more work"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I was the first thing that came to mind. I have not put much time into\nit",
              "reply_to": "Matthew Wilcox",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author responds to Matthew Wilcox's concern about fragmentation when using 16k base pages, explaining that the parent page table would need to be populated with 16 entries but fragmentation within the page is not a concern.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "clarification",
                "explanation"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Yeah, that's a possible way. We would need to populate 16 page table\nentries of the parent page table. But you don't need to care about\nfragmentation within the page.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "Matthew Wilcox",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kalesh Singh",
              "summary": "Reviewer noted that the patch's design may not be suitable for architectures other than x86, as it relies on specific hardware features and may not generalize well to other platforms.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "generalization",
                "architecture-specific"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "On Thu, Feb 19, 2026 at 7:39AM David Hildenbrand (Arm)\n<david@kernel.org> wrote:",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kalesh Singh",
              "summary": "Reviewer Kalesh Singh noted that the current design does not enforce a larger granularity on VMAs to emulate a userspace page size, which is necessary for Android's compatibility testing of apps for 16KB devices, and expressed interest in discussing whether this use case can be covered by extending the current design.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes",
                "interested in discussion"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Hi Kiryl,\n\nI'd be interested to discuss this at LSFMM.\n\nOn Android, we have a separate but related use case: we emulate the\nuserspace page size on x86, primarily to enable app developers to\nconduct compatibility testing of their apps for 16KB Android devices.\n[1]\n\nIt mainly works by enforcing a larger granularity on the VMAs to\nemulate a userspace page size, somewhat similar to what David\nmentioned, while the underlying kernel still operates on a 4KB\ngranularity. [2]\n\nIIUC the current design would not enfore the larger granularity /\nalignment for VMAs to avoid breaking ABI. However, I'd be interest to\ndiscuss whether it can be extended to cover this usecase as well.\n\n[1]  https://developer.android.com/guide/practices/page-sizes#16kb-emulator\n[2] https://source.android.com/docs/core/architecture/16kb-page-size/getting-started-cf-x86-64-pgagnostic\n\nThanks,\nKalesh",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Zi Yan",
              "summary": "Reviewer suggested adding a super pageblock that consists of N consecutive pageblocks to enable anti-fragmentation at larger granularity, such as 1GB, and questioned whether free pages from memory compaction should go into the buddy allocator.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "questioning",
                "debating"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Right. The idea is to add super pageblock (or whatever name), which consists of N consecutive\npageblocks, so that anti fragmentation can work at larger granularity, e.g., 1GB, to create\nfree pages. Whether 1GB free pages from memory compaction need to go into buddy allocator\nor not is debatable.\n\n--\nBest Regards,\nYan, Zi",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Liam Howlett",
              "summary": "The reviewer expressed concern that increasing page size would increase memory pressure and degrade primary workloads on machines with multiple concurrent tasks, potentially leading to more frequent OOMs.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "memory_pressure",
                "workload_degradation"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "But we are in reclaim a lot more these days.  As I'm sure you are aware,\nwe are trying to maximize the resources (both cpu and ram) of any\nmachine powered on.  Entering reclaim will consume the cpu time and will\naffect other tasks.\n\nEspecially with multiple workload machines, the tendency is to have a\nprimary focus with the lower desired work being killed, if necessary.\nReducing the overhead just means more secondary tasks, or a bigger\nfootprint of the ones already executing.\n\nIncreasing the memory pressure will degrade the primary workload more\nfrequently, even if we recover enough to avoid OOMing the secondary.\n\nWhile in the struct page tax world, the secondary task would be killed\nafter a shorter (and less frequently executed) reclaim comes up short.\nSo, I would think that we would be degrading the primary workload in an\nattempt to keep the secondary alive?  Maybe I'm over-simplifying here?\n\nNear the other end of the spectrum, we have chromebooks that are\nconstantly in reclaim, even with 4k pages.  I guess these machines would\nbe destine to maintain the same page size they use today.  That is, this\nsolution for the struct page tax is only useful if you have a lot of\nmemory.  But then again, that's where the bookkeeping costs become hard\nto take.\n\nThanks,\nLiam",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "David Laight",
              "summary": "Reviewer David Laight pointed out that the patch does not handle the case where PTE_SIZE is less than PG_SIZE, including misaligned cases in page faults, and requested further consideration of this edge case.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "On Thu, 19 Feb 2026 15:08:51 +0000\nKiryl Shutsemau <kas@kernel.org> wrote:",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David Laight",
              "summary": "Reviewer David Laight raised concerns about potential issues with PAGE_SIZE being used for buffers, mmap of kernel memory, and alignment of PCIe windows, requesting consideration of these aspects.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Also the 'random' buffers that are PAGE_SIZE rather than 4k.\n\nI also wonder how is affects mmap of kernel memory and the alignement\nof PCIe windows (etc).\n\n\tDavid",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer noted that if the page size is changed to 64k or 16k on x86, it would be possible to run emulated 64k processes alongside 4k processes on the same machine without needing special handling for VMAs crossing base pages.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "considering",
                "makes my head hurt"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Right, see the proposal from Dev on the list.\n\n From user-space POV, the pagesize would be 64K for these emulated \nprocesses. That is, VMAs must be suitable aligned etc.\n\nOne key thing I think is that you could run such emulated-64k process \n(that actually support it!) with 4k processes on the same machine, like \nArm is considering.\n\nYou would have no weird \"vma crosses base pages\" handling, which is just \nrather nasty and makes my head hurt.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David (Arm) expressed concerns that the proposed patch would reintroduce memory waste issues seen on Arm when using 64k page size, citing previous experiences and improvements made to achieve 4k performance.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "memory waste",
                "performance"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Well, yes, like Willy says, there are already similar custom solutions \nfor s390x and ppc.\n\nPasha talked recently about the memory waste of 16k kernel stacks and \nhow we would want to reduce that to 4k. In your proposal, it would be \n64k, unless you somehow manage to allocate multiple kernel stacks from \nthe same 64k page. My head hurts thinking about whether that could work, \nmaybe it could (no idea about guard pages in there, though).\n\n\nLet's take a look at the history of page size usage on Arm (people can \nfeel free to correct me):\n\n(1) Most distros were using 64k on Arm.\n\n(2) People realized that 64k was suboptimal many use cases (memory\n     waste for stacks, pagecache, etc) and started to switch to 4k. I\n     remember that mostly HPC-centric users sticked to 64k, but there was\n     also demand from others to be able to stay on 64k.\n\n(3) Arm improved performance on a 4k kernel by adding cont-pte support,\n     trying to get closer to 64k native performance.\n\n(4) Achieving 64k native performance is hard, which is why per-process\n     page sizes are being explored to get the best out of both worlds\n     (use 64k page size only where it really matters for performance).\n\nArm clearly has the added benefit of actually benefiting from hardware \nsupport for 64k.\n\nIIUC, what you are proposing feels a bit like traveling back in time \nwhen it comes to the memory waste problem that Arm users encountered.\n\nWhere do you see the big difference to 64k on Arm in your proposal? \nWould you currently also be running 64k Arm in production and the memory \nwaste etc is acceptable?\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author acknowledges that a larger page size would be difficult to adopt due to existing legacy code on x86, but no specific plan for addressing this issue is mentioned.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "acknowledges limitation",
                "no clear resolution"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Well, it will drastically limit the adoption. We have too much legacy\nstuff on x86.",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author responded to David's (Arm) concern about kernel stack allocation by suggesting that vmalloc can handle sub-page granularity and asking if slab-allocated stacks would work for large base page sizes.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "clarifying question",
                "explaining reasoning"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Kernel stack is allocated from vmalloc. I think mapping them with\nsub-page granularity should be doable.\n\nBTW, do you see any reason why slab-allocated stack wouldn't work for\nlarge base page sizes? There's no requirement for it be aligned to page\nor PTE, right?",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "The author is addressing David's concern that the patch does not consider the existing 64k page size on Arm, and is pushing back by stating that they want to bring this option to x86 for machines with over 2TiB of RAM, citing scalability benefits.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "pushing back",
                "citing scalability benefits"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "That's the point. I don't see a big difference to 64k Arm. I want to\nbring this option to x86: at some machine size it makes sense trade\nmemory consumption for scalability. I am targeting it to machines with\nover 2TiB of RAM.\n\nBTW, we do run 64k Arm in our fleet. There's some growing pains, but it\nlooks good in general We have no plans to switch to 4k (or 16k) at the\nmoment. 512M THPs also look good on some workloads.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author acknowledges the need for ABI compatibility and proposes adding a knob or personality(2) flag to enforce it, but does not commit to a specific solution.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "acknowledges need for fix",
                "proposes potential solution"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I don't want to break ABI, but might add a knob (maybe personality(2) ?)\nfor enforcement to see what breaks.\n\nIn general, I would prefer to advertise a new value to userspace that\nwould mean preferred virtual address space granularity.",
              "reply_to": "Kalesh Singh",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author responded to Liam's point about balancing struct page size and page cache rounding overhead, stating that he doesn't think this balance will be the primary factor in sizing tasks and scheduling between machines.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "clarification",
                "explaining"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I am not sure I fully follow your point.\n\nSizing tasks and scheduling tasks between machines is hard in general.\nI don't think the balance between struct page tax and page cache\nrounding overhead is going to be the primary factor.",
              "reply_to": "Liam Howlett",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "The author acknowledged that smaller machines won't benefit from 64k pages, implying they're not a priority for this patch.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "acknowledged",
                "implied"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Smaller machines are not target for 64k pages. They will not benefit\nfrom them.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "Liam Howlett",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Liam Howlett",
              "summary": "Reviewer Liam Howlett noted that increasing page size could lead to increased reclaim penalties due to more frequent reclaim operations, which is a potential trade-off not previously considered.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "trade-offs",
                "reclaim penalty"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I think there are more trade offs than what you listed.  It's still\nprobably worth doing, but I wanted to know if you though that this would\ncause us to spend more time in reclaim, which seems to be implied above.\nSo, another trade-off might be all the reclaim penalty being paid more\nfrequently?\n\n...\n\nThanks,\nLiam",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author is uncertain about the benefits of reducing allocation events and reclaim work, considering it too vague at this stage.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "uncertainty",
                "vagueness"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I am not sure.\n\nKernel would need to do less work in reclaim per unit of memory.\nDepending on workloads you might see less allocation events and\ntherefore less frequent reclaim.\n\nIt's all too hand-wavy at the stage.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "Liam Howlett",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David (Arm) noted that many modern applications can handle differing page sizes and questioned the need for conversion to a larger page size, but also acknowledged that legacy code may still be hardcoded to use 4k pagesize.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "questioning the necessity of change",
                "acknowledging potential complexity"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I'd assume that many applications nowadays can deal with differing page \nsizes (thanks to some other architectures paving the way).\n\nBut yes, some real legacy stuff, or stuff that ever only cared about \nintel still hardcodes pagesize=4k.\n\nIn Meta's fleet, I'd be quite interesting how much conversion there \nwould have to be done.\n\nFor legacy apps, you could still run them as 4k pagesize on the same \nsystem, of course.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David (Arm) expressed concern about the sub-page mapping mechanism, specifically how to handle the mapcount when any part of a page is mapped, and described it as 'scary'.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "requested clarification",
                "expressed uncertainty"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I still have to wrap my head around the sub-page mapping here as well. \nIt's scary.\n\nRe mapcount: I think if any part of the page is mapped, it would be \nconsidered mapped -> mapcount += 1.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David noted that splitting PAGE_SIZE into PTE_SIZE and PG_SIZE may require additional metadata in the page table, specifically a dedicated type (PGTY_table) to store separate metadata in the ptdesc, similar to kernel stack proposals.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I'd assume that would work. Devil is in the detail with these things \nbefore we have memdescs.\n\nE.g., page table have a dedicated type (PGTY_table) and store separate \nmetadata in the ptdesc. For kernel stack there was once a proposal to \nhave a type but it is not upstream.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David suggested simplifying the patch by removing or hiding sub-page mapping logic, making it easier to understand and review.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Okay, that's valuable information, thanks!\n\nBeing able to remove the sub-page mapping part (or being able to just \nhide it somewhere deep down in arch code) would make this a lot easier \nto digest.\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kalesh Singh",
              "summary": "Reviewer Kalesh Singh noted that the personality(2) system call may be too late to enforce larger VMA alignment, as initial userspace mappings are already established by then, and suggested using an early_param for global enforcement and a prctl/personality flag for per-process opt-in.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I think personality(2) may be too late? By the time a process invokes\nit, the initial userspace mappings (executable, linker for init, etc)\nare already established with the default granularity.\n\nTo handle this, I've been using an early_param to enforce the larger\nVMA alignment system-wide right from boot.\n\nPerhaps, something for global enforcement (Kconfig/early param) and a\nprctl/personality flag for per-process opt in?",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kalesh Singh",
              "summary": "Reviewer noted that userspace allocators may benefit from knowing the optimal page size (PG_SIZE) for layout optimization, while still being able to operate at PTE_SIZE granularity.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "consideration of user-space implications"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "This makes sense for maintaining ABI compatibility. Userspace\nallocators might want to optimize their layouts to match PG_SIZE while\nstill being able to operate at PTE_SIZE when needed.\n\n-- Kalesh",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kalesh Singh",
              "summary": "Reviewer noted that the patch does not handle the case where PTE_SIZE is less than PG_SIZE, including misaligned cases in page faults, and requested that the page fault handler be updated to handle this scenario.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "On Fri, Feb 20, 2026 at 8:30AM David Hildenbrand (Arm)\n<david@kernel.org> wrote:",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kalesh Singh",
              "summary": "Reviewer noted that linker settings would cause ELF segment alignment issues, preventing correct loading of binaries with default max-page-size set to 4096, and suggested this as a major concern for the patch.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "linker settings",
                "ELF segment alignment"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I think most issues will stem from linkers setting the default ELF\nsegment alignment (max-page-size) for x86 to 4096. So those ELFs will\nnot load correctly or at all on the larger emulated granularity.\n\n-- Kalesh",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            }
          ]
        },
        {
          "activity_type": "patch_reviewed",
          "subject": "Re: [LSF/MM/BPF TOPIC] 64k (or 16k) base page size on x86",
          "message_id": "aZcuvbTTXn1MD5KK@thinkstation",
          "url": "https://lore.kernel.org/all/aZcuvbTTXn1MD5KK@thinkstation/",
          "date": "2026-02-19T15:50:29Z",
          "in_reply_to": null,
          "ack_type": null,
          "is_ongoing": false,
          "submitted_date": null,
          "patch_summary": "",
          "analysis_source": "llm-per-reviewer",
          "review_comments": [
            {
              "author": "Pedro Falcato",
              "summary": "Reviewer Pedro Falcato questioned the relevance of the patch's idea given the existence of mTHP, which can be toggled via sysfs to achieve similar benefits without modifying the kernel.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Doesn't this idea make less sense these days, with mTHP? Simply by toggling one\nof the entries in /sys/kernel/mm/transparent_hugepage.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Pedro Falcato",
              "summary": "Reviewer Pedro Falcato suggested adding a way to enforce a minimum allocation order globally on the page cache to address scalability issues, and noted that some points from the patch are not addressed by other ongoing work such as mTHP or memdesc.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes",
                "suggested improvements"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "We could perhaps add a way to enforce a min_order globally on the page cache,\nas a way to address it.\n\nThere are some points there which aren't addressed by mTHP work in any way\n(1G THPs for one), others which are being addressed separately (memdesc work\ntrying to cut down on struct page overhead).\n\n(I also don't understand your point about order-5 allocation, AFAIK pcp will\ncache up to COSTLY_ORDER (3) and PMD order, but I'm probably not seeing the\nfull picture)\n\n\n-- \nPedro",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer suggested emulating a larger page size (64k) for user space on x86 while still using 4k pages internally, reducing zone lock contention and other issues.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "When discussing per-process page sizes with Ryan and Dev, I mentioned \nthat having a larger emulated page size could be interesting for other \narchitectures as well.\n\nThat is, we would emulate a 64K page size on Intel for user space as \nwell, but let the OS work with 4K pages.\n\nWe'd only allocate+map large folios into user space + pagecache, but \nstill allow for page tables etc. to not waste memory.\n\nSo \"most\" of your allocations in the system would actually be at least \n64k, reducing zone lock contention etc.\n\n\nIt doesn't solve all the problems you wanted to tackle on your list \n(e.g., \"struct page\" overhead, which will be sorted out by memdescs).\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "The author responded to a concern that the patch's best-effort approach to large pages (mTHP) might not guarantee allocation of 64k pages, explaining that fragmentation is not a concern because the kernel will allocate as many 64k pages as available memory allows.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "clarification",
                "explanation"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "mTHP is still best effort. This is way you don't need to care about\nfragmentation, you will get your 64k page as long as you have free\nmemory.",
              "reply_to": "Pedro Falcato",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "The author addressed Pedro Falcato's concern about the increased work for the page allocator to merge/split buddy pages, explaining that it is actually cheaper with a higher base page size.",
              "sentiment": "POSITIVE",
              "sentiment_signals": [
                "acknowledged and explained feedback",
                "provided technical justification"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "With higher base page size, page allocator doesn't need to do as much\nwork to merge/split buddy pages. So serving the same 2M as order-5 is\ncheaper than order-9.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "Pedro Falcato",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David noted that the proposed change would lead to reduced page table merging and splitting due to larger allocation sizes, which is a natural consequence of using 64k pages instead of 4k",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "no clear technical objection or suggestion"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I think the idea is that if most of your allocations (anon + pagecache) \nare 64k instead of 4k, on average, you'll just naturally do less merging \nsplitting.\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author disagrees that emulation can help reduce zone lock contention, citing potential for increased contention due to mixed page sizes.",
              "sentiment": "CONTENTIOUS",
              "sentiment_signals": [
                "pushes back on reviewer's suggestion",
                "disagrees with proposed solution"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I am not convinced emulation would help zone lock contention. I expect\ncontention to be higher if page allocator would see a mix of 4k and 64k\nrequests. It sounds like constant split/merge under the lock.",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author acknowledged that the current implementation of the buddy allocator cannot serve 1G pages, and expressed uncertainty about how to achieve viable 1G THPs without it.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "uncertainty",
                "acknowledgment of limitation"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I don't think we can serve 1G pages out of buddy allocator with 4k\norder-0. And without it, I don't see how to get to a viable 1G THPs.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David (Arm) noted that if most allocations are larger than 64k, the benefits of splitting page size into two values may be diminished, as there will still be some splitting and merging required for smaller allocations.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "If most your allocations are larger, then there isn't that much \nsplitting/merging.\n\nThere will be some for the < 64k allocations of course, but when all \nuser space+page cache is >= 64 then the split/merge + zone lock should \nbe heavily reduced.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David (Arm) expressed skepticism about the proposed change, suggesting that previous work by Zi Yan might be a more viable solution.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "skepticism",
                "alternative solution"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Zi Yan was one working on this, and I think we had ideas on how to make \nthat work in the long run.\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Dave Hansen",
              "summary": "Reviewer Dave Hansen noted that a 64k page cache would consume significantly more memory than expected, citing his own kernel tree's disk and page cache sizes under different page sizes, and suggested that the benefits of reducing 'struct page' overhead may be outweighed by increased RAM usage.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes",
                "questioning benefits"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "First of all, this looks like fun. Nice work! I'm not opposed at all in\nconcept to cleaning up things and doing the logical separation you\ndescribed to split buddy granularity and mapping granularity. That seems\nlike a worthy endeavor and some of the union/#define tricks look like a\nlikely viable way to do it incrementally.\n\nBut I don't think there's going to be a lot of memory savings in the\nend. Maybe this would bring the mem= hyperscalers back into the fold and\nhave them actually start using 'struct page' again for their VM memory.\nDunno.\n\nBut, let's look at my kernel directory and round the file sizes up to\n4k, 16k and 64k:\n\nfind .  -printf '%s\\n' | while read size; do echo\t\\\n\t\t$(((size + 0x0fff) & 0xfffff000))\t\\\n\t\t$(((size + 0x3fff) & 0xffffc000))\t\\\n\t\t$(((size + 0xffff) & 0xffff0000));\ndone\n\n... and add them all up:\n\n11,297,648 KB - on disk\n11,297,712 KB - in a 4k page cache\n12,223,488 KB - in a 16k page cache\n16,623,296 KB - in a 64k page cache\n\nSo a 64k page cache eats ~5GB of extra memory for a kernel tree (well,\n_my_ kernel tree). In other words, if you are looking for memory savings\non my laptop, you'll need ~300GB of RAM before 'struct page' overhead\noverwhelms the page cache bloat from a single kernel tree.\n\nThe whole kernel obviously isn't in the page cache all at the same time.\nThe page cache across the system is also obviously different than a\nkernel tree, but you get the point.\n\nThat's not to diminish how useful something like this might be,\nespecially for folks that are sensitive to 'struct page' overhead or\nallocator performance.\n\nBut, it will mostly be getting better performance at the _cost_ of\nconsuming more RAM, not saving RAM.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author clarifies whether the proposed 64k page size should be enforced on user-space ABI, specifically asking if all mappings should be 64k aligned.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "clarifying question",
                "no clear resolution signal"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Just to clarify, do you want it to be enforced on userspace ABI.\nLike, all mappings are 64k aligned?",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "The author acknowledges that memory waste for page tables is a solvable issue and proposes using the slab allocator to address it, indicating no immediate fix but a potential solution in the future.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "acknowledges an issue",
                "proposes a solution"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Waste of memory for page table is solvable and pretty straight forward.\nMost of such cases can be solve mechanically by switching to slab.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Dave Hansen",
              "summary": "Reviewer Dave Hansen pointed out that the patch does not handle page faults into file mappings correctly when PTE_SIZE is less than PG_SIZE, and suggested adding a check to ensure that the VMA start address is aligned to PG_SIZE.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "On 2/19/26 07:08, Kiryl Shutsemau wrote:\n...",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Dave Hansen",
              "summary": "Reviewer noted that the patch introduces a significant number of changes across multiple files, primarily due to renaming, and requested further analysis on the actual code modifications.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "requested additional review"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "A few notes about the diffstats:\n\n$ git diff v6.17..HEAD arch/x86 | diffstat | tail -1\n 105 files changed, 874 insertions(+), 843 deletions(-)\n$ git diff v6.17..HEAD mm | diffstat | tail -1\n 53 files changed, 1136 insertions(+), 1069 deletions(-)\n\nThe vast, vast majority of this seems to be the renames. Stuff like:",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Dave Hansen",
              "summary": "Reviewer Dave Hansen noted that the patch requires auditing for logic changes and requested a clear separation between mechanical and logical modifications.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested_changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "That stuff obviously needs to be audited but it's far less concerning\nthan the logic changes.\n\nSo just for review sanity, if you go forward with this, I'd very much\nappreciate a strong separation of the purely mechanical bits from any\nlogic changes.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Dave Hansen",
              "summary": "Reviewer Dave Hansen noted that the proposed patch is essentially dependent on a full tree conversion to ptdescs, and suggested that instead of implementing this series, we should focus on identifying other necessary changes before proceeding.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Others mentioned this, but I think this essentially gates what you are\ndoing behind a full tree conversion over to ptdescs.\n\nThe most useful thing we can do with this series is look at it and\ndecide what _other_ things need to get done before the tree could\npossibly go in that direction, like ptdesc or a the disambiguation\nbetween PTE_SIZE and PG_SIZE that you've kicked off here.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Matthew Wilcox",
              "summary": "Reviewer Matthew Wilcox suggested an alternative approach to implementing larger page sizes by allocating the larger size and using it for multiple entries, expressing skepticism about the slab approach",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "skeptical",
                "alternative"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Have you looked at the s390/ppc implementations (yes, they're different,\nno, that sucks)?  slab seems like the wrong approach to me.\n\nThere's a third approach that I've never looked at which is to allocate\nthe larger size, then just use it for N consecutive entries.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Pedro Falcato",
              "summary": "The reviewer notes that the proposed patch, which splits PAGE_SIZE into PTE_SIZE and PG_SIZE, would allow for 90%+ of allocations to be 64K in size, assuming slab_min_order is adjusted accordingly.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "no clear signal",
                "neutral comment"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Yep. That plus slab_min_order would hopefully yield a system where 90%+\n(depending on how your filesystem's buffer cache works) allocations are 64K.\n\n-- \nPedro",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author acknowledges that struct page memory consumption is a problem, but notes that it's static and cannot be reclaimed, whereas page cache rounding overhead can be controlled by userspace",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "acknowledged the issue",
                "provided explanation"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "That's fair.\n\nThe problem with struct page memory consumption is that it is static and\ncannot be reclaimed. You pay the struct page tax no matter what.\n\nPage cache rounding overhead can be large, but a motivated userspace can\nkeep it under control by avoiding splitting a dataset into many small\nfiles. And this memory is reclaimable.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "Dave Hansen",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author acknowledged that packing of page tables is not required for correctness and plans to implement this in the proof-of-concept (PoC) version.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "acknowledged a technical detail",
                "plans to address it"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I have not followed ptdescs closely. Need to catch up.\n\nFor PoC, I will just waste full order-0 page for page table. Packing is\nnot required for correctness.",
              "reply_to": "Dave Hansen",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Dave Hansen",
              "summary": "Reviewer noted that the proposed change to separate PAGE_SIZE into PTE_SIZE and PG_SIZE would not significantly impact the KPTI pgd allocation size, as the current 8k allocation will fit within a 128k page.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "no clear technical objection",
                "acknowledgment of potential issues"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Yeah, I guess padding it out is ugly but effective.\n\nI was trying to figure out how it would apply to the KPTI pgd because we\njust flip bit 12 to switch between user and kernel PGDs. But I guess the\n8k of PGDs in the current allocation will fit fine in 128k, so it's\nweird but functional.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author acknowledges a need for further work on handling page faults and VMA alignment, but does not commit to a specific fix or timeline.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "acknowledges need for further work"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I was the first thing that came to mind. I have not put much time into\nit",
              "reply_to": "Matthew Wilcox",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author acknowledges a possible way to handle fragmentation, but doesn't address the main concern about TLB coalescing and misaligned cases.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "acknowledges a possible solution",
                "doesn't address main concern"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Yeah, that's a possible way. We would need to populate 16 page table\nentries of the parent page table. But you don't need to care about\nfragmentation within the page.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "Matthew Wilcox",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kalesh Singh",
              "summary": "Reviewer Kalesh Singh noted that the patch does not address the complexity of page fault handling for PTE_SIZE < PG_SIZE, including misaligned cases, and requested a substantial rework of page fault and VMA handling.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "On Thu, Feb 19, 2026 at 7:39AM David Hildenbrand (Arm)\n<david@kernel.org> wrote:",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kalesh Singh",
              "summary": "Reviewer Kalesh Singh noted that the current design does not enforce a larger granularity on VMAs to emulate a userspace page size, which is necessary for Android's use case of emulating 16KB devices on x86, and expressed interest in discussing whether this can be extended to cover their use case.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes",
                "expressed interest in discussion"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Hi Kiryl,\n\nI'd be interested to discuss this at LSFMM.\n\nOn Android, we have a separate but related use case: we emulate the\nuserspace page size on x86, primarily to enable app developers to\nconduct compatibility testing of their apps for 16KB Android devices.\n[1]\n\nIt mainly works by enforcing a larger granularity on the VMAs to\nemulate a userspace page size, somewhat similar to what David\nmentioned, while the underlying kernel still operates on a 4KB\ngranularity. [2]\n\nIIUC the current design would not enfore the larger granularity /\nalignment for VMAs to avoid breaking ABI. However, I'd be interest to\ndiscuss whether it can be extended to cover this usecase as well.\n\n[1]  https://developer.android.com/guide/practices/page-sizes#16kb-emulator\n[2] https://source.android.com/docs/core/architecture/16kb-page-size/getting-started-cf-x86-64-pgagnostic\n\nThanks,\nKalesh",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Zi Yan",
              "summary": "Reviewer suggested adding a super pageblock that consists of N consecutive pageblocks to enable anti-fragmentation at larger granularity, such as 1GB, and questioned whether 1GB free pages from memory compaction should go into the buddy allocator or not.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "debate",
                "question"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Right. The idea is to add super pageblock (or whatever name), which consists of N consecutive\npageblocks, so that anti fragmentation can work at larger granularity, e.g., 1GB, to create\nfree pages. Whether 1GB free pages from memory compaction need to go into buddy allocator\nor not is debatable.\n\n--\nBest Regards,\nYan, Zi",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Liam Howlett",
              "summary": "Reviewer Liam Howlett noted that increasing page size may not be beneficial for systems under memory pressure, as it can lead to increased CPU usage and reduced performance of primary workloads, while secondary tasks are prioritized.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "But we are in reclaim a lot more these days.  As I'm sure you are aware,\nwe are trying to maximize the resources (both cpu and ram) of any\nmachine powered on.  Entering reclaim will consume the cpu time and will\naffect other tasks.\n\nEspecially with multiple workload machines, the tendency is to have a\nprimary focus with the lower desired work being killed, if necessary.\nReducing the overhead just means more secondary tasks, or a bigger\nfootprint of the ones already executing.\n\nIncreasing the memory pressure will degrade the primary workload more\nfrequently, even if we recover enough to avoid OOMing the secondary.\n\nWhile in the struct page tax world, the secondary task would be killed\nafter a shorter (and less frequently executed) reclaim comes up short.\nSo, I would think that we would be degrading the primary workload in an\nattempt to keep the secondary alive?  Maybe I'm over-simplifying here?\n\nNear the other end of the spectrum, we have chromebooks that are\nconstantly in reclaim, even with 4k pages.  I guess these machines would\nbe destine to maintain the same page size they use today.  That is, this\nsolution for the struct page tax is only useful if you have a lot of\nmemory.  But then again, that's where the bookkeeping costs become hard\nto take.\n\nThanks,\nLiam",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "David Laight",
              "summary": "Reviewer David Laight noted that the patch does not address the issue of TLB coalescing, which is a significant performance concern for large page sizes.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "TLB coalescing",
                "performance concern"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "On Thu, 19 Feb 2026 15:08:51 +0000\nKiryl Shutsemau <kas@kernel.org> wrote:",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David Laight",
              "summary": "Reviewer questioned whether changing page size would affect buffers, mmap of kernel memory, and alignment of PCIe windows",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "requested clarification",
                "raised questions"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Also the 'random' buffers that are PAGE_SIZE rather than 4k.\n\nI also wonder how is affects mmap of kernel memory and the alignement\nof PCIe windows (etc).\n\n\tDavid",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer noted that allowing 64k page size on x86 could enable running emulated 64k processes alongside native 4k processes, avoiding the complexity of 'vma crosses base pages' handling.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "considering",
                "makes my head hurt"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Right, see the proposal from Dev on the list.\n\n From user-space POV, the pagesize would be 64K for these emulated \nprocesses. That is, VMAs must be suitable aligned etc.\n\nOne key thing I think is that you could run such emulated-64k process \n(that actually support it!) with 4k processes on the same machine, like \nArm is considering.\n\nYou would have no weird \"vma crosses base pages\" handling, which is just \nrather nasty and makes my head hurt.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David (Arm) expressed concerns that the proposed patch would reintroduce memory waste issues seen on ARM, where moving from 64k to 4k page size improved performance and reduced waste. He questioned whether the benefits of larger page sizes outweigh the drawbacks, particularly in light of hardware support for 64k pages.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes",
                "concerns about memory waste"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Well, yes, like Willy says, there are already similar custom solutions \nfor s390x and ppc.\n\nPasha talked recently about the memory waste of 16k kernel stacks and \nhow we would want to reduce that to 4k. In your proposal, it would be \n64k, unless you somehow manage to allocate multiple kernel stacks from \nthe same 64k page. My head hurts thinking about whether that could work, \nmaybe it could (no idea about guard pages in there, though).\n\n\nLet's take a look at the history of page size usage on Arm (people can \nfeel free to correct me):\n\n(1) Most distros were using 64k on Arm.\n\n(2) People realized that 64k was suboptimal many use cases (memory\n     waste for stacks, pagecache, etc) and started to switch to 4k. I\n     remember that mostly HPC-centric users sticked to 64k, but there was\n     also demand from others to be able to stay on 64k.\n\n(3) Arm improved performance on a 4k kernel by adding cont-pte support,\n     trying to get closer to 64k native performance.\n\n(4) Achieving 64k native performance is hard, which is why per-process\n     page sizes are being explored to get the best out of both worlds\n     (use 64k page size only where it really matters for performance).\n\nArm clearly has the added benefit of actually benefiting from hardware \nsupport for 64k.\n\nIIUC, what you are proposing feels a bit like traveling back in time \nwhen it comes to the memory waste problem that Arm users encountered.\n\nWhere do you see the big difference to 64k on Arm in your proposal? \nWould you currently also be running 64k Arm in production and the memory \nwaste etc is acceptable?\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "The author acknowledges that adopting a 64k base page size on x86 would be challenging due to existing legacy code, but does not commit to addressing this issue in the patch.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "acknowledges limitation",
                "does not commit to fix"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Well, it will drastically limit the adoption. We have too much legacy\nstuff on x86.",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author responded to a concern about kernel stack allocation in the context of large base page sizes by suggesting that vmalloc can handle sub-page granularity and asking if slab-allocated stacks would work for large page sizes.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "clarifying question",
                "explaining reasoning"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Kernel stack is allocated from vmalloc. I think mapping them with\nsub-page granularity should be doable.\n\nBTW, do you see any reason why slab-allocated stack wouldn't work for\nlarge base page sizes? There's no requirement for it be aligned to page\nor PTE, right?",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author responded to David's (Arm) feedback by stating that they don't see a significant difference between 64k pages on x86 and Arm, and are targeting the patch for machines with over 2TiB of RAM, where memory consumption can be traded off for scalability.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "acknowledged feedback",
                "provided additional context"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "That's the point. I don't see a big difference to 64k Arm. I want to\nbring this option to x86: at some machine size it makes sense trade\nmemory consumption for scalability. I am targeting it to machines with\nover 2TiB of RAM.\n\nBTW, we do run 64k Arm in our fleet. There's some growing pains, but it\nlooks good in general We have no plans to switch to 4k (or 16k) at the\nmoment. 512M THPs also look good on some workloads.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author acknowledges the need for ABI preservation and suggests adding a knob or personality(2) flag to enforce it, indicating a fix is planned.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "acknowledges need for fix",
                "suggests solution"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I don't want to break ABI, but might add a knob (maybe personality(2) ?)\nfor enforcement to see what breaks.\n\nIn general, I would prefer to advertise a new value to userspace that\nwould mean preferred virtual address space granularity.",
              "reply_to": "Kalesh Singh",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author responded to Liam's feedback by expressing uncertainty about understanding the point being made, suggesting that the balance between struct page overhead and page cache rounding overhead may not be a significant concern.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "uncertainty",
                "lack of clear resolution"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I am not sure I fully follow your point.\n\nSizing tasks and scheduling tasks between machines is hard in general.\nI don't think the balance between struct page tax and page cache\nrounding overhead is going to be the primary factor.",
              "reply_to": "Liam Howlett",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "The author acknowledged that smaller machines are not suitable for 64k pages, implying a design consideration is being addressed.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "acknowledged a design consideration",
                "implied further refinement needed"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Smaller machines are not target for 64k pages. They will not benefit\nfrom them.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "Liam Howlett",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Liam Howlett",
              "summary": "Reviewer Liam Howlett noted that increasing page size could lead to increased reclaim penalties due to more frequent reclaim operations, which is a trade-off not initially considered in the patch.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "trade-offs",
                "reclaim penalty"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I think there are more trade offs than what you listed.  It's still\nprobably worth doing, but I wanted to know if you though that this would\ncause us to spend more time in reclaim, which seems to be implied above.\nSo, another trade-off might be all the reclaim penalty being paid more\nfrequently?\n\n...\n\nThanks,\nLiam",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "The author is unsure about the benefits of reducing allocation events and reclaim work in the kernel, considering it too vague at this stage.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "uncertainty",
                "lack of clear resolution"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I am not sure.\n\nKernel would need to do less work in reclaim per unit of memory.\nDepending on workloads you might see less allocation events and\ntherefore less frequent reclaim.\n\nIt's all too hand-wavy at the stage.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "Liam Howlett",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David (Arm) expressed concerns about potential compatibility issues with legacy applications that hardcode a page size of 4k, and suggested exploring how much conversion would be required for Meta's fleet.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "compatibility",
                "legacy apps"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I'd assume that many applications nowadays can deal with differing page \nsizes (thanks to some other architectures paving the way).\n\nBut yes, some real legacy stuff, or stuff that ever only cared about \nintel still hardcodes pagesize=4k.\n\nIn Meta's fleet, I'd be quite interesting how much conversion there \nwould have to be done.\n\nFor legacy apps, you could still run them as 4k pagesize on the same \nsystem, of course.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David (Arm) expressed concern about the sub-page mapping mechanism, specifically how to handle the mapping count when only a part of the page is mapped.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested clarification",
                "expressed uncertainty"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I still have to wrap my head around the sub-page mapping here as well. \nIt's scary.\n\nRe mapcount: I think if any part of the page is mapped, it would be \nconsidered mapped -> mapcount += 1.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David noted that splitting PAGE_SIZE into PTE_SIZE and PG_SIZE may require additional metadata in the page table, specifically a dedicated type for kernel stack pages, which was previously proposed but not upstream.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes",
                "potential complexity"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I'd assume that would work. Devil is in the detail with these things \nbefore we have memdescs.\n\nE.g., page table have a dedicated type (PGTY_table) and store separate \nmetadata in the ptdesc. For kernel stack there was once a proposal to \nhave a type but it is not upstream.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David suggested simplifying the patch by removing or hiding sub-page mapping details, which are currently scattered throughout the arch code, making it harder to understand and review.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Okay, that's valuable information, thanks!\n\nBeing able to remove the sub-page mapping part (or being able to just \nhide it somewhere deep down in arch code) would make this a lot easier \nto digest.\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kalesh Singh",
              "summary": "Reviewer Kalesh Singh noted that the personality(2) system call may be too late to enforce larger VMA alignment, as initial userspace mappings are already established by then, and suggested using an early_param for global enforcement and a prctl/personality flag for per-process opt-in.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I think personality(2) may be too late? By the time a process invokes\nit, the initial userspace mappings (executable, linker for init, etc)\nare already established with the default granularity.\n\nTo handle this, I've been using an early_param to enforce the larger\nVMA alignment system-wide right from boot.\n\nPerhaps, something for global enforcement (Kconfig/early param) and a\nprctl/personality flag for per-process opt in?",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kalesh Singh",
              "summary": "Reviewer noted that userspace allocators may benefit from knowing the optimal page size (PG_SIZE) for layout optimization, while still being able to operate at PTE_SIZE granularity.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "no clear signal of approval or disapproval"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "This makes sense for maintaining ABI compatibility. Userspace\nallocators might want to optimize their layouts to match PG_SIZE while\nstill being able to operate at PTE_SIZE when needed.\n\n-- Kalesh",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kalesh Singh",
              "summary": "Reviewer noted that the patch's approach to separating PAGE_SIZE into PTE_SIZE and PG_SIZE may not be suitable for architectures other than x86, as it relies on the assumption that page table entries (PTEs) are aligned to a power of 2, which is not necessarily true for all architectures.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "architecture-specific concern",
                "potential portability issue"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "On Fri, Feb 20, 2026 at 8:30AM David Hildenbrand (Arm)\n<david@kernel.org> wrote:",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kalesh Singh",
              "summary": "Reviewer noted that ELF segment alignment is set to 4096 by default, which may cause issues when loading binaries on systems with a larger page size, and suggested this as the main source of potential problems.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "potential compatibility issue",
                "linker settings"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I think most issues will stem from linkers setting the default ELF\nsegment alignment (max-page-size) for x86 to 4096. So those ELFs will\nnot load correctly or at all on the larger emulated granularity.\n\n-- Kalesh",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            }
          ]
        },
        {
          "activity_type": "patch_reviewed",
          "subject": "Re: [LSF/MM/BPF TOPIC] 64k (or 16k) base page size on x86",
          "message_id": "aZcrj4iYLzXk7SPz@thinkstation",
          "url": "https://lore.kernel.org/all/aZcrj4iYLzXk7SPz@thinkstation/",
          "date": "2026-02-19T15:28:08Z",
          "in_reply_to": null,
          "ack_type": null,
          "is_ongoing": false,
          "submitted_date": null,
          "patch_summary": "",
          "analysis_source": "llm-per-reviewer",
          "review_comments": [
            {
              "author": "Pedro Falcato",
              "summary": "Reviewer Pedro Falcato questioned the relevance of the patch's idea given the existence of mTHP, which can be toggled via a sysfs interface",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "questioning the relevance",
                "existence of alternative solution"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Doesn't this idea make less sense these days, with mTHP? Simply by toggling one\nof the entries in /sys/kernel/mm/transparent_hugepage.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Pedro Falcato",
              "summary": "Reviewer suggested adding a global minimum page cache order to address scalability issues, mentioning that this would complement other ongoing work such as memory descriptor optimization and THP enhancements.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes",
                "complementary approach"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "We could perhaps add a way to enforce a min_order globally on the page cache,\nas a way to address it.\n\nThere are some points there which aren't addressed by mTHP work in any way\n(1G THPs for one), others which are being addressed separately (memdesc work\ntrying to cut down on struct page overhead).\n\n(I also don't understand your point about order-5 allocation, AFAIK pcp will\ncache up to COSTLY_ORDER (3) and PMD order, but I'm probably not seeing the\nfull picture)\n\n\n-- \nPedro",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer suggested emulating a larger page size (64K) for user space on x86 while still using 4K pages internally, which would reduce zone lock contention and other issues.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "When discussing per-process page sizes with Ryan and Dev, I mentioned \nthat having a larger emulated page size could be interesting for other \narchitectures as well.\n\nThat is, we would emulate a 64K page size on Intel for user space as \nwell, but let the OS work with 4K pages.\n\nWe'd only allocate+map large folios into user space + pagecache, but \nstill allow for page tables etc. to not waste memory.\n\nSo \"most\" of your allocations in the system would actually be at least \n64k, reducing zone lock contention etc.\n\n\nIt doesn't solve all the problems you wanted to tackle on your list \n(e.g., \"struct page\" overhead, which will be sorted out by memdescs).\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author responded to a concern that the mTHP (mmap Huge Pages) approach is not reliable by explaining it's 'best effort' and doesn't require worrying about fragmentation, as long as there's free memory.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "clarification",
                "explanation"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "mTHP is still best effort. This is way you don't need to care about\nfragmentation, you will get your 64k page as long as you have free\nmemory.",
              "reply_to": "Pedro Falcato",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "The author addressed Pedro Falcato's concern about the efficiency of page allocation with higher base page sizes, explaining that it reduces the work needed to merge/split buddy pages and makes serving large allocations cheaper.",
              "sentiment": "POSITIVE",
              "sentiment_signals": [
                "acknowledged a benefit",
                "explained reasoning"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "With higher base page size, page allocator doesn't need to do as much\nwork to merge/split buddy pages. So serving the same 2M as order-5 is\ncheaper than order-9.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "Pedro Falcato",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David noted that the proposed change would lead to reduced page splitting and merging due to larger allocation sizes, which would result in fewer TLB misses on average.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "signal1",
                "signal2"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I think the idea is that if most of your allocations (anon + pagecache) \nare 64k instead of 4k, on average, you'll just naturally do less merging \nsplitting.\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author disagrees that emulation can help reduce zone lock contention, expects contention to increase due to mixing 4k and 64k requests.",
              "sentiment": "CONTENTIOUS",
              "sentiment_signals": [
                "disagreement",
                "expectation_of_increased_contention"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I am not convinced emulation would help zone lock contention. I expect\ncontention to be higher if page allocator would see a mix of 4k and 64k\nrequests. It sounds like constant split/merge under the lock.",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author addressed David's concern about serving 1G pages out of the buddy allocator with a 4k order-0 page size, agreeing that it is not viable and questioning how to achieve 1G THPs without it.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "acknowledges limitation",
                "seeks clarification"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I don't think we can serve 1G pages out of buddy allocator with 4k\norder-0. And without it, I don't see how to get to a viable 1G THPs.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David (Arm) noted that if most allocations are larger than 64k, the benefits of splitting page size into PTE_SIZE and PG_SIZE may be diminished, as there will still be some splitting/merging required for smaller allocations.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "If most your allocations are larger, then there isn't that much \nsplitting/merging.\n\nThere will be some for the < 64k allocations of course, but when all \nuser space+page cache is >= 64 then the split/merge + zone lock should \nbe heavily reduced.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David expressed skepticism about the proposed patch, suggesting that previous work by Zi Yan could be leveraged to achieve the desired outcome.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "skepticism",
                "previous work"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Zi Yan was one working on this, and I think we had ideas on how to make \nthat work in the long run.\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Dave Hansen",
              "summary": "Reviewer Dave Hansen noted that a 64k page cache would consume around 5GB of extra memory for a kernel tree, and questioned the potential memory savings of the proposed change.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "questioning the effectiveness of the proposal",
                "highlighting a significant drawback"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "First of all, this looks like fun. Nice work! I'm not opposed at all in\nconcept to cleaning up things and doing the logical separation you\ndescribed to split buddy granularity and mapping granularity. That seems\nlike a worthy endeavor and some of the union/#define tricks look like a\nlikely viable way to do it incrementally.\n\nBut I don't think there's going to be a lot of memory savings in the\nend. Maybe this would bring the mem= hyperscalers back into the fold and\nhave them actually start using 'struct page' again for their VM memory.\nDunno.\n\nBut, let's look at my kernel directory and round the file sizes up to\n4k, 16k and 64k:\n\nfind .  -printf '%s\\n' | while read size; do echo\t\\\n\t\t$(((size + 0x0fff) & 0xfffff000))\t\\\n\t\t$(((size + 0x3fff) & 0xffffc000))\t\\\n\t\t$(((size + 0xffff) & 0xffff0000));\ndone\n\n... and add them all up:\n\n11,297,648 KB - on disk\n11,297,712 KB - in a 4k page cache\n12,223,488 KB - in a 16k page cache\n16,623,296 KB - in a 64k page cache\n\nSo a 64k page cache eats ~5GB of extra memory for a kernel tree (well,\n_my_ kernel tree). In other words, if you are looking for memory savings\non my laptop, you'll need ~300GB of RAM before 'struct page' overhead\noverwhelms the page cache bloat from a single kernel tree.\n\nThe whole kernel obviously isn't in the page cache all at the same time.\nThe page cache across the system is also obviously different than a\nkernel tree, but you get the point.\n\nThat's not to diminish how useful something like this might be,\nespecially for folks that are sensitive to 'struct page' overhead or\nallocator performance.\n\nBut, it will mostly be getting better performance at the _cost_ of\nconsuming more RAM, not saving RAM.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author asks for clarification on whether the proposed page size change should enforce alignment of user-space mappings.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "clarifying question"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Just to clarify, do you want it to be enforced on userspace ABI.\nLike, all mappings are 64k aligned?",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author acknowledges that memory waste due to page table overhead is a solvable issue and proposes using slab allocation, indicating a potential fix for this specific concern.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "acknowledges a problem",
                "proposes a solution"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Waste of memory for page table is solvable and pretty straight forward.\nMost of such cases can be solve mechanically by switching to slab.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Dave Hansen",
              "summary": "Reviewer Dave Hansen noted that the patch's approach to splitting PAGE_SIZE into PTE_SIZE and PG_SIZE may not be suitable for architectures other than x86, as it relies on the assumption that the page table entry (PTE) size is equal to the order-0 buddy allocation size.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "architecture-specific concerns"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "On 2/19/26 07:08, Kiryl Shutsemau wrote:\n...",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Dave Hansen",
              "summary": "Reviewer noted that the patch introduces a large number of changes across various files, primarily due to renaming, and requested further analysis on the actual code modifications.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "large number of changes",
                "primarily due to renaming"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "A few notes about the diffstats:\n\n$ git diff v6.17..HEAD arch/x86 | diffstat | tail -1\n 105 files changed, 874 insertions(+), 843 deletions(-)\n$ git diff v6.17..HEAD mm | diffstat | tail -1\n 53 files changed, 1136 insertions(+), 1069 deletions(-)\n\nThe vast, vast majority of this seems to be the renames. Stuff like:",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Dave Hansen",
              "summary": "Reviewer Dave Hansen noted that the patch requires careful auditing to separate mechanical and logic changes, expressing more concern about the latter.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "concerns about logic changes",
                "request for separation of mechanical and logic changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "That stuff obviously needs to be audited but it's far less concerning\nthan the logic changes.\n\nSo just for review sanity, if you go forward with this, I'd very much\nappreciate a strong separation of the purely mechanical bits from any\nlogic changes.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Dave Hansen",
              "summary": "Reviewer Dave Hansen noted that the proposed patch is not independent of other changes, specifically the conversion to ptdescs, and suggested that the series should focus on identifying additional requirements before proceeding.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "gates",
                "other things need to get done"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Others mentioned this, but I think this essentially gates what you are\ndoing behind a full tree conversion over to ptdescs.\n\nThe most useful thing we can do with this series is look at it and\ndecide what _other_ things need to get done before the tree could\npossibly go in that direction, like ptdesc or a the disambiguation\nbetween PTE_SIZE and PG_SIZE that you've kicked off here.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Matthew Wilcox",
              "summary": "Reviewer Matthew Wilcox expressed skepticism about the proposed slab allocation approach and suggested an alternative method of allocating a larger size and using it for multiple page table entries",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "skeptical",
                "alternative suggestion"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Have you looked at the s390/ppc implementations (yes, they're different,\nno, that sucks)?  slab seems like the wrong approach to me.\n\nThere's a third approach that I've never looked at which is to allocate\nthe larger size, then just use it for N consecutive entries.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Pedro Falcato",
              "summary": "Reviewer Pedro Falcato noted that the proposed patch would allow 90%+ of allocations to be 64k, which he hopes would yield a system where most allocations are 64K.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "no clear signal"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Yep. That plus slab_min_order would hopefully yield a system where 90%+\n(depending on how your filesystem's buffer cache works) allocations are 64K.\n\n-- \nPedro",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author acknowledged that the static struct page memory consumption is a problem, but noted that page cache rounding overhead can be managed by userspace and is reclaimable.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "acknowledged a concern",
                "provided explanation"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "That's fair.\n\nThe problem with struct page memory consumption is that it is static and\ncannot be reclaimed. You pay the struct page tax no matter what.\n\nPage cache rounding overhead can be large, but a motivated userspace can\nkeep it under control by avoiding splitting a dataset into many small\nfiles. And this memory is reclaimable.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "Dave Hansen",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author acknowledges that packing of page tables is not required for correctness and plans to implement a PoC without it, but notes they need to catch up on ptdescs",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "acknowledges need to learn more",
                "plans to implement PoC"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I have not followed ptdescs closely. Need to catch up.\n\nFor PoC, I will just waste full order-0 page for page table. Packing is\nnot required for correctness.",
              "reply_to": "Dave Hansen",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Dave Hansen",
              "summary": "Reviewer Dave Hansen noted that the proposed change to separate PAGE_SIZE into PTE_SIZE and PG_SIZE would not impact the KPTI pgd allocation size, as it currently fits within the 128k page size.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "no clear technical objection or suggestion"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Yeah, I guess padding it out is ugly but effective.\n\nI was trying to figure out how it would apply to the KPTI pgd because we\njust flip bit 12 to switch between user and kernel PGDs. But I guess the\n8k of PGDs in the current allocation will fit fine in 128k, so it's\nweird but functional.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author acknowledges a need for more work on handling page faults and VMA alignment, but does not commit to a specific fix or timeline.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "acknowledges need for more work",
                "does not commit to a specific fix"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I was the first thing that came to mind. I have not put much time into\nit",
              "reply_to": "Matthew Wilcox",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author acknowledges that populating 16 page table entries of the parent page table is a possible way to handle the new page size, but doesn't address concerns about fragmentation within the page.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "acknowledged alternative solution",
                "did not address concern"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Yeah, that's a possible way. We would need to populate 16 page table\nentries of the parent page table. But you don't need to care about\nfragmentation within the page.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "Matthew Wilcox",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kalesh Singh",
              "summary": "Reviewer noted that the patch introduces a new page size, but does not specify how to handle existing hardware that only supports 4k pages, and requested clarification on this point.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "On Thu, Feb 19, 2026 at 7:39AM David Hildenbrand (Arm)\n<david@kernel.org> wrote:",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kalesh Singh",
              "summary": "Reviewer Kalesh Singh noted that the current design does not enforce a larger granularity on VMAs to emulate a userspace page size, which is necessary for Android's compatibility testing of apps for 16KB devices, and expressed interest in discussing whether this can be extended to cover this use case.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes",
                "interested in discussion"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Hi Kiryl,\n\nI'd be interested to discuss this at LSFMM.\n\nOn Android, we have a separate but related use case: we emulate the\nuserspace page size on x86, primarily to enable app developers to\nconduct compatibility testing of their apps for 16KB Android devices.\n[1]\n\nIt mainly works by enforcing a larger granularity on the VMAs to\nemulate a userspace page size, somewhat similar to what David\nmentioned, while the underlying kernel still operates on a 4KB\ngranularity. [2]\n\nIIUC the current design would not enfore the larger granularity /\nalignment for VMAs to avoid breaking ABI. However, I'd be interest to\ndiscuss whether it can be extended to cover this usecase as well.\n\n[1]  https://developer.android.com/guide/practices/page-sizes#16kb-emulator\n[2] https://source.android.com/docs/core/architecture/16kb-page-size/getting-started-cf-x86-64-pgagnostic\n\nThanks,\nKalesh",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Zi Yan",
              "summary": "Reviewer suggested adding a super pageblock consisting of N consecutive pageblocks to enable anti-fragmentation at larger granularity, specifically 1GB, and questioned whether these free pages should go into the buddy allocator.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "debate",
                "question"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Right. The idea is to add super pageblock (or whatever name), which consists of N consecutive\npageblocks, so that anti fragmentation can work at larger granularity, e.g., 1GB, to create\nfree pages. Whether 1GB free pages from memory compaction need to go into buddy allocator\nor not is debatable.\n\n--\nBest Regards,\nYan, Zi",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Liam Howlett",
              "summary": "Reviewer Liam Howlett noted that increasing page size may not be beneficial for systems under heavy memory pressure, as it would increase CPU usage and potentially degrade primary workloads to keep secondary tasks alive.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "But we are in reclaim a lot more these days.  As I'm sure you are aware,\nwe are trying to maximize the resources (both cpu and ram) of any\nmachine powered on.  Entering reclaim will consume the cpu time and will\naffect other tasks.\n\nEspecially with multiple workload machines, the tendency is to have a\nprimary focus with the lower desired work being killed, if necessary.\nReducing the overhead just means more secondary tasks, or a bigger\nfootprint of the ones already executing.\n\nIncreasing the memory pressure will degrade the primary workload more\nfrequently, even if we recover enough to avoid OOMing the secondary.\n\nWhile in the struct page tax world, the secondary task would be killed\nafter a shorter (and less frequently executed) reclaim comes up short.\nSo, I would think that we would be degrading the primary workload in an\nattempt to keep the secondary alive?  Maybe I'm over-simplifying here?\n\nNear the other end of the spectrum, we have chromebooks that are\nconstantly in reclaim, even with 4k pages.  I guess these machines would\nbe destine to maintain the same page size they use today.  That is, this\nsolution for the struct page tax is only useful if you have a lot of\nmemory.  But then again, that's where the bookkeeping costs become hard\nto take.\n\nThanks,\nLiam",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "David Laight",
              "summary": "Reviewer David Laight pointed out that the patch does not handle the case where PTE_SIZE is less than PG_SIZE, including misaligned cases in page faults.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "On Thu, 19 Feb 2026 15:08:51 +0000\nKiryl Shutsemau <kas@kernel.org> wrote:",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David Laight",
              "summary": "Reviewer questioned the impact on 'random' buffers, mmap of kernel memory, and alignment of PCIe windows",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "unclear",
                "further investigation needed"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Also the 'random' buffers that are PAGE_SIZE rather than 4k.\n\nI also wonder how is affects mmap of kernel memory and the alignement\nof PCIe windows (etc).\n\n\tDavid",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer noted that allowing 64k (or 16k) page size on x86 would enable running emulated-64k processes alongside 4k processes on the same machine, avoiding 'vma crosses base pages' handling issues.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "considering",
                "makes my head hurt"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Right, see the proposal from Dev on the list.\n\n From user-space POV, the pagesize would be 64K for these emulated \nprocesses. That is, VMAs must be suitable aligned etc.\n\nOne key thing I think is that you could run such emulated-64k process \n(that actually support it!) with 4k processes on the same machine, like \nArm is considering.\n\nYou would have no weird \"vma crosses base pages\" handling, which is just \nrather nasty and makes my head hurt.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David (Arm) expressed concerns that the proposed patch to introduce a 64k base page size on x86 would reintroduce memory waste issues similar to those encountered by Arm users in the past, and questioned whether the benefits of the proposal outweigh the costs.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes",
                "concerns about memory waste"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Well, yes, like Willy says, there are already similar custom solutions \nfor s390x and ppc.\n\nPasha talked recently about the memory waste of 16k kernel stacks and \nhow we would want to reduce that to 4k. In your proposal, it would be \n64k, unless you somehow manage to allocate multiple kernel stacks from \nthe same 64k page. My head hurts thinking about whether that could work, \nmaybe it could (no idea about guard pages in there, though).\n\n\nLet's take a look at the history of page size usage on Arm (people can \nfeel free to correct me):\n\n(1) Most distros were using 64k on Arm.\n\n(2) People realized that 64k was suboptimal many use cases (memory\n     waste for stacks, pagecache, etc) and started to switch to 4k. I\n     remember that mostly HPC-centric users sticked to 64k, but there was\n     also demand from others to be able to stay on 64k.\n\n(3) Arm improved performance on a 4k kernel by adding cont-pte support,\n     trying to get closer to 64k native performance.\n\n(4) Achieving 64k native performance is hard, which is why per-process\n     page sizes are being explored to get the best out of both worlds\n     (use 64k page size only where it really matters for performance).\n\nArm clearly has the added benefit of actually benefiting from hardware \nsupport for 64k.\n\nIIUC, what you are proposing feels a bit like traveling back in time \nwhen it comes to the memory waste problem that Arm users encountered.\n\nWhere do you see the big difference to 64k on Arm in your proposal? \nWould you currently also be running 64k Arm in production and the memory \nwaste etc is acceptable?\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author acknowledges that a larger page size would limit adoption due to existing legacy code on x86 and expresses concern about its impact.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "acknowledges limitation",
                "expresses concern"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Well, it will drastically limit the adoption. We have too much legacy\nstuff on x86.",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author responded to David's concern about kernel stack allocation by suggesting that vmalloc can map the stack with sub-page granularity and asking if there's a reason why slab-allocated stack wouldn't work for large base page sizes.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "clarifying question",
                "explaining reasoning"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Kernel stack is allocated from vmalloc. I think mapping them with\nsub-page granularity should be doable.\n\nBTW, do you see any reason why slab-allocated stack wouldn't work for\nlarge base page sizes? There's no requirement for it be aligned to page\nor PTE, right?",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author responded to reviewer feedback by stating that they don't see a significant difference between 64k pages on x86 and Arm, and are targeting the patch for machines with over 2TiB of RAM, indicating no immediate plans to revise the patch.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "no clear resolution signal",
                "author provided additional context"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "That's the point. I don't see a big difference to 64k Arm. I want to\nbring this option to x86: at some machine size it makes sense trade\nmemory consumption for scalability. I am targeting it to machines with\nover 2TiB of RAM.\n\nBTW, we do run 64k Arm in our fleet. There's some growing pains, but it\nlooks good in general We have no plans to switch to 4k (or 16k) at the\nmoment. 512M THPs also look good on some workloads.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author acknowledges the need for ABI preservation and proposes adding a knob to enforce preferred virtual address space granularity, but does not commit to implementing it.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "acknowledges need for fix",
                "proposes potential solution"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I don't want to break ABI, but might add a knob (maybe personality(2) ?)\nfor enforcement to see what breaks.\n\nIn general, I would prefer to advertise a new value to userspace that\nwould mean preferred virtual address space granularity.",
              "reply_to": "Kalesh Singh",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author responded to Liam's point about balancing struct page size and page cache rounding overhead, expressing uncertainty about its significance.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "uncertainty",
                "lack of clear resolution"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I am not sure I fully follow your point.\n\nSizing tasks and scheduling tasks between machines is hard in general.\nI don't think the balance between struct page tax and page cache\nrounding overhead is going to be the primary factor.",
              "reply_to": "Liam Howlett",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "The author acknowledges that smaller machines won't benefit from the proposed 64k page size, but doesn't address the specific technical concerns raised by Liam Howlett.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "acknowledged a limitation",
                "didn't address technical concerns"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Smaller machines are not target for 64k pages. They will not benefit\nfrom them.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "Liam Howlett",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Liam Howlett",
              "summary": "Reviewer Liam Howlett noted that increasing page size could lead to increased reclaim penalties due to more frequent reclaim operations, which is a trade-off not previously considered.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "trade-offs",
                "reclaim penalty"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I think there are more trade offs than what you listed.  It's still\nprobably worth doing, but I wanted to know if you though that this would\ncause us to spend more time in reclaim, which seems to be implied above.\nSo, another trade-off might be all the reclaim penalty being paid more\nfrequently?\n\n...\n\nThanks,\nLiam",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author is unsure about the benefits of reducing allocation events and reclaim work, considers it too speculative at this stage.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "uncertainty",
                "speculation"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I am not sure.\n\nKernel would need to do less work in reclaim per unit of memory.\nDepending on workloads you might see less allocation events and\ntherefore less frequent reclaim.\n\nIt's all too hand-wavy at the stage.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "Liam Howlett",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David (Arm) expressed concerns about potential compatibility issues with legacy applications that hardcode PAGE_SIZE to 4KB, and suggested that conversion efforts would be necessary for such cases.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "potential compatibility issues",
                "conversion efforts"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I'd assume that many applications nowadays can deal with differing page \nsizes (thanks to some other architectures paving the way).\n\nBut yes, some real legacy stuff, or stuff that ever only cared about \nintel still hardcodes pagesize=4k.\n\nIn Meta's fleet, I'd be quite interesting how much conversion there \nwould have to be done.\n\nFor legacy apps, you could still run them as 4k pagesize on the same \nsystem, of course.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David expressed concern about sub-page mapping and its implications on mapcount, finding it 'scary' and requesting clarification.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes",
                "concerns"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I still have to wrap my head around the sub-page mapping here as well. \nIt's scary.\n\nRe mapcount: I think if any part of the page is mapped, it would be \nconsidered mapped -> mapcount += 1.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David noted that splitting PAGE_SIZE into PTE_SIZE and PG_SIZE may require additional metadata in the page table, specifically a dedicated type for kernel stack pages, which was previously proposed but not upstream.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I'd assume that would work. Devil is in the detail with these things \nbefore we have memdescs.\n\nE.g., page table have a dedicated type (PGTY_table) and store separate \nmetadata in the ptdesc. For kernel stack there was once a proposal to \nhave a type but it is not upstream.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David suggested simplifying the patch by removing or hiding the sub-page mapping part, which would make it easier to understand and implement.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Okay, that's valuable information, thanks!\n\nBeing able to remove the sub-page mapping part (or being able to just \nhide it somewhere deep down in arch code) would make this a lot easier \nto digest.\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kalesh Singh",
              "summary": "Reviewer Kalesh Singh noted that the personality(2) system call may be too late to enforce larger VMA alignment, as initial userspace mappings are already established by then, and suggested using an early_param for global enforcement and a prctl/personality flag for per-process opt-in.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I think personality(2) may be too late? By the time a process invokes\nit, the initial userspace mappings (executable, linker for init, etc)\nare already established with the default granularity.\n\nTo handle this, I've been using an early_param to enforce the larger\nVMA alignment system-wide right from boot.\n\nPerhaps, something for global enforcement (Kconfig/early param) and a\nprctl/personality flag for per-process opt in?",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kalesh Singh",
              "summary": "Reviewer noted that userspace allocators may benefit from knowing the optimal page size (PG_SIZE) for layout optimization, while still being able to operate at PTE_SIZE granularity.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "consideration",
                "optimization"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "This makes sense for maintaining ABI compatibility. Userspace\nallocators might want to optimize their layouts to match PG_SIZE while\nstill being able to operate at PTE_SIZE when needed.\n\n-- Kalesh",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kalesh Singh",
              "summary": "Reviewer noted that the patch does not handle page faults into anonymous mappings and file-CoW mappings correctly, as these cases require handling of misaligned PTE entries.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "On Fri, Feb 20, 2026 at 8:30AM David Hildenbrand (Arm)\n<david@kernel.org> wrote:",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kalesh Singh",
              "summary": "Reviewer noted that ELF segment alignment is set to 4k by default, which would cause issues when loading binaries on systems with a larger page size, and suggested this as a major concern.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "major_concern",
                "potential_breakage"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I think most issues will stem from linkers setting the default ELF\nsegment alignment (max-page-size) for x86 to 4096. So those ELFs will\nnot load correctly or at all on the larger emulated granularity.\n\n-- Kalesh",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            }
          ]
        }
      ],
      "patches_acked": [],
      "discussions_posted": [
        {
          "activity_type": "discussion_posted",
          "subject": "[LSF/MM/BPF TOPIC] 64k (or 16k) base page size on x86",
          "message_id": "aZcmlIF4bmG0twkp@thinkstation",
          "url": "https://lore.kernel.org/all/aZcmlIF4bmG0twkp@thinkstation/",
          "date": "2026-02-19T15:08:59Z",
          "in_reply_to": null,
          "ack_type": null,
          "is_ongoing": false,
          "submitted_date": null,
          "patch_summary": "",
          "analysis_source": "llm-per-reviewer",
          "review_comments": [
            {
              "author": "Pedro Falcato",
              "summary": "Reviewer Pedro Falcato questioned the relevance of the proposed patch, citing that modern systems can easily enable large pages using the transparent hugepages feature",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Doesn't this idea make less sense these days, with mTHP? Simply by toggling one\nof the entries in /sys/kernel/mm/transparent_hugepage.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Pedro Falcato",
              "summary": "Reviewer Pedro Falcato suggested adding a global minimum page cache order to address scalability issues, noting that some points are being addressed separately (e.g., memory descriptor work) and expressing confusion about the benefits of larger allocation sizes.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes",
                "confusion"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "We could perhaps add a way to enforce a min_order globally on the page cache,\nas a way to address it.\n\nThere are some points there which aren't addressed by mTHP work in any way\n(1G THPs for one), others which are being addressed separately (memdesc work\ntrying to cut down on struct page overhead).\n\n(I also don't understand your point about order-5 allocation, AFAIK pcp will\ncache up to COSTLY_ORDER (3) and PMD order, but I'm probably not seeing the\nfull picture)\n\n\n-- \nPedro",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer suggested emulating a larger page size (64k) for user space on x86 while still using 4k pages internally, reducing zone lock contention and other issues.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "When discussing per-process page sizes with Ryan and Dev, I mentioned \nthat having a larger emulated page size could be interesting for other \narchitectures as well.\n\nThat is, we would emulate a 64K page size on Intel for user space as \nwell, but let the OS work with 4K pages.\n\nWe'd only allocate+map large folios into user space + pagecache, but \nstill allow for page tables etc. to not waste memory.\n\nSo \"most\" of your allocations in the system would actually be at least \n64k, reducing zone lock contention etc.\n\n\nIt doesn't solve all the problems you wanted to tackle on your list \n(e.g., \"struct page\" overhead, which will be sorted out by memdescs).\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author responded to concerns about fragmentation in mTHP (Memory Transparent Huge Pages) by explaining that it's a best-effort mechanism, meaning users don't need to worry about fragmentation as long as there is free memory.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "clarification",
                "explanation"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "mTHP is still best effort. This is way you don't need to care about\nfragmentation, you will get your 64k page as long as you have free\nmemory.",
              "reply_to": "Pedro Falcato",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "The author addressed Pedro's concern about the efficiency of the page allocator by explaining that a higher base page size reduces the work needed to merge/split buddy pages, making it cheaper for the allocator to serve large allocations.",
              "sentiment": "POSITIVE",
              "sentiment_signals": [
                "acknowledged a benefit",
                "explained reasoning"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "With higher base page size, page allocator doesn't need to do as much\nwork to merge/split buddy pages. So serving the same 2M as order-5 is\ncheaper than order-9.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "Pedro Falcato",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David noted that the proposed change to use larger page sizes would lead to reduced page splitting and merging due to increased allocation size, but did not provide a clear technical solution or suggestion for implementation.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "no concrete suggestion",
                "neutral tone"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I think the idea is that if most of your allocations (anon + pagecache) \nare 64k instead of 4k, on average, you'll just naturally do less merging \nsplitting.\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author pushed back on reviewer's suggestion that emulation could help reduce zone lock contention, arguing it would actually increase contention due to frequent split/merge operations.",
              "sentiment": "CONTENTIOUS",
              "sentiment_signals": [
                "pushed_back",
                "disagreed"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I am not convinced emulation would help zone lock contention. I expect\ncontention to be higher if page allocator would see a mix of 4k and 64k\nrequests. It sounds like constant split/merge under the lock.",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author acknowledged that the current implementation cannot support 1G pages out of the buddy allocator, and expressed skepticism about achieving viable 1G THPs without this feature.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "acknowledged a limitation",
                "expressed skepticism"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I don't think we can serve 1G pages out of buddy allocator with 4k\norder-0. And without it, I don't see how to get to a viable 1G THPs.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David (Arm) noted that if most allocations are larger than 64k, the benefits of splitting page size into PTE_SIZE and PG_SIZE may be reduced, as there will still be some splitting/merging required for smaller allocations.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "If most your allocations are larger, then there isn't that much \nsplitting/merging.\n\nThere will be some for the < 64k allocations of course, but when all \nuser space+page cache is >= 64 then the split/merge + zone lock should \nbe heavily reduced.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David expressed skepticism about the proposed change, suggesting that previous work by Zi Yan might provide a solution and implying that more discussion is needed before proceeding.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "skepticism",
                "request for further discussion"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Zi Yan was one working on this, and I think we had ideas on how to make \nthat work in the long run.\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Dave Hansen",
              "summary": "Reviewer Dave Hansen questioned the effectiveness of separating buddy granularity and mapping granularity in terms of memory savings, citing a kernel tree analysis that showed a 64k page cache would consume an additional ~5GB of RAM.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes",
                "questioned effectiveness"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "First of all, this looks like fun. Nice work! I'm not opposed at all in\nconcept to cleaning up things and doing the logical separation you\ndescribed to split buddy granularity and mapping granularity. That seems\nlike a worthy endeavor and some of the union/#define tricks look like a\nlikely viable way to do it incrementally.\n\nBut I don't think there's going to be a lot of memory savings in the\nend. Maybe this would bring the mem= hyperscalers back into the fold and\nhave them actually start using 'struct page' again for their VM memory.\nDunno.\n\nBut, let's look at my kernel directory and round the file sizes up to\n4k, 16k and 64k:\n\nfind .  -printf '%s\\n' | while read size; do echo\t\\\n\t\t$(((size + 0x0fff) & 0xfffff000))\t\\\n\t\t$(((size + 0x3fff) & 0xffffc000))\t\\\n\t\t$(((size + 0xffff) & 0xffff0000));\ndone\n\n... and add them all up:\n\n11,297,648 KB - on disk\n11,297,712 KB - in a 4k page cache\n12,223,488 KB - in a 16k page cache\n16,623,296 KB - in a 64k page cache\n\nSo a 64k page cache eats ~5GB of extra memory for a kernel tree (well,\n_my_ kernel tree). In other words, if you are looking for memory savings\non my laptop, you'll need ~300GB of RAM before 'struct page' overhead\noverwhelms the page cache bloat from a single kernel tree.\n\nThe whole kernel obviously isn't in the page cache all at the same time.\nThe page cache across the system is also obviously different than a\nkernel tree, but you get the point.\n\nThat's not to diminish how useful something like this might be,\nespecially for folks that are sensitive to 'struct page' overhead or\nallocator performance.\n\nBut, it will mostly be getting better performance at the _cost_ of\nconsuming more RAM, not saving RAM.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author clarifies whether the proposed page size change should also affect user-space application binary interface (ABI), specifically asking if all mappings should be 64k aligned.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "clarifying question",
                "no clear resolution signal"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Just to clarify, do you want it to be enforced on userspace ABI.\nLike, all mappings are 64k aligned?",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author acknowledges that memory waste due to page table size is a solvable issue and proposes using slab allocation, indicating a planned fix.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "acknowledges a problem",
                "proposes a solution"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Waste of memory for page table is solvable and pretty straight forward.\nMost of such cases can be solve mechanically by switching to slab.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Dave Hansen",
              "summary": "Reviewer Dave Hansen noted that the patch introduces a new page size, but does not provide a clear plan for handling existing hardware and firmware that assumes a fixed PAGE_SIZE value, requesting more information on how to handle this transition.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes",
                "lack of clear plan"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "On 2/19/26 07:08, Kiryl Shutsemau wrote:\n...",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Dave Hansen",
              "summary": "Reviewer noted that the patch introduces a large number of changes across various files, primarily due to the renaming of macros and functions, which is overwhelming and may hide potential issues.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "large number of changes",
                "renaming of macros and functions"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "A few notes about the diffstats:\n\n$ git diff v6.17..HEAD arch/x86 | diffstat | tail -1\n 105 files changed, 874 insertions(+), 843 deletions(-)\n$ git diff v6.17..HEAD mm | diffstat | tail -1\n 53 files changed, 1136 insertions(+), 1069 deletions(-)\n\nThe vast, vast majority of this seems to be the renames. Stuff like:",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Dave Hansen",
              "summary": "Reviewer Dave Hansen expressed concern that the patch's logic changes need to be clearly separated from its mechanical changes, and requested a clear distinction between the two for review sanity.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested_changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "That stuff obviously needs to be audited but it's far less concerning\nthan the logic changes.\n\nSo just for review sanity, if you go forward with this, I'd very much\nappreciate a strong separation of the purely mechanical bits from any\nlogic changes.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Dave Hansen",
              "summary": "Reviewer Dave Hansen suggested that the patch should be gated behind a full tree conversion to ptdescs, as it essentially relies on this change. He also mentioned that looking at what other changes are needed before the tree can go in this direction is more useful than implementing the current series.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "gated behind another change",
                "need to look at other dependencies"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Others mentioned this, but I think this essentially gates what you are\ndoing behind a full tree conversion over to ptdescs.\n\nThe most useful thing we can do with this series is look at it and\ndecide what _other_ things need to get done before the tree could\npossibly go in that direction, like ptdesc or a the disambiguation\nbetween PTE_SIZE and PG_SIZE that you've kicked off here.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Matthew Wilcox",
              "summary": "Reviewer Matthew Wilcox questioned the proposed slab allocation approach and suggested an alternative method of allocating a larger page size and using it for multiple entries",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Have you looked at the s390/ppc implementations (yes, they're different,\nno, that sucks)?  slab seems like the wrong approach to me.\n\nThere's a third approach that I've never looked at which is to allocate\nthe larger size, then just use it for N consecutive entries.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Pedro Falcato",
              "summary": "Reviewer Pedro Falcato noted that the proposed change would result in 90%+ of allocations being 64k, depending on filesystem buffer cache behavior, and expressed hope for this outcome.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "hopeful",
                "optimistic"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Yep. That plus slab_min_order would hopefully yield a system where 90%+\n(depending on how your filesystem's buffer cache works) allocations are 64K.\n\n-- \nPedro",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author acknowledged that the static struct page memory consumption is a problem, but noted that page cache rounding overhead can be controlled by userspace, and emphasized that this memory is reclaimable.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "acknowledged",
                "emphasized"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "That's fair.\n\nThe problem with struct page memory consumption is that it is static and\ncannot be reclaimed. You pay the struct page tax no matter what.\n\nPage cache rounding overhead can be large, but a motivated userspace can\nkeep it under control by avoiding splitting a dataset into many small\nfiles. And this memory is reclaimable.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "Dave Hansen",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author acknowledged that packing of page tables is not necessary for correctness and plans to implement a PoC without it, but will need to catch up on ptdescs",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "acknowledged fix needed",
                "planned implementation"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I have not followed ptdescs closely. Need to catch up.\n\nFor PoC, I will just waste full order-0 page for page table. Packing is\nnot required for correctness.",
              "reply_to": "Dave Hansen",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Dave Hansen",
              "summary": "Reviewer Dave Hansen noted that the proposed change to use a larger page size would not cause issues with the kernel page table isolation (KPTI) due to the existing allocation of PGDs, which would fit within the new page size.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "no clear technical objection or suggestion"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Yeah, I guess padding it out is ugly but effective.\n\nI was trying to figure out how it would apply to the KPTI pgd because we\njust flip bit 12 to switch between user and kernel PGDs. But I guess the\n8k of PGDs in the current allocation will fit fine in 128k, so it's\nweird but functional.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author acknowledges that they haven't spent enough time on the patch and implies it's incomplete, but doesn't commit to revising or fixing specific issues.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "acknowledges incompleteness",
                "no clear plan for revision"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I was the first thing that came to mind. I have not put much time into\nit",
              "reply_to": "Matthew Wilcox",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author addresses Matthew Wilcox's concern that using 16k base pages would require populating 16 page table entries of the parent page table, and responds that fragmentation within the page is not a concern.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "clarification",
                "explanation"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Yeah, that's a possible way. We would need to populate 16 page table\nentries of the parent page table. But you don't need to care about\nfragmentation within the page.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "Matthew Wilcox",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kalesh Singh",
              "summary": "Reviewer noted that the patch does not address the issue of TLB coalescing and requested alignment to be naturally aligned for optimal performance.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes",
                "performance optimization"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "On Thu, Feb 19, 2026 at 7:39AM David Hildenbrand (Arm)\n<david@kernel.org> wrote:",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Kalesh Singh",
              "summary": "Reviewer Kalesh Singh noted that the current design would not enforce a larger granularity or alignment for VMAs to avoid breaking ABI, and requested discussion on whether it can be extended to cover Android's use case of emulating userspace page size on x86.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes",
                "discussion"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Hi Kiryl,\n\nI'd be interested to discuss this at LSFMM.\n\nOn Android, we have a separate but related use case: we emulate the\nuserspace page size on x86, primarily to enable app developers to\nconduct compatibility testing of their apps for 16KB Android devices.\n[1]\n\nIt mainly works by enforcing a larger granularity on the VMAs to\nemulate a userspace page size, somewhat similar to what David\nmentioned, while the underlying kernel still operates on a 4KB\ngranularity. [2]\n\nIIUC the current design would not enfore the larger granularity /\nalignment for VMAs to avoid breaking ABI. However, I'd be interest to\ndiscuss whether it can be extended to cover this usecase as well.\n\n[1]  https://developer.android.com/guide/practices/page-sizes#16kb-emulator\n[2] https://source.android.com/docs/core/architecture/16kb-page-size/getting-started-cf-x86-64-pgagnostic\n\nThanks,\nKalesh",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Zi Yan",
              "summary": "Reviewer suggested adding a super pageblock that consists of N consecutive pageblocks to enable anti-fragmentation at larger granularity, such as 1GB, and questioned whether free pages from memory compaction should go into the buddy allocator.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "questioning",
                "debating"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Right. The idea is to add super pageblock (or whatever name), which consists of N consecutive\npageblocks, so that anti fragmentation can work at larger granularity, e.g., 1GB, to create\nfree pages. Whether 1GB free pages from memory compaction need to go into buddy allocator\nor not is debatable.\n\n--\nBest Regards,\nYan, Zi",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Liam Howlett",
              "summary": "Reviewer Liam Howlett noted that increasing page size may not be beneficial for systems under memory pressure, as it can lead to increased CPU usage and affect primary workloads, while also being less effective on low-memory machines like Chromebooks.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes",
                "alternative perspective"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "But we are in reclaim a lot more these days.  As I'm sure you are aware,\nwe are trying to maximize the resources (both cpu and ram) of any\nmachine powered on.  Entering reclaim will consume the cpu time and will\naffect other tasks.\n\nEspecially with multiple workload machines, the tendency is to have a\nprimary focus with the lower desired work being killed, if necessary.\nReducing the overhead just means more secondary tasks, or a bigger\nfootprint of the ones already executing.\n\nIncreasing the memory pressure will degrade the primary workload more\nfrequently, even if we recover enough to avoid OOMing the secondary.\n\nWhile in the struct page tax world, the secondary task would be killed\nafter a shorter (and less frequently executed) reclaim comes up short.\nSo, I would think that we would be degrading the primary workload in an\nattempt to keep the secondary alive?  Maybe I'm over-simplifying here?\n\nNear the other end of the spectrum, we have chromebooks that are\nconstantly in reclaim, even with 4k pages.  I guess these machines would\nbe destine to maintain the same page size they use today.  That is, this\nsolution for the struct page tax is only useful if you have a lot of\nmemory.  But then again, that's where the bookkeeping costs become hard\nto take.\n\nThanks,\nLiam",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "David Laight",
              "summary": "Reviewer David Laight noted that the patch does not address the issue of TLB coalescing on non-aligned mappings, which could lead to performance issues.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "performance",
                "alignment"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "On Thu, 19 Feb 2026 15:08:51 +0000\nKiryl Shutsemau <kas@kernel.org> wrote:",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David Laight",
              "summary": "Reviewer David Laight raised concerns about potential issues with PAGE_SIZE being used for buffers, mmap of kernel memory, and alignment of PCIe windows, requesting further consideration.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Also the 'random' buffers that are PAGE_SIZE rather than 4k.\n\nI also wonder how is affects mmap of kernel memory and the alignement\nof PCIe windows (etc).\n\n\tDavid",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David (Arm) noted that the proposed change to use a 64k page size would allow for emulated processes to run on the same machine as native 4k processes, eliminating the need for 'vma crosses base pages' handling, which he finds complex.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Right, see the proposal from Dev on the list.\n\n From user-space POV, the pagesize would be 64K for these emulated \nprocesses. That is, VMAs must be suitable aligned etc.\n\nOne key thing I think is that you could run such emulated-64k process \n(that actually support it!) with 4k processes on the same machine, like \nArm is considering.\n\nYou would have no weird \"vma crosses base pages\" handling, which is just \nrather nasty and makes my head hurt.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David (Arm) expressed concerns that the proposed patch to introduce a 64k base page size on x86 would reintroduce memory waste issues similar to those encountered by Arm users in the past, and questioned whether the benefits of the proposal outweigh the potential drawbacks.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes",
                "concerns about memory waste"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Well, yes, like Willy says, there are already similar custom solutions \nfor s390x and ppc.\n\nPasha talked recently about the memory waste of 16k kernel stacks and \nhow we would want to reduce that to 4k. In your proposal, it would be \n64k, unless you somehow manage to allocate multiple kernel stacks from \nthe same 64k page. My head hurts thinking about whether that could work, \nmaybe it could (no idea about guard pages in there, though).\n\n\nLet's take a look at the history of page size usage on Arm (people can \nfeel free to correct me):\n\n(1) Most distros were using 64k on Arm.\n\n(2) People realized that 64k was suboptimal many use cases (memory\n     waste for stacks, pagecache, etc) and started to switch to 4k. I\n     remember that mostly HPC-centric users sticked to 64k, but there was\n     also demand from others to be able to stay on 64k.\n\n(3) Arm improved performance on a 4k kernel by adding cont-pte support,\n     trying to get closer to 64k native performance.\n\n(4) Achieving 64k native performance is hard, which is why per-process\n     page sizes are being explored to get the best out of both worlds\n     (use 64k page size only where it really matters for performance).\n\nArm clearly has the added benefit of actually benefiting from hardware \nsupport for 64k.\n\nIIUC, what you are proposing feels a bit like traveling back in time \nwhen it comes to the memory waste problem that Arm users encountered.\n\nWhere do you see the big difference to 64k on Arm in your proposal? \nWould you currently also be running 64k Arm in production and the memory \nwaste etc is acceptable?\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "The author acknowledges that a larger page size would limit the patch's adoption due to existing legacy code on x86, but does not indicate any plans for revision.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "acknowledges limitation",
                "no fix planned"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Well, it will drastically limit the adoption. We have too much legacy\nstuff on x86.",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author responded to a concern about kernel stack allocation on large base page sizes by suggesting that vmalloc can handle sub-page granularity and asking if slab-allocated stacks would work for large base page sizes.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "clarifying question",
                "explaining reasoning"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Kernel stack is allocated from vmalloc. I think mapping them with\nsub-page granularity should be doable.\n\nBTW, do you see any reason why slab-allocated stack wouldn't work for\nlarge base page sizes? There's no requirement for it be aligned to page\nor PTE, right?",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author responded to David's feedback by stating that they don't see a significant difference between 64k page size on x86 and Arm, and are targeting this option for machines with over 2TiB of RAM, indicating no immediate plans to revise the patch.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "no big difference",
                "targeting large machines"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "That's the point. I don't see a big difference to 64k Arm. I want to\nbring this option to x86: at some machine size it makes sense trade\nmemory consumption for scalability. I am targeting it to machines with\nover 2TiB of RAM.\n\nBTW, we do run 64k Arm in our fleet. There's some growing pains, but it\nlooks good in general We have no plans to switch to 4k (or 16k) at the\nmoment. 512M THPs also look good on some workloads.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author acknowledges the need for ABI preservation and proposes adding a knob or personality(2) flag to enforce it, without committing to specific implementation details.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "acknowledges need for fix",
                "proposes alternative solution"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I don't want to break ABI, but might add a knob (maybe personality(2) ?)\nfor enforcement to see what breaks.\n\nIn general, I would prefer to advertise a new value to userspace that\nwould mean preferred virtual address space granularity.",
              "reply_to": "Kalesh Singh",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author responded to Liam's feedback by expressing uncertainty about the importance of balancing struct page size and page cache rounding overhead, indicating that he doesn't think it will be a major issue.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "uncertainty",
                "lack of clear resolution"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I am not sure I fully follow your point.\n\nSizing tasks and scheduling tasks between machines is hard in general.\nI don't think the balance between struct page tax and page cache\nrounding overhead is going to be the primary factor.",
              "reply_to": "Liam Howlett",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "The author is addressing a concern about the applicability of 64k pages to smaller machines, stating that they will not benefit from this change and implying that it's not a priority.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "acknowledging feedback",
                "clarifying scope"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Smaller machines are not target for 64k pages. They will not benefit\nfrom them.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "Liam Howlett",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Liam Howlett",
              "summary": "Reviewer Liam Howlett noted that the proposed change may introduce additional reclaim penalties due to increased frequency of reclaim operations, which could be a significant trade-off.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "trade-offs",
                "reclaim penalty"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I think there are more trade offs than what you listed.  It's still\nprobably worth doing, but I wanted to know if you though that this would\ncause us to spend more time in reclaim, which seems to be implied above.\nSo, another trade-off might be all the reclaim penalty being paid more\nfrequently?\n\n...\n\nThanks,\nLiam",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kiryl Shutsemau (author)",
              "summary": "Author is unsure about the benefits of reducing allocation events and reclaim work, considering it too speculative at this stage.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "uncertainty",
                "speculation"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I am not sure.\n\nKernel would need to do less work in reclaim per unit of memory.\nDepending on workloads you might see less allocation events and\ntherefore less frequent reclaim.\n\nIt's all too hand-wavy at the stage.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
              "reply_to": "Liam Howlett",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer noted that many applications can adapt to different page sizes, but legacy code or Intel-specific code may hardcode PAGE_SIZE=4K and require conversion.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "raised a practical consideration",
                "did not express strong opinion"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I'd assume that many applications nowadays can deal with differing page \nsizes (thanks to some other architectures paving the way).\n\nBut yes, some real legacy stuff, or stuff that ever only cared about \nintel still hardcodes pagesize=4k.\n\nIn Meta's fleet, I'd be quite interesting how much conversion there \nwould have to be done.\n\nFor legacy apps, you could still run them as 4k pagesize on the same \nsystem, of course.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David expressed concern about sub-page mapping, specifically how to handle re-mapping a partially mapped page, and found the concept 'scary'.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "requested clarification",
                "expressed uncertainty"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "I still have to wrap my head around the sub-page mapping here as well. \nIt's scary.\n\nRe mapcount: I think if any part of the page is mapped, it would be \nconsidered mapped -> mapcount += 1.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David noted that implementing the proposed page size split would require careful consideration of metadata storage in page tables, specifically the use of dedicated types and separate metadata storage, as seen in PGTY_table and ptdesc.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I'd assume that would work. Devil is in the detail with these things \nbefore we have memdescs.\n\nE.g., page table have a dedicated type (PGTY_table) and store separate \nmetadata in the ptdesc. For kernel stack there was once a proposal to \nhave a type but it is not upstream.",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David suggested simplifying the patch by removing or hiding the sub-page mapping part, which would make it easier to understand and implement.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Okay, that's valuable information, thanks!\n\nBeing able to remove the sub-page mapping part (or being able to just \nhide it somewhere deep down in arch code) would make this a lot easier \nto digest.\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kalesh Singh",
              "summary": "Reviewer Kalesh Singh noted that the personality(2) system call may be too late to enforce larger VMA alignment, as initial userspace mappings are already established by then, and suggested using an early_param for global enforcement and a prctl/personality flag for per-process opt-in.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I think personality(2) may be too late? By the time a process invokes\nit, the initial userspace mappings (executable, linker for init, etc)\nare already established with the default granularity.\n\nTo handle this, I've been using an early_param to enforce the larger\nVMA alignment system-wide right from boot.\n\nPerhaps, something for global enforcement (Kconfig/early param) and a\nprctl/personality flag for per-process opt in?",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kalesh Singh",
              "summary": "Reviewer noted that userspace allocators may benefit from optimizing their layouts to match the new PG_SIZE, allowing them to take advantage of larger allocations while still being able to operate at PTE_SIZE when needed.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "no clear technical objection or suggestion"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "This makes sense for maintaining ABI compatibility. Userspace\nallocators might want to optimize their layouts to match PG_SIZE while\nstill being able to operate at PTE_SIZE when needed.\n\n-- Kalesh",
              "reply_to": "Kiryl Shutsemau",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kalesh Singh",
              "summary": "Reviewer Kalesh Singh noted that the patch's approach to splitting PAGE_SIZE into PTE_SIZE and PG_SIZE may not be suitable for architectures other than x86, as it relies on specific assumptions about page table entry alignment and TLB behavior.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "architecture-specific concerns"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "On Fri, Feb 20, 2026 at 8:30AM David Hildenbrand (Arm)\n<david@kernel.org> wrote:",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            },
            {
              "author": "Kalesh Singh",
              "summary": "Reviewer noted that ELF segment alignment is set to 4096 by default, which would cause issues when loading binaries on systems using a larger page size",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "potential compatibility issue",
                "linker settings"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I think most issues will stem from linkers setting the default ELF\nsegment alignment (max-page-size) for x86 to 4096. So those ELFs will\nnot load correctly or at all on the larger emulated granularity.\n\n-- Kalesh",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            }
          ]
        }
      ],
      "errors": []
    },
    {
      "name": "Leo Martins",
      "primary_email": "loemra.dev@gmail.com",
      "patches_submitted": [],
      "patches_reviewed": [],
      "patches_acked": [],
      "discussions_posted": [],
      "errors": []
    },
    {
      "name": "Mark Harmstone",
      "primary_email": "mark@harmstone.com",
      "patches_submitted": [
        {
          "activity_type": "patch_submitted",
          "subject": "[PATCH] btrfs: add check in remove_range_from_remap_tree() for a NULL block group",
          "message_id": "20260219163313.15888-1-mark@harmstone.com",
          "url": "https://lore.kernel.org/all/20260219163313.15888-1-mark@harmstone.com/",
          "date": "2026-02-19T16:33:18Z",
          "in_reply_to": null,
          "ack_type": null,
          "is_ongoing": false,
          "submitted_date": null,
          "patch_summary": "The patch adds a check in the remove_range_from_remap_tree() function to handle a NULL block group, preventing potential segfaults and returning an error instead.",
          "analysis_source": "llm",
          "review_comments": [
            {
              "author": "Filipe Manana",
              "summary": "Suggested using unlikely() to handle the unexpected NULL block group, and added a Fixes tag referencing the related patch in Linus' tree.",
              "sentiment": "POSITIVE",
              "sentiment_signals": [
                "positive suggestion"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "On Thu, Feb 19, 2026 at 4:33PM Mark Harmstone <mark@harmstone.com> wrote:\n>\n> Add a check in remove_range_from_remap_tree() after we call\n> btrfs_lookup_block_group(), to check if it is NULL. This shouldn't\n> happen, but if it does we at least get an error rather than a segfault.\n>\n> This fixes a bug introduced in the patch \"btrfs: handle deletions from\n> remapped block group\" in for-next.\n\nSame comment as for the other patch, that change is already in Linus'\ntree, so we can and should add here a:\n\nFixes: 979e1dc3d69e (\"btrfs: handle deletions from remapped block group\")\n\n\n>\n> Signed-off-by: Mark Harmstone <mark@harmstone.com>\n> Suggested-by: Chris Mason <clm@fb.com>\n> Link: https://lore.kernel.org/linux-btrfs/20260125125129.2245240-1-clm@meta.com/\n> ---\n>  fs/btrfs/relocation.c | 3 +++\n>  1 file changed, 3 insertions(+)\n>\n> diff --git a/fs/btrfs/relocation.c b/fs/btrfs/relocation.c\n> index f2abc5d625c1..679e551707f5 100644\n> --- a/fs/btrfs/relocation.c\n> +++ b/fs/btrfs/relocation.c\n> @@ -6003,6 +6003,9 @@ static int remove_range_from_remap_tree(struct btrfs_trans_handle *trans,\n>                 struct btrfs_block_group *dest_bg;\n>\n>                 dest_bg = btrfs_lookup_block_group(fs_info, new_addr);\n> +               if (!dest_bg)\n> +                       return -EUCLEAN;\n\nSince this is a EUCLEAN and highly unexpected, we can use unlikely\nhere, see: https://btrfs.readthedocs.io/en/latest/dev/Development-notes.html\n\nWith those two changes:\n\nReviewed-by: Filipe Manana <fdmanana@suse.com>\n\nThanks.\n\n> +\n>                 adjust_block_group_remap_bytes(trans, dest_bg, -overlap_length);\n>                 btrfs_put_block_group(dest_bg);\n>                 ret = btrfs_add_to_free_space_tree(trans,\n> --\n> 2.52.0\n>\n>\n\n",
              "reply_to": "Mark Harmstone",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            }
          ]
        },
        {
          "activity_type": "patch_submitted",
          "subject": "[PATCH] btrfs: fix transaction handle leaks in btrfs_last_identity_remap_gone()",
          "message_id": "20260219162151.5567-1-mark@harmstone.com",
          "url": "https://lore.kernel.org/all/20260219162151.5567-1-mark@harmstone.com/",
          "date": "2026-02-19T16:22:04Z",
          "in_reply_to": null,
          "ack_type": null,
          "is_ongoing": false,
          "submitted_date": null,
          "patch_summary": "The patch fixes a bug in the Btrfs file system where transaction handles are leaked when aborting transactions in btrfs_last_identity_remap_gone(). The fix involves adding calls to btrfs_end_transaction() after aborting transactions.",
          "analysis_source": "llm",
          "review_comments": [
            {
              "author": "Filipe Manana",
              "summary": "Suggested adding a Fixes tag to reference the commit ID of the related fix in Linus' tree. Provided Reviewed-by tag after verifying the patch.",
              "sentiment": "POSITIVE",
              "sentiment_signals": [
                "positive feedback"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "On Thu, Feb 19, 2026 at 4:24PM Mark Harmstone <mark@harmstone.com> wrote:\n>\n> btrfs_abort_transaction(), unlike btrfs_commit_transaction(), doesn't\n> also free the transaction handle. Fix the instances in\n> btrfs_last_identity_remap_gone() where we're also leaking the\n> transaction on abort.\n>\n> This fixes a bug introduced in \"btrfs: handle deletions from remapped\n> block group\" in for-next.\n\nIn for-next and in Linus' tree already, commit\n979e1dc3d69e4c825eec05d05d9567b251f6ec23.\nOnce you see David's pull request to Linus, you can assume the commit\nID is stable and it will match the commit ID in Linus' tree once\nmerged.\n\nSo we can, and should, add here:\n\nFixes: 979e1dc3d69e (\"btrfs: handle deletions from remapped block group\")\n\nWith that added:\n\nReviewed-by: Filipe Manana <fdmanana@suse.com>\n\nThanks.\n\n>\n> Signed-off-by: Mark Harmstone <mark@harmstone.com>\n> Suggested-by: Chris Mason <clm@fb.com>\n> Link: https://lore.kernel.org/linux-btrfs/20260125125129.2245240-1-clm@meta.com/\n> ---\n>  fs/btrfs/relocation.c | 3 +++\n>  1 file changed, 3 insertions(+)\n>\n> diff --git a/fs/btrfs/relocation.c b/fs/btrfs/relocation.c\n> index 8a8a66112d42..f2abc5d625c1 100644\n> --- a/fs/btrfs/relocation.c\n> +++ b/fs/btrfs/relocation.c\n> @@ -4715,6 +4715,7 @@ int btrfs_last_identity_remap_gone(struct btrfs_chunk_map *chunk_map,\n>         ret = btrfs_remove_dev_extents(trans, chunk_map);\n>         if (unlikely(ret)) {\n>                 btrfs_abort_transaction(trans, ret);\n> +               btrfs_end_transaction(trans);\n>                 return ret;\n>         }\n>\n> @@ -4724,6 +4725,7 @@ int btrfs_last_identity_remap_gone(struct btrfs_chunk_map *chunk_map,\n>                 if (unlikely(ret)) {\n>                         mutex_unlock(&trans->fs_info->chunk_mutex);\n>                         btrfs_abort_transaction(trans, ret);\n> +                       btrfs_end_transaction(trans);\n>                         return ret;\n>                 }\n>         }\n> @@ -4742,6 +4744,7 @@ int btrfs_last_identity_remap_gone(struct btrfs_chunk_map *chunk_map,\n>         ret = remove_chunk_stripes(trans, chunk_map, path);\n>         if (unlikely(ret)) {\n>                 btrfs_abort_transaction(trans, ret);\n> +               btrfs_end_transaction(trans);\n>                 return ret;\n>         }\n>\n> --\n> 2.52.0\n>\n>\n\n",
              "reply_to": "Mark Harmstone",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            }
          ]
        },
        {
          "activity_type": "patch_submitted",
          "subject": "[PATCH] btrfs: print correct subvol num if can't delete because of active swapfile",
          "message_id": "20260218120322.327-1-mark@harmstone.com",
          "url": "https://lore.kernel.org/all/20260218120322.327-1-mark@harmstone.com/",
          "date": "2026-02-18T12:03:29Z",
          "in_reply_to": null,
          "ack_type": null,
          "is_ongoing": true,
          "submitted_date": "2026-02-18",
          "patch_summary": "This patch fixes an error message in the btrfs_delete_subvolume() function, which incorrectly prints the parent subvolume number instead of the target subvolume number when a deletion is prevented due to an active swapfile.",
          "analysis_source": "llm",
          "review_comments": [
            {
              "author": "Filipe Manana",
              "summary": "Approved the patch with a Reviewed-by tag, indicating it looks good to them.",
              "sentiment": "POSITIVE",
              "sentiment_signals": [
                "APPROVAL"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "On Wed, Feb 18, 2026 at 12:03PM Mark Harmstone <mark@harmstone.com> wrote:\n>\n> Fix the error message in btrfs_delete_subvolume() if we can't delete a\n> subvolume because it has an active swapfile: we were printing the number\n> of the parent rather than the target.\n>\n> Fixes: 60021bd754c6 (\"btrfs: prevent subvol with swapfile from being deleted\")\n> Signed-off-by: Mark Harmstone <mark@harmstone.com>\n\nReviewed-by: Filipe Manana <fdmanana@suse.com>\n\nLooks good, thanks.\n\n> ---\n>  fs/btrfs/inode.c | 2 +-\n>  1 file changed, 1 insertion(+), 1 deletion(-)\n>\n> diff --git a/fs/btrfs/inode.c b/fs/btrfs/inode.c\n> index 4523b689711d..233d91556fe4 100644\n> --- a/fs/btrfs/inode.c\n> +++ b/fs/btrfs/inode.c\n> @@ -4804,7 +4804,7 @@ int btrfs_delete_subvolume(struct btrfs_inode *dir, struct dentry *dentry)\n>                 spin_unlock(&dest->root_item_lock);\n>                 btrfs_warn(fs_info,\n>                            \"attempt to delete subvolume %llu with active swapfile\",\n> -                          btrfs_root_id(root));\n> +                          btrfs_root_id(dest));\n>                 ret = -EPERM;\n>                 goto out_up_write;\n>         }\n> --\n> 2.52.0\n>\n>\n",
              "reply_to": "",
              "message_date": "2026-02-18",
              "analysis_source": "llm"
            },
            {
              "author": "Qu Wenruo",
              "summary": "Approved the patch with a Reviewed-by tag, indicating it looks good to them.",
              "sentiment": "POSITIVE",
              "sentiment_signals": [
                "APPROVAL"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "\n\n 2026/2/18 22:33, Mark Harmstone :\n> Fix the error message in btrfs_delete_subvolume() if we can't delete a\n> subvolume because it has an active swapfile: we were printing the number\n> of the parent rather than the target.\n> \n> Fixes: 60021bd754c6 (\"btrfs: prevent subvol with swapfile from being deleted\")\n> Signed-off-by: Mark Harmstone <mark@harmstone.com>\n\nReviewed-by: Qu Wenruo <wqu@suse.com>\n\nThanks,\nQu\n\n> ---\n>   fs/btrfs/inode.c | 2 +-\n>   1 file changed, 1 insertion(+), 1 deletion(-)\n> \n> diff --git a/fs/btrfs/inode.c b/fs/btrfs/inode.c\n> index 4523b689711d..233d91556fe4 100644\n> --- a/fs/btrfs/inode.c\n> +++ b/fs/btrfs/inode.c\n> @@ -4804,7 +4804,7 @@ int btrfs_delete_subvolume(struct btrfs_inode *dir, struct dentry *dentry)\n>   \t\tspin_unlock(&dest->root_item_lock);\n>   \t\tbtrfs_warn(fs_info,\n>   \t\t\t   \"attempt to delete subvolume %llu with active swapfile\",\n> -\t\t\t   btrfs_root_id(root));\n> +\t\t\t   btrfs_root_id(dest));\n>   \t\tret = -EPERM;\n>   \t\tgoto out_up_write;\n>   \t}\n\n\n",
              "reply_to": "",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            }
          ]
        },
        {
          "activity_type": "patch_submitted",
          "subject": "[PATCH] btrfs: fix error messages in btrfs_check_features()",
          "message_id": "20260218111346.31243-1-mark@harmstone.com",
          "url": "https://lore.kernel.org/all/20260218111346.31243-1-mark@harmstone.com/",
          "date": "2026-02-18T11:14:00Z",
          "in_reply_to": null,
          "ack_type": null,
          "is_ongoing": true,
          "submitted_date": "2026-02-18",
          "patch_summary": "The patch fixes error messages in btrfs_check_features() by changing the way unsupported flags are handled, reverting to the previous behavior of only printing unrecognized flags.",
          "analysis_source": "llm",
          "review_comments": [
            {
              "author": "Qu Wenruo",
              "summary": "Gave a Reviewed-by tag without providing any specific feedback or suggestions.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "\n\n\\u5728 2026/2/18 21:43, Mark Harmstone \\u5199\\u9053:\n> Commit d7f67ac9 introduced a regression when it comes to handling\n> unsupported incompat or compat_ro flags. Beforehand we only printed the\n> flags that we didn't recognize, afterwards we printed them all, which is\n> less useful. Fix the error handling so it behaves like it used to.\n> \n> Signed-off-by: Mark Harmstone <mark@harmstone.com>\n> Fixes: d7f67ac9a928 (\"btrfs: relax block-group-tree feature dependency checks\")\n\nReviewed-by: Qu Wenruo <wqu@suse.com>\n\nThanks,\nQu\n\n> ---\n>   fs/btrfs/disk-io.c | 6 +++---\n>   1 file changed, 3 insertions(+), 3 deletions(-)\n> \n> diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c\n> index f39008591631..7478d1c50cca 100644\n> --- a/fs/btrfs/disk-io.c\n> +++ b/fs/btrfs/disk-io.c\n> @@ -3176,7 +3176,7 @@ int btrfs_check_features(struct btrfs_fs_info *fs_info, bool is_rw_mount)\n>   \tif (incompat & ~BTRFS_FEATURE_INCOMPAT_SUPP) {\n>   \t\tbtrfs_err(fs_info,\n>   \t\t\"cannot mount because of unknown incompat features (0x%llx)\",\n> -\t\t    incompat);\n> +\t\t    incompat & ~BTRFS_FEATURE_INCOMPAT_SUPP);\n>   \t\treturn -EINVAL;\n>   \t}\n>   \n> @@ -3208,7 +3208,7 @@ int btrfs_check_features(struct btrfs_fs_info *fs_info, bool is_rw_mount)\n>   \tif (compat_ro_unsupp && is_rw_mount) {\n>   \t\tbtrfs_err(fs_info,\n>   \t\"cannot mount read-write because of unknown compat_ro features (0x%llx)\",\n> -\t\t       compat_ro);\n> +\t\t       compat_ro_unsupp);\n>   \t\treturn -EINVAL;\n>   \t}\n>   \n> @@ -3221,7 +3221,7 @@ int btrfs_check_features(struct btrfs_fs_info *fs_info, bool is_rw_mount)\n>   \t    !btrfs_test_opt(fs_info, NOLOGREPLAY)) {\n>   \t\tbtrfs_err(fs_info,\n>   \"cannot replay dirty log with unsupported compat_ro features (0x%llx), try rescue=nologreplay\",\n> -\t\t\t  compat_ro);\n> +\t\t\t  compat_ro_unsupp);\n>   \t\treturn -EINVAL;\n>   \t}\n>   \n\n\n",
              "reply_to": "",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            }
          ]
        }
      ],
      "patches_reviewed": [],
      "patches_acked": [],
      "discussions_posted": [],
      "errors": []
    },
    {
      "name": "Nhat Pham",
      "primary_email": "nphamcs@gmail.com",
      "patches_submitted": [],
      "patches_reviewed": [],
      "patches_acked": [],
      "discussions_posted": [],
      "errors": []
    },
    {
      "name": "Rik van Riel",
      "primary_email": "riel@surriel.com",
      "patches_submitted": [],
      "patches_reviewed": [
        {
          "activity_type": "patch_reviewed",
          "subject": "Re: [LSF/MM/BPF TOPIC] Beyond 2MB: Why Terabyte-Scale Machines Need 1GB Transparent Huge Pages",
          "message_id": "0c81121c23a9b1016425da100f11cb31feddd7ad.camel@surriel.com",
          "url": "https://lore.kernel.org/all/0c81121c23a9b1016425da100f11cb31feddd7ad.camel@surriel.com/",
          "date": "2026-02-19T19:03:13Z",
          "in_reply_to": null,
          "ack_type": null,
          "is_ongoing": false,
          "submitted_date": null,
          "patch_summary": "",
          "analysis_source": "llm-per-reviewer",
          "review_comments": [
            {
              "author": "David (Arm)",
              "summary": "Reviewer noted that migrating 1 GiB THPs to the page allocator instead of splitting them could be an interesting approach, but this method does not work when remapping a 1 GiB THP for use by PMDs or other mappings.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "There once was this proposal where we would, instead of splitting a THP, \nmigrate all memory away instead. That means, instead of splitting the 1 \nGiB THP, you would instead return it to the page allocator where \nsomebody else could use it.\n\nHowever, we cannot easily do the same when remapping a 1 GiB THP to be \nmapped by PMDs etc. I think there are examples where that just doesn't \nwork or is not desired.\n\nBut I considered that in general (avoid folio_split()) an interesting \napproach. The remapping part is a bit different though.\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Usama Arif",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Johannes Weiner",
              "summary": "The reviewer noted that preserving contiguity in TLB coalescing is beneficial and suggested doing this lazily by scanning deferred split lists when a larger page cannot be allocated, rather than splitting huge pages for virtual memory purposes.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": true,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "With TLB coalescing, there is benefit in preserving contiguity. If you\nlop off the last 4k of a 2M-backed range, a split still gives you 511\ncontiguously mapped pfns that can be coalesced.\n\nIt would be unfortunate to lose that for pure virtual memory splits,\nwhile there is no demand or no shortage of huge pages. But it might be\npossible to do this lazily, e.g. when somebody has trouble getting a\nlarger page, scan the deferred split lists for candidates to migrate.",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Zi Yan",
              "summary": "Reviewer Zi Yan suggested using non-uniform splitting for folios larger than the page size (PMD), allowing after-split folios to remain as large as possible.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "suggestion",
                "improvement"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "With mapping of folios > PMD with PMDs, you can use non uniform split to keep\nafter-split folios as large as possible.",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Zi Yan",
              "summary": "Reviewer Yan noted that hardware support for multiple TLB entries translating to the same physical frame would enable remapping of 1GB PUD mappings without splitting them into PMDs and PTEs, but without such hardware support, software will need to split the PUD.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "If HW can support multiple TLB entries translating to the same physical frame\nand allow translation priority of TLB entries, this remapping would be easy\nand we can still keep the 1GB PUD mapping. Basically, we can have 1GB TLB entry\npointing to the 1GB folio and another 4KB TLB entry pointing to the remapped\nregion and overriding the part in the original 1GB vaddr region.\n\nWithout that, SW will need to split the PUD into PMDs and PTEs.\n\n\nBest Regards,\nYan, Zi",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Zi Yan",
              "summary": "Reviewer Zi Yan questioned the relevance of CPU-specific features (PTE coalescing and contig PTE) to the patch's goal of introducing 1GB transparent huge pages, asking about PMD level ARM contiguous bit support.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "questioning",
                "request for clarification"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Which CPU are you referring to? AMD\\u2019s PTE coalescing works up to 32KB\nand ARM\\u2019s contig PTE supports larger sizes. BTW, do we have PMD level\nARM contiguous bit support?",
              "reply_to": "Johannes Weiner",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Zi Yan",
              "summary": "Reviewer noted that the patch does not handle the case where a 1GB THP is split into smaller pages, which would lead to memory waste and prevent partial reclaim.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Best Regards,\nYan, Zi",
              "reply_to": "Johannes Weiner",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Johannes Weiner",
              "summary": "Reviewer noted that any CPU coalescing benefits from 1GB THPs would be lost due to subsequent fragmentation into 4KB pagelets, making the large page size ineffective.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": true,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I'm not aware of a CPU that will coalesce the 511 entries into a\nsingle one. But *any* coalescing effects will be lost when the range\nis scattered into discontiguous 4k pagelets.",
              "reply_to": "Zi Yan",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Matthew Wilcox",
              "summary": "Reviewer Matthew Wilcox expressed concern about the feasibility of implementing 1GB transparent huge pages, citing potential hardware compatibility issues and warning that attempting to do so could lead to significant problems.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Uh, do you know any hardware that supports that?  Every CPU I'm familiar\nwith has notes suggesting that trying to do this will cause you to Have\nA Very Bad Day.",
              "reply_to": "Zi Yan",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Zi Yan",
              "summary": "Reviewer Yan noted that the TLB would need to handle sub-range translations for >PTE TLB hits, which could be complex and require additional data structures or rewalks of each sub-range.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "NEUTRAL"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "No. I was imagining it. :)\n\nBut thinking about it more, that means for every >PTE TLB hit, HW needs to know\nwhether any sub-range has an additional translation. It is easy if all sub-range\ntranslations are present in the TLB. Otherwise, a per sub range bitmap or rewalks\nof each sub range is needed. Never mind, thank you for waking me up in my\ndaydream.\n\nBest Regards,\nYan, Zi",
              "reply_to": "Matthew Wilcox",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Rik Riel",
              "summary": "Reviewer Rik Riel expressed concerns about the long-term implications of 1TB pages, suggesting that physical memory handling needs to be reevaluated for this scale. He proposed splitting system memory into movable and non-movable areas to prevent memory fragmentation and false OOMs.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes",
                "lack of clear direction"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "While I agree with the idea of starting simple, I think\nwe should ask the question of what we want physical memory\nhandling to look like if 1TB pages become more common,\nand applications start to rely on them to meet their\nperformance goals.\n\nWe have CMA balancing code today. It seems to work, but\nit likely is not the long term direction we want to go,\nmostly due to the way CMA does allocations.\n\nIt seems clear that in order to prevent memory fragmentation,\nwe need to split up system memory in some way between an area\nthat is used only for movable allocations, and an area where\nany kind of allocation can go.\n\nThis would need something similar to CMA balancing to prevent\nfalse OOMs for non-movable allocations.\n\nHowever, beyond that I really do not have any idea of what\nthings should look like.\n\nWhat do we want the kernel to do here?\n\n\n-- \nAll Rights Reversed.",
              "reply_to": "Usama Arif",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "Reviewer David (Arm) suggested that the buddy system should be taught to manage pages larger than its current maximum, and also proposed teaching compaction to compact/group on a larger granularity, noting potential complexities and limitations.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes",
                "complexity"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "This subtopic is certainly worth a separate session as it's quite \ninvolved, but I assume the right (tm) thing to do will be\n\n(a) Teaching the buddy to manage pages larger than the current maximum\n     buddy order. There will certainly be some work required to get to\n     that point (and Zi Yan already did some work). It might also be\n     fair to say that order > current  buddy order might behave different\n     at least to some degree (thinking about relation to zone alignment,\n     section sizes etc).\n\n     If we require vmemmap for these larger orders, maybe the buddy order\n     could more easily exceed the section size; I don't remember all of\n     the details why that limitation was in place (but one of them was\n     memmap continuity within a high-order buddy page, which is only\n     guaranteed within a memory section with CONFIG_SPARSEMEM).\n\n(b) Teaching compaction etc. to *also* compact/group on a larger\n     granularity (in addition to current sized pageblocks). When we\n     discussed that in the past we used the term superblock, that\n     Zi Yan just brought up again in another thread [1].\n\n\n\nThere was a proposal a while ago to internally separate zones into \nchunks of memory (I think the proposal used DRAM banks, such that you \ncould more easily power down unused DRAM banks). I'm not saying we \nshould do that, but maybe something like sub-zones could be something to \nexplore. Maybe not.\n\nBig, more complex topic :)\n\n\n[1] \nhttps://lore.kernel.org/r/34730030-48F6-4D0C-91EA-998A5AF93F5F@nvidia.com\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Rik Riel",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            }
          ]
        }
      ],
      "patches_acked": [],
      "discussions_posted": [],
      "errors": []
    },
    {
      "name": "Shakeel Butt",
      "primary_email": "shakeel.butt@linux.dev",
      "patches_submitted": [],
      "patches_reviewed": [],
      "patches_acked": [],
      "discussions_posted": [],
      "errors": []
    },
    {
      "name": "Usama Arif",
      "primary_email": "usama.arif@linux.dev",
      "patches_submitted": [],
      "patches_reviewed": [],
      "patches_acked": [],
      "discussions_posted": [
        {
          "activity_type": "discussion_posted",
          "subject": "[LSF/MM/BPF TOPIC] Beyond 2MB: Why Terabyte-Scale Machines Need 1GB Transparent Huge Pages",
          "message_id": "540c5c13-9cfb-44ea-b18f-8e4abff30a01@linux.dev",
          "url": "https://lore.kernel.org/all/540c5c13-9cfb-44ea-b18f-8e4abff30a01@linux.dev/",
          "date": "2026-02-19T15:53:55Z",
          "in_reply_to": null,
          "ack_type": null,
          "is_ongoing": false,
          "submitted_date": null,
          "patch_summary": "",
          "analysis_source": "llm-per-reviewer",
          "review_comments": [
            {
              "author": "David (Arm)",
              "summary": "Reviewer noted that migrating all memory away from a 1 GiB THP instead of splitting it could be an interesting approach, but this method does not work when remapping the THP to be mapped by PMDs or other cases where it is not desired.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "considered that in general (avoid folio_split()) an interesting approach"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "There once was this proposal where we would, instead of splitting a THP, \nmigrate all memory away instead. That means, instead of splitting the 1 \nGiB THP, you would instead return it to the page allocator where \nsomebody else could use it.\n\nHowever, we cannot easily do the same when remapping a 1 GiB THP to be \nmapped by PMDs etc. I think there are examples where that just doesn't \nwork or is not desired.\n\nBut I considered that in general (avoid folio_split()) an interesting \napproach. The remapping part is a bit different though.\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Usama Arif",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Johannes Weiner",
              "summary": "Reviewer noted that preserving contiguity in TLB coalescing is beneficial and suggested doing this lazily when huge pages are scarce, by scanning deferred split lists for migration candidates.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": true,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "With TLB coalescing, there is benefit in preserving contiguity. If you\nlop off the last 4k of a 2M-backed range, a split still gives you 511\ncontiguously mapped pfns that can be coalesced.\n\nIt would be unfortunate to lose that for pure virtual memory splits,\nwhile there is no demand or no shortage of huge pages. But it might be\npossible to do this lazily, e.g. when somebody has trouble getting a\nlarger page, scan the deferred split lists for candidates to migrate.",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Zi Yan",
              "summary": "Reviewer Zi Yan suggested using non-uniform splitting to maintain large page sizes after splitting folios greater than PMD, potentially improving performance.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": true,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "With mapping of folios > PMD with PMDs, you can use non uniform split to keep\nafter-split folios as large as possible.",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Zi Yan",
              "summary": "Reviewer Yan noted that hardware support for multiple TLB entries translating to the same physical frame would allow remapping of 1GB PUD mappings without splitting them into PMDs and PTEs, but without such hardware support, software will need to split the PUD.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": true,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "If HW can support multiple TLB entries translating to the same physical frame\nand allow translation priority of TLB entries, this remapping would be easy\nand we can still keep the 1GB PUD mapping. Basically, we can have 1GB TLB entry\npointing to the 1GB folio and another 4KB TLB entry pointing to the remapped\nregion and overriding the part in the original 1GB vaddr region.\n\nWithout that, SW will need to split the PUD into PMDs and PTEs.\n\n\nBest Regards,\nYan, Zi",
              "reply_to": "David (Arm)",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Zi Yan",
              "summary": "Reviewer Zi Yan questioned the relevance of specific CPU architectures to the proposed 1GB Transparent Huge Pages feature, pointing out that AMD's PTE coalescing works up to 32KB and ARM's contig PTE supports larger sizes, and asked about PMD level ARM contiguous bit support.",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "questioning the relevance of specific CPU architectures"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Which CPU are you referring to? AMD\\u2019s PTE coalescing works up to 32KB\nand ARM\\u2019s contig PTE supports larger sizes. BTW, do we have PMD level\nARM contiguous bit support?",
              "reply_to": "Johannes Weiner",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Zi Yan",
              "summary": "Reviewer noted that the patch does not handle the case where a 1GB huge page is split into smaller pages, which would lead to memory waste and make recovery from HWPOISON more difficult.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "memory accounting",
                "splitting"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "Best Regards,\nYan, Zi",
              "reply_to": "Johannes Weiner",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Johannes Weiner",
              "summary": "Reviewer Johannes Weiner noted that any coalescing benefits from large THPs would be lost due to fragmentation, as the memory range is split into smaller 4KB pagelets.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": true,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "I'm not aware of a CPU that will coalesce the 511 entries into a\nsingle one. But *any* coalescing effects will be lost when the range\nis scattered into discontiguous 4k pagelets.",
              "reply_to": "Zi Yan",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Matthew Wilcox",
              "summary": "The reviewer expressed concern about the feasibility of implementing 1GB transparent huge pages, citing potential hardware compatibility issues and warning that attempting to do so could result in significant problems.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "Uh, do you know any hardware that supports that?  Every CPU I'm familiar\nwith has notes suggesting that trying to do this will cause you to Have\nA Very Bad Day.",
              "reply_to": "Zi Yan",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Zi Yan",
              "summary": "Reviewer Yan noted that the TLB would need to handle additional translations for sub-ranges of a 1GB page, potentially requiring a per-sub-range bitmap or rewalks of each sub-range",
              "sentiment": "NEUTRAL",
              "sentiment_signals": [
                "reopened discussion on technical implications"
              ],
              "has_inline_review": false,
              "tags_given": [],
              "raw_body": "No. I was imagining it. :)\n\nBut thinking about it more, that means for every >PTE TLB hit, HW needs to know\nwhether any sub-range has an additional translation. It is easy if all sub-range\ntranslations are present in the TLB. Otherwise, a per sub range bitmap or rewalks\nof each sub range is needed. Never mind, thank you for waking me up in my\ndaydream.\n\nBest Regards,\nYan, Zi",
              "reply_to": "Matthew Wilcox",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "Rik Riel",
              "summary": "Reviewer Rik Riel questioned whether the current approach to handling large memory allocations is sustainable and asked for a long-term vision on how physical memory handling should change if 1TB pages become common, suggesting that movable and non-movable allocation areas may be necessary to prevent memory fragmentation.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes",
                "suggested further exploration"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "While I agree with the idea of starting simple, I think\nwe should ask the question of what we want physical memory\nhandling to look like if 1TB pages become more common,\nand applications start to rely on them to meet their\nperformance goals.\n\nWe have CMA balancing code today. It seems to work, but\nit likely is not the long term direction we want to go,\nmostly due to the way CMA does allocations.\n\nIt seems clear that in order to prevent memory fragmentation,\nwe need to split up system memory in some way between an area\nthat is used only for movable allocations, and an area where\nany kind of allocation can go.\n\nThis would need something similar to CMA balancing to prevent\nfalse OOMs for non-movable allocations.\n\nHowever, beyond that I really do not have any idea of what\nthings should look like.\n\nWhat do we want the kernel to do here?\n\n\n-- \nAll Rights Reversed.",
              "reply_to": "Usama Arif",
              "message_date": "2026-02-19",
              "analysis_source": "llm"
            },
            {
              "author": "David (Arm)",
              "summary": "The reviewer suggests that teaching the buddy to manage pages larger than the current maximum buddy order and modifying compaction algorithms to compact on a larger granularity are potential solutions for managing large memory sizes.",
              "sentiment": "NEEDS_WORK",
              "sentiment_signals": [
                "requested changes",
                "potential solutions"
              ],
              "has_inline_review": false,
              "tags_given": [
                "Reviewed-by"
              ],
              "raw_body": "This subtopic is certainly worth a separate session as it's quite \ninvolved, but I assume the right (tm) thing to do will be\n\n(a) Teaching the buddy to manage pages larger than the current maximum\n     buddy order. There will certainly be some work required to get to\n     that point (and Zi Yan already did some work). It might also be\n     fair to say that order > current  buddy order might behave different\n     at least to some degree (thinking about relation to zone alignment,\n     section sizes etc).\n\n     If we require vmemmap for these larger orders, maybe the buddy order\n     could more easily exceed the section size; I don't remember all of\n     the details why that limitation was in place (but one of them was\n     memmap continuity within a high-order buddy page, which is only\n     guaranteed within a memory section with CONFIG_SPARSEMEM).\n\n(b) Teaching compaction etc. to *also* compact/group on a larger\n     granularity (in addition to current sized pageblocks). When we\n     discussed that in the past we used the term superblock, that\n     Zi Yan just brought up again in another thread [1].\n\n\n\nThere was a proposal a while ago to internally separate zones into \nchunks of memory (I think the proposal used DRAM banks, such that you \ncould more easily power down unused DRAM banks). I'm not saying we \nshould do that, but maybe something like sub-zones could be something to \nexplore. Maybe not.\n\nBig, more complex topic :)\n\n\n[1] \nhttps://lore.kernel.org/r/34730030-48F6-4D0C-91EA-998A5AF93F5F@nvidia.com\n\n-- \nCheers,\n\nDavid",
              "reply_to": "Rik Riel",
              "message_date": "2026-02-20",
              "analysis_source": "llm"
            }
          ]
        }
      ],
      "errors": []
    }
  ]
}