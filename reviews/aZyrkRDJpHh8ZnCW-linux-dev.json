{
  "thread_id": "aZyrkRDJpHh8ZnCW@linux.dev",
  "subject": "Re: [PATCH v7 2/3] mm: vmscan: add cgroup IDs to vmscan tracepoints",
  "url": "https://lore.kernel.org/all/aZyrkRDJpHh8ZnCW@linux.dev/",
  "dates": {
    "2026-02-13": {
      "report_file": "2026-02-23_ollama_llama3.1-8b.html",
      "developer": "Shakeel Butt",
      "reviews": [
        {
          "author": "Thomas Ballasi (author)",
          "summary": "Author addressed a concern about passing memcg pointers as arguments in tracepoints instead of using memcg_id, explaining that this change was made to update Steven's patch and improve the code.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Changes in v6:\n- Updated Steven's patch with sign-off\n- Passed memcg pointers as arguments in tracepoints instead of memcg_id\n\nLink to v5:\nhttps://lore.kernel.org/linux-trace-kernel/20260122182510.2126-1-tballasi@linux.microsoft.com/\n\nSigned-off-by: Thomas Ballasi <tballasi@linux.microsoft.com>\n\nSteven Rostedt (1):\n  tracing: Add __event_in_*irq() helpers\n\nThomas Ballasi (2):\n  mm: vmscan: add cgroup IDs to vmscan tracepoints\n  mm: vmscan: add PIDs to vmscan tracepoints\n\n include/trace/events/vmscan.h              | 104 +++++++++++++--------\n include/trace/stages/stage3_trace_output.h |   8 ++\n include/trace/stages/stage7_class_define.h |  19 ++++\n mm/shrinker.c                              |   6 +-\n mm/vmscan.c                                |  17 ++--\n 5 files changed, 106 insertions(+), 48 deletions(-)\n\n-- \n2.33.8",
          "reply_to": "",
          "message_date": "2026-02-13"
        },
        {
          "author": "Thomas Ballasi (author)",
          "summary": "The author addressed a concern about tracepoint flags being stored in the event structure itself, instead of using helper macros that can access the flags portion of the event header. The author agreed to use these helper macros and added them to the patch.",
          "sentiment": "positive",
          "sentiment_signals": [
            "agreed",
            "added"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "From: Steven Rostedt <rostedt@goodmis.org>\n\nSome trace events want to expose in their output if they were triggered in\nan interrupt or softirq context. Instead of recording this in the event\nstructure itself, as this information is stored in the flags portion of\nthe event header, add helper macros that can be used in the print format:\n\n  TP_printk(\"val=%d %s\", __entry->val, __entry_in_irq() ? \"(in-irq)\" : \"\")\n\nThis will output \"(in-irq)\" for the event in the trace data if the event\nwas triggered in hard or soft interrupt context.\n\nLink: https://lore.kernel.org/all/20251229132942.31a2b583@gandalf.local.home/\n\nSigned-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>\nSigned-off-by: Thomas Ballasi <tballasi@linux.microsoft.com>\n---\n include/trace/stages/stage3_trace_output.h |  8 ++++++++\n include/trace/stages/stage7_class_define.h | 19 +++++++++++++++++++\n 2 files changed, 27 insertions(+)\n\ndiff --git a/include/trace/stages/stage3_trace_output.h b/include/trace/stages/stage3_trace_output.h\nindex 1e7b0bef95f52..53a23988a3b8a 100644\n--- a/include/trace/stages/stage3_trace_output.h\n+++ b/include/trace/stages/stage3_trace_output.h\n@@ -150,3 +150,11 @@\n \n #undef __get_buf\n #define __get_buf(len)\t\ttrace_seq_acquire(p, (len))\n+\n+#undef __event_in_hardirq\n+#undef __event_in_softirq\n+#undef __event_in_irq\n+\n+#define __event_in_hardirq()\t(__entry->ent.flags & TRACE_FLAG_HARDIRQ)\n+#define __event_in_softirq()\t(__entry->ent.flags & TRACE_FLAG_SOFTIRQ)\n+#define __event_in_irq()\t(__entry->ent.flags & (TRACE_FLAG_HARDIRQ | TRACE_FLAG_SOFTIRQ))\ndiff --git a/include/trace/stages/stage7_class_define.h b/include/trace/stages/stage7_class_define.h\nindex fcd564a590f43..47008897a7956 100644\n--- a/include/trace/stages/stage7_class_define.h\n+++ b/include/trace/stages/stage7_class_define.h\n@@ -26,6 +26,25 @@\n #undef __print_hex_dump\n #undef __get_buf\n \n+#undef __event_in_hardirq\n+#undef __event_in_softirq\n+#undef __event_in_irq\n+\n+/*\n+ * The TRACE_FLAG_* are enums. Instead of using TRACE_DEFINE_ENUM(),\n+ * use their hardcoded values. These values are parsed by user space\n+ * tooling elsewhere so they will never change.\n+ *\n+ * See \"enum trace_flag_type\" in linux/trace_events.h:\n+ *   TRACE_FLAG_HARDIRQ\n+ *   TRACE_FLAG_SOFTIRQ\n+ */\n+\n+/* This is what is displayed in the format files */\n+#define __event_in_hardirq()\t(REC->common_flags & 0x8)\n+#define __event_in_softirq()\t(REC->common_flags & 0x10)\n+#define __event_in_irq()\t(REC->common_flags & 0x18)\n+\n /*\n  * The below is not executed in the kernel. It is only what is\n  * displayed in the print format for userspace to parse.\n-- \n2.33.8",
          "reply_to": "",
          "message_date": "2026-02-13"
        },
        {
          "author": "Thomas Ballasi (author)",
          "summary": "The author addressed a concern about the default value of the memory cgroup ID (memcg_id) in vmscan tracepoints, explaining that it is defaulted to 0 for operations not associated with a specific cgroup.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Memory reclaim events are currently difficult to attribute to\nspecific cgroups, making debugging memory pressure issues\nchallenging.  This patch adds memory cgroup ID (memcg_id) to key\nvmscan tracepoints to enable better correlation and analysis.\n\nFor operations not associated with a specific cgroup, the field\nis defaulted to 0.\n\nSigned-off-by: Thomas Ballasi <tballasi@linux.microsoft.com>\n---\n include/trace/events/vmscan.h | 83 ++++++++++++++++++++---------------\n mm/shrinker.c                 |  6 ++-\n mm/vmscan.c                   | 17 +++----\n 3 files changed, 61 insertions(+), 45 deletions(-)\n\ndiff --git a/include/trace/events/vmscan.h b/include/trace/events/vmscan.h\nindex 490958fa10dee..1212f6a7c223e 100644\n--- a/include/trace/events/vmscan.h\n+++ b/include/trace/events/vmscan.h\n@@ -114,85 +114,92 @@ TRACE_EVENT(mm_vmscan_wakeup_kswapd,\n \n DECLARE_EVENT_CLASS(mm_vmscan_direct_reclaim_begin_template,\n \n-\tTP_PROTO(int order, gfp_t gfp_flags),\n+\tTP_PROTO(gfp_t gfp_flags, int order, struct mem_cgroup *memcg),\n \n-\tTP_ARGS(order, gfp_flags),\n+\tTP_ARGS(gfp_flags, order, memcg),\n \n \tTP_STRUCT__entry(\n-\t\t__field(\tint,\torder\t\t)\n \t\t__field(\tunsigned long,\tgfp_flags\t)\n+\t\t__field(\tu64,\tmemcg_id\t)\n+\t\t__field(\tint,\torder\t\t)\n \t),\n \n \tTP_fast_assign(\n-\t\t__entry->order\t\t= order;\n \t\t__entry->gfp_flags\t= (__force unsigned long)gfp_flags;\n+\t\t__entry->order\t\t= order;\n+\t\t__entry->memcg_id\t= mem_cgroup_id(memcg);\n \t),\n \n-\tTP_printk(\"order=%d gfp_flags=%s\",\n+\tTP_printk(\"order=%d gfp_flags=%s memcg_id=%llu\",\n \t\t__entry->order,\n-\t\tshow_gfp_flags(__entry->gfp_flags))\n+\t\tshow_gfp_flags(__entry->gfp_flags),\n+\t\t__entry->memcg_id)\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_begin_template, mm_vmscan_direct_reclaim_begin,\n \n-\tTP_PROTO(int order, gfp_t gfp_flags),\n+\tTP_PROTO(gfp_t gfp_flags, int order, struct mem_cgroup *memcg),\n \n-\tTP_ARGS(order, gfp_flags)\n+\tTP_ARGS(gfp_flags, order, memcg)\n );\n \n #ifdef CONFIG_MEMCG\n DEFINE_EVENT(mm_vmscan_direct_reclaim_begin_template, mm_vmscan_memcg_reclaim_begin,\n \n-\tTP_PROTO(int order, gfp_t gfp_flags),\n+\tTP_PROTO(gfp_t gfp_flags, int order, struct mem_cgroup *memcg),\n \n-\tTP_ARGS(order, gfp_flags)\n+\tTP_ARGS(gfp_flags, order, memcg)\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_begin_template, mm_vmscan_memcg_softlimit_reclaim_begin,\n \n-\tTP_PROTO(int order, gfp_t gfp_flags),\n+\tTP_PROTO(gfp_t gfp_flags, int order, struct mem_cgroup *memcg),\n \n-\tTP_ARGS(order, gfp_flags)\n+\tTP_ARGS(gfp_flags, order, memcg)\n );\n #endif /* CONFIG_MEMCG */\n \n DECLARE_EVENT_CLASS(mm_vmscan_direct_reclaim_end_template,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, struct mem_cgroup *memcg),\n \n-\tTP_ARGS(nr_reclaimed),\n+\tTP_ARGS(nr_reclaimed, memcg),\n \n \tTP_STRUCT__entry(\n \t\t__field(\tunsigned long,\tnr_reclaimed\t)\n+\t\t__field(\tu64,\tmemcg_id\t)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->nr_reclaimed\t= nr_reclaimed;\n+\t\t__entry->memcg_id\t= mem_cgroup_id(memcg);\n \t),\n \n-\tTP_printk(\"nr_reclaimed=%lu\", __entry->nr_reclaimed)\n+\tTP_printk(\"nr_reclaimed=%lu memcg_id=%llu\",\n+\t\t__entry->nr_reclaimed,\n+\t\t__entry->memcg_id)\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_direct_reclaim_end,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, struct mem_cgroup *memcg),\n \n-\tTP_ARGS(nr_reclaimed)\n+\tTP_ARGS(nr_reclaimed, memcg)\n );\n \n #ifdef CONFIG_MEMCG\n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_memcg_reclaim_end,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, struct mem_cgroup *memcg),\n \n-\tTP_ARGS(nr_reclaimed)\n+\tTP_ARGS(nr_reclaimed, memcg)\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_memcg_softlimit_reclaim_end,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, struct mem_cgroup *memcg),\n \n-\tTP_ARGS(nr_reclaimed)\n+\tTP_ARGS(nr_reclaimed, memcg)\n );\n #endif /* CONFIG_MEMCG */\n \n@@ -200,39 +207,42 @@ TRACE_EVENT(mm_shrink_slab_start,\n \tTP_PROTO(struct shrinker *shr, struct shrink_control *sc,\n \t\tlong nr_objects_to_shrink, unsigned long cache_items,\n \t\tunsigned long long delta, unsigned long total_scan,\n-\t\tint priority),\n+\t\tint priority, struct mem_cgroup *memcg),\n \n \tTP_ARGS(shr, sc, nr_objects_to_shrink, cache_items, delta, total_scan,\n-\t\tpriority),\n+\t\tpriority, memcg),\n \n \tTP_STRUCT__entry(\n \t\t__field(struct shrinker *, shr)\n \t\t__field(void *, shrink)\n-\t\t__field(int, nid)\n \t\t__field(long, nr_objects_to_shrink)\n \t\t__field(unsigned long, gfp_flags)\n \t\t__field(unsigned long, cache_items)\n \t\t__field(unsigned long long, delta)\n \t\t__field(unsigned long, total_scan)\n \t\t__field(int, priority)\n+\t\t__field(int, nid)\n+\t\t__field(u64, memcg_id)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->shr = shr;\n \t\t__entry->shrink = shr->scan_objects;\n-\t\t__entry->nid = sc->nid;\n \t\t__entry->nr_objects_to_shrink = nr_objects_to_shrink;\n \t\t__entry->gfp_flags = (__force unsigned long)sc->gfp_mask;\n \t\t__entry->cache_items = cache_items;\n \t\t__entry->delta = delta;\n \t\t__entry->total_scan = total_scan;\n \t\t__entry->priority = priority;\n+\t\t__entry->nid = sc->nid;\n+\t\t__entry->memcg_id = mem_cgroup_id(memcg);\n \t),\n \n-\tTP_printk(\"%pS %p: nid: %d objects to shrink %ld gfp_flags %s cache items %ld delta %lld total_scan %ld priority %d\",\n+\tTP_printk(\"%pS %p: nid: %d memcg_id: %llu objects to shrink %ld gfp_flags %s cache items %ld delta %lld total_scan %ld priority %d\",\n \t\t__entry->shrink,\n \t\t__entry->shr,\n \t\t__entry->nid,\n+\t\t__entry->memcg_id,\n \t\t__entry->nr_objects_to_shrink,\n \t\tshow_gfp_flags(__entry->gfp_flags),\n \t\t__entry->cache_items,\n@@ -243,35 +253,38 @@ TRACE_EVENT(mm_shrink_slab_start,\n \n TRACE_EVENT(mm_shrink_slab_end,\n \tTP_PROTO(struct shrinker *shr, int nid, int shrinker_retval,\n-\t\tlong unused_scan_cnt, long new_scan_cnt, long total_scan),\n+\t\tlong unused_scan_cnt, long new_scan_cnt, long total_scan, struct mem_cgroup *memcg),\n \n \tTP_ARGS(shr, nid, shrinker_retval, unused_scan_cnt, new_scan_cnt,\n-\t\ttotal_scan),\n+\t\ttotal_scan, memcg),\n \n \tTP_STRUCT__entry(\n \t\t__field(struct shrinker *, shr)\n-\t\t__field(int, nid)\n \t\t__field(void *, shrink)\n \t\t__field(long, unused_scan)\n \t\t__field(long, new_scan)\n-\t\t__field(int, retval)\n \t\t__field(long, total_scan)\n+\t\t__field(int, nid)\n+\t\t__field(int, retval)\n+\t\t__field(u64, memcg_id)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->shr = shr;\n-\t\t__entry->nid = nid;\n \t\t__entry->shrink = shr->scan_objects;\n \t\t__entry->unused_scan = unused_scan_cnt;\n \t\t__entry->new_scan = new_scan_cnt;\n-\t\t__entry->retval = shrinker_retval;\n \t\t__entry->total_scan = total_scan;\n+\t\t__entry->nid = nid;\n+\t\t__entry->retval = shrinker_retval;\n+\t\t__entry->memcg_id = mem_cgroup_id(memcg);\n \t),\n \n-\tTP_printk(\"%pS %p: nid: %d unused scan count %ld new scan count %ld total_scan %ld last shrinker return val %d\",\n+\tTP_printk(\"%pS %p: nid: %d memcg_id: %llu unused scan count %ld new scan count %ld total_scan %ld last shrinker return val %d\",\n \t\t__entry->shrink,\n \t\t__entry->shr,\n \t\t__entry->nid,\n+\t\t__entry->memcg_id,\n \t\t__entry->unused_scan,\n \t\t__entry->new_scan,\n \t\t__entry->total_scan,\n@@ -504,9 +517,9 @@ TRACE_EVENT(mm_vmscan_node_reclaim_begin,\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_node_reclaim_end,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, struct mem_cgroup *memcg),\n \n-\tTP_ARGS(nr_reclaimed)\n+\tTP_ARGS(nr_reclaimed, memcg)\n );\n \n TRACE_EVENT(mm_vmscan_throttled,\ndiff --git a/mm/shrinker.c b/mm/shrinker.c\nindex 4a93fd433689a..ddf784f996a59 100644\n--- a/mm/shrinker.c\n+++ b/mm/shrinker.c\n@@ -410,7 +410,8 @@ static unsigned long do_shrink_slab(struct shrink_control *shrinkctl,\n \ttotal_scan = min(total_scan, (2 * freeable));\n \n \ttrace_mm_shrink_slab_start(shrinker, shrinkctl, nr,\n-\t\t\t\t   freeable, delta, total_scan, priority);\n+\t\t\t\t   freeable, delta, total_scan, priority,\n+\t\t\t\t   shrinkctl->memcg);\n \n \t/*\n \t * Normally, we should not scan less than batch_size objects in one\n@@ -461,7 +462,8 @@ static unsigned long do_shrink_slab(struct shrink_control *shrinkctl,\n \t */\n \tnew_nr = add_nr_deferred(next_deferred, shrinker, shrinkctl);\n \n-\ttrace_mm_shrink_slab_end(shrinker, shrinkctl->nid, freed, nr, new_nr, total_scan);\n+\ttrace_mm_shrink_slab_end(shrinker, shrinkctl->nid, freed, nr, new_nr, total_scan,\n+\t\t\t\t shrinkctl->memcg);\n \treturn freed;\n }\n \ndiff --git a/mm/vmscan.c b/mm/vmscan.c\nindex 614ccf39fe3fa..9d512fb354fcd 100644\n--- a/mm/vmscan.c\n+++ b/mm/vmscan.c\n@@ -6603,11 +6603,11 @@ unsigned long try_to_free_pages(struct zonelist *zonelist, int order,\n \t\treturn 1;\n \n \tset_task_reclaim_state(current, &sc.reclaim_state);\n-\ttrace_mm_vmscan_direct_reclaim_begin(order, sc.gfp_mask);\n+\ttrace_mm_vmscan_direct_reclaim_begin(sc.gfp_mask, order, 0);\n \n \tnr_reclaimed = do_try_to_free_pages(zonelist, &sc);\n \n-\ttrace_mm_vmscan_direct_reclaim_end(nr_reclaimed);\n+\ttrace_mm_vmscan_direct_reclaim_end(nr_reclaimed, 0);\n \tset_task_reclaim_state(current, NULL);\n \n \treturn nr_reclaimed;\n@@ -6636,8 +6636,9 @@ unsigned long mem_cgroup_shrink_node(struct mem_cgroup *memcg,\n \tsc.gfp_mask = (gfp_mask & GFP_RECLAIM_MASK) |\n \t\t\t(GFP_HIGHUSER_MOVABLE & ~GFP_RECLAIM_MASK);\n \n-\ttrace_mm_vmscan_memcg_softlimit_reclaim_begin(sc.order,\n-\t\t\t\t\t\t      sc.gfp_mask);\n+\ttrace_mm_vmscan_memcg_softlimit_reclaim_begin(sc.gfp_mask,\n+\t\t\t\t\t\t      sc.order,\n+\t\t\t\t\t\t      memcg);\n \n \t/*\n \t * NOTE: Although we can get the priority field, using it\n@@ -6648,7 +6649,7 @@ unsigned long mem_cgroup_shrink_node(struct mem_cgroup *memcg,\n \t */\n \tshrink_lruvec(lruvec, &sc);\n \n-\ttrace_mm_vmscan_memcg_softlimit_reclaim_end(sc.nr_reclaimed);\n+\ttrace_mm_vmscan_memcg_softlimit_reclaim_end(sc.nr_reclaimed, memcg);\n \n \t*nr_scanned = sc.nr_scanned;\n \n@@ -6684,13 +6685,13 @@ unsigned long try_to_free_mem_cgroup_pages(struct mem_cgroup *memcg,\n \tstruct zonelist *zonelist = node_zonelist(numa_node_id(), sc.gfp_mask);\n \n \tset_task_reclaim_state(current, &sc.reclaim_state);\n-\ttrace_mm_vmscan_memcg_reclaim_begin(0, sc.gfp_mask);\n+\ttrace_mm_vmscan_memcg_reclaim_begin(sc.gfp_mask, 0, memcg);\n \tnoreclaim_flag = memalloc_noreclaim_save();\n \n \tnr_reclaimed = do_try_to_free_pages(zonelist, &sc);\n \n \tmemalloc_noreclaim_restore(noreclaim_flag);\n-\ttrace_mm_vmscan_memcg_reclaim_end(nr_reclaimed);\n+\ttrace_mm_vmscan_memcg_reclaim_end(nr_reclaimed, memcg);\n \tset_task_reclaim_state(current, NULL);\n \n \treturn nr_reclaimed;\n@@ -7642,7 +7643,7 @@ static unsigned long __node_reclaim(struct pglist_data *pgdat, gfp_t gfp_mask,\n \tdelayacct_freepages_end();\n \tpsi_memstall_leave(&pflags);\n \n-\ttrace_mm_vmscan_node_reclaim_end(sc->nr_reclaimed);\n+\ttrace_mm_vmscan_node_reclaim_end(sc->nr_reclaimed, 0);\n \n \treturn sc->nr_reclaimed;\n }\n-- \n2.33.8",
          "reply_to": "",
          "message_date": "2026-02-13"
        },
        {
          "author": "Thomas Ballasi (author)",
          "summary": "The author is addressing a concern about the reliability of PID detection in interrupt or RCU contexts, explaining that the PID field uses in_task() to safely access current->pid when in process context and sets it to -1 as a sentinel value otherwise.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "The changes aims at adding additionnal tracepoints variables to help\ndebuggers attribute them to specific processes.\n\nThe PID field uses in_task() to reliably detect when we're in process\ncontext and can safely access current->pid.  When not in process\ncontext (such as in interrupt or in an asynchronous RCU context), the\nfield is set to -1 as a sentinel value.\n\nSigned-off-by: Thomas Ballasi <tballasi@linux.microsoft.com>\n---\n include/trace/events/vmscan.h | 35 +++++++++++++++++++++++++----------\n 1 file changed, 25 insertions(+), 10 deletions(-)\n\ndiff --git a/include/trace/events/vmscan.h b/include/trace/events/vmscan.h\nindex 1212f6a7c223e..a68b712ef757a 100644\n--- a/include/trace/events/vmscan.h\n+++ b/include/trace/events/vmscan.h\n@@ -122,18 +122,22 @@ DECLARE_EVENT_CLASS(mm_vmscan_direct_reclaim_begin_template,\n \t\t__field(\tunsigned long,\tgfp_flags\t)\n \t\t__field(\tu64,\tmemcg_id\t)\n \t\t__field(\tint,\torder\t\t)\n+\t\t__field(\tint,\tpid\t\t)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->gfp_flags\t= (__force unsigned long)gfp_flags;\n \t\t__entry->order\t\t= order;\n+\t\t__entry->pid\t\t= current->pid;\n \t\t__entry->memcg_id\t= mem_cgroup_id(memcg);\n \t),\n \n-\tTP_printk(\"order=%d gfp_flags=%s memcg_id=%llu\",\n+\tTP_printk(\"order=%d gfp_flags=%s pid=%d memcg_id=%llu %s\",\n \t\t__entry->order,\n \t\tshow_gfp_flags(__entry->gfp_flags),\n-\t\t__entry->memcg_id)\n+\t\t__entry->pid,\n+\t\t__entry->memcg_id,\n+\t\t__event_in_irq() ? \"(in-irq)\" : \"\")\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_begin_template, mm_vmscan_direct_reclaim_begin,\n@@ -168,16 +172,20 @@ DECLARE_EVENT_CLASS(mm_vmscan_direct_reclaim_end_template,\n \tTP_STRUCT__entry(\n \t\t__field(\tunsigned long,\tnr_reclaimed\t)\n \t\t__field(\tu64,\tmemcg_id\t)\n+\t\t__field(\tint,\tpid\t\t)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->nr_reclaimed\t= nr_reclaimed;\n \t\t__entry->memcg_id\t= mem_cgroup_id(memcg);\n+\t\t__entry->pid\t\t= current->pid;\n \t),\n \n-\tTP_printk(\"nr_reclaimed=%lu memcg_id=%llu\",\n+\tTP_printk(\"nr_reclaimed=%lu pid=%d memcg_id=%llu %s\",\n \t\t__entry->nr_reclaimed,\n-\t\t__entry->memcg_id)\n+\t\t__entry->pid,\n+\t\t__entry->memcg_id,\n+\t\t__event_in_irq() ? \"(in-irq)\" : \"\")\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_direct_reclaim_end,\n@@ -220,9 +228,10 @@ TRACE_EVENT(mm_shrink_slab_start,\n \t\t__field(unsigned long, cache_items)\n \t\t__field(unsigned long long, delta)\n \t\t__field(unsigned long, total_scan)\n+\t\t__field(u64, memcg_id)\n \t\t__field(int, priority)\n \t\t__field(int, nid)\n-\t\t__field(u64, memcg_id)\n+\t\t__field(int, pid)\n \t),\n \n \tTP_fast_assign(\n@@ -236,19 +245,22 @@ TRACE_EVENT(mm_shrink_slab_start,\n \t\t__entry->priority = priority;\n \t\t__entry->nid = sc->nid;\n \t\t__entry->memcg_id = mem_cgroup_id(memcg);\n+\t\t__entry->pid = current->pid;\n \t),\n \n-\tTP_printk(\"%pS %p: nid: %d memcg_id: %llu objects to shrink %ld gfp_flags %s cache items %ld delta %lld total_scan %ld priority %d\",\n+\tTP_printk(\"%pS %p: nid: %d pid: %d memcg_id: %llu objects to shrink %ld gfp_flags %s cache items %ld delta %lld total_scan %ld priority %d %s\",\n \t\t__entry->shrink,\n \t\t__entry->shr,\n \t\t__entry->nid,\n+\t\t__entry->pid,\n \t\t__entry->memcg_id,\n \t\t__entry->nr_objects_to_shrink,\n \t\tshow_gfp_flags(__entry->gfp_flags),\n \t\t__entry->cache_items,\n \t\t__entry->delta,\n \t\t__entry->total_scan,\n-\t\t__entry->priority)\n+\t\t__entry->priority,\n+\t\t__event_in_irq() ? \"(in-irq)\" : \"\")\n );\n \n TRACE_EVENT(mm_shrink_slab_end,\n@@ -266,29 +278,32 @@ TRACE_EVENT(mm_shrink_slab_end,\n \t\t__field(long, total_scan)\n \t\t__field(int, nid)\n \t\t__field(int, retval)\n+\t\t__field(int, pid)\n \t\t__field(u64, memcg_id)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->shr = shr;\n-\t\t__entry->shrink = shr->scan_objects;\n \t\t__entry->unused_scan = unused_scan_cnt;\n \t\t__entry->new_scan = new_scan_cnt;\n \t\t__entry->total_scan = total_scan;\n \t\t__entry->nid = nid;\n \t\t__entry->retval = shrinker_retval;\n+\t\t__entry->pid = current->pid;\n \t\t__entry->memcg_id = mem_cgroup_id(memcg);\n \t),\n \n-\tTP_printk(\"%pS %p: nid: %d memcg_id: %llu unused scan count %ld new scan count %ld total_scan %ld last shrinker return val %d\",\n+\tTP_printk(\"%pS %p: nid: %d pid: %d memcg_id: %llu unused scan count %ld new scan count %ld total_scan %ld last shrinker return val %d %s\",\n \t\t__entry->shrink,\n \t\t__entry->shr,\n \t\t__entry->nid,\n+\t\t__entry->pid,\n \t\t__entry->memcg_id,\n \t\t__entry->unused_scan,\n \t\t__entry->new_scan,\n \t\t__entry->total_scan,\n-\t\t__entry->retval)\n+\t\t__entry->retval,\n+\t\t__event_in_irq() ? \"(in-irq)\" : \"\")\n );\n \n TRACE_EVENT(mm_vmscan_lru_isolate,\n-- \n2.33.8",
          "reply_to": "",
          "message_date": "2026-02-13"
        }
      ],
      "analysis_source": "llm-per-reviewer"
    },
    "2026-02-16": {
      "report_file": "2026-02-23_ollama_llama3.1-8b.html",
      "developer": "Shakeel Butt",
      "reviews": [
        {
          "author": "Usama Arif",
          "summary": "Reviewer questioned the removal of __entry->shrink in this patch, wondering if it was an intentional change, and implied that its presence is still necessary for some functionality.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "unclear intention",
            "potential bug"
          ],
          "has_inline_review": true,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "__entry->shrink is removed here, but still printed below. Was this an intended\nchange of this commit?",
          "reply_to": "Thomas Ballasi",
          "message_date": "2026-02-16"
        },
        {
          "author": "Steven Rostedt",
          "summary": "reviewer noted that the patch does not handle the case where a cgroup is being moved to another parent, and suggested adding a check for this scenario\n\nreviewer made a lighthearted comment about the patch author typing tracepoint names manually, rather than copying them from another file",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "On Mon, 16 Feb 2026 08:13:21 -0800\nUsama Arif <usama.arif@linux.dev> wrote:\n\n---\n\nYeah. That's when you should have done \"cut-and-paste\" but instead just\ntyped it in by memory :-p\n\n-- Steve",
          "reply_to": "Usama Arif",
          "message_date": "2026-02-16"
        }
      ],
      "analysis_source": "llm-per-reviewer"
    },
    "2026-02-23": {
      "report_file": "2026-02-23_ollama_llama3.1-8b.html",
      "developer": "Shakeel Butt",
      "reviews": [
        {
          "author": "Thomas Ballasi (author)",
          "summary": "Author acknowledged a concern about the __entry_in_irq() macro and confirmed that it was renamed to __event_in_irq() in v6, which addressed the issue.",
          "sentiment": "positive",
          "sentiment_signals": [
            "acknowledged",
            "confirmed"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Changes in v6:\n- Edited __entry_in_irq() to __event_in_irq() in corresponding commit\n  message\n- Restore an entry that was removed inadvertently\n\nLink to v6:\nhttps://lore.kernel.org/linux-trace-kernel/20260213181537.54350-1-tballasi@linux.microsoft.com/\n\nSigned-off-by: Thomas Ballasi <tballasi@linux.microsoft.com>\n\nSteven Rostedt (1):\n  tracing: Add __event_in_*irq() helpers\n\nThomas Ballasi (2):\n  mm: vmscan: add cgroup IDs to vmscan tracepoints\n  mm: vmscan: add PIDs to vmscan tracepoints\n\n include/trace/events/vmscan.h              | 103 +++++++++++++--------\n include/trace/stages/stage3_trace_output.h |   8 ++\n include/trace/stages/stage7_class_define.h |  19 ++++\n mm/shrinker.c                              |   6 +-\n mm/vmscan.c                                |  17 ++--\n 5 files changed, 106 insertions(+), 47 deletions(-)\n\n-- \n2.33.8",
          "reply_to": "",
          "message_date": "2026-02-23"
        },
        {
          "author": "Thomas Ballasi (author)",
          "summary": "The author is addressing a concern about tracepoint flags and how they are stored in the event header, specifically that some events want to expose if triggered in interrupt or softirq context. The author agrees that instead of recording this information directly in the event structure, helper macros should be used to access the flags portion of the event header. A fix is planned for v2.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "acknowledged a need for restructuring",
            "agreed to restructure in v2"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "From: Steven Rostedt <rostedt@goodmis.org>\n\nSome trace events want to expose in their output if they were triggered in\nan interrupt or softirq context. Instead of recording this in the event\nstructure itself, as this information is stored in the flags portion of\nthe event header, add helper macros that can be used in the print format:\n\n  TP_printk(\"val=%d %s\", __entry->val, __event_in_irq() ? \"(in-irq)\" : \"\")\n\nThis will output \"(in-irq)\" for the event in the trace data if the event\nwas triggered in hard or soft interrupt context.\n\nLink: https://lore.kernel.org/all/20251229132942.31a2b583@gandalf.local.home/\n\nSigned-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>\nSigned-off-by: Thomas Ballasi <tballasi@linux.microsoft.com>\n---\n include/trace/stages/stage3_trace_output.h |  8 ++++++++\n include/trace/stages/stage7_class_define.h | 19 +++++++++++++++++++\n 2 files changed, 27 insertions(+)\n\ndiff --git a/include/trace/stages/stage3_trace_output.h b/include/trace/stages/stage3_trace_output.h\nindex 1e7b0bef95f52..53a23988a3b8a 100644\n--- a/include/trace/stages/stage3_trace_output.h\n+++ b/include/trace/stages/stage3_trace_output.h\n@@ -150,3 +150,11 @@\n \n #undef __get_buf\n #define __get_buf(len)\t\ttrace_seq_acquire(p, (len))\n+\n+#undef __event_in_hardirq\n+#undef __event_in_softirq\n+#undef __event_in_irq\n+\n+#define __event_in_hardirq()\t(__entry->ent.flags & TRACE_FLAG_HARDIRQ)\n+#define __event_in_softirq()\t(__entry->ent.flags & TRACE_FLAG_SOFTIRQ)\n+#define __event_in_irq()\t(__entry->ent.flags & (TRACE_FLAG_HARDIRQ | TRACE_FLAG_SOFTIRQ))\ndiff --git a/include/trace/stages/stage7_class_define.h b/include/trace/stages/stage7_class_define.h\nindex fcd564a590f43..47008897a7956 100644\n--- a/include/trace/stages/stage7_class_define.h\n+++ b/include/trace/stages/stage7_class_define.h\n@@ -26,6 +26,25 @@\n #undef __print_hex_dump\n #undef __get_buf\n \n+#undef __event_in_hardirq\n+#undef __event_in_softirq\n+#undef __event_in_irq\n+\n+/*\n+ * The TRACE_FLAG_* are enums. Instead of using TRACE_DEFINE_ENUM(),\n+ * use their hardcoded values. These values are parsed by user space\n+ * tooling elsewhere so they will never change.\n+ *\n+ * See \"enum trace_flag_type\" in linux/trace_events.h:\n+ *   TRACE_FLAG_HARDIRQ\n+ *   TRACE_FLAG_SOFTIRQ\n+ */\n+\n+/* This is what is displayed in the format files */\n+#define __event_in_hardirq()\t(REC->common_flags & 0x8)\n+#define __event_in_softirq()\t(REC->common_flags & 0x10)\n+#define __event_in_irq()\t(REC->common_flags & 0x18)\n+\n /*\n  * The below is not executed in the kernel. It is only what is\n  * displayed in the print format for userspace to parse.\n-- \n2.33.8",
          "reply_to": "",
          "message_date": "2026-02-23"
        },
        {
          "author": "Thomas Ballasi (author)",
          "summary": "The author addressed a concern about the default value of the memory cgroup ID (memcg_id) in tracepoints, explaining that it is defaulted to 0 for operations not associated with a specific cgroup.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Memory reclaim events are currently difficult to attribute to\nspecific cgroups, making debugging memory pressure issues\nchallenging.  This patch adds memory cgroup ID (memcg_id) to key\nvmscan tracepoints to enable better correlation and analysis.\n\nFor operations not associated with a specific cgroup, the field\nis defaulted to 0.\n\nSigned-off-by: Thomas Ballasi <tballasi@linux.microsoft.com>\n---\n include/trace/events/vmscan.h | 83 ++++++++++++++++++++---------------\n mm/shrinker.c                 |  6 ++-\n mm/vmscan.c                   | 17 +++----\n 3 files changed, 61 insertions(+), 45 deletions(-)\n\ndiff --git a/include/trace/events/vmscan.h b/include/trace/events/vmscan.h\nindex 490958fa10dee..1212f6a7c223e 100644\n--- a/include/trace/events/vmscan.h\n+++ b/include/trace/events/vmscan.h\n@@ -114,85 +114,92 @@ TRACE_EVENT(mm_vmscan_wakeup_kswapd,\n \n DECLARE_EVENT_CLASS(mm_vmscan_direct_reclaim_begin_template,\n \n-\tTP_PROTO(int order, gfp_t gfp_flags),\n+\tTP_PROTO(gfp_t gfp_flags, int order, struct mem_cgroup *memcg),\n \n-\tTP_ARGS(order, gfp_flags),\n+\tTP_ARGS(gfp_flags, order, memcg),\n \n \tTP_STRUCT__entry(\n-\t\t__field(\tint,\torder\t\t)\n \t\t__field(\tunsigned long,\tgfp_flags\t)\n+\t\t__field(\tu64,\tmemcg_id\t)\n+\t\t__field(\tint,\torder\t\t)\n \t),\n \n \tTP_fast_assign(\n-\t\t__entry->order\t\t= order;\n \t\t__entry->gfp_flags\t= (__force unsigned long)gfp_flags;\n+\t\t__entry->order\t\t= order;\n+\t\t__entry->memcg_id\t= mem_cgroup_id(memcg);\n \t),\n \n-\tTP_printk(\"order=%d gfp_flags=%s\",\n+\tTP_printk(\"order=%d gfp_flags=%s memcg_id=%llu\",\n \t\t__entry->order,\n-\t\tshow_gfp_flags(__entry->gfp_flags))\n+\t\tshow_gfp_flags(__entry->gfp_flags),\n+\t\t__entry->memcg_id)\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_begin_template, mm_vmscan_direct_reclaim_begin,\n \n-\tTP_PROTO(int order, gfp_t gfp_flags),\n+\tTP_PROTO(gfp_t gfp_flags, int order, struct mem_cgroup *memcg),\n \n-\tTP_ARGS(order, gfp_flags)\n+\tTP_ARGS(gfp_flags, order, memcg)\n );\n \n #ifdef CONFIG_MEMCG\n DEFINE_EVENT(mm_vmscan_direct_reclaim_begin_template, mm_vmscan_memcg_reclaim_begin,\n \n-\tTP_PROTO(int order, gfp_t gfp_flags),\n+\tTP_PROTO(gfp_t gfp_flags, int order, struct mem_cgroup *memcg),\n \n-\tTP_ARGS(order, gfp_flags)\n+\tTP_ARGS(gfp_flags, order, memcg)\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_begin_template, mm_vmscan_memcg_softlimit_reclaim_begin,\n \n-\tTP_PROTO(int order, gfp_t gfp_flags),\n+\tTP_PROTO(gfp_t gfp_flags, int order, struct mem_cgroup *memcg),\n \n-\tTP_ARGS(order, gfp_flags)\n+\tTP_ARGS(gfp_flags, order, memcg)\n );\n #endif /* CONFIG_MEMCG */\n \n DECLARE_EVENT_CLASS(mm_vmscan_direct_reclaim_end_template,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, struct mem_cgroup *memcg),\n \n-\tTP_ARGS(nr_reclaimed),\n+\tTP_ARGS(nr_reclaimed, memcg),\n \n \tTP_STRUCT__entry(\n \t\t__field(\tunsigned long,\tnr_reclaimed\t)\n+\t\t__field(\tu64,\tmemcg_id\t)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->nr_reclaimed\t= nr_reclaimed;\n+\t\t__entry->memcg_id\t= mem_cgroup_id(memcg);\n \t),\n \n-\tTP_printk(\"nr_reclaimed=%lu\", __entry->nr_reclaimed)\n+\tTP_printk(\"nr_reclaimed=%lu memcg_id=%llu\",\n+\t\t__entry->nr_reclaimed,\n+\t\t__entry->memcg_id)\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_direct_reclaim_end,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, struct mem_cgroup *memcg),\n \n-\tTP_ARGS(nr_reclaimed)\n+\tTP_ARGS(nr_reclaimed, memcg)\n );\n \n #ifdef CONFIG_MEMCG\n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_memcg_reclaim_end,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, struct mem_cgroup *memcg),\n \n-\tTP_ARGS(nr_reclaimed)\n+\tTP_ARGS(nr_reclaimed, memcg)\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_memcg_softlimit_reclaim_end,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, struct mem_cgroup *memcg),\n \n-\tTP_ARGS(nr_reclaimed)\n+\tTP_ARGS(nr_reclaimed, memcg)\n );\n #endif /* CONFIG_MEMCG */\n \n@@ -200,39 +207,42 @@ TRACE_EVENT(mm_shrink_slab_start,\n \tTP_PROTO(struct shrinker *shr, struct shrink_control *sc,\n \t\tlong nr_objects_to_shrink, unsigned long cache_items,\n \t\tunsigned long long delta, unsigned long total_scan,\n-\t\tint priority),\n+\t\tint priority, struct mem_cgroup *memcg),\n \n \tTP_ARGS(shr, sc, nr_objects_to_shrink, cache_items, delta, total_scan,\n-\t\tpriority),\n+\t\tpriority, memcg),\n \n \tTP_STRUCT__entry(\n \t\t__field(struct shrinker *, shr)\n \t\t__field(void *, shrink)\n-\t\t__field(int, nid)\n \t\t__field(long, nr_objects_to_shrink)\n \t\t__field(unsigned long, gfp_flags)\n \t\t__field(unsigned long, cache_items)\n \t\t__field(unsigned long long, delta)\n \t\t__field(unsigned long, total_scan)\n \t\t__field(int, priority)\n+\t\t__field(int, nid)\n+\t\t__field(u64, memcg_id)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->shr = shr;\n \t\t__entry->shrink = shr->scan_objects;\n-\t\t__entry->nid = sc->nid;\n \t\t__entry->nr_objects_to_shrink = nr_objects_to_shrink;\n \t\t__entry->gfp_flags = (__force unsigned long)sc->gfp_mask;\n \t\t__entry->cache_items = cache_items;\n \t\t__entry->delta = delta;\n \t\t__entry->total_scan = total_scan;\n \t\t__entry->priority = priority;\n+\t\t__entry->nid = sc->nid;\n+\t\t__entry->memcg_id = mem_cgroup_id(memcg);\n \t),\n \n-\tTP_printk(\"%pS %p: nid: %d objects to shrink %ld gfp_flags %s cache items %ld delta %lld total_scan %ld priority %d\",\n+\tTP_printk(\"%pS %p: nid: %d memcg_id: %llu objects to shrink %ld gfp_flags %s cache items %ld delta %lld total_scan %ld priority %d\",\n \t\t__entry->shrink,\n \t\t__entry->shr,\n \t\t__entry->nid,\n+\t\t__entry->memcg_id,\n \t\t__entry->nr_objects_to_shrink,\n \t\tshow_gfp_flags(__entry->gfp_flags),\n \t\t__entry->cache_items,\n@@ -243,35 +253,38 @@ TRACE_EVENT(mm_shrink_slab_start,\n \n TRACE_EVENT(mm_shrink_slab_end,\n \tTP_PROTO(struct shrinker *shr, int nid, int shrinker_retval,\n-\t\tlong unused_scan_cnt, long new_scan_cnt, long total_scan),\n+\t\tlong unused_scan_cnt, long new_scan_cnt, long total_scan, struct mem_cgroup *memcg),\n \n \tTP_ARGS(shr, nid, shrinker_retval, unused_scan_cnt, new_scan_cnt,\n-\t\ttotal_scan),\n+\t\ttotal_scan, memcg),\n \n \tTP_STRUCT__entry(\n \t\t__field(struct shrinker *, shr)\n-\t\t__field(int, nid)\n \t\t__field(void *, shrink)\n \t\t__field(long, unused_scan)\n \t\t__field(long, new_scan)\n-\t\t__field(int, retval)\n \t\t__field(long, total_scan)\n+\t\t__field(int, nid)\n+\t\t__field(int, retval)\n+\t\t__field(u64, memcg_id)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->shr = shr;\n-\t\t__entry->nid = nid;\n \t\t__entry->shrink = shr->scan_objects;\n \t\t__entry->unused_scan = unused_scan_cnt;\n \t\t__entry->new_scan = new_scan_cnt;\n-\t\t__entry->retval = shrinker_retval;\n \t\t__entry->total_scan = total_scan;\n+\t\t__entry->nid = nid;\n+\t\t__entry->retval = shrinker_retval;\n+\t\t__entry->memcg_id = mem_cgroup_id(memcg);\n \t),\n \n-\tTP_printk(\"%pS %p: nid: %d unused scan count %ld new scan count %ld total_scan %ld last shrinker return val %d\",\n+\tTP_printk(\"%pS %p: nid: %d memcg_id: %llu unused scan count %ld new scan count %ld total_scan %ld last shrinker return val %d\",\n \t\t__entry->shrink,\n \t\t__entry->shr,\n \t\t__entry->nid,\n+\t\t__entry->memcg_id,\n \t\t__entry->unused_scan,\n \t\t__entry->new_scan,\n \t\t__entry->total_scan,\n@@ -504,9 +517,9 @@ TRACE_EVENT(mm_vmscan_node_reclaim_begin,\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_node_reclaim_end,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, struct mem_cgroup *memcg),\n \n-\tTP_ARGS(nr_reclaimed)\n+\tTP_ARGS(nr_reclaimed, memcg)\n );\n \n TRACE_EVENT(mm_vmscan_throttled,\ndiff --git a/mm/shrinker.c b/mm/shrinker.c\nindex 4a93fd433689a..ddf784f996a59 100644\n--- a/mm/shrinker.c\n+++ b/mm/shrinker.c\n@@ -410,7 +410,8 @@ static unsigned long do_shrink_slab(struct shrink_control *shrinkctl,\n \ttotal_scan = min(total_scan, (2 * freeable));\n \n \ttrace_mm_shrink_slab_start(shrinker, shrinkctl, nr,\n-\t\t\t\t   freeable, delta, total_scan, priority);\n+\t\t\t\t   freeable, delta, total_scan, priority,\n+\t\t\t\t   shrinkctl->memcg);\n \n \t/*\n \t * Normally, we should not scan less than batch_size objects in one\n@@ -461,7 +462,8 @@ static unsigned long do_shrink_slab(struct shrink_control *shrinkctl,\n \t */\n \tnew_nr = add_nr_deferred(next_deferred, shrinker, shrinkctl);\n \n-\ttrace_mm_shrink_slab_end(shrinker, shrinkctl->nid, freed, nr, new_nr, total_scan);\n+\ttrace_mm_shrink_slab_end(shrinker, shrinkctl->nid, freed, nr, new_nr, total_scan,\n+\t\t\t\t shrinkctl->memcg);\n \treturn freed;\n }\n \ndiff --git a/mm/vmscan.c b/mm/vmscan.c\nindex 614ccf39fe3fa..9d512fb354fcd 100644\n--- a/mm/vmscan.c\n+++ b/mm/vmscan.c\n@@ -6603,11 +6603,11 @@ unsigned long try_to_free_pages(struct zonelist *zonelist, int order,\n \t\treturn 1;\n \n \tset_task_reclaim_state(current, &sc.reclaim_state);\n-\ttrace_mm_vmscan_direct_reclaim_begin(order, sc.gfp_mask);\n+\ttrace_mm_vmscan_direct_reclaim_begin(sc.gfp_mask, order, 0);\n \n \tnr_reclaimed = do_try_to_free_pages(zonelist, &sc);\n \n-\ttrace_mm_vmscan_direct_reclaim_end(nr_reclaimed);\n+\ttrace_mm_vmscan_direct_reclaim_end(nr_reclaimed, 0);\n \tset_task_reclaim_state(current, NULL);\n \n \treturn nr_reclaimed;\n@@ -6636,8 +6636,9 @@ unsigned long mem_cgroup_shrink_node(struct mem_cgroup *memcg,\n \tsc.gfp_mask = (gfp_mask & GFP_RECLAIM_MASK) |\n \t\t\t(GFP_HIGHUSER_MOVABLE & ~GFP_RECLAIM_MASK);\n \n-\ttrace_mm_vmscan_memcg_softlimit_reclaim_begin(sc.order,\n-\t\t\t\t\t\t      sc.gfp_mask);\n+\ttrace_mm_vmscan_memcg_softlimit_reclaim_begin(sc.gfp_mask,\n+\t\t\t\t\t\t      sc.order,\n+\t\t\t\t\t\t      memcg);\n \n \t/*\n \t * NOTE: Although we can get the priority field, using it\n@@ -6648,7 +6649,7 @@ unsigned long mem_cgroup_shrink_node(struct mem_cgroup *memcg,\n \t */\n \tshrink_lruvec(lruvec, &sc);\n \n-\ttrace_mm_vmscan_memcg_softlimit_reclaim_end(sc.nr_reclaimed);\n+\ttrace_mm_vmscan_memcg_softlimit_reclaim_end(sc.nr_reclaimed, memcg);\n \n \t*nr_scanned = sc.nr_scanned;\n \n@@ -6684,13 +6685,13 @@ unsigned long try_to_free_mem_cgroup_pages(struct mem_cgroup *memcg,\n \tstruct zonelist *zonelist = node_zonelist(numa_node_id(), sc.gfp_mask);\n \n \tset_task_reclaim_state(current, &sc.reclaim_state);\n-\ttrace_mm_vmscan_memcg_reclaim_begin(0, sc.gfp_mask);\n+\ttrace_mm_vmscan_memcg_reclaim_begin(sc.gfp_mask, 0, memcg);\n \tnoreclaim_flag = memalloc_noreclaim_save();\n \n \tnr_reclaimed = do_try_to_free_pages(zonelist, &sc);\n \n \tmemalloc_noreclaim_restore(noreclaim_flag);\n-\ttrace_mm_vmscan_memcg_reclaim_end(nr_reclaimed);\n+\ttrace_mm_vmscan_memcg_reclaim_end(nr_reclaimed, memcg);\n \tset_task_reclaim_state(current, NULL);\n \n \treturn nr_reclaimed;\n@@ -7642,7 +7643,7 @@ static unsigned long __node_reclaim(struct pglist_data *pgdat, gfp_t gfp_mask,\n \tdelayacct_freepages_end();\n \tpsi_memstall_leave(&pflags);\n \n-\ttrace_mm_vmscan_node_reclaim_end(sc->nr_reclaimed);\n+\ttrace_mm_vmscan_node_reclaim_end(sc->nr_reclaimed, 0);\n \n \treturn sc->nr_reclaimed;\n }\n-- \n2.33.8",
          "reply_to": "",
          "message_date": "2026-02-23"
        },
        {
          "author": "Thomas Ballasi (author)",
          "summary": "The author addressed a concern about the reliability of PID detection in interrupt or RCU contexts, explaining that they use in_task() to safely access current->pid when in process context and set it to -1 as a sentinel value otherwise.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "The changes aims at adding additionnal tracepoints variables to help\ndebuggers attribute them to specific processes.\n\nThe PID field uses in_task() to reliably detect when we're in process\ncontext and can safely access current->pid.  When not in process\ncontext (such as in interrupt or in an asynchronous RCU context), the\nfield is set to -1 as a sentinel value.\n\nSigned-off-by: Thomas Ballasi <tballasi@linux.microsoft.com>\n---\n include/trace/events/vmscan.h | 34 +++++++++++++++++++++++++---------\n 1 file changed, 25 insertions(+), 9 deletions(-)\n\ndiff --git a/include/trace/events/vmscan.h b/include/trace/events/vmscan.h\nindex 1212f6a7c223e..15b31281f0955 100644\n--- a/include/trace/events/vmscan.h\n+++ b/include/trace/events/vmscan.h\n@@ -122,18 +122,22 @@ DECLARE_EVENT_CLASS(mm_vmscan_direct_reclaim_begin_template,\n \t\t__field(\tunsigned long,\tgfp_flags\t)\n \t\t__field(\tu64,\tmemcg_id\t)\n \t\t__field(\tint,\torder\t\t)\n+\t\t__field(\tint,\tpid\t\t)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->gfp_flags\t= (__force unsigned long)gfp_flags;\n \t\t__entry->order\t\t= order;\n+\t\t__entry->pid\t\t= current->pid;\n \t\t__entry->memcg_id\t= mem_cgroup_id(memcg);\n \t),\n \n-\tTP_printk(\"order=%d gfp_flags=%s memcg_id=%llu\",\n+\tTP_printk(\"order=%d gfp_flags=%s pid=%d memcg_id=%llu %s\",\n \t\t__entry->order,\n \t\tshow_gfp_flags(__entry->gfp_flags),\n-\t\t__entry->memcg_id)\n+\t\t__entry->pid,\n+\t\t__entry->memcg_id,\n+\t\t__event_in_irq() ? \"(in-irq)\" : \"\")\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_begin_template, mm_vmscan_direct_reclaim_begin,\n@@ -168,16 +172,20 @@ DECLARE_EVENT_CLASS(mm_vmscan_direct_reclaim_end_template,\n \tTP_STRUCT__entry(\n \t\t__field(\tunsigned long,\tnr_reclaimed\t)\n \t\t__field(\tu64,\tmemcg_id\t)\n+\t\t__field(\tint,\tpid\t\t)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->nr_reclaimed\t= nr_reclaimed;\n \t\t__entry->memcg_id\t= mem_cgroup_id(memcg);\n+\t\t__entry->pid\t\t= current->pid;\n \t),\n \n-\tTP_printk(\"nr_reclaimed=%lu memcg_id=%llu\",\n+\tTP_printk(\"nr_reclaimed=%lu pid=%d memcg_id=%llu %s\",\n \t\t__entry->nr_reclaimed,\n-\t\t__entry->memcg_id)\n+\t\t__entry->pid,\n+\t\t__entry->memcg_id,\n+\t\t__event_in_irq() ? \"(in-irq)\" : \"\")\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_direct_reclaim_end,\n@@ -220,9 +228,10 @@ TRACE_EVENT(mm_shrink_slab_start,\n \t\t__field(unsigned long, cache_items)\n \t\t__field(unsigned long long, delta)\n \t\t__field(unsigned long, total_scan)\n+\t\t__field(u64, memcg_id)\n \t\t__field(int, priority)\n \t\t__field(int, nid)\n-\t\t__field(u64, memcg_id)\n+\t\t__field(int, pid)\n \t),\n \n \tTP_fast_assign(\n@@ -236,19 +245,22 @@ TRACE_EVENT(mm_shrink_slab_start,\n \t\t__entry->priority = priority;\n \t\t__entry->nid = sc->nid;\n \t\t__entry->memcg_id = mem_cgroup_id(memcg);\n+\t\t__entry->pid = current->pid;\n \t),\n \n-\tTP_printk(\"%pS %p: nid: %d memcg_id: %llu objects to shrink %ld gfp_flags %s cache items %ld delta %lld total_scan %ld priority %d\",\n+\tTP_printk(\"%pS %p: nid: %d pid: %d memcg_id: %llu objects to shrink %ld gfp_flags %s cache items %ld delta %lld total_scan %ld priority %d %s\",\n \t\t__entry->shrink,\n \t\t__entry->shr,\n \t\t__entry->nid,\n+\t\t__entry->pid,\n \t\t__entry->memcg_id,\n \t\t__entry->nr_objects_to_shrink,\n \t\tshow_gfp_flags(__entry->gfp_flags),\n \t\t__entry->cache_items,\n \t\t__entry->delta,\n \t\t__entry->total_scan,\n-\t\t__entry->priority)\n+\t\t__entry->priority,\n+\t\t__event_in_irq() ? \"(in-irq)\" : \"\")\n );\n \n TRACE_EVENT(mm_shrink_slab_end,\n@@ -266,6 +278,7 @@ TRACE_EVENT(mm_shrink_slab_end,\n \t\t__field(long, total_scan)\n \t\t__field(int, nid)\n \t\t__field(int, retval)\n+\t\t__field(int, pid)\n \t\t__field(u64, memcg_id)\n \t),\n \n@@ -277,18 +290,21 @@ TRACE_EVENT(mm_shrink_slab_end,\n \t\t__entry->total_scan = total_scan;\n \t\t__entry->nid = nid;\n \t\t__entry->retval = shrinker_retval;\n+\t\t__entry->pid = current->pid;\n \t\t__entry->memcg_id = mem_cgroup_id(memcg);\n \t),\n \n-\tTP_printk(\"%pS %p: nid: %d memcg_id: %llu unused scan count %ld new scan count %ld total_scan %ld last shrinker return val %d\",\n+\tTP_printk(\"%pS %p: nid: %d pid: %d memcg_id: %llu unused scan count %ld new scan count %ld total_scan %ld last shrinker return val %d %s\",\n \t\t__entry->shrink,\n \t\t__entry->shr,\n \t\t__entry->nid,\n+\t\t__entry->pid,\n \t\t__entry->memcg_id,\n \t\t__entry->unused_scan,\n \t\t__entry->new_scan,\n \t\t__entry->total_scan,\n-\t\t__entry->retval)\n+\t\t__entry->retval,\n+\t\t__event_in_irq() ? \"(in-irq)\" : \"\")\n );\n \n TRACE_EVENT(mm_vmscan_lru_isolate,\n-- \n2.33.8",
          "reply_to": "",
          "message_date": "2026-02-23"
        },
        {
          "author": "Shakeel Butt",
          "summary": "Gave Reviewed-by",
          "sentiment": "positive",
          "sentiment_signals": [],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "heuristic",
          "raw_body": "",
          "reply_to": "Thomas Ballasi",
          "message_date": "2026-02-23"
        },
        {
          "author": "Shakeel Butt",
          "summary": "Gave Acked-by",
          "sentiment": "positive",
          "sentiment_signals": [],
          "has_inline_review": false,
          "tags_given": [
            "Acked-by"
          ],
          "analysis_source": "heuristic",
          "raw_body": "",
          "reply_to": "Thomas Ballasi",
          "message_date": "2026-02-23"
        },
        {
          "author": "Shakeel Butt",
          "summary": "Reviewer Shakeel Butt questioned the necessity of an __event_in_irq() check in this patch, pointing out that memory reclaim only occurs in process context and therefore such a check is not required.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested change",
            "technical clarification"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Where is this in_task() check happening? Also this patch is changing\ntracepoints for memory reclaim which never happens in any context other than\nprocess context, so we don't need __event_in_irq() checks for these tracepoints.",
          "reply_to": "Thomas Ballasi",
          "message_date": "2026-02-23"
        }
      ],
      "analysis_source": "llm-per-reviewer"
    },
    "2026-02-24": {
      "report_file": "2026-02-23_ollama_llama3.1-8b.html",
      "developer": "Shakeel Butt",
      "reviews": [
        {
          "author": "Masami (Google)",
          "summary": "Reviewer noted that the patch does not handle the case where a cgroup is being destroyed, and requested that the patch be updated to handle this scenario\n\nReviewer Masami suggested using the existing common_pid field in the tracepoint format to store the current process ID, instead of duplicating it.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "missing edge case",
            "requested change"
          ],
          "has_inline_review": true,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Hi,\n\nOn Mon, 23 Feb 2026 09:15:44 -0800\nThomas Ballasi <tballasi@linux.microsoft.com> wrote:\n\n---\n\nAll entries saves current->pid in common_pid field. Can you use\nthis common field?\n\n# cat events/vmscan/mm_vmscan_reclaim_pages/format \nname: mm_vmscan_reclaim_pages\nID: 590\nformat:\n\tfield:unsigned short common_type;\toffset:0;\tsize:2;\tsigned:0;\n\tfield:unsigned char common_flags;\toffset:2;\tsize:1;\tsigned:0;\n\tfield:unsigned char common_preempt_count;\toffset:3;\tsize:1;\tsigned:0;\n\tfield:int common_pid;\toffset:4;\tsize:4;\tsigned:1;    ## <------------here\n\n\tfield:int nid;\toffset:8;\tsize:4;\tsigned:1;\n\tfield:unsigned long nr_scanned;\toffset:16;\tsize:8;\tsigned:0;\n\tfield:unsigned long nr_reclaimed;\toffset:24;\tsize:8;\tsigned:0;\n\tfield:unsigned long nr_dirty;\toffset:32;\tsize:8;\tsigned:0;\n\tfield:unsigned long nr_writeback;\toffset:40;\tsize:8;\tsigned:0;\n\tfield:unsigned long nr_congested;\toffset:48;\tsize:8;\tsigned:0;\n\tfield:unsigned long nr_immediate;\toffset:56;\tsize:8;\tsigned:0;\n\tfield:unsigned int nr_activate0;\toffset:64;\tsize:4;\tsigned:0;\n\tfield:unsigned int nr_activate1;\toffset:68;\tsize:4;\tsigned:0;\n\tfield:unsigned long nr_ref_keep;\toffset:72;\tsize:8;\tsigned:0;\n\tfield:unsigned long nr_unmap_fail;\toffset:80;\tsize:8;\tsigned:0;\n\nThank you,\n\n-- \nMasami Hiramatsu (Google) <mhiramat@kernel.org>",
          "reply_to": "Thomas Ballasi",
          "message_date": "2026-02-24"
        }
      ],
      "analysis_source": "llm-per-reviewer"
    }
  }
}