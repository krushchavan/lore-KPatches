{
  "thread_id": "20260213144704.2780265-1-gourry@gourry.net",
  "subject": "Re: [PATCH] dax/hmem, cxl: Defer and resolve ownership of Soft Reserved memory ranges",
  "url": "https://lore.kernel.org/all/20260213144704.2780265-1-gourry@gourry.net/",
  "dates": {
    "2026-02-13": {
      "report_file": "2026-02-13_ollama_llama3.1-8b.html",
      "developer": "Gregory Price",
      "reviews": [
        {
          "author": "Smita Koralahalli (author)",
          "summary": "The reviewer, Smita Koralahalli (author), raised concerns about the patch's handling of Soft Reserved memory ranges and their deferral on DEV_DAX_CXL. They suggested that the patch should ensure cxl_acpi has published CXL Window resources before HMEM walks Soft Reserved ranges.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes"
          ],
          "has_inline_review": true,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "From: Dan Williams <dan.j.williams@intel.com>\n\nEnsure cxl_acpi has published CXL Window resources before HMEM walks Soft\nReserved ranges.\n\nReplace MODULE_SOFTDEP(\"pre: cxl_acpi\") with an explicit, synchronous\nrequest_module(\"cxl_acpi\"). MODULE_SOFTDEP() only guarantees eventual\nloading, it does not enforce that the dependency has finished init\nbefore the current module runs. This can cause HMEM to start before\ncxl_acpi has populated the resource tree, breaking detection of overlaps\nbetween Soft Reserved and CXL Windows.\n\nAlso, request cxl_pci before HMEM walks Soft Reserved ranges. Unlike\ncxl_acpi, cxl_pci attach is asynchronous and creates dependent devices\nthat trigger further module loads. Asynchronous probe flushing\n(wait_for_device_probe()) is added later in the series in a deferred\ncontext before HMEM makes ownership decisions for Soft Reserved ranges.\n\nAdd an additional explicit Kconfig ordering so that CXL_ACPI and CXL_PCI\nmust be initialized before DEV_DAX_HMEM. This prevents HMEM from consuming\nSoft Reserved ranges before CXL drivers have had a chance to claim them.\n\nSigned-off-by: Dan Williams <dan.j.williams@intel.com>\nSigned-off-by: Smita Koralahalli <Smita.KoralahalliChannabasappa@amd.com>\nReviewed-by: Dave Jiang <dave.jiang@intel.com>\nReviewed-by: Jonathan Cameron <jonathan.cameron@huawei.com>\n---\n drivers/dax/Kconfig     |  2 ++\n drivers/dax/hmem/hmem.c | 17 ++++++++++-------\n 2 files changed, 12 insertions(+), 7 deletions(-)\n\ndiff --git a/drivers/dax/Kconfig b/drivers/dax/Kconfig\nindex d656e4c0eb84..3683bb3f2311 100644\n--- a/drivers/dax/Kconfig\n+++ b/drivers/dax/Kconfig\n@@ -48,6 +48,8 @@ config DEV_DAX_CXL\n \ttristate \"CXL DAX: direct access to CXL RAM regions\"\n \tdepends on CXL_BUS && CXL_REGION && DEV_DAX\n \tdefault CXL_REGION && DEV_DAX\n+\tdepends on CXL_ACPI >= DEV_DAX_HMEM\n+\tdepends on CXL_PCI >= DEV_DAX_HMEM\n \thelp\n \t  CXL RAM regions are either mapped by platform-firmware\n \t  and published in the initial system-memory map as \"System RAM\", mapped\ndiff --git a/drivers/dax/hmem/hmem.c b/drivers/dax/hmem/hmem.c\nindex 1cf7c2a0ee1c..008172fc3607 100644\n--- a/drivers/dax/hmem/hmem.c\n+++ b/drivers/dax/hmem/hmem.c\n@@ -139,6 +139,16 @@ static __init int dax_hmem_init(void)\n {\n \tint rc;\n \n+\t/*\n+\t * Ensure that cxl_acpi and cxl_pci have a chance to kick off\n+\t * CXL topology discovery at least once before scanning the\n+\t * iomem resource tree for IORES_DESC_CXL resources.\n+\t */\n+\tif (IS_ENABLED(CONFIG_DEV_DAX_CXL)) {\n+\t\trequest_module(\"cxl_acpi\");\n+\t\trequest_module(\"cxl_pci\");\n+\t}\n+\n \trc = platform_driver_register(&dax_hmem_platform_driver);\n \tif (rc)\n \t\treturn rc;\n@@ -159,13 +169,6 @@ static __exit void dax_hmem_exit(void)\n module_init(dax_hmem_init);\n module_exit(dax_hmem_exit);\n \n-/* Allow for CXL to define its own dax regions */\n-#if IS_ENABLED(CONFIG_CXL_REGION)\n-#if IS_MODULE(CONFIG_CXL_ACPI)\n-MODULE_SOFTDEP(\"pre: cxl_acpi\");\n-#endif\n-#endif\n-\n MODULE_ALIAS(\"platform:hmem*\");\n MODULE_ALIAS(\"platform:hmem_platform*\");\n MODULE_DESCRIPTION(\"HMEM DAX: direct access to 'specific purpose' memory\");\n-- \n2.17.1\n\n\n\n---\n\nThis series aims to address long-standing conflicts between HMEM and\nCXL when handling Soft Reserved memory ranges.\n\nReworked from Dan's patch:\nhttps://git.kernel.org/pub/scm/linux/kernel/git/cxl/cxl.git/patch/?id=ab70c6227ee6165a562c215d9dcb4a1c55620d5d\n\nPrevious work:\nhttps://lore.kernel.org/all/20250715180407.47426-1-Smita.KoralahalliChannabasappa@amd.com/\n\nLink to v5:\nhttps://lore.kernel.org/all/20260122045543.218194-1-Smita.KoralahalliChannabasappa@amd.com\n\nThe series is based on branch \"for-7.0/cxl-init\" and base-commit is\nbase-commit: bc62f5b308cbdedf29132fe96e9d591e526527e1\n\n[1] After offlining the memory I can tear down the regions and recreate\nthem back. dax_cxl creates dax devices and onlines memory.\n850000000-284fffffff : CXL Window 0\n  850000000-284fffffff : region0\n    850000000-284fffffff : dax0.0\n      850000000-284fffffff : System RAM (kmem)\n\n[2] With CONFIG_CXL_REGION disabled, all the resources are handled by\nHMEM. Soft Reserved range shows up in /proc/iomem, no regions come up\nand dax devices are created from HMEM.\n850000000-284fffffff : CXL Window 0\n  850000000-284fffffff : Soft Reserved\n    850000000-284fffffff : dax0.0\n      850000000-284fffffff : System RAM (kmem)\n\n[3] Region assembly failure works same as [2].\n\n[4] REGISTER path:\nWhen CXL_BUS = y (with CXL_ACPI, CXL_PCI, CXL_PORT, CXL_MEM = y),\nthe dax_cxl driver is probed and completes initialization before dax_hmem\nprobes. This scenario was tested with CXL = y, DAX_CXL = m and\nDAX_HMEM = m. To validate the REGISTER path, I forced REGISTER even in\ncases where SR completely overlaps the CXL region as I did not have access\nto a system where the CXL region range is smaller than the SR range.\n\n850000000-284fffffff : Soft Reserved\n  850000000-284fffffff : CXL Window 0\n    850000000-280fffffff : region0\n      850000000-284fffffff : dax0.0\n        850000000-284fffffff : System RAM (kmem)\n\n\"path\":\"\\/platform\\/ACPI0017:00\\/root0\\/decoder0.0\\/region0\\/dax_region0\",\n\"id\":0,\n\"size\":\"128.00 GiB (137.44 GB)\",\n\"align\":2097152\n\n[   35.961707] cxl-dax: cxl_dax_region_init()\n[   35.961713] cxl-dax: registering driver.\n[   35.961715] cxl-dax: dax_hmem work flushed.\n[   35.961754] alloc_dev_dax_range:  dax0.0: alloc range[0]:\n0x000000850000000:0x000000284fffffff\n[   35.976622] hmem: hmem_platform probe started.\n[   35.980821] cxl_bus_probe: cxl_dax_region dax_region0: probe: 0\n[   36.819566] hmem_platform hmem_platform.0: Soft Reserved not fully\ncontained in CXL; using HMEM\n[   36.819569] hmem_register_device: hmem_platform hmem_platform.0:\nregistering CXL range: [mem 0x850000000-0x284fffffff flags 0x80000200]\n[   36.934156] alloc_dax_region: hmem hmem.6: dax_region resource conflict\nfor [mem 0x850000000-0x284fffffff]\n[   36.989310] hmem hmem.6: probe with driver hmem failed with error -12\n\n[5] When CXL_BUS = m (with CXL_ACPI, CXL_PCI, CXL_PORT, CXL_MEM = m),\nDAX_CXL = m and DAX_HMEM = y the results are as expected. To validate the\nREGISTER path, I forced REGISTER even in cases where SR completely\noverlaps the CXL region as I did not have access to a system where the\nCXL region range is smaller than the SR range.\n\n850000000-284fffffff : Soft Reserved\n  850000000-284fffffff : CXL Window 0\n    850000000-280fffffff : region0\n      850000000-284fffffff : dax6.0\n        850000000-284fffffff : System RAM (kmem)\n\n\"path\":\"\\/platform\\/hmem.6\",\n\"id\":6,\n\"size\":\"128.00 GiB (137.44 GB)\",\n\"align\":2097152\n\n[   30.897665] devm_cxl_add_dax_region: cxl_region region0: region0:\nregister dax_region0\n[   30.921015] hmem: hmem_platform probe started.\n[   31.017946] hmem_platform hmem_platform.0: Soft Reserved not fully\ncontained in CXL; using HMEM\n[   31.056310] alloc_dev_dax_range:  dax6.0: alloc range[0]:\n0x0000000850000000:0x000000284fffffff\n[   34.781516] cxl-dax: cxl_dax_region_init()\n[   34.781522] cxl-dax: registering driver.\n[   34.781523] cxl-dax: dax_hmem work flushed.\n[   34.781549] alloc_dax_region: cxl_dax_region dax_region0: dax_region\nresource conflict for [mem 0x850000000-0x284fffffff]\n[   34.781552] cxl_bus_probe: cxl_dax_region dax_region0: probe: -12\n[   34.781554] cxl_dax_region dax_region0: probe with driver cxl_dax_region\nfailed with error -12\n\nv6 updates:\n- Patch 1-3 no changes.\n- New Patches 4-5.\n- (void *)res -> res.\n- cxl_region_contains_soft_reserve -> region_contains_soft_reserve.\n- New file include/cxl/cxl.h\n- Introduced singleton workqueue.\n- hmem to queue the work and cxl to flush.\n- cxl_contains_soft_reserve() -> soft_reserve_has_cxl_match().\n- Included descriptions for dax_cxl_mode.\n- kzalloc -> kmalloc in add_soft_reserve_into_iomem()\n- dax_cxl_mode is exported to CXL.\n- Introduced hmem_register_cxl_device() for walking only CXL\nintersected SR ranges the second time.\n\nv5 updates:\n- Patch 1 dropped as its been merged for-7.0/cxl-init.\n- Added Reviewed-by tags.\n- Shared dax_cxl_mode between dax/cxl.c and dax/hmem.c and used\n  -EPROBE_DEFER to defer dax_cxl.\n- CXL_REGION_F_AUTO check for resetting decoders.\n- Teardown all CXL regions if any one CXL region doesn't fully contain\n  the Soft Reserved range.\n- Added helper cxl_region_contains_sr() to determine Soft Reserved\n  ownership.\n- bus_rescan_devices() to retry dax_cxl.\n- Added guard(rwsem_read)(&cxl_rwsem.region).\n\nv4 updates:\n- No changes patches 1-3.\n- New patches 4-7.\n- handle_deferred_cxl() has been enhanced to handle case where CXL\n  regions do not contiguously and fully cover Soft Reserved ranges.\n- Support added to defer cxl_dax registration.\n- Support added to teardown cxl regions.\n\nv3 updates:\n - Fixed two \"From\".\n\nv2 updates:\n - Removed conditional check on CONFIG_EFI_SOFT_RESERVE as dax_hmem\n   depends on CONFIG_EFI_SOFT_RESERVE. (Zhijian)\n - Added TODO note. (Zhijian)\n - Included region_intersects_soft_reserve() inside CONFIG_EFI_SOFT_RESERVE\n   conditional check. (Zhijian)\n - insert_resource_late() -> insert_resource_expand_to_fit() and\n   __insert_resource_expand_to_fit() replacement. (Boris)\n - Fixed Co-developed and Signed-off by. (Dan)\n - Combined 2/6 and 3/6 into a single patch. (Zhijian).\n - Skip local variable in remove_soft_reserved. (Jonathan)\n - Drop kfree with __free(). (Jonathan)\n - return 0 -> return dev_add_action_or_reset(host...) (Jonathan)\n - Dropped 6/6.\n - Reviewed-by tags (Dave, Jonathan)\n\nDan Williams (3):\n  dax/hmem: Request cxl_acpi and cxl_pci before walking Soft Reserved\n    ranges\n  dax/hmem: Gate Soft Reserved deferral on DEV_DAX_CXL\n  dax/cxl, hmem: Initialize hmem early and defer dax_cxl binding\n\nSmita Koralahalli (6):\n  cxl/region: Skip decoder reset on detach for autodiscovered regions\n  dax: Track all dax_region allocations under a global resource tree\n  cxl/region: Add helper to check Soft Reserved containment by CXL\n    regions\n  dax: Add deferred-work helpers for dax_hmem and dax_cxl coordination\n  dax/hmem, cxl: Defer and resolve ownership of Soft Reserved memory\n    ranges\n  dax/hmem: Reintroduce Soft Reserved ranges back into the iomem tree\n\n drivers/cxl/core/region.c |  34 +++++++++-\n drivers/dax/Kconfig       |   2 +\n drivers/dax/Makefile      |   3 +-\n drivers/dax/bus.c         |  84 ++++++++++++++++++++++++-\n drivers/dax/bus.h         |  26 ++++++++\n drivers/dax/cxl.c         |  28 ++++++++-\n drivers/dax/hmem/hmem.c   | 129 ++++++++++++++++++++++++++++++++++----\n include/cxl/cxl.h         |  15 +++++\n 8 files changed, 303 insertions(+), 18 deletions(-)\n create mode 100644 include/cxl/cxl.h\n\n-- \n2.17.1\n\n\n\n---\n\nFrom: Dan Williams <dan.j.williams@intel.com>\n\nMove hmem/ earlier in the dax Makefile so that hmem_init() runs before\ndax_cxl.\n\nIn addition, defer registration of the dax_cxl driver to a workqueue\ninstead of using module_cxl_driver(). This ensures that dax_hmem has\nan opportunity to initialize and register its deferred callback and make\nownership decisions before dax_cxl begins probing and claiming Soft\nReserved ranges.\n\nMark the dax_cxl driver as PROBE_PREFER_ASYNCHRONOUS so its probe runs\nout of line from other synchronous probing avoiding ordering\ndependencies while coordinating ownership decisions with dax_hmem.\n\nSigned-off-by: Dan Williams <dan.j.williams@intel.com>\nSigned-off-by: Smita Koralahalli <Smita.KoralahalliChannabasappa@amd.com>\n---\n drivers/dax/Makefile |  3 +--\n drivers/dax/cxl.c    | 27 ++++++++++++++++++++++++++-\n 2 files changed, 27 insertions(+), 3 deletions(-)\n\ndiff --git a/drivers/dax/Makefile b/drivers/dax/Makefile\nindex 5ed5c39857c8..70e996bf1526 100644\n--- a/drivers/dax/Makefile\n+++ b/drivers/dax/Makefile\n@@ -1,4 +1,5 @@\n # SPDX-License-Identifier: GPL-2.0\n+obj-y += hmem/\n obj-$(CONFIG_DAX) += dax.o\n obj-$(CONFIG_DEV_DAX) += device_dax.o\n obj-$(CONFIG_DEV_DAX_KMEM) += kmem.o\n@@ -10,5 +11,3 @@ dax-y += bus.o\n device_dax-y := device.o\n dax_pmem-y := pmem.o\n dax_cxl-y := cxl.o\n-\n-obj-y += hmem/\ndiff --git a/drivers/dax/cxl.c b/drivers/dax/cxl.c\nindex 13cd94d32ff7..a2136adfa186 100644\n--- a/drivers/dax/cxl.c\n+++ b/drivers/dax/cxl.c\n@@ -38,10 +38,35 @@ static struct cxl_driver cxl_dax_region_driver = {\n \t.id = CXL_DEVICE_DAX_REGION,\n \t.drv = {\n \t\t.suppress_bind_attrs = true,\n+\t\t.probe_type = PROBE_PREFER_ASYNCHRONOUS,\n \t},\n };\n \n-module_cxl_driver(cxl_dax_region_driver);\n+static void cxl_dax_region_driver_register(struct work_struct *work)\n+{\n+\tcxl_driver_register(&cxl_dax_region_driver);\n+}\n+\n+static DECLARE_WORK(cxl_dax_region_driver_work, cxl_dax_region_driver_register);\n+\n+static int __init cxl_dax_region_init(void)\n+{\n+\t/*\n+\t * Need to resolve a race with dax_hmem wanting to drive regions\n+\t * instead of CXL\n+\t */\n+\tqueue_work(system_long_wq, &cxl_dax_region_driver_work);\n+\treturn 0;\n+}\n+module_init(cxl_dax_region_init);\n+\n+static void __exit cxl_dax_region_exit(void)\n+{\n+\tflush_work(&cxl_dax_region_driver_work);\n+\tcxl_driver_unregister(&cxl_dax_region_driver);\n+}\n+module_exit(cxl_dax_region_exit);\n+\n MODULE_ALIAS_CXL(CXL_DEVICE_DAX_REGION);\n MODULE_DESCRIPTION(\"CXL DAX: direct access to CXL regions\");\n MODULE_LICENSE(\"GPL\");\n-- \n2.17.1\n\n\n\n---\n\n__cxl_decoder_detach() currently resets decoder programming whenever a\nregion is detached if cxl_config_state is beyond CXL_CONFIG_ACTIVE. For\nautodiscovered regions, this can incorrectly tear down decoder state\nthat may be relied upon by other consumers or by subsequent ownership\ndecisions.\n\nSkip cxl_region_decode_reset() during detach when CXL_REGION_F_AUTO is\nset.\n\nSigned-off-by: Smita Koralahalli <Smita.KoralahalliChannabasappa@amd.com>\nReviewed-by: Jonathan Cameron <jonathan.cameron@huawei.com>\nReviewed-by: Dave Jiang <dave.jiang@intel.com>\nReviewed-by: Alejandro Lucero <alucerop@amd.com>\n---\n drivers/cxl/core/region.c | 4 +++-\n 1 file changed, 3 insertions(+), 1 deletion(-)\n\ndiff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c\nindex ae899f68551f..45ee598daf95 100644\n--- a/drivers/cxl/core/region.c\n+++ b/drivers/cxl/core/region.c\n@@ -2178,7 +2178,9 @@ __cxl_decoder_detach(struct cxl_region *cxlr,\n \t\tcxled->part = -1;\n \n \tif (p->state > CXL_CONFIG_ACTIVE) {\n-\t\tcxl_region_decode_reset(cxlr, p->interleave_ways);\n+\t\tif (!test_bit(CXL_REGION_F_AUTO, &cxlr->flags))\n+\t\t\tcxl_region_decode_reset(cxlr, p->interleave_ways);\n+\n \t\tp->state = CXL_CONFIG_ACTIVE;\n \t}\n \n-- \n2.17.1\n\n\n\n---\n\nIntroduce a global \"DAX Regions\" resource root and register each\ndax_region->res under it via request_resource(). Release the resource on\ndax_region teardown.\n\nBy enforcing a single global namespace for dax_region allocations, this\nensures only one of dax_hmem or dax_cxl can successfully register a\ndax_region for a given range.\n\nCo-developed-by: Dan Williams <dan.j.williams@intel.com>\nSigned-off-by: Dan Williams <dan.j.williams@intel.com>\nSigned-off-by: Smita Koralahalli <Smita.KoralahalliChannabasappa@amd.com>\n---\n drivers/dax/bus.c | 23 ++++++++++++++++++++---\n 1 file changed, 20 insertions(+), 3 deletions(-)\n\ndiff --git a/drivers/dax/bus.c b/drivers/dax/bus.c\nindex fde29e0ad68b..5f387feb95f0 100644\n--- a/drivers/dax/bus.c\n+++ b/drivers/dax/bus.c\n@@ -10,6 +10,7 @@\n #include \"dax-private.h\"\n #include \"bus.h\"\n \n+static struct resource dax_regions = DEFINE_RES_MEM_NAMED(0, -1, \"DAX Regions\");\n static DEFINE_MUTEX(dax_bus_lock);\n \n /*\n@@ -625,6 +626,8 @@ static void dax_region_unregister(void *region)\n {\n \tstruct dax_region *dax_region = region;\n \n+\tscoped_guard(rwsem_write, &dax_region_rwsem)\n+\t\trelease_resource(&dax_region->res);\n \tsysfs_remove_groups(&dax_region->dev->kobj,\n \t\t\tdax_region_attribute_groups);\n \tdax_region_put(dax_region);\n@@ -635,6 +638,7 @@ struct dax_region *alloc_dax_region(struct device *parent, int region_id,\n \t\tunsigned long flags)\n {\n \tstruct dax_region *dax_region;\n+\tint rc;\n \n \t/*\n \t * The DAX core assumes that it can store its private data in\n@@ -667,14 +671,27 @@ struct dax_region *alloc_dax_region(struct device *parent, int region_id,\n \t\t.flags = IORESOURCE_MEM | flags,\n \t};\n \n-\tif (sysfs_create_groups(&parent->kobj, dax_region_attribute_groups)) {\n-\t\tkfree(dax_region);\n-\t\treturn NULL;\n+\tscoped_guard(rwsem_write, &dax_region_rwsem)\n+\t\trc = request_resource(&dax_regions, &dax_region->res);\n+\tif (rc) {\n+\t\tdev_dbg(parent, \"dax_region resource conflict for %pR\\n\",\n+\t\t\t&dax_region->res);\n+\t\tgoto err_res;\n \t}\n \n+\tif (sysfs_create_groups(&parent->kobj, dax_region_attribute_groups))\n+\t\tgoto err_sysfs;\n+\n \tif (devm_add_action_or_reset(parent, dax_region_unregister, dax_region))\n \t\treturn NULL;\n \treturn dax_region;\n+\n+err_sysfs:\n+\tscoped_guard(rwsem_write, &dax_region_rwsem)\n+\t\trelease_resource(&dax_region->res);\n+err_res:\n+\tkfree(dax_region);\n+\treturn NULL;\n }\n EXPORT_SYMBOL_GPL(alloc_dax_region);\n \n-- \n2.17.1\n\n\n\n---\n\nAdd a helper to determine whether a given Soft Reserved memory range is\nfully contained within the committed CXL region.\n\nThis helper provides a primitive for policy decisions in subsequent\npatches such as co-ordination with dax_hmem to determine whether CXL has\nfully claimed ownership of Soft Reserved memory ranges.\n\nSigned-off-by: Smita Koralahalli <Smita.KoralahalliChannabasappa@amd.com>\nReviewed-by: Jonathan Cameron <jonathan.cameron@huawei.com>\nReviewed-by: Dave Jiang <dave.jiang@intel.com>\n---\n drivers/cxl/core/region.c | 30 ++++++++++++++++++++++++++++++\n include/cxl/cxl.h         | 15 +++++++++++++++\n 2 files changed, 45 insertions(+)\n create mode 100644 include/cxl/cxl.h\n\ndiff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c\nindex 45ee598daf95..96ed550bfd2e 100644\n--- a/drivers/cxl/core/region.c\n+++ b/drivers/cxl/core/region.c\n@@ -12,6 +12,7 @@\n #include <linux/idr.h>\n #include <linux/memory-tiers.h>\n #include <linux/string_choices.h>\n+#include <cxl/cxl.h>\n #include <cxlmem.h>\n #include <cxl.h>\n #include \"core.h\"\n@@ -3875,6 +3876,35 @@ static int cxl_region_debugfs_poison_clear(void *data, u64 offset)\n DEFINE_DEBUGFS_ATTRIBUTE(cxl_poison_clear_fops, NULL,\n \t\t\t cxl_region_debugfs_poison_clear, \"%llx\\n\");\n \n+static int region_contains_soft_reserve(struct device *dev, void *data)\n+{\n+\tstruct resource *res = data;\n+\tstruct cxl_region *cxlr;\n+\tstruct cxl_region_params *p;\n+\n+\tif (!is_cxl_region(dev))\n+\t\treturn 0;\n+\n+\tcxlr = to_cxl_region(dev);\n+\tp = &cxlr->params;\n+\n+\tif (p->state != CXL_CONFIG_COMMIT)\n+\t\treturn 0;\n+\n+\tif (!p->res)\n+\t\treturn 0;\n+\n+\treturn resource_contains(p->res, res) ? 1 : 0;\n+}\n+\n+bool cxl_region_contains_soft_reserve(struct resource *res)\n+{\n+\tguard(rwsem_read)(&cxl_rwsem.region);\n+\treturn bus_for_each_dev(&cxl_bus_type, NULL, res,\n+\t\t\t\tregion_contains_soft_reserve) != 0;\n+}\n+EXPORT_SYMBOL_GPL(cxl_region_contains_soft_reserve);\n+\n static int cxl_region_can_probe(struct cxl_region *cxlr)\n {\n \tstruct cxl_region_params *p = &cxlr->params;\ndiff --git a/include/cxl/cxl.h b/include/cxl/cxl.h\nnew file mode 100644\nindex 000000000000..db1f588e106c\n--- /dev/null\n+++ b/include/cxl/cxl.h\n@@ -0,0 +1,15 @@\n+/* SPDX-License-Identifier: GPL-2.0-only */\n+/* Copyright (c) 2026 Advanced Micro Devices, Inc. */\n+#ifndef _CXL_H_\n+#define _CXL_H_\n+\n+#ifdef CONFIG_CXL_REGION\n+bool cxl_region_contains_soft_reserve(struct resource *res);\n+#else\n+static inline bool cxl_region_contains_soft_reserve(struct resource *res)\n+{\n+\treturn false;\n+}\n+#endif\n+\n+#endif /* _CXL_H_ */\n-- \n2.17.1\n\n\n\n---\n\nReworked from a patch by Alison Schofield <alison.schofield@intel.com>\n\nReintroduce Soft Reserved range into the iomem_resource tree for HMEM\nto consume.\n\nThis restores visibility in /proc/iomem for ranges actively in use, while\navoiding the early-boot conflicts that occurred when Soft Reserved was\npublished into iomem before CXL window and region discovery.\n\nLink: https://lore.kernel.org/linux-cxl/29312c0765224ae76862d59a17748c8188fb95f1.1692638817.git.alison.schofield@intel.com/\nCo-developed-by: Alison Schofield <alison.schofield@intel.com>\nSigned-off-by: Alison Schofield <alison.schofield@intel.com>\nCo-developed-by: Zhijian Li <lizhijian@fujitsu.com>\nSigned-off-by: Zhijian Li <lizhijian@fujitsu.com>\nSigned-off-by: Smita Koralahalli <Smita.KoralahalliChannabasappa@amd.com>\nReviewed-by: Dave Jiang <dave.jiang@intel.com>\nReviewed-by: Jonathan Cameron <jonathan.cameron@huawei.com>\nReviewed-by: Dan Williams <dan.j.williams@intel.com>\n---\n drivers/dax/hmem/hmem.c | 32 +++++++++++++++++++++++++++++++-\n 1 file changed, 31 insertions(+), 1 deletion(-)\n\ndiff --git a/drivers/dax/hmem/hmem.c b/drivers/dax/hmem/hmem.c\nindex 85854e25254b..c07bf5fe833d 100644\n--- a/drivers/dax/hmem/hmem.c\n+++ b/drivers/dax/hmem/hmem.c\n@@ -59,6 +59,34 @@ static void release_hmem(void *pdev)\n \tplatform_device_unregister(pdev);\n }\n \n+static void remove_soft_reserved(void *r)\n+{\n+\tremove_resource(r);\n+\tkfree(r);\n+}\n+\n+static int add_soft_reserve_into_iomem(struct device *host,\n+\t\t\t\t       const struct resource *res)\n+{\n+\tint rc;\n+\n+\tstruct resource *soft __free(kfree) =\n+\t\tkmalloc(sizeof(*res), GFP_KERNEL);\n+\tif (!soft)\n+\t\treturn -ENOMEM;\n+\n+\t*soft = DEFINE_RES_NAMED_DESC(res->start, (res->end - res->start + 1),\n+\t\t\t\t      \"Soft Reserved\", IORESOURCE_MEM,\n+\t\t\t\t      IORES_DESC_SOFT_RESERVED);\n+\n+\trc = insert_resource(&iomem_resource, soft);\n+\tif (rc)\n+\t\treturn rc;\n+\n+\treturn devm_add_action_or_reset(host, remove_soft_reserved,\n+\t\t\t\t\tno_free_ptr(soft));\n+}\n+\n static int hmem_register_device(struct device *host, int target_nid,\n \t\t\t\tconst struct resource *res)\n {\n@@ -88,7 +116,9 @@ static int hmem_register_device(struct device *host, int target_nid,\n \tif (rc != REGION_INTERSECTS)\n \t\treturn 0;\n \n-\t/* TODO: Add Soft-Reserved memory back to iomem */\n+\trc = add_soft_reserve_into_iomem(host, res);\n+\tif (rc)\n+\t\treturn rc;\n \n \tid = memregion_alloc(GFP_KERNEL);\n \tif (id < 0) {\n-- \n2.17.1\n\n\n\n---\n\nAdd helpers to register, queue and flush the deferred work.\n\nThese helpers allow dax_hmem to execute ownership resolution outside the\nprobe context before dax_cxl binds.\n\nSigned-off-by: Smita Koralahalli <Smita.KoralahalliChannabasappa@amd.com>\n---\n drivers/dax/bus.c | 58 +++++++++++++++++++++++++++++++++++++++++++++++\n drivers/dax/bus.h |  7 ++++++\n 2 files changed, 65 insertions(+)\n\ndiff --git a/drivers/dax/bus.c b/drivers/dax/bus.c\nindex 5f387feb95f0..92b88952ede1 100644\n--- a/drivers/dax/bus.c\n+++ b/drivers/dax/bus.c\n@@ -25,6 +25,64 @@ DECLARE_RWSEM(dax_region_rwsem);\n  */\n DECLARE_RWSEM(dax_dev_rwsem);\n \n+static DEFINE_MUTEX(dax_hmem_lock);\n+static dax_hmem_deferred_fn hmem_deferred_fn;\n+static void *dax_hmem_data;\n+\n+static void hmem_deferred_work(struct work_struct *work)\n+{\n+\tdax_hmem_deferred_fn fn;\n+\tvoid *data;\n+\n+\tscoped_guard(mutex, &dax_hmem_lock) {\n+\t\tfn = hmem_deferred_fn;\n+\t\tdata = dax_hmem_data;\n+\t}\n+\n+\tif (fn)\n+\t\tfn(data);\n+}\n+\n+static DECLARE_WORK(dax_hmem_work, hmem_deferred_work);\n+\n+int dax_hmem_register_work(dax_hmem_deferred_fn fn, void *data)\n+{\n+\tguard(mutex)(&dax_hmem_lock);\n+\n+\tif (hmem_deferred_fn)\n+\t\treturn -EINVAL;\n+\n+\thmem_deferred_fn = fn;\n+\tdax_hmem_data = data;\n+\treturn 0;\n+}\n+EXPORT_SYMBOL_GPL(dax_hmem_register_work);\n+\n+int dax_hmem_unregister_work(dax_hmem_deferred_fn fn, void *data)\n+{\n+\tguard(mutex)(&dax_hmem_lock);\n+\n+\tif (hmem_deferred_fn != fn || dax_hmem_data != data)\n+\t\treturn -EINVAL;\n+\n+\thmem_deferred_fn = NULL;\n+\tdax_hmem_data = NULL;\n+\treturn 0;\n+}\n+EXPORT_SYMBOL_GPL(dax_hmem_unregister_work);\n+\n+void dax_hmem_queue_work(void)\n+{\n+\tqueue_work(system_long_wq, &dax_hmem_work);\n+}\n+EXPORT_SYMBOL_GPL(dax_hmem_queue_work);\n+\n+void dax_hmem_flush_work(void)\n+{\n+\tflush_work(&dax_hmem_work);\n+}\n+EXPORT_SYMBOL_GPL(dax_hmem_flush_work);\n+\n #define DAX_NAME_LEN 30\n struct dax_id {\n \tstruct list_head list;\ndiff --git a/drivers/dax/bus.h b/drivers/dax/bus.h\nindex cbbf64443098..b58a88e8089c 100644\n--- a/drivers/dax/bus.h\n+++ b/drivers/dax/bus.h\n@@ -41,6 +41,13 @@ struct dax_device_driver {\n \tvoid (*remove)(struct dev_dax *dev);\n };\n \n+typedef void (*dax_hmem_deferred_fn)(void *data);\n+\n+int dax_hmem_register_work(dax_hmem_deferred_fn fn, void *data);\n+int dax_hmem_unregister_work(dax_hmem_deferred_fn fn, void *data);\n+void dax_hmem_queue_work(void);\n+void dax_hmem_flush_work(void);\n+\n int __dax_driver_register(struct dax_device_driver *dax_drv,\n \t\tstruct module *module, const char *mod_name);\n #define dax_driver_register(driver) \\\n-- \n2.17.1\n\n\n\n---\n\nThe current probe time ownership check for Soft Reserved memory based\nsolely on CXL window intersection is insufficient. dax_hmem probing is not\nalways guaranteed to run after CXL enumeration and region assembly, which\ncan lead to incorrect ownership decisions before the CXL stack has\nfinished publishing windows and assembling committed regions.\n\nIntroduce deferred ownership handling for Soft Reserved ranges that\nintersect CXL windows. When such a range is encountered during dax_hmem\nprobe, schedule deferred work and wait for the CXL stack to complete\nenumeration and region assembly before deciding ownership.\n\nEvaluate ownership of Soft Reserved ranges based on CXL region\ncontainment.\n\n   - If all Soft Reserved ranges are fully contained within committed CXL\n     regions, DROP handling Soft Reserved ranges from dax_hmem and allow\n     dax_cxl to bind.\n\n   - If any Soft Reserved range is not fully claimed by committed CXL\n     region, REGISTER the Soft Reserved ranges with dax_hmem.\n\nUse dax_cxl_mode to coordinate ownership decisions for Soft Reserved\nranges. Once, ownership resolution is complete, flush the deferred work\nfrom dax_cxl before allowing dax_cxl to bind.\n\nThis enforces a strict ownership. Either CXL fully claims the Soft\nreserved ranges or it relinquishes it entirely.\n\nCo-developed-by: Dan Williams <dan.j.williams@intel.com>\nSigned-off-by: Dan Williams <dan.j.williams@intel.com>\nSigned-off-by: Smita Koralahalli <Smita.KoralahalliChannabasappa@amd.com>\n---\n drivers/dax/bus.c       |  3 ++\n drivers/dax/bus.h       | 19 ++++++++++\n drivers/dax/cxl.c       |  1 +\n drivers/dax/hmem/hmem.c | 78 +++++++++++++++++++++++++++++++++++++++--\n 4 files changed, 99 insertions(+), 2 deletions(-)\n\ndiff --git a/drivers/dax/bus.c b/drivers/dax/bus.c\nindex 92b88952ede1..81985bcc70f9 100644\n--- a/drivers/dax/bus.c\n+++ b/drivers/dax/bus.c\n@@ -25,6 +25,9 @@ DECLARE_RWSEM(dax_region_rwsem);\n  */\n DECLARE_RWSEM(dax_dev_rwsem);\n \n+enum dax_cxl_mode dax_cxl_mode = DAX_CXL_MODE_DEFER;\n+EXPORT_SYMBOL_NS_GPL(dax_cxl_mode, \"CXL\");\n+\n static DEFINE_MUTEX(dax_hmem_lock);\n static dax_hmem_deferred_fn hmem_deferred_fn;\n static void *dax_hmem_data;\ndiff --git a/drivers/dax/bus.h b/drivers/dax/bus.h\nindex b58a88e8089c..82616ff52fd1 100644\n--- a/drivers/dax/bus.h\n+++ b/drivers/dax/bus.h\n@@ -41,6 +41,25 @@ struct dax_device_driver {\n \tvoid (*remove)(struct dev_dax *dev);\n };\n \n+/*\n+ * enum dax_cxl_mode - State machine to determine ownership for CXL\n+ * tagged Soft Reserved memory ranges.\n+ * @DAX_CXL_MODE_DEFER: Ownership resolution pending. Set while waiting\n+ * for CXL enumeration and region assembly to complete.\n+ * @DAX_CXL_MODE_REGISTER: CXL regions do not fully cover Soft Reserved\n+ * ranges. Fall back to registering those ranges via dax_hmem.\n+ * @DAX_CXL_MODE_DROP: All Soft Reserved ranges intersecting CXL windows\n+ * are fully contained within committed CXL regions. Drop HMEM handling\n+ * and allow dax_cxl to bind.\n+ */\n+enum dax_cxl_mode {\n+\tDAX_CXL_MODE_DEFER,\n+\tDAX_CXL_MODE_REGISTER,\n+\tDAX_CXL_MODE_DROP,\n+};\n+\n+extern enum dax_cxl_mode dax_cxl_mode;\n+\n typedef void (*dax_hmem_deferred_fn)(void *data);\n \n int dax_hmem_register_work(dax_hmem_deferred_fn fn, void *data);\ndiff --git a/drivers/dax/cxl.c b/drivers/dax/cxl.c\nindex a2136adfa186..3ab39b77843d 100644\n--- a/drivers/dax/cxl.c\n+++ b/drivers/dax/cxl.c\n@@ -44,6 +44,7 @@ static struct cxl_driver cxl_dax_region_driver = {\n \n static void cxl_dax_region_driver_register(struct work_struct *work)\n {\n+\tdax_hmem_flush_work();\n \tcxl_driver_register(&cxl_dax_region_driver);\n }\n \ndiff --git a/drivers/dax/hmem/hmem.c b/drivers/dax/hmem/hmem.c\nindex 1e3424358490..85854e25254b 100644\n--- a/drivers/dax/hmem/hmem.c\n+++ b/drivers/dax/hmem/hmem.c\n@@ -3,6 +3,7 @@\n #include <linux/memregion.h>\n #include <linux/module.h>\n #include <linux/dax.h>\n+#include <cxl/cxl.h>\n #include \"../bus.h\"\n \n static bool region_idle;\n@@ -69,8 +70,18 @@ static int hmem_register_device(struct device *host, int target_nid,\n \tif (IS_ENABLED(CONFIG_DEV_DAX_CXL) &&\n \t    region_intersects(res->start, resource_size(res), IORESOURCE_MEM,\n \t\t\t      IORES_DESC_CXL) != REGION_DISJOINT) {\n-\t\tdev_dbg(host, \"deferring range to CXL: %pr\\n\", res);\n-\t\treturn 0;\n+\t\tswitch (dax_cxl_mode) {\n+\t\tcase DAX_CXL_MODE_DEFER:\n+\t\t\tdev_dbg(host, \"deferring range to CXL: %pr\\n\", res);\n+\t\t\tdax_hmem_queue_work();\n+\t\t\treturn 0;\n+\t\tcase DAX_CXL_MODE_REGISTER:\n+\t\t\tdev_dbg(host, \"registering CXL range: %pr\\n\", res);\n+\t\t\tbreak;\n+\t\tcase DAX_CXL_MODE_DROP:\n+\t\t\tdev_dbg(host, \"dropping CXL range: %pr\\n\", res);\n+\t\t\treturn 0;\n+\t\t}\n \t}\n \n \trc = region_intersects_soft_reserve(res->start, resource_size(res));\n@@ -123,8 +134,70 @@ static int hmem_register_device(struct device *host, int target_nid,\n \treturn rc;\n }\n \n+static int hmem_register_cxl_device(struct device *host, int target_nid,\n+\t\t\t\t    const struct resource *res)\n+{\n+\tif (region_intersects(res->start, resource_size(res), IORESOURCE_MEM,\n+\t\t\t      IORES_DESC_CXL) != REGION_DISJOINT)\n+\t\treturn hmem_register_device(host, target_nid, res);\n+\n+\treturn 0;\n+}\n+\n+static int soft_reserve_has_cxl_match(struct device *host, int target_nid,\n+\t\t\t\t      const struct resource *res)\n+{\n+\tif (region_intersects(res->start, resource_size(res), IORESOURCE_MEM,\n+\t\t\t      IORES_DESC_CXL) != REGION_DISJOINT) {\n+\t\tif (!cxl_region_contains_soft_reserve((struct resource *)res))\n+\t\t\treturn 1;\n+\t}\n+\n+\treturn 0;\n+}\n+\n+static void process_defer_work(void *data)\n+{\n+\tstruct platform_device *pdev = data;\n+\tint rc;\n+\n+\t/* relies on cxl_acpi and cxl_pci having had a chance to load */\n+\twait_for_device_probe();\n+\n+\trc = walk_hmem_resources(&pdev->dev, soft_reserve_has_cxl_match);\n+\n+\tif (!rc) {\n+\t\tdax_cxl_mode = DAX_CXL_MODE_DROP;\n+\t\tdev_dbg(&pdev->dev, \"All Soft Reserved ranges claimed by CXL\\n\");\n+\t} else {\n+\t\tdax_cxl_mode = DAX_CXL_MODE_REGISTER;\n+\t\tdev_warn(&pdev->dev,\n+\t\t\t \"Soft Reserved not fully contained in CXL; using HMEM\\n\");\n+\t}\n+\n+\twalk_hmem_resources(&pdev->dev, hmem_register_cxl_device);\n+}\n+\n+static void kill_defer_work(void *data)\n+{\n+\tstruct platform_device *pdev = data;\n+\n+\tdax_hmem_flush_work();\n+\tdax_hmem_unregister_work(process_defer_work, pdev);\n+}\n+\n static int dax_hmem_platform_probe(struct platform_device *pdev)\n {\n+\tint rc;\n+\n+\trc = dax_hmem_register_work(process_defer_work, pdev);\n+\tif (rc)\n+\t\treturn rc;\n+\n+\trc = devm_add_action_or_reset(&pdev->dev, kill_defer_work, pdev);\n+\tif (rc)\n+\t\treturn rc;\n+\n \treturn walk_hmem_resources(&pdev->dev, hmem_register_device);\n }\n \n@@ -174,3 +247,4 @@ MODULE_ALIAS(\"platform:hmem_platform*\");\n MODULE_DESCRIPTION(\"HMEM DAX: direct access to 'specific purpose' memory\");\n MODULE_LICENSE(\"GPL v2\");\n MODULE_AUTHOR(\"Intel Corporation\");\n+MODULE_IMPORT_NS(\"CXL\");\n-- \n2.17.1\n\n",
          "reply_to": ""
        },
        {
          "author": "Alison Schofield",
          "summary": "Reviewer Alison Schofield raised concerns about the handling of region teardown in the patch, specifically questioning whether it aligns with previous discussions and decisions. She also pointed out that the new approach may not be suitable for all use cases.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes",
            "unclear intention"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "On Tue, Feb 10, 2026 at 06:44:52AM +0000, Smita Koralahalli wrote:\n> This series aims to address long-standing conflicts between HMEM and\n> CXL when handling Soft Reserved memory ranges.\n> \n> Reworked from Dan's patch:\n> https://git.kernel.org/pub/scm/linux/kernel/git/cxl/cxl.git/patch/?id=ab70c6227ee6165a562c215d9dcb4a1c55620d5d\n> \n> Previous work:\n> https://lore.kernel.org/all/20250715180407.47426-1-Smita.KoralahalliChannabasappa@amd.com/\n> \n> Link to v5:\n> https://lore.kernel.org/all/20260122045543.218194-1-Smita.KoralahalliChannabasappa@amd.com\n> \n> The series is based on branch \"for-7.0/cxl-init\" and base-commit is\n> base-commit: bc62f5b308cbdedf29132fe96e9d591e526527e1\n> \n> [1] After offlining the memory I can tear down the regions and recreate\n> them back. dax_cxl creates dax devices and onlines memory.\n> 850000000-284fffffff : CXL Window 0\n>   850000000-284fffffff : region0\n>     850000000-284fffffff : dax0.0\n>       850000000-284fffffff : System RAM (kmem)\n> \n> [2] With CONFIG_CXL_REGION disabled, all the resources are handled by\n> HMEM. Soft Reserved range shows up in /proc/iomem, no regions come up\n> and dax devices are created from HMEM.\n> 850000000-284fffffff : CXL Window 0\n>   850000000-284fffffff : Soft Reserved\n>     850000000-284fffffff : dax0.0\n>       850000000-284fffffff : System RAM (kmem)\n> \n> [3] Region assembly failure works same as [2].\n> \n> [4] REGISTER path:\n> When CXL_BUS = y (with CXL_ACPI, CXL_PCI, CXL_PORT, CXL_MEM = y),\n> the dax_cxl driver is probed and completes initialization before dax_hmem\n> probes. This scenario was tested with CXL = y, DAX_CXL = m and\n> DAX_HMEM = m. To validate the REGISTER path, I forced REGISTER even in\n> cases where SR completely overlaps the CXL region as I did not have access\n> to a system where the CXL region range is smaller than the SR range.\n> \n> 850000000-284fffffff : Soft Reserved\n>   850000000-284fffffff : CXL Window 0\n>     850000000-280fffffff : region0\n>       850000000-284fffffff : dax0.0\n>         850000000-284fffffff : System RAM (kmem)\n> \n> \"path\":\"\\/platform\\/ACPI0017:00\\/root0\\/decoder0.0\\/region0\\/dax_region0\",\n> \"id\":0,\n> \"size\":\"128.00 GiB (137.44 GB)\",\n> \"align\":2097152\n> \n> [   35.961707] cxl-dax: cxl_dax_region_init()\n> [   35.961713] cxl-dax: registering driver.\n> [   35.961715] cxl-dax: dax_hmem work flushed.\n> [   35.961754] alloc_dev_dax_range:  dax0.0: alloc range[0]:\n> 0x000000850000000:0x000000284fffffff\n> [   35.976622] hmem: hmem_platform probe started.\n> [   35.980821] cxl_bus_probe: cxl_dax_region dax_region0: probe: 0\n> [   36.819566] hmem_platform hmem_platform.0: Soft Reserved not fully\n> contained in CXL; using HMEM\n> [   36.819569] hmem_register_device: hmem_platform hmem_platform.0:\n> registering CXL range: [mem 0x850000000-0x284fffffff flags 0x80000200]\n> [   36.934156] alloc_dax_region: hmem hmem.6: dax_region resource conflict\n> for [mem 0x850000000-0x284fffffff]\n> [   36.989310] hmem hmem.6: probe with driver hmem failed with error -12\n> \n> [5] When CXL_BUS = m (with CXL_ACPI, CXL_PCI, CXL_PORT, CXL_MEM = m),\n> DAX_CXL = m and DAX_HMEM = y the results are as expected. To validate the\n> REGISTER path, I forced REGISTER even in cases where SR completely\n> overlaps the CXL region as I did not have access to a system where the\n> CXL region range is smaller than the SR range.\n> \n> 850000000-284fffffff : Soft Reserved\n>   850000000-284fffffff : CXL Window 0\n>     850000000-280fffffff : region0\n>       850000000-284fffffff : dax6.0\n>         850000000-284fffffff : System RAM (kmem)\n> \n> \"path\":\"\\/platform\\/hmem.6\",\n> \"id\":6,\n> \"size\":\"128.00 GiB (137.44 GB)\",\n> \"align\":2097152\n> \n> [   30.897665] devm_cxl_add_dax_region: cxl_region region0: region0:\n> register dax_region0\n> [   30.921015] hmem: hmem_platform probe started.\n> [   31.017946] hmem_platform hmem_platform.0: Soft Reserved not fully\n> contained in CXL; using HMEM\n> [   31.056310] alloc_dev_dax_range:  dax6.0: alloc range[0]:\n> 0x0000000850000000:0x000000284fffffff\n> [   34.781516] cxl-dax: cxl_dax_region_init()\n> [   34.781522] cxl-dax: registering driver.\n> [   34.781523] cxl-dax: dax_hmem work flushed.\n> [   34.781549] alloc_dax_region: cxl_dax_region dax_region0: dax_region\n> resource conflict for [mem 0x850000000-0x284fffffff]\n> [   34.781552] cxl_bus_probe: cxl_dax_region dax_region0: probe: -12\n> [   34.781554] cxl_dax_region dax_region0: probe with driver cxl_dax_region\n> failed with error -12\n> \n> v6 updates:\n> - Patch 1-3 no changes.\n> - New Patches 4-5.\n> - (void *)res -> res.\n> - cxl_region_contains_soft_reserve -> region_contains_soft_reserve.\n> - New file include/cxl/cxl.h\n> - Introduced singleton workqueue.\n> - hmem to queue the work and cxl to flush.\n> - cxl_contains_soft_reserve() -> soft_reserve_has_cxl_match().\n> - Included descriptions for dax_cxl_mode.\n> - kzalloc -> kmalloc in add_soft_reserve_into_iomem()\n> - dax_cxl_mode is exported to CXL.\n> - Introduced hmem_register_cxl_device() for walking only CXL\n> intersected SR ranges the second time.\n\nDuring v5 review of this patch:\n\n[PATCH v5 6/7] dax/hmem, cxl: Defer and resolve ownership of Soft Reserved memory ranges\n\nthere was discussion around handling region teardown. It's not mentioned\nin the changelog, and the teardown is completely removed from the patch.\n\nThe discussion seemed to be leaning towards not tearing down 'all', but\nit's not clear to me that we decided not to tear down anything - which\nthis update now does. \n\nAnd, as you may be guessing, I'm seeing disabled regions with DAX children\nand figuring out what can be done with them.\n\nCan you explain the new approach so I can test against that intention?\n\nFYI - I am able to confirm the dax regions are back for no-soft-reserved\ncase, and my basic hotplug flow works with v6.\n\n-- Alison\n\n\n---\n\nOn Tue, Feb 10, 2026 at 06:44:53AM +0000, Smita Koralahalli wrote:\n> From: Dan Williams <dan.j.williams@intel.com>\n> \n> Ensure cxl_acpi has published CXL Window resources before HMEM walks Soft\n> Reserved ranges.\n> \n> Replace MODULE_SOFTDEP(\"pre: cxl_acpi\") with an explicit, synchronous\n> request_module(\"cxl_acpi\"). MODULE_SOFTDEP() only guarantees eventual\n> loading, it does not enforce that the dependency has finished init\n> before the current module runs. This can cause HMEM to start before\n> cxl_acpi has populated the resource tree, breaking detection of overlaps\n> between Soft Reserved and CXL Windows.\n> \n> Also, request cxl_pci before HMEM walks Soft Reserved ranges. Unlike\n> cxl_acpi, cxl_pci attach is asynchronous and creates dependent devices\n> that trigger further module loads. Asynchronous probe flushing\n> (wait_for_device_probe()) is added later in the series in a deferred\n> context before HMEM makes ownership decisions for Soft Reserved ranges.\n> \n> Add an additional explicit Kconfig ordering so that CXL_ACPI and CXL_PCI\n> must be initialized before DEV_DAX_HMEM. This prevents HMEM from consuming\n> Soft Reserved ranges before CXL drivers have had a chance to claim them.\n\nReviewed-by: Alison Schofield <alison.schofield@intel.com>\n\nsnip\n\n\n\n---\n\nOn Tue, Feb 10, 2026 at 06:44:54AM +0000, Smita Koralahalli wrote:\n> From: Dan Williams <dan.j.williams@intel.com>\n> \n> Replace IS_ENABLED(CONFIG_CXL_REGION) with IS_ENABLED(CONFIG_DEV_DAX_CXL)\n> so that HMEM only defers Soft Reserved ranges when CXL DAX support is\n> enabled. This makes the coordination between HMEM and the CXL stack more\n> precise and prevents deferral in unrelated CXL configurations.\n\n\nReviewed-by: Alison Schofield <alison.schofield@intel.com>\n\nsnip\n\n\n---\n\nOn Tue, Feb 10, 2026 at 06:44:55AM +0000, Smita Koralahalli wrote:\n> __cxl_decoder_detach() currently resets decoder programming whenever a\n> region is detached if cxl_config_state is beyond CXL_CONFIG_ACTIVE. For\n\nNot sure 'detached' is the right word. Unregistered maybe?\n\n> autodiscovered regions, this can incorrectly tear down decoder state\n> that may be relied upon by other consumers or by subsequent ownership\n> decisions.\n> \n> Skip cxl_region_decode_reset() during detach when CXL_REGION_F_AUTO is\n> set.\n\nI get how this is needed in the failover to DAX case, yet I'm not clear\nhow it fits in with folks that just want to destroy that auto region\nand resuse the pieces.\n\nYour other recent patch cxl/hdm: Avoid DVSEC fallback after region teardown[1],\nshowed me that the memdevs, when left with the endpoint decoders not reset,\nwill keep trying to create another region when reprobed.\n\n[1] https://lore.kernel.org/linux-cxl/aY6pTk63ivjkanlR@aschofie-mobl2.lan/\n\nI think the patch does what it says it does. Perhaps expand on why that \nis always the right thing to do.\n\n--Alison\n\n\n> \n> Signed-off-by: Smita Koralahalli <Smita.KoralahalliChannabasappa@amd.com>\n> Reviewed-by: Jonathan Cameron <jonathan.cameron@huawei.com>\n> Reviewed-by: Dave Jiang <dave.jiang@intel.com>\n> Reviewed-by: Alejandro Lucero <alucerop@amd.com>\n> ---\n>  drivers/cxl/core/region.c | 4 +++-\n>  1 file changed, 3 insertions(+), 1 deletion(-)\n> \n> diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c\n> index ae899f68551f..45ee598daf95 100644\n> --- a/drivers/cxl/core/region.c\n> +++ b/drivers/cxl/core/region.c\n> @@ -2178,7 +2178,9 @@ __cxl_decoder_detach(struct cxl_region *cxlr,\n>  \t\tcxled->part = -1;\n>  \n>  \tif (p->state > CXL_CONFIG_ACTIVE) {\n> -\t\tcxl_region_decode_reset(cxlr, p->interleave_ways);\n> +\t\tif (!test_bit(CXL_REGION_F_AUTO, &cxlr->flags))\n> +\t\t\tcxl_region_decode_reset(cxlr, p->interleave_ways);\n> +\n>  \t\tp->state = CXL_CONFIG_ACTIVE;\n>  \t}\n>  \n> -- \n> 2.17.1\n> \n",
          "reply_to": "Smita Koralahalli"
        },
        {
          "author": "Koralahalli Smita",
          "summary": "Reviewer Smita Koralahalli clarified that the disabled regions on CXL side are expected as Dan mentioned, showing that CXL tried to claim the range but HMEM got there first.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "no clear objection"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Hi Alison,\n\nOn 2/10/2026 11:16 AM, Alison Schofield wrote:\n> On Tue, Feb 10, 2026 at 06:44:52AM +0000, Smita Koralahalli wrote:\n>> This series aims to address long-standing conflicts between HMEM and\n>> CXL when handling Soft Reserved memory ranges.\n>>\n>> Reworked from Dan's patch:\n>> https://git.kernel.org/pub/scm/linux/kernel/git/cxl/cxl.git/patch/?id=ab70c6227ee6165a562c215d9dcb4a1c55620d5d\n>>\n>> Previous work:\n>> https://lore.kernel.org/all/20250715180407.47426-1-Smita.KoralahalliChannabasappa@amd.com/\n>>\n>> Link to v5:\n>> https://lore.kernel.org/all/20260122045543.218194-1-Smita.KoralahalliChannabasappa@amd.com\n>>\n>> The series is based on branch \"for-7.0/cxl-init\" and base-commit is\n>> base-commit: bc62f5b308cbdedf29132fe96e9d591e526527e1\n>>\n>> [1] After offlining the memory I can tear down the regions and recreate\n>> them back. dax_cxl creates dax devices and onlines memory.\n>> 850000000-284fffffff : CXL Window 0\n>>    850000000-284fffffff : region0\n>>      850000000-284fffffff : dax0.0\n>>        850000000-284fffffff : System RAM (kmem)\n>>\n>> [2] With CONFIG_CXL_REGION disabled, all the resources are handled by\n>> HMEM. Soft Reserved range shows up in /proc/iomem, no regions come up\n>> and dax devices are created from HMEM.\n>> 850000000-284fffffff : CXL Window 0\n>>    850000000-284fffffff : Soft Reserved\n>>      850000000-284fffffff : dax0.0\n>>        850000000-284fffffff : System RAM (kmem)\n>>\n>> [3] Region assembly failure works same as [2].\n>>\n>> [4] REGISTER path:\n>> When CXL_BUS = y (with CXL_ACPI, CXL_PCI, CXL_PORT, CXL_MEM = y),\n>> the dax_cxl driver is probed and completes initialization before dax_hmem\n>> probes. This scenario was tested with CXL = y, DAX_CXL = m and\n>> DAX_HMEM = m. To validate the REGISTER path, I forced REGISTER even in\n>> cases where SR completely overlaps the CXL region as I did not have access\n>> to a system where the CXL region range is smaller than the SR range.\n>>\n>> 850000000-284fffffff : Soft Reserved\n>>    850000000-284fffffff : CXL Window 0\n>>      850000000-280fffffff : region0\n>>        850000000-284fffffff : dax0.0\n>>          850000000-284fffffff : System RAM (kmem)\n>>\n>> \"path\":\"\\/platform\\/ACPI0017:00\\/root0\\/decoder0.0\\/region0\\/dax_region0\",\n>> \"id\":0,\n>> \"size\":\"128.00 GiB (137.44 GB)\",\n>> \"align\":2097152\n>>\n>> [   35.961707] cxl-dax: cxl_dax_region_init()\n>> [   35.961713] cxl-dax: registering driver.\n>> [   35.961715] cxl-dax: dax_hmem work flushed.\n>> [   35.961754] alloc_dev_dax_range:  dax0.0: alloc range[0]:\n>> 0x000000850000000:0x000000284fffffff\n>> [   35.976622] hmem: hmem_platform probe started.\n>> [   35.980821] cxl_bus_probe: cxl_dax_region dax_region0: probe: 0\n>> [   36.819566] hmem_platform hmem_platform.0: Soft Reserved not fully\n>> contained in CXL; using HMEM\n>> [   36.819569] hmem_register_device: hmem_platform hmem_platform.0:\n>> registering CXL range: [mem 0x850000000-0x284fffffff flags 0x80000200]\n>> [   36.934156] alloc_dax_region: hmem hmem.6: dax_region resource conflict\n>> for [mem 0x850000000-0x284fffffff]\n>> [   36.989310] hmem hmem.6: probe with driver hmem failed with error -12\n>>\n>> [5] When CXL_BUS = m (with CXL_ACPI, CXL_PCI, CXL_PORT, CXL_MEM = m),\n>> DAX_CXL = m and DAX_HMEM = y the results are as expected. To validate the\n>> REGISTER path, I forced REGISTER even in cases where SR completely\n>> overlaps the CXL region as I did not have access to a system where the\n>> CXL region range is smaller than the SR range.\n>>\n>> 850000000-284fffffff : Soft Reserved\n>>    850000000-284fffffff : CXL Window 0\n>>      850000000-280fffffff : region0\n>>        850000000-284fffffff : dax6.0\n>>          850000000-284fffffff : System RAM (kmem)\n>>\n>> \"path\":\"\\/platform\\/hmem.6\",\n>> \"id\":6,\n>> \"size\":\"128.00 GiB (137.44 GB)\",\n>> \"align\":2097152\n>>\n>> [   30.897665] devm_cxl_add_dax_region: cxl_region region0: region0:\n>> register dax_region0\n>> [   30.921015] hmem: hmem_platform probe started.\n>> [   31.017946] hmem_platform hmem_platform.0: Soft Reserved not fully\n>> contained in CXL; using HMEM\n>> [   31.056310] alloc_dev_dax_range:  dax6.0: alloc range[0]:\n>> 0x0000000850000000:0x000000284fffffff\n>> [   34.781516] cxl-dax: cxl_dax_region_init()\n>> [   34.781522] cxl-dax: registering driver.\n>> [   34.781523] cxl-dax: dax_hmem work flushed.\n>> [   34.781549] alloc_dax_region: cxl_dax_region dax_region0: dax_region\n>> resource conflict for [mem 0x850000000-0x284fffffff]\n>> [   34.781552] cxl_bus_probe: cxl_dax_region dax_region0: probe: -12\n>> [   34.781554] cxl_dax_region dax_region0: probe with driver cxl_dax_region\n>> failed with error -12\n>>\n>> v6 updates:\n>> - Patch 1-3 no changes.\n>> - New Patches 4-5.\n>> - (void *)res -> res.\n>> - cxl_region_contains_soft_reserve -> region_contains_soft_reserve.\n>> - New file include/cxl/cxl.h\n>> - Introduced singleton workqueue.\n>> - hmem to queue the work and cxl to flush.\n>> - cxl_contains_soft_reserve() -> soft_reserve_has_cxl_match().\n>> - Included descriptions for dax_cxl_mode.\n>> - kzalloc -> kmalloc in add_soft_reserve_into_iomem()\n>> - dax_cxl_mode is exported to CXL.\n>> - Introduced hmem_register_cxl_device() for walking only CXL\n>> intersected SR ranges the second time.\n> \n> During v5 review of this patch:\n> \n> [PATCH v5 6/7] dax/hmem, cxl: Defer and resolve ownership of Soft Reserved memory ranges\n> \n> there was discussion around handling region teardown. It's not mentioned\n> in the changelog, and the teardown is completely removed from the patch.\n> \n> The discussion seemed to be leaning towards not tearing down 'all', but\n> it's not clear to me that we decided not to tear down anything - which\n> this update now does.\n> \n> And, as you may be guessing, I'm seeing disabled regions with DAX children\n> and figuring out what can be done with them.\n> \n> Can you explain the new approach so I can test against that intention?\n> \n> FYI - I am able to confirm the dax regions are back for no-soft-reserved\n> case, and my basic hotplug flow works with v6.\n> \n> -- Alison\n\nHi Alison,\n\nThanks for the test and confirming the no-soft-reserved and hotplug \ncases work.\n\nYou're right that cxl_region_teardown_all() was removed in v6. I should \nhave called this out more clearly in the changelog. Here's what I learnt \nfrom v5 review. Correct me if I misunderstood.\n\nDuring v5 review, regarding dropping teardown (comments from Dan):\n\n\"If we go with the alloc_dax_region() observation in my other mail it \nmeans that the HPA space will already be claimed and \ncxl_dax_region_probe() will fail. If we can get to that point of \"all \nHMEM registered, and all CXL regions failing to attach their\ncxl_dax_region devices\" that is a good stopping point. Then can decide \nif a follow-on patch is needed to cleanup that state \n(cxl_region_teardown_all()) , or if it can just idle that way in the \nmessy state and wait for userspace to cleanup if it wants.\"\n\nhttps://lore.kernel.org/all/697aad9546542_30951007c@dwillia2-mobl4.notmuch/\n\nAlso:\n\n\"In other words, I thought total teardown would be simpler, but as the \nfeedback keeps coming in, I think that brings a different set of \ncomplexity. So just inject failures for dax_cxl to trip over and then we \ncan go further later to effect total teardown if that proves to not be \nenough.\"\n\nhttps://lore.kernel.org/all/697a9d46b147e_309510027@dwillia2-mobl4.notmuch/\n\nThe v6 approach replaces teardown with the alloc_dax_region() resource \nexclusion in patch 5. When HMEM wins the ownership decision (REGISTER \npath), it successfully claims the dax_region resource range first. When \ndax_cxl later tries to probe, its alloc_dax_region() call hits a \nresource conflict and fails, leaving the cxl_dax_region device in a \ndisabled state.\n\n(There is a separate ordering issue when CXL is built-in and HMEM is a \nmodule, where dax_cxl may claim the dax_region first as observed in \nexperiments [4] and [5], but that is an independent topic and might not \nbe relevant here.)\n\nSo the disabled regions with DAX children you are seeing on the CXL side \nare likely expected as Dan mentioned - they show that CXL tried to claim \nthe range but HMEM got there first. Though the cxl region remains \ncommitted, no dax_region gets created for it because the HPA space is \nalready taken.\n\nThanks\nSmita\n\n",
          "reply_to": "Alison Schofield"
        },
        {
          "author": "Alison Schofield",
          "summary": "Reviewer Alison Schofield raised concerns that the patch does not accurately reflect the memory topology, citing discrepancies between expected and actual views of Soft Reserved regions.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes",
            "disagreement with patch"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "On Tue, Feb 10, 2026 at 11:49:04AM -0800, Koralahalli Channabasappa, Smita wrote:\n> Hi Alison,\n> \n> On 2/10/2026 11:16 AM, Alison Schofield wrote:\n> > On Tue, Feb 10, 2026 at 06:44:52AM +0000, Smita Koralahalli wrote:\n> > > This series aims to address long-standing conflicts between HMEM and\n> > > CXL when handling Soft Reserved memory ranges.\n> > > \n> > > Reworked from Dan's patch:\n> > > https://git.kernel.org/pub/scm/linux/kernel/git/cxl/cxl.git/patch/?id=ab70c6227ee6165a562c215d9dcb4a1c55620d5d\n> > > \n> > > Previous work:\n> > > https://lore.kernel.org/all/20250715180407.47426-1-Smita.KoralahalliChannabasappa@amd.com/\n> > > \n> > > Link to v5:\n> > > https://lore.kernel.org/all/20260122045543.218194-1-Smita.KoralahalliChannabasappa@amd.com\n> > > \n> > > The series is based on branch \"for-7.0/cxl-init\" and base-commit is\n> > > base-commit: bc62f5b308cbdedf29132fe96e9d591e526527e1\n> > > \n> > > [1] After offlining the memory I can tear down the regions and recreate\n> > > them back. dax_cxl creates dax devices and onlines memory.\n> > > 850000000-284fffffff : CXL Window 0\n> > >    850000000-284fffffff : region0\n> > >      850000000-284fffffff : dax0.0\n> > >        850000000-284fffffff : System RAM (kmem)\n> > > \n> > > [2] With CONFIG_CXL_REGION disabled, all the resources are handled by\n> > > HMEM. Soft Reserved range shows up in /proc/iomem, no regions come up\n> > > and dax devices are created from HMEM.\n> > > 850000000-284fffffff : CXL Window 0\n> > >    850000000-284fffffff : Soft Reserved\n> > >      850000000-284fffffff : dax0.0\n> > >        850000000-284fffffff : System RAM (kmem)\n> > > \n> > > [3] Region assembly failure works same as [2].\n> > > \n> > > [4] REGISTER path:\n> > > When CXL_BUS = y (with CXL_ACPI, CXL_PCI, CXL_PORT, CXL_MEM = y),\n> > > the dax_cxl driver is probed and completes initialization before dax_hmem\n> > > probes. This scenario was tested with CXL = y, DAX_CXL = m and\n> > > DAX_HMEM = m. To validate the REGISTER path, I forced REGISTER even in\n> > > cases where SR completely overlaps the CXL region as I did not have access\n> > > to a system where the CXL region range is smaller than the SR range.\n> > > \n> > > 850000000-284fffffff : Soft Reserved\n> > >    850000000-284fffffff : CXL Window 0\n> > >      850000000-280fffffff : region0\n> > >        850000000-284fffffff : dax0.0\n> > >          850000000-284fffffff : System RAM (kmem)\n> > > \n> > > \"path\":\"\\/platform\\/ACPI0017:00\\/root0\\/decoder0.0\\/region0\\/dax_region0\",\n> > > \"id\":0,\n> > > \"size\":\"128.00 GiB (137.44 GB)\",\n> > > \"align\":2097152\n> > > \n> > > [   35.961707] cxl-dax: cxl_dax_region_init()\n> > > [   35.961713] cxl-dax: registering driver.\n> > > [   35.961715] cxl-dax: dax_hmem work flushed.\n> > > [   35.961754] alloc_dev_dax_range:  dax0.0: alloc range[0]:\n> > > 0x000000850000000:0x000000284fffffff\n> > > [   35.976622] hmem: hmem_platform probe started.\n> > > [   35.980821] cxl_bus_probe: cxl_dax_region dax_region0: probe: 0\n> > > [   36.819566] hmem_platform hmem_platform.0: Soft Reserved not fully\n> > > contained in CXL; using HMEM\n> > > [   36.819569] hmem_register_device: hmem_platform hmem_platform.0:\n> > > registering CXL range: [mem 0x850000000-0x284fffffff flags 0x80000200]\n> > > [   36.934156] alloc_dax_region: hmem hmem.6: dax_region resource conflict\n> > > for [mem 0x850000000-0x284fffffff]\n> > > [   36.989310] hmem hmem.6: probe with driver hmem failed with error -12\n> > > \n> > > [5] When CXL_BUS = m (with CXL_ACPI, CXL_PCI, CXL_PORT, CXL_MEM = m),\n> > > DAX_CXL = m and DAX_HMEM = y the results are as expected. To validate the\n> > > REGISTER path, I forced REGISTER even in cases where SR completely\n> > > overlaps the CXL region as I did not have access to a system where the\n> > > CXL region range is smaller than the SR range.\n> > > \n> > > 850000000-284fffffff : Soft Reserved\n> > >    850000000-284fffffff : CXL Window 0\n> > >      850000000-280fffffff : region0\n> > >        850000000-284fffffff : dax6.0\n> > >          850000000-284fffffff : System RAM (kmem)\n> > > \n> > > \"path\":\"\\/platform\\/hmem.6\",\n> > > \"id\":6,\n> > > \"size\":\"128.00 GiB (137.44 GB)\",\n> > > \"align\":2097152\n> > > \n> > > [   30.897665] devm_cxl_add_dax_region: cxl_region region0: region0:\n> > > register dax_region0\n> > > [   30.921015] hmem: hmem_platform probe started.\n> > > [   31.017946] hmem_platform hmem_platform.0: Soft Reserved not fully\n> > > contained in CXL; using HMEM\n> > > [   31.056310] alloc_dev_dax_range:  dax6.0: alloc range[0]:\n> > > 0x0000000850000000:0x000000284fffffff\n> > > [   34.781516] cxl-dax: cxl_dax_region_init()\n> > > [   34.781522] cxl-dax: registering driver.\n> > > [   34.781523] cxl-dax: dax_hmem work flushed.\n> > > [   34.781549] alloc_dax_region: cxl_dax_region dax_region0: dax_region\n> > > resource conflict for [mem 0x850000000-0x284fffffff]\n> > > [   34.781552] cxl_bus_probe: cxl_dax_region dax_region0: probe: -12\n> > > [   34.781554] cxl_dax_region dax_region0: probe with driver cxl_dax_region\n> > > failed with error -12\n> > > \n> > > v6 updates:\n> > > - Patch 1-3 no changes.\n> > > - New Patches 4-5.\n> > > - (void *)res -> res.\n> > > - cxl_region_contains_soft_reserve -> region_contains_soft_reserve.\n> > > - New file include/cxl/cxl.h\n> > > - Introduced singleton workqueue.\n> > > - hmem to queue the work and cxl to flush.\n> > > - cxl_contains_soft_reserve() -> soft_reserve_has_cxl_match().\n> > > - Included descriptions for dax_cxl_mode.\n> > > - kzalloc -> kmalloc in add_soft_reserve_into_iomem()\n> > > - dax_cxl_mode is exported to CXL.\n> > > - Introduced hmem_register_cxl_device() for walking only CXL\n> > > intersected SR ranges the second time.\n> > \n> > During v5 review of this patch:\n> > \n> > [PATCH v5 6/7] dax/hmem, cxl: Defer and resolve ownership of Soft Reserved memory ranges\n> > \n> > there was discussion around handling region teardown. It's not mentioned\n> > in the changelog, and the teardown is completely removed from the patch.\n> > \n> > The discussion seemed to be leaning towards not tearing down 'all', but\n> > it's not clear to me that we decided not to tear down anything - which\n> > this update now does.\n> > \n> > And, as you may be guessing, I'm seeing disabled regions with DAX children\n> > and figuring out what can be done with them.\n> > \n> > Can you explain the new approach so I can test against that intention?\n> > \n> > FYI - I am able to confirm the dax regions are back for no-soft-reserved\n> > case, and my basic hotplug flow works with v6.\n> > \n> > -- Alison\n> \n> Hi Alison,\n> \n> Thanks for the test and confirming the no-soft-reserved and hotplug cases\n> work.\n> \n> You're right that cxl_region_teardown_all() was removed in v6. I should have\n> called this out more clearly in the changelog. Here's what I learnt from v5\n> review. Correct me if I misunderstood.\n> \n> During v5 review, regarding dropping teardown (comments from Dan):\n> \n> \"If we go with the alloc_dax_region() observation in my other mail it means\n> that the HPA space will already be claimed and cxl_dax_region_probe() will\n> fail. If we can get to that point of \"all HMEM registered, and all CXL\n> regions failing to attach their\n> cxl_dax_region devices\" that is a good stopping point. Then can decide if a\n> follow-on patch is needed to cleanup that state (cxl_region_teardown_all())\n> , or if it can just idle that way in the messy state and wait for userspace\n> to cleanup if it wants.\"\n> \n> https://lore.kernel.org/all/697aad9546542_30951007c@dwillia2-mobl4.notmuch/\n> \n> Also:\n> \n> \"In other words, I thought total teardown would be simpler, but as the\n> feedback keeps coming in, I think that brings a different set of complexity.\n> So just inject failures for dax_cxl to trip over and then we can go further\n> later to effect total teardown if that proves to not be enough.\"\n> \n> https://lore.kernel.org/all/697a9d46b147e_309510027@dwillia2-mobl4.notmuch/\n> \n> The v6 approach replaces teardown with the alloc_dax_region() resource\n> exclusion in patch 5. When HMEM wins the ownership decision (REGISTER path),\n> it successfully claims the dax_region resource range first. When dax_cxl\n> later tries to probe, its alloc_dax_region() call hits a resource conflict\n> and fails, leaving the cxl_dax_region device in a disabled state.\n> \n> (There is a separate ordering issue when CXL is built-in and HMEM is a\n> module, where dax_cxl may claim the dax_region first as observed in\n> experiments [4] and [5], but that is an independent topic and might not be\n> relevant here.)\n> \n> So the disabled regions with DAX children you are seeing on the CXL side are\n> likely expected as Dan mentioned - they show that CXL tried to claim the\n> range but HMEM got there first. Though the cxl region remains committed, no\n> dax_region gets created for it because the HPA space is already taken.\n\nHi Smita,\n\nThe disable regions I'm seeing are the remnants of failed region assemblies\nwhere HMEM rightfully took over. So the take over is good, but the expected\nview shown way above and repasted below is not what I'm seeing. Case [3]\nis not the same as Case [2], but have a region btw the SR and DAX.\n\n\n> > > [2] With CONFIG_CXL_REGION disabled, all the resources are handled by\n> > > HMEM. Soft Reserved range shows up in /proc/iomem, no regions come up\n> > > and dax devices are created from HMEM.\n> > > 850000000-284fffffff : CXL Window 0\n> > >    850000000-284fffffff : Soft Reserved\n> > >      850000000-284fffffff : dax0.0\n> > >        850000000-284fffffff : System RAM (kmem)\n> > > \n> > > [3] Region assembly failure works same as [2].\n> > > \n\nI posted a patch[1] that I think gets us to what is expected.\nFWIW I do agree with abandoning the teardown all approach. In this\npatch I still don't suggest tearing down the region. It can stay for\n'forensics', but I do think we should make /proc/iomem accurately\nreflect the memory topology.\n\n[1] https://lore.kernel.org/linux-cxl/20260212062250.1219043-1-alison.schofield@intel.com/\n\n-- Alison\n\n> \n> Thanks\n> Smita\n> \n",
          "reply_to": "Koralahalli Smita"
        },
        {
          "author": "Tomasz Wolski",
          "summary": "The reviewer, Tomasz Wolski, asked for clarification on the scenario where this patch is needed, specifically when CXL memory is installed or hot-plugged without Soft Reserve and how it affects region creation.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification requested"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": ">\n>FYI - I am able to confirm the dax regions are back for no-soft-reserved\n>case, and my basic hotplug flow works with v6.\n>\n>-- Alison\n\nHello Alison,\n\nI wanted to ask about this scenario.\nIs my understanding correct that this fix is needed for cases without Soft Reserve and:\n1) CXL memory is installed in the server (no hotplug) and OS is started\n2) CXL memory is hot-plugged after the OS starts\n3) Tests with cxl-test driver\n\nIn such case either the admin fails to manually create region via cxl cli (if there\nwas no auto-regions) or regions fails to be created automatically during driver probe\n\nIs this correct?\n\nBest regards,\nTomasz\n",
          "reply_to": "Alison Schofield"
        },
        {
          "author": "Koralahalli Smita",
          "summary": "The reviewer pointed out a typo in the patch description, specifically correcting DAX_HMEM to m.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "typo"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "\nOn 2/9/2026 10:44 PM, Smita Koralahalli wrote:\n> This series aims to address long-standing conflicts between HMEM and\n> CXL when handling Soft Reserved memory ranges.\n> \n> Reworked from Dan's patch:\n> https://git.kernel.org/pub/scm/linux/kernel/git/cxl/cxl.git/patch/?id=ab70c6227ee6165a562c215d9dcb4a1c55620d5d\n> \n> Previous work:\n> https://lore.kernel.org/all/20250715180407.47426-1-Smita.KoralahalliChannabasappa@amd.com/\n> \n> Link to v5:\n> https://lore.kernel.org/all/20260122045543.218194-1-Smita.KoralahalliChannabasappa@amd.com\n> \n> The series is based on branch \"for-7.0/cxl-init\" and base-commit is\n> base-commit: bc62f5b308cbdedf29132fe96e9d591e526527e1\n> \n\n[snip]..\n\n> [5] When CXL_BUS = m (with CXL_ACPI, CXL_PCI, CXL_PORT, CXL_MEM = m),\n> DAX_CXL = m and DAX_HMEM = y the results are as expected. To validate the\n\nTypo here, this is DAX_HMEM = m. Rest all looks good.\n\nThanks\nSmita.\n\n\n> REGISTER path, I forced REGISTER even in cases where SR completely\n> overlaps the CXL region as I did not have access to a system where the\n> CXL region range is smaller than the SR range.\n> \n> 850000000-284fffffff : Soft Reserved\n>    850000000-284fffffff : CXL Window 0\n>      850000000-280fffffff : region0\n>        850000000-284fffffff : dax6.0\n>          850000000-284fffffff : System RAM (kmem)\n> \n> \"path\":\"\\/platform\\/hmem.6\",\n> \"id\":6,\n> \"size\":\"128.00 GiB (137.44 GB)\",\n> \"align\":2097152\n> \n> [   30.897665] devm_cxl_add_dax_region: cxl_region region0: region0:\n> register dax_region0\n> [   30.921015] hmem: hmem_platform probe started.\n> [   31.017946] hmem_platform hmem_platform.0: Soft Reserved not fully\n> contained in CXL; using HMEM\n> [   31.056310] alloc_dev_dax_range:  dax6.0: alloc range[0]:\n> 0x0000000850000000:0x000000284fffffff\n> [   34.781516] cxl-dax: cxl_dax_region_init()\n> [   34.781522] cxl-dax: registering driver.\n> [   34.781523] cxl-dax: dax_hmem work flushed.\n> [   34.781549] alloc_dax_region: cxl_dax_region dax_region0: dax_region\n> resource conflict for [mem 0x850000000-0x284fffffff]\n> [   34.781552] cxl_bus_probe: cxl_dax_region dax_region0: probe: -12\n> [   34.781554] cxl_dax_region dax_region0: probe with driver cxl_dax_region\n> failed with error -12\n> \n[snip]\n\n\n",
          "reply_to": "Smita Koralahalli"
        },
        {
          "author": "Alison Schofield",
          "summary": "Reviewer Alison Schofield pointed out a potential issue where the Soft Reserved range may not be created due to a misunderstanding of CXL and DAX regions.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "potential issue",
            "misunderstanding"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "On Thu, Feb 12, 2026 at 03:44:15PM +0100, Tomasz Wolski wrote:\n> >\n> >FYI - I am able to confirm the dax regions are back for no-soft-reserved\n> >case, and my basic hotplug flow works with v6.\n> >\n> >-- Alison\n> \n> Hello Alison,\n> \n> I wanted to ask about this scenario.\n> Is my understanding correct that this fix is needed for cases without Soft Reserve and:\n> 1) CXL memory is installed in the server (no hotplug) and OS is started\n> 2) CXL memory is hot-plugged after the OS starts\n> 3) Tests with cxl-test driver \n                               or QEMU\n\n> \n> In such case either the admin fails to manually create region via cxl cli (if there\n> was no auto-regions) or regions fails to be created automatically during driver probe\n\nThe CXL region creates 'OK'. It is the DAX region that is not created.\n\n> \n> Is this correct?\n> \n> Best regards,\n> Tomasz\n",
          "reply_to": "Tomasz Wolski"
        },
        {
          "author": "Yasunori (Fujitsu)",
          "summary": "The reviewer, Yasunori, raised concerns about handling case 1) where EFI_MEMORY_SP is not defined in the firmware, questioning why Linux drivers must handle this scenario and suggesting that platform vendors should modify their firmware instead.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes",
            "clarification needed"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Hello, Alison-san,\r\n\r\nI would like to clarify your answer a bit more.\r\n\r\n> On Thu, Feb 12, 2026 at 03:44:15PM +0100, Tomasz Wolski wrote:\r\n> > >\r\n> > >FYI - I am able to confirm the dax regions are back for\r\n> > >no-soft-reserved case, and my basic hotplug flow works with v6.\r\n> > >\r\n> > >-- Alison\r\n> >\r\n> > Hello Alison,\r\n> >\r\n> > I wanted to ask about this scenario.\r\n> > Is my understanding correct that this fix is needed for cases without Soft\r\n> Reserve and:\r\n> > 1) CXL memory is installed in the server (no hotplug) and OS is\r\n> > started\r\n> > 2) CXL memory is hot-plugged after the OS starts\r\n> > 3) Tests with cxl-test driver\r\n>                                or QEMU\r\n\r\nThough I can understand that cases 2) and 3) include QEMU, I'm not sure why Linux drivers must handle case 1).\r\nIn such a case, I feel that the platform vendor should modify the firmware to define EFI_MEMORY_SP.\r\n\r\nIn the past, I actually encountered another issue between our platform firmware and a Linux driver:\r\nhttps://lore.kernel.org/linux-cxl/OS9PR01MB12421AEA8B27BF942CD0F18B19057A@OS9PR01MB12421.jpnprd01.prod.outlook.com/\r\nIn that case, I asked our firmware team to modify the firmware, and the issue was resolved.\r\n\r\nTherefore, I would like to confirm why case 1) must be handled.\r\nHave any actual machines already been released with such firmware?\r\nOtherwise, is this just to prepare for a platform whose firmware cannot be fixed on the firmware side?\r\n\r\nThanks,\r\n---\r\nYasunori Goto\r\n\r\n\r\n\n\n---\n\n\r\n> On Fri, Feb 13, 2026 at 07:47:08AM +0000, Yasunori Goto (Fujitsu) wrote:\r\n> > Hello, Alison-san,\r\n> >\r\n> > I would like to clarify your answer a bit more.\r\n> >\r\n> > > On Thu, Feb 12, 2026 at 03:44:15PM +0100, Tomasz Wolski wrote:\r\n> > > > >\r\n> > > > >FYI - I am able to confirm the dax regions are back for\r\n> > > > >no-soft-reserved case, and my basic hotplug flow works with v6.\r\n> > > > >\r\n> > > > >-- Alison\r\n> > > >\r\n> > > > Hello Alison,\r\n> > > >\r\n> > > > I wanted to ask about this scenario.\r\n> > > > Is my understanding correct that this fix is needed for cases\r\n> > > > without Soft\r\n> > > Reserve and:\r\n> > > > 1) CXL memory is installed in the server (no hotplug) and OS is\r\n> > > > started\r\n> > > > 2) CXL memory is hot-plugged after the OS starts\r\n> > > > 3) Tests with cxl-test driver\r\n> > >                                or QEMU\r\n> >\r\n> > Though I can understand that cases 2) and 3) include QEMU, I'm not sure\r\n> why Linux drivers must handle case 1).\r\n> > In such a case, I feel that the platform vendor should modify the firmware to\r\n> define EFI_MEMORY_SP.\r\n> >\r\n> > In the past, I actually encountered another issue between our platform\r\n> firmware and a Linux driver:\r\n> >\r\n> https://lore.kernel.org/linux-cxl/OS9PR01MB12421AEA8B27BF942CD0F18B1\r\n> 90\r\n> > 57A@OS9PR01MB12421.jpnprd01.prod.outlook.com/\r\n> > In that case, I asked our firmware team to modify the firmware, and the issue\r\n> was resolved.\r\n> >\r\n> > Therefore, I would like to confirm why case 1) must be handled.\r\n> > Have any actual machines already been released with such firmware?\r\n> > Otherwise, is this just to prepare for a platform whose firmware cannot be\r\n> fixed on the firmware side?\r\n> \r\n> Maybe I'm misunderstanding Tomasz's Case 1), because this is not a\r\n> work-around for a firmware issue.\r\n> \r\n> The CXL driver always tries to create DAX regions out of RAM regions.\r\n> That happens if the CXL region is BIOS defined 'auto' region or a region\r\n> requested via userspace. That is irregardless of Soft Reserved existence.\r\n> Soft-Reserved is not a requirement for CXL or DAX region creation.\r\n\r\nI misunderstood it \r\nI'll re-check the specifications.\r\nSorry for the noise.\r\n\r\n> \r\n> That piece broke in an earlier rev of this patchset [1] where the calls to\r\n> devm_cxl_add_dax_region(cxlr) started returning EPROBE_DEFER.\r\n> \r\n> I intended to point out to Smita, that behavior is restored in v6.\r\n\r\nThank you very much.\r\n\r\n-----\r\nYasunori Goto\r\n",
          "reply_to": "Alison Schofield"
        },
        {
          "author": "Gregory Price",
          "summary": "Reviewer Gregory Price raised concerns about a potential deadlock in the error path when handling Soft Reserved memory ranges, specifically when a CXL-intersecting range is encountered first and then a non-CXL Soft Reserved range fails to register.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "potential deadlock",
            "requested changes"
          ],
          "has_inline_review": true,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "On Tue, Feb 10, 2026 at 06:44:52AM +0000, Smita Koralahalli wrote:\n> This series aims to address long-standing conflicts between HMEM and\n> CXL when handling Soft Reserved memory ranges.\n> \n> Reworked from Dan's patch:\n> https://git.kernel.org/pub/scm/linux/kernel/git/cxl/cxl.git/patch/?id=ab70c6227ee6165a562c215d9dcb4a1c55620d5d\n>\n\nLink is broken: bad commit reference\n\n\n---\n\nOn Tue, Feb 10, 2026 at 06:45:00AM +0000, Smita Koralahalli wrote:\n\nThis is a review generated by kreview-0811365ff2\nReference: https://github.com/masoncl/review-prompts/\n\nThis is not an automated email, I thought this looked valid, the rest of\nthe text here is auto-generated.\n\n~Gregory\n\n---\n\n[...]\n\n> +static void process_defer_work(void *data)\n> +{\n> +\tstruct platform_device *pdev = data;\n> +\tint rc;\n> +\n> +\t/* relies on cxl_acpi and cxl_pci having had a chance to load */\n> +\twait_for_device_probe();\n\n[...]\n\n> +static void kill_defer_work(void *data)\n> +{\n> +\tstruct platform_device *pdev = data;\n> +\n> +\tdax_hmem_flush_work();\n> +\tdax_hmem_unregister_work(process_defer_work, pdev);\n> +}\n> +\n>  static int dax_hmem_platform_probe(struct platform_device *pdev)\n>  {\n> +\tint rc;\n> +\n> +\trc = dax_hmem_register_work(process_defer_work, pdev);\n> +\tif (rc)\n> +\t\treturn rc;\n> +\n> +\trc = devm_add_action_or_reset(&pdev->dev, kill_defer_work, pdev);\n> +\tif (rc)\n> +\t\treturn rc;\n> +\n>  \treturn walk_hmem_resources(&pdev->dev, hmem_register_device);\n>  }\n\nIs there a potential deadlock in the error path here? If\nwalk_hmem_resources() encounters a CXL-intersecting range first\n(calling dax_hmem_queue_work(), which schedules process_defer_work\non system_long_wq), and then a subsequent non-CXL Soft Reserved\nrange fails to register, the probe returns an error. The devres\ncleanup then calls kill_defer_work -> dax_hmem_flush_work() ->\nflush_work(&dax_hmem_work).\n\nMeanwhile, process_defer_work calls wait_for_device_probe(), which\nwaits for probe_count to reach zero. Since devres_release_all runs\ninside really_probe before driver_probe_device decrements\nprobe_count, this looks like a circular wait:\n\n  driver_probe_device\n    atomic_inc(&probe_count)\n    __driver_probe_device\n      really_probe\n        dax_hmem_platform_probe\n          walk_hmem_resources -> hmem_register_device\n            CXL range: dax_hmem_queue_work()\n            non-CXL range: fails\n          returns error\n        devres_release_all\n          kill_defer_work\n            dax_hmem_flush_work\n              flush_work(&dax_hmem_work)  <-- waits for process_defer_work\n                process_defer_work\n                  wait_for_device_probe() <-- waits for probe_count == 0\n    atomic_dec(&probe_count)              <-- never reached\n\nThe trigger requires both CXL-intersecting and non-CXL Soft Reserved\nranges with the non-CXL registration failing, so the window is narrow,\nbut the deadlock would be permanent if hit.\n\nWould it be safer to cancel the work instead of flushing it in the\nerror path, or to avoid queuing deferred work during the initial\nwalk?\n",
          "reply_to": "Smita Koralahalli"
        },
        {
          "author": "Alison Schofield",
          "summary": "Alison Schofield questioned the patch's intent, pointing out that CXL driver always tries to create DAX regions out of RAM regions regardless of Soft Reserved existence.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "questioned the patch's intent"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "On Fri, Feb 13, 2026 at 07:47:08AM +0000, Yasunori Goto (Fujitsu) wrote:\n> Hello, Alison-san,\n> \n> I would like to clarify your answer a bit more.\n> \n> > On Thu, Feb 12, 2026 at 03:44:15PM +0100, Tomasz Wolski wrote:\n> > > >\n> > > >FYI - I am able to confirm the dax regions are back for\n> > > >no-soft-reserved case, and my basic hotplug flow works with v6.\n> > > >\n> > > >-- Alison\n> > >\n> > > Hello Alison,\n> > >\n> > > I wanted to ask about this scenario.\n> > > Is my understanding correct that this fix is needed for cases without Soft\n> > Reserve and:\n> > > 1) CXL memory is installed in the server (no hotplug) and OS is\n> > > started\n> > > 2) CXL memory is hot-plugged after the OS starts\n> > > 3) Tests with cxl-test driver\n> >                                or QEMU\n> \n> Though I can understand that cases 2) and 3) include QEMU, I'm not sure why Linux drivers must handle case 1).\n> In such a case, I feel that the platform vendor should modify the firmware to define EFI_MEMORY_SP.\n> \n> In the past, I actually encountered another issue between our platform firmware and a Linux driver:\n> https://lore.kernel.org/linux-cxl/OS9PR01MB12421AEA8B27BF942CD0F18B19057A@OS9PR01MB12421.jpnprd01.prod.outlook.com/\n> In that case, I asked our firmware team to modify the firmware, and the issue was resolved.\n> \n> Therefore, I would like to confirm why case 1) must be handled.\n> Have any actual machines already been released with such firmware?\n> Otherwise, is this just to prepare for a platform whose firmware cannot be fixed on the firmware side?\n\nMaybe I'm misunderstanding Tomasz's Case 1), because this is not\na work-around for a firmware issue.\n\nThe CXL driver always tries to create DAX regions out of RAM regions.\nThat happens if the CXL region is BIOS defined 'auto' region or a\nregion requested via userspace. That is irregardless of Soft Reserved\nexistence. Soft-Reserved is not a requirement for CXL or DAX region\ncreation.\n\nThat piece broke in an earlier rev of this patchset [1] where the calls\nto devm_cxl_add_dax_region(cxlr) started returning EPROBE_DEFER.\n\nI intended to point out to Smita, that behavior is restored in v6.\n\n--Alison\n\n[1] https://lore.kernel.org/linux-cxl/aXMWzC8zf3bqIHJ0@aschofie-mobl2.lan/\n\n\n> \n> Thanks,\n> ---\n> Yasunori Goto\n> \n> \n",
          "reply_to": "Yasunori (Fujitsu)"
        },
        {
          "author": "Koralahalli Smita",
          "summary": "Reviewer Smita Koralahalli pointed out a potential deadlock in the original patch and suggested an alternative approach to avoid it, which involves setting a flag when deferring CXL-intersecting ranges and queuing work after the initial walk is complete.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes",
            "alternative solution"
          ],
          "has_inline_review": true,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "On 2/13/2026 6:47 AM, Gregory Price wrote:\n> On Tue, Feb 10, 2026 at 06:45:00AM +0000, Smita Koralahalli wrote:\n> \n> This is a review generated by kreview-0811365ff2\n> Reference: https://github.com/masoncl/review-prompts/\n> \n> This is not an automated email, I thought this looked valid, the rest of\n> the text here is auto-generated.\n> \n> ~Gregory\n> \n> ---\n> \n> [...]\n> \n>> +static void process_defer_work(void *data)\n>> +{\n>> +\tstruct platform_device *pdev = data;\n>> +\tint rc;\n>> +\n>> +\t/* relies on cxl_acpi and cxl_pci having had a chance to load */\n>> +\twait_for_device_probe();\n> \n> [...]\n> \n>> +static void kill_defer_work(void *data)\n>> +{\n>> +\tstruct platform_device *pdev = data;\n>> +\n>> +\tdax_hmem_flush_work();\n>> +\tdax_hmem_unregister_work(process_defer_work, pdev);\n>> +}\n>> +\n>>   static int dax_hmem_platform_probe(struct platform_device *pdev)\n>>   {\n>> +\tint rc;\n>> +\n>> +\trc = dax_hmem_register_work(process_defer_work, pdev);\n>> +\tif (rc)\n>> +\t\treturn rc;\n>> +\n>> +\trc = devm_add_action_or_reset(&pdev->dev, kill_defer_work, pdev);\n>> +\tif (rc)\n>> +\t\treturn rc;\n>> +\n>>   \treturn walk_hmem_resources(&pdev->dev, hmem_register_device);\n>>   }\n> \n> Is there a potential deadlock in the error path here? If\n> walk_hmem_resources() encounters a CXL-intersecting range first\n> (calling dax_hmem_queue_work(), which schedules process_defer_work\n> on system_long_wq), and then a subsequent non-CXL Soft Reserved\n> range fails to register, the probe returns an error. The devres\n> cleanup then calls kill_defer_work -> dax_hmem_flush_work() ->\n> flush_work(&dax_hmem_work).\n> \n> Meanwhile, process_defer_work calls wait_for_device_probe(), which\n> waits for probe_count to reach zero. Since devres_release_all runs\n> inside really_probe before driver_probe_device decrements\n> probe_count, this looks like a circular wait:\n> \n>    driver_probe_device\n>      atomic_inc(&probe_count)\n>      __driver_probe_device\n>        really_probe\n>          dax_hmem_platform_probe\n>            walk_hmem_resources -> hmem_register_device\n>              CXL range: dax_hmem_queue_work()\n>              non-CXL range: fails\n>            returns error\n>          devres_release_all\n>            kill_defer_work\n>              dax_hmem_flush_work\n>                flush_work(&dax_hmem_work)  <-- waits for process_defer_work\n>                  process_defer_work\n>                    wait_for_device_probe() <-- waits for probe_count == 0\n>      atomic_dec(&probe_count)              <-- never reached\n> \n> The trigger requires both CXL-intersecting and non-CXL Soft Reserved\n> ranges with the non-CXL registration failing, so the window is narrow,\n> but the deadlock would be permanent if hit.\n> \n> Would it be safer to cancel the work instead of flushing it in the\n> error path, or to avoid queuing deferred work during the initial\n> walk?\n\nYes, you're right, that's a real deadlock. Thanks for pointing this out.\n\nThis might affect any wait on the work \\u2014 flush_work, cancel_work_sync, \nall the same problem.\n\nJust using dax_hmem_unregister_work (which only grabs the mutex and\nNULLs pointers) avoids the deadlock but opens a use-after-free: the \nworker may have already copied fn/data and be mid-execution of \nprocess_defer_work(pdev) while devres tears down the pdev underneath it.\n\nYour suggestion of avoiding queuing during the initial walk is the right \napproach I think. Set a flag when hmem_register_device defers a \nCXL-intersecting range, queue the work after walk_hmem_resources returns \nsuccessfully. Something like:\n\nstatic int dax_hmem_platform_probe(struct platform_device *pdev)\n{\n\t..\n\t..\n- \treturn walk_hmem_resources(&pdev->dev, hmem_register_device);\n+\trc = walk_hmem_resources(&pdev->dev, hmem_register_device);\n+\tif (rc)\n+\t\treturn rc;\n\n+\tif (defer) //defer is set under DAX_CXL_MODE_DEFER\n+\t\tdax_hmem_queue_work();\n}\n\nI think this works but there might be subtleties I'm missing. What do \nyou think?\n\nThanks\nSmita\n",
          "reply_to": "Gregory Price"
        },
        {
          "author": "Dave Jiang",
          "summary": "Reviewer Dave Jiang suggested using a typical work_struct pattern instead of a global lock for dax_hmem and dax_cxl coordination, and asked if a reference should be taken on pdev when queuing work.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes",
            "technical concerns"
          ],
          "has_inline_review": true,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "\n\nOn 2/9/26 11:44 PM, Smita Koralahalli wrote:\n> From: Dan Williams <dan.j.williams@intel.com>\n> \n> Move hmem/ earlier in the dax Makefile so that hmem_init() runs before\n> dax_cxl.\n> \n> In addition, defer registration of the dax_cxl driver to a workqueue\n> instead of using module_cxl_driver(). This ensures that dax_hmem has\n> an opportunity to initialize and register its deferred callback and make\n> ownership decisions before dax_cxl begins probing and claiming Soft\n> Reserved ranges.\n> \n> Mark the dax_cxl driver as PROBE_PREFER_ASYNCHRONOUS so its probe runs\n> out of line from other synchronous probing avoiding ordering\n> dependencies while coordinating ownership decisions with dax_hmem.\n> \n> Signed-off-by: Dan Williams <dan.j.williams@intel.com>\n> Signed-off-by: Smita Koralahalli <Smita.KoralahalliChannabasappa@amd.com>\n\nReviewed-by: Dave Jiang <dave.jiang@intel.com>\n\n> ---\n>  drivers/dax/Makefile |  3 +--\n>  drivers/dax/cxl.c    | 27 ++++++++++++++++++++++++++-\n>  2 files changed, 27 insertions(+), 3 deletions(-)\n> \n> diff --git a/drivers/dax/Makefile b/drivers/dax/Makefile\n> index 5ed5c39857c8..70e996bf1526 100644\n> --- a/drivers/dax/Makefile\n> +++ b/drivers/dax/Makefile\n> @@ -1,4 +1,5 @@\n>  # SPDX-License-Identifier: GPL-2.0\n> +obj-y += hmem/\n>  obj-$(CONFIG_DAX) += dax.o\n>  obj-$(CONFIG_DEV_DAX) += device_dax.o\n>  obj-$(CONFIG_DEV_DAX_KMEM) += kmem.o\n> @@ -10,5 +11,3 @@ dax-y += bus.o\n>  device_dax-y := device.o\n>  dax_pmem-y := pmem.o\n>  dax_cxl-y := cxl.o\n> -\n> -obj-y += hmem/\n> diff --git a/drivers/dax/cxl.c b/drivers/dax/cxl.c\n> index 13cd94d32ff7..a2136adfa186 100644\n> --- a/drivers/dax/cxl.c\n> +++ b/drivers/dax/cxl.c\n> @@ -38,10 +38,35 @@ static struct cxl_driver cxl_dax_region_driver = {\n>  \t.id = CXL_DEVICE_DAX_REGION,\n>  \t.drv = {\n>  \t\t.suppress_bind_attrs = true,\n> +\t\t.probe_type = PROBE_PREFER_ASYNCHRONOUS,\n>  \t},\n>  };\n>  \n> -module_cxl_driver(cxl_dax_region_driver);\n> +static void cxl_dax_region_driver_register(struct work_struct *work)\n> +{\n> +\tcxl_driver_register(&cxl_dax_region_driver);\n> +}\n> +\n> +static DECLARE_WORK(cxl_dax_region_driver_work, cxl_dax_region_driver_register);\n> +\n> +static int __init cxl_dax_region_init(void)\n> +{\n> +\t/*\n> +\t * Need to resolve a race with dax_hmem wanting to drive regions\n> +\t * instead of CXL\n> +\t */\n> +\tqueue_work(system_long_wq, &cxl_dax_region_driver_work);\n> +\treturn 0;\n> +}\n> +module_init(cxl_dax_region_init);\n> +\n> +static void __exit cxl_dax_region_exit(void)\n> +{\n> +\tflush_work(&cxl_dax_region_driver_work);\n> +\tcxl_driver_unregister(&cxl_dax_region_driver);\n> +}\n> +module_exit(cxl_dax_region_exit);\n> +\n>  MODULE_ALIAS_CXL(CXL_DEVICE_DAX_REGION);\n>  MODULE_DESCRIPTION(\"CXL DAX: direct access to CXL regions\");\n>  MODULE_LICENSE(\"GPL\");\n\n\n\n---\n\n\n\nOn 2/9/26 11:44 PM, Smita Koralahalli wrote:\n> Introduce a global \"DAX Regions\" resource root and register each\n> dax_region->res under it via request_resource(). Release the resource on\n> dax_region teardown.\n> \n> By enforcing a single global namespace for dax_region allocations, this\n> ensures only one of dax_hmem or dax_cxl can successfully register a\n> dax_region for a given range.\n> \n> Co-developed-by: Dan Williams <dan.j.williams@intel.com>\n> Signed-off-by: Dan Williams <dan.j.williams@intel.com>\n> Signed-off-by: Smita Koralahalli <Smita.KoralahalliChannabasappa@amd.com>\n\nReviewed-by: Dave Jiang <dave.jiang@intel.com>\n\n> ---\n>  drivers/dax/bus.c | 23 ++++++++++++++++++++---\n>  1 file changed, 20 insertions(+), 3 deletions(-)\n> \n> diff --git a/drivers/dax/bus.c b/drivers/dax/bus.c\n> index fde29e0ad68b..5f387feb95f0 100644\n> --- a/drivers/dax/bus.c\n> +++ b/drivers/dax/bus.c\n> @@ -10,6 +10,7 @@\n>  #include \"dax-private.h\"\n>  #include \"bus.h\"\n>  \n> +static struct resource dax_regions = DEFINE_RES_MEM_NAMED(0, -1, \"DAX Regions\");\n>  static DEFINE_MUTEX(dax_bus_lock);\n>  \n>  /*\n> @@ -625,6 +626,8 @@ static void dax_region_unregister(void *region)\n>  {\n>  \tstruct dax_region *dax_region = region;\n>  \n> +\tscoped_guard(rwsem_write, &dax_region_rwsem)\n> +\t\trelease_resource(&dax_region->res);\n>  \tsysfs_remove_groups(&dax_region->dev->kobj,\n>  \t\t\tdax_region_attribute_groups);\n>  \tdax_region_put(dax_region);\n> @@ -635,6 +638,7 @@ struct dax_region *alloc_dax_region(struct device *parent, int region_id,\n>  \t\tunsigned long flags)\n>  {\n>  \tstruct dax_region *dax_region;\n> +\tint rc;\n>  \n>  \t/*\n>  \t * The DAX core assumes that it can store its private data in\n> @@ -667,14 +671,27 @@ struct dax_region *alloc_dax_region(struct device *parent, int region_id,\n>  \t\t.flags = IORESOURCE_MEM | flags,\n>  \t};\n>  \n> -\tif (sysfs_create_groups(&parent->kobj, dax_region_attribute_groups)) {\n> -\t\tkfree(dax_region);\n> -\t\treturn NULL;\n> +\tscoped_guard(rwsem_write, &dax_region_rwsem)\n> +\t\trc = request_resource(&dax_regions, &dax_region->res);\n> +\tif (rc) {\n> +\t\tdev_dbg(parent, \"dax_region resource conflict for %pR\\n\",\n> +\t\t\t&dax_region->res);\n> +\t\tgoto err_res;\n>  \t}\n>  \n> +\tif (sysfs_create_groups(&parent->kobj, dax_region_attribute_groups))\n> +\t\tgoto err_sysfs;\n> +\n>  \tif (devm_add_action_or_reset(parent, dax_region_unregister, dax_region))\n>  \t\treturn NULL;\n>  \treturn dax_region;\n> +\n> +err_sysfs:\n> +\tscoped_guard(rwsem_write, &dax_region_rwsem)\n> +\t\trelease_resource(&dax_region->res);\n> +err_res:\n> +\tkfree(dax_region);\n> +\treturn NULL;\n>  }\n>  EXPORT_SYMBOL_GPL(alloc_dax_region);\n>  \n\n\n\n---\n\n\n\nOn 2/9/26 11:44 PM, Smita Koralahalli wrote:\n> Add helpers to register, queue and flush the deferred work.\n> \n> These helpers allow dax_hmem to execute ownership resolution outside the\n> probe context before dax_cxl binds.\n> \n> Signed-off-by: Smita Koralahalli <Smita.KoralahalliChannabasappa@amd.com>\n> ---\n>  drivers/dax/bus.c | 58 +++++++++++++++++++++++++++++++++++++++++++++++\n>  drivers/dax/bus.h |  7 ++++++\n>  2 files changed, 65 insertions(+)\n> \n> diff --git a/drivers/dax/bus.c b/drivers/dax/bus.c\n> index 5f387feb95f0..92b88952ede1 100644\n> --- a/drivers/dax/bus.c\n> +++ b/drivers/dax/bus.c\n> @@ -25,6 +25,64 @@ DECLARE_RWSEM(dax_region_rwsem);\n>   */\n>  DECLARE_RWSEM(dax_dev_rwsem);\n>  \n> +static DEFINE_MUTEX(dax_hmem_lock);\n> +static dax_hmem_deferred_fn hmem_deferred_fn;\n> +static void *dax_hmem_data;\n> +\n> +static void hmem_deferred_work(struct work_struct *work)\n> +{\n> +\tdax_hmem_deferred_fn fn;\n> +\tvoid *data;\n> +\n> +\tscoped_guard(mutex, &dax_hmem_lock) {\n> +\t\tfn = hmem_deferred_fn;\n> +\t\tdata = dax_hmem_data;\n> +\t}\n> +\n> +\tif (fn)\n> +\t\tfn(data);\n> +}\n\nInstead of having a global lock and dealing with all the global variables, why not just do this with the typical work_struct usage pattern and allocate a work item when queuing work?\n\nDJ\n\n> +\n> +static DECLARE_WORK(dax_hmem_work, hmem_deferred_work);\n> +\n> +int dax_hmem_register_work(dax_hmem_deferred_fn fn, void *data)\n> +{\n> +\tguard(mutex)(&dax_hmem_lock);\n> +\n> +\tif (hmem_deferred_fn)\n> +\t\treturn -EINVAL;\n> +\n> +\thmem_deferred_fn = fn;\n> +\tdax_hmem_data = data;\n> +\treturn 0;\n> +}\n> +EXPORT_SYMBOL_GPL(dax_hmem_register_work);\n> +\n> +int dax_hmem_unregister_work(dax_hmem_deferred_fn fn, void *data)\n> +{\n> +\tguard(mutex)(&dax_hmem_lock);\n> +\n> +\tif (hmem_deferred_fn != fn || dax_hmem_data != data)\n> +\t\treturn -EINVAL;\n> +\n> +\thmem_deferred_fn = NULL;\n> +\tdax_hmem_data = NULL;\n> +\treturn 0;\n> +}\n> +EXPORT_SYMBOL_GPL(dax_hmem_unregister_work);\n> +\n> +void dax_hmem_queue_work(void)\n> +{\n> +\tqueue_work(system_long_wq, &dax_hmem_work);\n> +}\n> +EXPORT_SYMBOL_GPL(dax_hmem_queue_work);\n> +\n> +void dax_hmem_flush_work(void)\n> +{\n> +\tflush_work(&dax_hmem_work);\n> +}\n> +EXPORT_SYMBOL_GPL(dax_hmem_flush_work);\n> +\n>  #define DAX_NAME_LEN 30\n>  struct dax_id {\n>  \tstruct list_head list;\n> diff --git a/drivers/dax/bus.h b/drivers/dax/bus.h\n> index cbbf64443098..b58a88e8089c 100644\n> --- a/drivers/dax/bus.h\n> +++ b/drivers/dax/bus.h\n> @@ -41,6 +41,13 @@ struct dax_device_driver {\n>  \tvoid (*remove)(struct dev_dax *dev);\n>  };\n>  \n> +typedef void (*dax_hmem_deferred_fn)(void *data);\n> +\n> +int dax_hmem_register_work(dax_hmem_deferred_fn fn, void *data);\n> +int dax_hmem_unregister_work(dax_hmem_deferred_fn fn, void *data);\n> +void dax_hmem_queue_work(void);\n> +void dax_hmem_flush_work(void);\n> +\n>  int __dax_driver_register(struct dax_device_driver *dax_drv,\n>  \t\tstruct module *module, const char *mod_name);\n>  #define dax_driver_register(driver) \\\n\n\n\n---\n\n\n\nOn 2/9/26 11:45 PM, Smita Koralahalli wrote:\n> The current probe time ownership check for Soft Reserved memory based\n> solely on CXL window intersection is insufficient. dax_hmem probing is not\n> always guaranteed to run after CXL enumeration and region assembly, which\n> can lead to incorrect ownership decisions before the CXL stack has\n> finished publishing windows and assembling committed regions.\n> \n> Introduce deferred ownership handling for Soft Reserved ranges that\n> intersect CXL windows. When such a range is encountered during dax_hmem\n> probe, schedule deferred work and wait for the CXL stack to complete\n> enumeration and region assembly before deciding ownership.\n> \n> Evaluate ownership of Soft Reserved ranges based on CXL region\n> containment.\n> \n>    - If all Soft Reserved ranges are fully contained within committed CXL\n>      regions, DROP handling Soft Reserved ranges from dax_hmem and allow\n>      dax_cxl to bind.\n> \n>    - If any Soft Reserved range is not fully claimed by committed CXL\n>      region, REGISTER the Soft Reserved ranges with dax_hmem.\n> \n> Use dax_cxl_mode to coordinate ownership decisions for Soft Reserved\n> ranges. Once, ownership resolution is complete, flush the deferred work\n> from dax_cxl before allowing dax_cxl to bind.\n> \n> This enforces a strict ownership. Either CXL fully claims the Soft\n> reserved ranges or it relinquishes it entirely.\n> \n> Co-developed-by: Dan Williams <dan.j.williams@intel.com>\n> Signed-off-by: Dan Williams <dan.j.williams@intel.com>\n> Signed-off-by: Smita Koralahalli <Smita.KoralahalliChannabasappa@amd.com>\n> ---\n>  drivers/dax/bus.c       |  3 ++\n>  drivers/dax/bus.h       | 19 ++++++++++\n>  drivers/dax/cxl.c       |  1 +\n>  drivers/dax/hmem/hmem.c | 78 +++++++++++++++++++++++++++++++++++++++--\n>  4 files changed, 99 insertions(+), 2 deletions(-)\n> \n> diff --git a/drivers/dax/bus.c b/drivers/dax/bus.c\n> index 92b88952ede1..81985bcc70f9 100644\n> --- a/drivers/dax/bus.c\n> +++ b/drivers/dax/bus.c\n> @@ -25,6 +25,9 @@ DECLARE_RWSEM(dax_region_rwsem);\n>   */\n>  DECLARE_RWSEM(dax_dev_rwsem);\n>  \n> +enum dax_cxl_mode dax_cxl_mode = DAX_CXL_MODE_DEFER;\n> +EXPORT_SYMBOL_NS_GPL(dax_cxl_mode, \"CXL\");\n> +\n>  static DEFINE_MUTEX(dax_hmem_lock);\n>  static dax_hmem_deferred_fn hmem_deferred_fn;\n>  static void *dax_hmem_data;\n> diff --git a/drivers/dax/bus.h b/drivers/dax/bus.h\n> index b58a88e8089c..82616ff52fd1 100644\n> --- a/drivers/dax/bus.h\n> +++ b/drivers/dax/bus.h\n> @@ -41,6 +41,25 @@ struct dax_device_driver {\n>  \tvoid (*remove)(struct dev_dax *dev);\n>  };\n>  \n> +/*\n> + * enum dax_cxl_mode - State machine to determine ownership for CXL\n> + * tagged Soft Reserved memory ranges.\n> + * @DAX_CXL_MODE_DEFER: Ownership resolution pending. Set while waiting\n> + * for CXL enumeration and region assembly to complete.\n> + * @DAX_CXL_MODE_REGISTER: CXL regions do not fully cover Soft Reserved\n> + * ranges. Fall back to registering those ranges via dax_hmem.\n> + * @DAX_CXL_MODE_DROP: All Soft Reserved ranges intersecting CXL windows\n> + * are fully contained within committed CXL regions. Drop HMEM handling\n> + * and allow dax_cxl to bind.\n> + */\n> +enum dax_cxl_mode {\n> +\tDAX_CXL_MODE_DEFER,\n> +\tDAX_CXL_MODE_REGISTER,\n> +\tDAX_CXL_MODE_DROP,\n> +};\n> +\n> +extern enum dax_cxl_mode dax_cxl_mode;\n> +\n>  typedef void (*dax_hmem_deferred_fn)(void *data);\n>  \n>  int dax_hmem_register_work(dax_hmem_deferred_fn fn, void *data);\n> diff --git a/drivers/dax/cxl.c b/drivers/dax/cxl.c\n> index a2136adfa186..3ab39b77843d 100644\n> --- a/drivers/dax/cxl.c\n> +++ b/drivers/dax/cxl.c\n> @@ -44,6 +44,7 @@ static struct cxl_driver cxl_dax_region_driver = {\n>  \n>  static void cxl_dax_region_driver_register(struct work_struct *work)\n>  {\n> +\tdax_hmem_flush_work();\n>  \tcxl_driver_register(&cxl_dax_region_driver);\n>  }\n>  \n> diff --git a/drivers/dax/hmem/hmem.c b/drivers/dax/hmem/hmem.c\n> index 1e3424358490..85854e25254b 100644\n> --- a/drivers/dax/hmem/hmem.c\n> +++ b/drivers/dax/hmem/hmem.c\n> @@ -3,6 +3,7 @@\n>  #include <linux/memregion.h>\n>  #include <linux/module.h>\n>  #include <linux/dax.h>\n> +#include <cxl/cxl.h>\n>  #include \"../bus.h\"\n>  \n>  static bool region_idle;\n> @@ -69,8 +70,18 @@ static int hmem_register_device(struct device *host, int target_nid,\n>  \tif (IS_ENABLED(CONFIG_DEV_DAX_CXL) &&\n>  \t    region_intersects(res->start, resource_size(res), IORESOURCE_MEM,\n>  \t\t\t      IORES_DESC_CXL) != REGION_DISJOINT) {\n> -\t\tdev_dbg(host, \"deferring range to CXL: %pr\\n\", res);\n> -\t\treturn 0;\n> +\t\tswitch (dax_cxl_mode) {\n> +\t\tcase DAX_CXL_MODE_DEFER:\n> +\t\t\tdev_dbg(host, \"deferring range to CXL: %pr\\n\", res);\n> +\t\t\tdax_hmem_queue_work();\n> +\t\t\treturn 0;\n> +\t\tcase DAX_CXL_MODE_REGISTER:\n> +\t\t\tdev_dbg(host, \"registering CXL range: %pr\\n\", res);\n> +\t\t\tbreak;\n> +\t\tcase DAX_CXL_MODE_DROP:\n> +\t\t\tdev_dbg(host, \"dropping CXL range: %pr\\n\", res);\n> +\t\t\treturn 0;\n> +\t\t}\n>  \t}\n>  \n>  \trc = region_intersects_soft_reserve(res->start, resource_size(res));\n> @@ -123,8 +134,70 @@ static int hmem_register_device(struct device *host, int target_nid,\n>  \treturn rc;\n>  }\n>  \n> +static int hmem_register_cxl_device(struct device *host, int target_nid,\n> +\t\t\t\t    const struct resource *res)\n> +{\n> +\tif (region_intersects(res->start, resource_size(res), IORESOURCE_MEM,\n> +\t\t\t      IORES_DESC_CXL) != REGION_DISJOINT)\n> +\t\treturn hmem_register_device(host, target_nid, res);\n> +\n> +\treturn 0;\n> +}\n> +\n> +static int soft_reserve_has_cxl_match(struct device *host, int target_nid,\n> +\t\t\t\t      const struct resource *res)\n> +{\n> +\tif (region_intersects(res->start, resource_size(res), IORESOURCE_MEM,\n> +\t\t\t      IORES_DESC_CXL) != REGION_DISJOINT) {\n> +\t\tif (!cxl_region_contains_soft_reserve((struct resource *)res))\n> +\t\t\treturn 1;\n> +\t}\n> +\n> +\treturn 0;\n> +}\n> +\n> +static void process_defer_work(void *data)\n> +{\n> +\tstruct platform_device *pdev = data;\n> +\tint rc;\n> +\n> +\t/* relies on cxl_acpi and cxl_pci having had a chance to load */\n> +\twait_for_device_probe();\n> +\n> +\trc = walk_hmem_resources(&pdev->dev, soft_reserve_has_cxl_match);\n> +\n> +\tif (!rc) {\n> +\t\tdax_cxl_mode = DAX_CXL_MODE_DROP;\n> +\t\tdev_dbg(&pdev->dev, \"All Soft Reserved ranges claimed by CXL\\n\");\n> +\t} else {\n> +\t\tdax_cxl_mode = DAX_CXL_MODE_REGISTER;\n> +\t\tdev_warn(&pdev->dev,\n> +\t\t\t \"Soft Reserved not fully contained in CXL; using HMEM\\n\");\n> +\t}\n> +\n> +\twalk_hmem_resources(&pdev->dev, hmem_register_cxl_device);\n> +}\n> +\n> +static void kill_defer_work(void *data)\n> +{\n> +\tstruct platform_device *pdev = data;\n> +\n> +\tdax_hmem_flush_work();\n> +\tdax_hmem_unregister_work(process_defer_work, pdev);\n> +}\n> +\n>  static int dax_hmem_platform_probe(struct platform_device *pdev)\n>  {\n> +\tint rc;\n> +\n> +\trc = dax_hmem_register_work(process_defer_work, pdev);\n\nDo we need to take a reference on pdev when we queue the work?\n\nDJ\n\n> +\tif (rc)\n> +\t\treturn rc;\n> +\n> +\trc = devm_add_action_or_reset(&pdev->dev, kill_defer_work, pdev);\n> +\tif (rc)\n> +\t\treturn rc;\n> +\n>  \treturn walk_hmem_resources(&pdev->dev, hmem_register_device);\n>  }\n>  \n> @@ -174,3 +247,4 @@ MODULE_ALIAS(\"platform:hmem_platform*\");\n>  MODULE_DESCRIPTION(\"HMEM DAX: direct access to 'specific purpose' memory\");\n>  MODULE_LICENSE(\"GPL v2\");\n>  MODULE_AUTHOR(\"Intel Corporation\");\n> +MODULE_IMPORT_NS(\"CXL\");\n\n",
          "reply_to": "Smita Koralahalli"
        },
        {
          "author": "Koralahalli Smita",
          "summary": "Reviewer Smita Koralahalli raised concerns about the implementation of deferred work for dax_hmem and dax_cxl coordination, specifically questioning the use of a statically allocated struct versus dynamically allocating one, and also suggesting that a mutex may not be necessary.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes",
            "technical concerns"
          ],
          "has_inline_review": true,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Hi Dave,\n\nOn 2/18/2026 9:52 AM, Dave Jiang wrote:\n> \n> \n> On 2/9/26 11:44 PM, Smita Koralahalli wrote:\n>> Add helpers to register, queue and flush the deferred work.\n>>\n>> These helpers allow dax_hmem to execute ownership resolution outside the\n>> probe context before dax_cxl binds.\n>>\n>> Signed-off-by: Smita Koralahalli <Smita.KoralahalliChannabasappa@amd.com>\n>> ---\n>>   drivers/dax/bus.c | 58 +++++++++++++++++++++++++++++++++++++++++++++++\n>>   drivers/dax/bus.h |  7 ++++++\n>>   2 files changed, 65 insertions(+)\n>>\n>> diff --git a/drivers/dax/bus.c b/drivers/dax/bus.c\n>> index 5f387feb95f0..92b88952ede1 100644\n>> --- a/drivers/dax/bus.c\n>> +++ b/drivers/dax/bus.c\n>> @@ -25,6 +25,64 @@ DECLARE_RWSEM(dax_region_rwsem);\n>>    */\n>>   DECLARE_RWSEM(dax_dev_rwsem);\n>>   \n>> +static DEFINE_MUTEX(dax_hmem_lock);\n>> +static dax_hmem_deferred_fn hmem_deferred_fn;\n>> +static void *dax_hmem_data;\n>> +\n>> +static void hmem_deferred_work(struct work_struct *work)\n>> +{\n>> +\tdax_hmem_deferred_fn fn;\n>> +\tvoid *data;\n>> +\n>> +\tscoped_guard(mutex, &dax_hmem_lock) {\n>> +\t\tfn = hmem_deferred_fn;\n>> +\t\tdata = dax_hmem_data;\n>> +\t}\n>> +\n>> +\tif (fn)\n>> +\t\tfn(data);\n>> +}\n> \n> Instead of having a global lock and dealing with all the global variables, why not just do this with the typical work_struct usage pattern and allocate a work item when queuing work?\n> \n> DJ\n\nThanks for the feedback.\n\nJust to clarify, are you hinting towards a statically allocated struct\nwith an embedded work_struct, something like below? Rather than the \ntypical kmalloc + container_of pattern?\n\n+struct dax_hmem_deferred_ctx {\n+\tstruct work_struct work;\n+\tdax_hmem_deferred_fn fn;\n+\tvoid *data;\n+};\n\n+static struct dax_hmem_deferred_ctx dax_hmem_ctx;\n\n+int dax_hmem_register_work(dax_hmem_deferred_fn fn, void *data)\n+{\n+\tif (dax_hmem_ctx.fn)\n+\t\treturn -EINVAL;\n\n+\tINIT_WORK(&dax_hmem_ctx.work, hmem_deferred_work);\n..\n\nMy understanding is that Dan wanted this to remain a singleton deferred \nwork item queued once and flushed from dax_cxl. I think with kmalloc + \ncontainer_of approach, every call would allocate and queue a new \nindependent work item..\n\nRegarding the mutex: looking at it again, it may not be necessary I \nthink. If we can rely on the call ordering (register_work() before \nqueue_work()), and if flush_work() in kill_defer_work() ensures the work \nhas fully completed before unregister_work() NULLs the pointers, then \nthe static struct above would be sufficient without additional locking. \nIf I'm missing a scenario or race here, please correct me.\n\nThanks,\nSmita\n\n> \n>> +\n>> +static DECLARE_WORK(dax_hmem_work, hmem_deferred_work);\n>> +\n>> +int dax_hmem_register_work(dax_hmem_deferred_fn fn, void *data)\n>> +{\n>> +\tguard(mutex)(&dax_hmem_lock);\n>> +\n>> +\tif (hmem_deferred_fn)\n>> +\t\treturn -EINVAL;\n>> +\n>> +\thmem_deferred_fn = fn;\n>> +\tdax_hmem_data = data;\n>> +\treturn 0;\n>> +}\n>> +EXPORT_SYMBOL_GPL(dax_hmem_register_work);\n>> +\n>> +int dax_hmem_unregister_work(dax_hmem_deferred_fn fn, void *data)\n>> +{\n>> +\tguard(mutex)(&dax_hmem_lock);\n>> +\n>> +\tif (hmem_deferred_fn != fn || dax_hmem_data != data)\n>> +\t\treturn -EINVAL;\n>> +\n>> +\thmem_deferred_fn = NULL;\n>> +\tdax_hmem_data = NULL;\n>> +\treturn 0;\n>> +}\n>> +EXPORT_SYMBOL_GPL(dax_hmem_unregister_work);\n>> +\n>> +void dax_hmem_queue_work(void)\n>> +{\n>> +\tqueue_work(system_long_wq, &dax_hmem_work);\n>> +}\n>> +EXPORT_SYMBOL_GPL(dax_hmem_queue_work);\n>> +\n>> +void dax_hmem_flush_work(void)\n>> +{\n>> +\tflush_work(&dax_hmem_work);\n>> +}\n>> +EXPORT_SYMBOL_GPL(dax_hmem_flush_work);\n>> +\n>>   #define DAX_NAME_LEN 30\n>>   struct dax_id {\n>>   \tstruct list_head list;\n>> diff --git a/drivers/dax/bus.h b/drivers/dax/bus.h\n>> index cbbf64443098..b58a88e8089c 100644\n>> --- a/drivers/dax/bus.h\n>> +++ b/drivers/dax/bus.h\n>> @@ -41,6 +41,13 @@ struct dax_device_driver {\n>>   \tvoid (*remove)(struct dev_dax *dev);\n>>   };\n>>   \n>> +typedef void (*dax_hmem_deferred_fn)(void *data);\n>> +\n>> +int dax_hmem_register_work(dax_hmem_deferred_fn fn, void *data);\n>> +int dax_hmem_unregister_work(dax_hmem_deferred_fn fn, void *data);\n>> +void dax_hmem_queue_work(void);\n>> +void dax_hmem_flush_work(void);\n>> +\n>>   int __dax_driver_register(struct dax_device_driver *dax_drv,\n>>   \t\tstruct module *module, const char *mod_name);\n>>   #define dax_driver_register(driver) \\\n> \n\n",
          "reply_to": "Dave Jiang"
        },
        {
          "author": "Tomasz Wolski",
          "summary": "Tomasz Wolski tested the patch on QEMU and physical setups, but raised a question about the 'Soft Reserve' parent entries in iomem, noting that they are present on QEMU but missing on his physical setup.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "question",
            "test"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Tested-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Tested on QEMU and physical setups. \n\nI have one question about \"Soft Reserve\" parent entries in iomem.\nOn QEMU I see parent \"Soft Reserved\":\n\na90000000-b4fffffff : Soft Reserved\n  a90000000-b4fffffff : CXL Window 0\n    a90000000-b4fffffff : dax1.0\n      a90000000-b4fffffff : System RAM (kmem)\n\nWhile on my physical setup this is missing - not sure if this is okay?\n\nBIOS-e820: [mem 0x0000002070000000-0x000000a06fffffff] soft reserved\n\n2070000000-606fffffff : CXL Window 0\n  2070000000-606fffffff : region0\n    2070000000-606fffffff : dax0.0\n      2070000000-606fffffff : System RAM (kmem)\n6070000000-a06fffffff : CXL Window 1\n  6070000000-a06fffffff : region1\n    6070000000-a06fffffff : dax1.0\n      6070000000-a06fffffff : System RAM (kmem)\n\nTested-by: Tomasz Wolski <tomasz.wolski@fujitsu.com>\n",
          "reply_to": "Smita Koralahalli"
        },
        {
          "author": "Alejandro Palau",
          "summary": "Reviewer Alejandro Palau expressed concerns about the patch's decision to defer and resolve ownership of Soft Reserved memory ranges, questioning why it's an all-or-nothing approach and suggesting that the reason for this decision should be explained in the commit message or code comments.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes",
            "clarification needed"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "\nOn 2/10/26 06:45, Smita Koralahalli wrote:\n> The current probe time ownership check for Soft Reserved memory based\n> solely on CXL window intersection is insufficient. dax_hmem probing is not\n> always guaranteed to run after CXL enumeration and region assembly, which\n> can lead to incorrect ownership decisions before the CXL stack has\n> finished publishing windows and assembling committed regions.\n>\n> Introduce deferred ownership handling for Soft Reserved ranges that\n> intersect CXL windows. When such a range is encountered during dax_hmem\n> probe, schedule deferred work and wait for the CXL stack to complete\n> enumeration and region assembly before deciding ownership.\n>\n> Evaluate ownership of Soft Reserved ranges based on CXL region\n> containment.\n>\n>     - If all Soft Reserved ranges are fully contained within committed CXL\n>       regions, DROP handling Soft Reserved ranges from dax_hmem and allow\n>       dax_cxl to bind.\n>\n>     - If any Soft Reserved range is not fully claimed by committed CXL\n>       region, REGISTER the Soft Reserved ranges with dax_hmem.\n>\n> Use dax_cxl_mode to coordinate ownership decisions for Soft Reserved\n> ranges. Once, ownership resolution is complete, flush the deferred work\n> from dax_cxl before allowing dax_cxl to bind.\n>\n> This enforces a strict ownership. Either CXL fully claims the Soft\n> reserved ranges or it relinquishes it entirely.\n\n\nAs I said before, I do not understand why this an all or none decision. \nIf I understood this right, we are not trusting on how the platform is \ndealing with CXL configuration leading to some soft reserved ranges not \nhaving a cxl region. If we do not trust it, why to give such a memory to \nthe kernel through hmem?\n\n\nIMO, it is important to state here the reason for this decision. If I \nunderstood this wrongly, I guess it is even more important to explain \nthe reason behind the decision in the commit and maybe as a comment in \nthe code as well. I could not understand it, but at least there would be \nan explanation.\n\n\nMoreover, as I also commented previously, with Type2 devices, it is \nalmost certain the modules containing the related drivers will not be \nprobed at this point, or if not fully certain, it is a potential \npossibility. That implies not all the soft reserved regions could have \nlinked cxl regions ... leading to given all those soft reserved ranges \nto hmem. I know the \"approved\" solution is Type2 should go without soft \nreserved memory, but some Type2 devices/drivers could be happy enough \nwith dax. If we do not want to deal with this problem now, at least \nthere should be some indication of this problem.\n\n\n>\n> Co-developed-by: Dan Williams <dan.j.williams@intel.com>\n> Signed-off-by: Dan Williams <dan.j.williams@intel.com>\n> Signed-off-by: Smita Koralahalli <Smita.KoralahalliChannabasappa@amd.com>\n> ---\n>   drivers/dax/bus.c       |  3 ++\n>   drivers/dax/bus.h       | 19 ++++++++++\n>   drivers/dax/cxl.c       |  1 +\n>   drivers/dax/hmem/hmem.c | 78 +++++++++++++++++++++++++++++++++++++++--\n>   4 files changed, 99 insertions(+), 2 deletions(-)\n>\n> diff --git a/drivers/dax/bus.c b/drivers/dax/bus.c\n> index 92b88952ede1..81985bcc70f9 100644\n> --- a/drivers/dax/bus.c\n> +++ b/drivers/dax/bus.c\n> @@ -25,6 +25,9 @@ DECLARE_RWSEM(dax_region_rwsem);\n>    */\n>   DECLARE_RWSEM(dax_dev_rwsem);\n>   \n> +enum dax_cxl_mode dax_cxl_mode = DAX_CXL_MODE_DEFER;\n> +EXPORT_SYMBOL_NS_GPL(dax_cxl_mode, \"CXL\");\n> +\n>   static DEFINE_MUTEX(dax_hmem_lock);\n>   static dax_hmem_deferred_fn hmem_deferred_fn;\n>   static void *dax_hmem_data;\n> diff --git a/drivers/dax/bus.h b/drivers/dax/bus.h\n> index b58a88e8089c..82616ff52fd1 100644\n> --- a/drivers/dax/bus.h\n> +++ b/drivers/dax/bus.h\n> @@ -41,6 +41,25 @@ struct dax_device_driver {\n>   \tvoid (*remove)(struct dev_dax *dev);\n>   };\n>   \n> +/*\n> + * enum dax_cxl_mode - State machine to determine ownership for CXL\n> + * tagged Soft Reserved memory ranges.\n> + * @DAX_CXL_MODE_DEFER: Ownership resolution pending. Set while waiting\n> + * for CXL enumeration and region assembly to complete.\n> + * @DAX_CXL_MODE_REGISTER: CXL regions do not fully cover Soft Reserved\n> + * ranges. Fall back to registering those ranges via dax_hmem.\n> + * @DAX_CXL_MODE_DROP: All Soft Reserved ranges intersecting CXL windows\n> + * are fully contained within committed CXL regions. Drop HMEM handling\n> + * and allow dax_cxl to bind.\n> + */\n> +enum dax_cxl_mode {\n> +\tDAX_CXL_MODE_DEFER,\n> +\tDAX_CXL_MODE_REGISTER,\n> +\tDAX_CXL_MODE_DROP,\n> +};\n> +\n> +extern enum dax_cxl_mode dax_cxl_mode;\n> +\n>   typedef void (*dax_hmem_deferred_fn)(void *data);\n>   \n>   int dax_hmem_register_work(dax_hmem_deferred_fn fn, void *data);\n> diff --git a/drivers/dax/cxl.c b/drivers/dax/cxl.c\n> index a2136adfa186..3ab39b77843d 100644\n> --- a/drivers/dax/cxl.c\n> +++ b/drivers/dax/cxl.c\n> @@ -44,6 +44,7 @@ static struct cxl_driver cxl_dax_region_driver = {\n>   \n>   static void cxl_dax_region_driver_register(struct work_struct *work)\n>   {\n> +\tdax_hmem_flush_work();\n>   \tcxl_driver_register(&cxl_dax_region_driver);\n>   }\n>   \n> diff --git a/drivers/dax/hmem/hmem.c b/drivers/dax/hmem/hmem.c\n> index 1e3424358490..85854e25254b 100644\n> --- a/drivers/dax/hmem/hmem.c\n> +++ b/drivers/dax/hmem/hmem.c\n> @@ -3,6 +3,7 @@\n>   #include <linux/memregion.h>\n>   #include <linux/module.h>\n>   #include <linux/dax.h>\n> +#include <cxl/cxl.h>\n>   #include \"../bus.h\"\n>   \n>   static bool region_idle;\n> @@ -69,8 +70,18 @@ static int hmem_register_device(struct device *host, int target_nid,\n>   \tif (IS_ENABLED(CONFIG_DEV_DAX_CXL) &&\n>   \t    region_intersects(res->start, resource_size(res), IORESOURCE_MEM,\n>   \t\t\t      IORES_DESC_CXL) != REGION_DISJOINT) {\n> -\t\tdev_dbg(host, \"deferring range to CXL: %pr\\n\", res);\n> -\t\treturn 0;\n> +\t\tswitch (dax_cxl_mode) {\n> +\t\tcase DAX_CXL_MODE_DEFER:\n> +\t\t\tdev_dbg(host, \"deferring range to CXL: %pr\\n\", res);\n> +\t\t\tdax_hmem_queue_work();\n> +\t\t\treturn 0;\n> +\t\tcase DAX_CXL_MODE_REGISTER:\n> +\t\t\tdev_dbg(host, \"registering CXL range: %pr\\n\", res);\n> +\t\t\tbreak;\n> +\t\tcase DAX_CXL_MODE_DROP:\n> +\t\t\tdev_dbg(host, \"dropping CXL range: %pr\\n\", res);\n> +\t\t\treturn 0;\n> +\t\t}\n>   \t}\n>   \n>   \trc = region_intersects_soft_reserve(res->start, resource_size(res));\n> @@ -123,8 +134,70 @@ static int hmem_register_device(struct device *host, int target_nid,\n>   \treturn rc;\n>   }\n>   \n> +static int hmem_register_cxl_device(struct device *host, int target_nid,\n> +\t\t\t\t    const struct resource *res)\n> +{\n> +\tif (region_intersects(res->start, resource_size(res), IORESOURCE_MEM,\n> +\t\t\t      IORES_DESC_CXL) != REGION_DISJOINT)\n> +\t\treturn hmem_register_device(host, target_nid, res);\n> +\n> +\treturn 0;\n> +}\n> +\n> +static int soft_reserve_has_cxl_match(struct device *host, int target_nid,\n> +\t\t\t\t      const struct resource *res)\n> +{\n> +\tif (region_intersects(res->start, resource_size(res), IORESOURCE_MEM,\n> +\t\t\t      IORES_DESC_CXL) != REGION_DISJOINT) {\n> +\t\tif (!cxl_region_contains_soft_reserve((struct resource *)res))\n> +\t\t\treturn 1;\n> +\t}\n> +\n> +\treturn 0;\n> +}\n> +\n> +static void process_defer_work(void *data)\n> +{\n> +\tstruct platform_device *pdev = data;\n> +\tint rc;\n> +\n> +\t/* relies on cxl_acpi and cxl_pci having had a chance to load */\n> +\twait_for_device_probe();\n> +\n> +\trc = walk_hmem_resources(&pdev->dev, soft_reserve_has_cxl_match);\n> +\n> +\tif (!rc) {\n> +\t\tdax_cxl_mode = DAX_CXL_MODE_DROP;\n> +\t\tdev_dbg(&pdev->dev, \"All Soft Reserved ranges claimed by CXL\\n\");\n> +\t} else {\n> +\t\tdax_cxl_mode = DAX_CXL_MODE_REGISTER;\n> +\t\tdev_warn(&pdev->dev,\n> +\t\t\t \"Soft Reserved not fully contained in CXL; using HMEM\\n\");\n> +\t}\n> +\n> +\twalk_hmem_resources(&pdev->dev, hmem_register_cxl_device);\n> +}\n> +\n> +static void kill_defer_work(void *data)\n> +{\n> +\tstruct platform_device *pdev = data;\n> +\n> +\tdax_hmem_flush_work();\n> +\tdax_hmem_unregister_work(process_defer_work, pdev);\n> +}\n> +\n>   static int dax_hmem_platform_probe(struct platform_device *pdev)\n>   {\n> +\tint rc;\n> +\n> +\trc = dax_hmem_register_work(process_defer_work, pdev);\n> +\tif (rc)\n> +\t\treturn rc;\n> +\n> +\trc = devm_add_action_or_reset(&pdev->dev, kill_defer_work, pdev);\n> +\tif (rc)\n> +\t\treturn rc;\n> +\n>   \treturn walk_hmem_resources(&pdev->dev, hmem_register_device);\n>   }\n>   \n> @@ -174,3 +247,4 @@ MODULE_ALIAS(\"platform:hmem_platform*\");\n>   MODULE_DESCRIPTION(\"HMEM DAX: direct access to 'specific purpose' memory\");\n>   MODULE_LICENSE(\"GPL v2\");\n>   MODULE_AUTHOR(\"Intel Corporation\");\n> +MODULE_IMPORT_NS(\"CXL\");\n\n",
          "reply_to": "Smita Koralahalli"
        }
      ],
      "analysis_source": "llm-per-reviewer"
    }
  }
}