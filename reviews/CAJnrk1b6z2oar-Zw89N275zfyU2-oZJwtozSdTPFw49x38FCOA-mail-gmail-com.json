{
  "thread_id": "CAJnrk1b6z2oar_Zw89N275zfyU2+oZJwtozSdTPFw49x38FCOA@mail.gmail.com",
  "subject": "[PATCH v4 19/25] fuse: add io-uring kernel-managed buffer ring",
  "url": "https://lore.kernel.org/all/CAJnrk1b6z2oar_Zw89N275zfyU2+oZJwtozSdTPFw49x38FCOA@mail.gmail.com/",
  "dates": {
    "2026-02-25": {
      "report_file": "2026-02-25_ollama_llama3.1-8b.html",
      "developer": "Joanne Koong",
      "reviews": [
        {
          "author": "Joanne Koong",
          "summary": "Raised questions about the handling of 0-byte payloads and the order of fuse_uring_headers_cleanup() and fuse_uring_get_next_fuse_req().",
          "sentiment": "neutral",
          "sentiment_signals": [
            "NEEDS_WORK"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "",
          "reply_to": "",
          "message_date": "",
          "message_id": ""
        }
      ],
      "analysis_source": "llm",
      "patch_summary": "The patch adds kernel-managed buffer ring support for io-uring in the FUSE filesystem."
    },
    "2026-02-26": {
      "report_file": "2026-02-25_ollama_llama3.1-8b.html",
      "developer": "Joanne Koong",
      "reviews": [
        {
          "author": "Joanne Koong",
          "summary": "Raised questions about the handling of 0-byte payloads and the order of fuse_uring_headers_cleanup() and fuse_uring_get_next_fuse_req().",
          "sentiment": "neutral",
          "sentiment_signals": [
            "NEEDS_WORK"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "On Thu, Feb 26, 2026 at 10:21 AM Bernd Schubert <bernd@bsbernd.com> wrote:\n>\n> On 2/26/26 00:42, Joanne Koong wrote:\n> > On Wed, Feb 25, 2026 at 9:55 AM Bernd Schubert <bernd@bsbernd.com> wrote:\n> >> On 1/28/26 22:44, Bernd Schubert wrote:\n> >>> On 1/17/26 00:30, Joanne Koong wrote:\n> >>>> diff --git a/fs/fuse/dev_uring.c b/fs/fuse/dev_uring.c\n> >>>> @@ -940,6 +1188,7 @@ static int fuse_uring_commit_fetch(struct io_uring_cmd *cmd, int issue_flags,\n> >>>>      unsigned int qid = READ_ONCE(cmd_req->qid);\n> >>>>      struct fuse_pqueue *fpq;\n> >>>>      struct fuse_req *req;\n> >>>> +    bool send;\n> >>>>\n> >>>>      err = -ENOTCONN;\n> >>>>      if (!ring)\n> >>>> @@ -990,7 +1239,12 @@ static int fuse_uring_commit_fetch(struct io_uring_cmd *cmd, int issue_flags,\n> >>>>\n> >>>>      /* without the queue lock, as other locks are taken */\n> >>>>      fuse_uring_prepare_cancel(cmd, issue_flags, ent);\n> >>>> -    fuse_uring_commit(ent, req, issue_flags);\n> >>>> +\n> >>>> +    err = fuse_uring_headers_prep(ent, ITER_SOURCE, issue_flags);\n> >>>> +    if (err)\n> >>>> +            fuse_uring_req_end(ent, req, err);\n> >>>> +    else\n> >>>> +            fuse_uring_commit(ent, req, issue_flags);\n> >>>>\n> >>>>      /*\n> >>>>       * Fetching the next request is absolutely required as queued\n> >>>> @@ -998,7 +1252,9 @@ static int fuse_uring_commit_fetch(struct io_uring_cmd *cmd, int issue_flags,\n> >>>>       * and fetching is done in one step vs legacy fuse, which has separated\n> >>>>       * read (fetch request) and write (commit result).\n> >>>>       */\n> >>>> -    if (fuse_uring_get_next_fuse_req(ent, queue))\n> >>>> +    send = fuse_uring_get_next_fuse_req(ent, queue, issue_flags);\n> >>>> +    fuse_uring_headers_cleanup(ent, issue_flags);\n> >>>> +    if (send)\n> >>>>              fuse_uring_send(ent, cmd, 0, issue_flags);\n> >>>>      return 0;\n> >>\n> >>\n> >> Hello Joanne,\n> >>\n> >> couldn't it call fuse_uring_headers_cleanup() before the\n> >> fuse_uring_get_next_fuse_req()? I find it a bit confusing that it firsts\n> >> gets the next request and then cleans up the buffer from the previous\n> >> request.\n> >\n> > Hi Bernd,\n> >\n> > Thanks for taking a look.\n> >\n> > The fuse_uring_headers_cleanup() call has to happen after the\n> > fuse_uring_get_next_fuse_req() call because\n> > fuse_uring_get_next_fuse_req() copies payload to the header, so we\n> > can't yet relinquish the refcount on the headers buffer / clean it up\n> > yet. I can add a comment about this to make this more clear.\n>\n> I only found time right now and already super late (or early) here.\n>\n> I guess that is fuse_uring_copy_to_ring -> copy_header_to_ring, but why\n> can it then call fuse_uring_headers_cleanup() ->\n> io_uring_fixed_index_put(). I.e. doesn't it put buffer it just copied\n> to? Why not the sequence of\n>\n> err = fuse_uring_headers_prep(ent, ITER_SOURCE, issue_flags);\n> fuse_uring_commit(ent, req, issue_flags);\n> fuse_uring_headers_cleanup(ent, issue_flags);\n>\n> And then fuse_uring_get_next_fuse_req() does another\n> fuse_uring_headers_prep() with ITER_DEST?\n\nThe headers buffer is the same buffer for the request that's being\ncommitted and the next request that is fetched (just like how the ent\nis the same ent for the request that's committed and the next fetched\nrequest). Because of this we can just reuse the same headers_iter and\ncall io_uring_fixed_index_put() after we're done copying over the next\nrequest. I can add a comment about this to make this more clear.\n\n>\n>\n> >\n> >>\n> >> As I understand it, the the patch basically adds the feature of 0-byte\n> >> payloads. Maybe worth mentioning in the commit message?\n> >\n> > Hmm I'm not really sure I am seeing where the 0-byte payload gets\n> > added. On the server side, they don't receive payloads that are\n> > 0-bytes. If there is no next fuse request to send, then nothing gets\n> > sent. But maybe I'm not interpreting your comment about 0-byte\n> > payloads correctly?\n>\n> There is fuse_uring_req_has_payload() and\n> fuse_uring_select_buffer()/fuse_uring_next_req_update_buffer() using\n> that function. When a request doesn't have a payload the ring entries\n> runs without a payload - effectively that introduces 0-byte payloads,\n> doesn't it?\n\nWhen the request doesn't have a payload, no ring entry gets used for\nthe request. The check for this happens in fuse_uring_prep_buffer()\n\nstatic int fuse_uring_prep_buffer(struct fuse_ring_ent *ent,\n                                  struct fuse_req *req, unsigned issue_flags)\n{\n        ...\n        /* no payload to copy, can skip selecting a buffer */\n        if (!fuse_uring_req_has_payload(req))\n                return 0;\n\n        return fuse_uring_select_buffer(ent, issue_flags);\n}\n\n>\n> >\n> >> I also wonder if it would be worth to document as code comment that\n> >> fuse_uring_ent_assign_req / fuse_uring_next_req_update_buffer are\n> >> allowed to fail for a buffer upgrade (i.e. 0 to max-payload). At least\n> >\n> > Good idea, I'll add a comment about this.\n> >\n> >> the current comment of  \"Fetching the next request is absolutely\n> >> required\" is actually not entirely true anymore.\n> >>\n> >\n> > I don't think this patch introduces new behavior on this front.\n> > fuse_uring_get_next_fuse_req() is still called to fetch the next\n> > request AFAICS.\n> >\n>\n> It still does, but if the request didn't have a payload it might not\n> have a buffer and if it didn't have a buffer and doesn't manage to get a\n> buffer, it doesn't handle a request - that a bit change of\n> 'commit-and-fetch always fetches a new request if there is any request\n> queued'.\n\nOk, I'll update the \"Fetching the next request is absolutely required\" comment.\n\nThanks,\nJoanne\n>\n>\n> Thanks,\n> Bernd\n\n",
          "reply_to": "",
          "message_date": "2026-02-26",
          "message_id": ""
        }
      ],
      "analysis_source": "llm",
      "patch_summary": "The patch adds kernel-managed buffer ring support for io-uring in the FUSE filesystem."
    }
  }
}