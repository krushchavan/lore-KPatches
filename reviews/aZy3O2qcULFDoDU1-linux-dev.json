{
  "thread_id": "aZy3O2qcULFDoDU1@linux.dev",
  "subject": "Re: [PATCH] mm/slab: initialize slab->stride early to avoid memory ordering issues",
  "url": "https://lore.kernel.org/all/aZy3O2qcULFDoDU1@linux.dev/",
  "dates": {
    "2026-02-23": {
      "report_file": "2026-02-23_ollama_llama3.1-8b.html",
      "developer": "Shakeel Butt",
      "reviews": [
        {
          "author": "Harry Yoo (author)",
          "summary": "The author is addressing a concern about the effectiveness of the patch in fixing memory ordering issues, specifically that it was unclear if the patch actually resolved the reported issue. The author explains the problem and its consequences, reiterates the fix, and does not indicate any plans for further revision.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Vlastimil, could you please update the changelog when applying this\nto the tree? I think this also explains [3] (thanks for raising it\noff-list, Vlastimil!):\n\nWhen alloc_slab_obj_exts() is called later (instead of during slab\nallocation and initialization), slab->stride and slab->obj_exts are\nupdated after the slab is already accessible by multiple CPUs.\n\nThe current implementation does not enforce memory ordering between\nslab->stride and slab->obj_exts. For correctness, slab->stride must be\nvisible before slab->obj_exts. Otherwise, concurrent readers may observe\nslab->obj_exts as non-zero while stride is still stale.\n\nWith stale slab->stride, slab_obj_ext() could return the wrong obj_ext.\nThis could cause two problems:\n\n  - obj_cgroup_put() is called on the wrong objcg, leading to\n    a use-after-free due to incorrect reference counting [1] by\n    decrementing the reference count more than it was incremented.\n\n  - refill_obj_stock() is called on the wrong objcg, leading to\n    a page_counter overflow [2] by uncharging more memory than charged.\n\nFix this by unconditionally initializing slab->stride in\nalloc_slab_obj_exts_early(), before the need_slab_obj_exts() check.\nIn the case of SLAB_OBJ_EXT_IN_OBJ, it is overridden in the function.\n\nThis ensures updates to slab->stride become visible before the slab\ncan be accessed by other CPUs via the per-node partial slab list\n(protected by spinlock with acquire/release semantics).\n\nThanks to Shakeel Butt for pointing out this issue [3].\n\nFixes: 7a8e71bc619d (\"mm/slab: use stride to access slabobj_ext\")\nReported-by: Venkat Rao Bagalkote <venkat88@linux.ibm.com>\nCloses: https://lore.kernel.org/lkml/ca241daa-e7e7-4604-a48d-de91ec9184a5@linux.ibm.com [1]\nCloses: https://lore.kernel.org/all/ddff7c7d-c0c3-4780-808f-9a83268bbf0c@linux.ibm.com [2]\nLink: https://lore.kernel.org/linux-mm/aZu9G9mVIVzSm6Ft@hyeyoo [3]\nSigned-off-by: Harry Yoo <harry.yoo@oracle.com>\n\n-- \nCheers,\nHarry / Hyeonggon",
          "reply_to": "",
          "message_date": "2026-02-23"
        },
        {
          "author": "Shakeel Butt",
          "summary": "Gave Reviewed-by",
          "sentiment": "positive",
          "sentiment_signals": [],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "heuristic",
          "raw_body": "",
          "reply_to": "Harry Yoo",
          "message_date": "2026-02-23"
        }
      ],
      "analysis_source": "llm-per-reviewer"
    },
    "2026-02-24": {
      "report_file": "2026-02-23_ollama_llama3.1-8b.html",
      "developer": "Shakeel Butt",
      "reviews": [
        {
          "author": "Venkat Bagalkote",
          "summary": "Reviewer Venkat Bagalkote reported that the patch does not fix the memory ordering issue, citing a kernel NULL pointer dereference on read at address 0x00000000 in the refill_obj_stock function. He applied the patch to the mainline repo and ran the complete test suite but was unable to confirm that it fixes the issue reported by [1].",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Thanks for the patch. I did ran the complete test suite, and \nunfortunately issue is reproducing.\n\nI applied this patch on mainline repo for testing.\n\nTraces:\n\n[ 9316.514161] BUG: Kernel NULL pointer dereference on read at 0x00000000\n[ 9316.514169] Faulting instruction address: 0xc0000000008b2ff4\n[ 9316.514176] Oops: Kernel access of bad area, sig: 7 [#1]\n[ 9316.514182] LE PAGE_SIZE=64K MMU=Radix SMP NR_CPUS=8192 NUMA pSeries\n[ 9316.514189] Modules linked in: overlay dm_zero dm_thin_pool \ndm_persistent_data dm_bio_prison dm_snapshot dm_bufio dm_flakey xfs loop \ndm_mod nft_fib_inet nft_fib_ipv4 nft_fib_ipv6 nft_fib nft_reject_inet \nnf_reject_ipv4 nf_reject_ipv6 nft_reject nft_ct nft_chain_nat nf_nat \nnf_conntrack nf_defrag_ipv6 nf_defrag_ipv4 ip_set bonding nf_tables tls \nsunrpc rfkill nfnetlink pseries_rng vmx_crypto dax_pmem fuse ext4 crc16 \nmbcache jbd2 nd_pmem papr_scm sd_mod libnvdimm sg ibmvscsi ibmveth \nscsi_transport_srp pseries_wdt [last unloaded: scsi_debug]\n[ 9316.514295] CPU: 16 UID: 0 PID: 0 Comm: swapper/16 Kdump: loaded \nTainted: G    W     7.0.0-rc1+ #1 PREEMPTLAZY\n[ 9316.514306] Tainted: [W]=WARN\n[ 9316.514311] Hardware name: IBM,9080-HEX Power11 (architected) \n0x820200 0xf000007 of:IBM,FW1110.01 (NH1110_069) hv:phyp pSeries\n[ 9316.514318] NIP: c0000000008b2ff4 LR: c0000000008b2fec CTR: \nc00000000036d680\n[ 9316.514326] REGS: c000000d0dcb7870 TRAP: 0300 Tainted: G  W    \n   (7.0.0-rc1+)\n[ 9316.514333] MSR: 8000000000009033 <SF,EE,ME,IR,DR,RI,LE> CR: \n84042802 XER: 20040000\n[ 9316.514356] CFAR: c000000000862e94 DAR: 0000000000000000 DSISR: \n00080000 IRQMASK: 0\n[ 9316.514356] GPR00: c0000000008b2fec c000000d0dcb7b10 c00000000243a500 \n0000000000000001\n[ 9316.514356] GPR04: 0000000000000008 0000000000000001 c0000000008b2fec \n0000000000000001\n[ 9316.514356] GPR08: a80e000000000000 0000000000000001 0000000000000007 \na80e000000000000\n[ 9316.514356] GPR12: c00e00000e7b6cd5 c000000d0ddf4700 c000000129a98e00 \n0000000000000006\n[ 9316.514356] GPR16: c000000007012fa0 c000000007012fa4 c000000005160980 \nc000000007012f88\n[ 9316.514356] GPR20: c00c000000021bec c000000d0d07f008 0000000000000001 \nffffffffffffff78\n[ 9316.514356] GPR24: 0000000000000005 c000000d0d58f180 c0000000032cf000 \nc000000d0ddf4700\n[ 9316.514356] GPR28: 0000000000000088 0000000000000000 c000000129a98e00 \nc000000d0d07f000\n[ 9316.514457] NIP [c0000000008b2ff4] refill_obj_stock+0x5b4/0x680\n[ 9316.514467] LR [c0000000008b2fec] refill_obj_stock+0x5ac/0x680\n[ 9316.514476] Call Trace:\n[ 9316.514481] [c000000d0dcb7b10] [c0000000008b2fec] \nrefill_obj_stock+0x5ac/0x680 (unreliable)\n[ 9316.514494] [c000000d0dcb7b90] [c0000000008b9598] \n__memcg_slab_free_hook+0x238/0x3ec\n[ 9316.514505] [c000000d0dcb7c60] [c0000000007f3d90] \n__rcu_free_sheaf_prepare+0x314/0x3e8\n[ 9316.514516] [c000000d0dcb7d10] [c0000000007fc2ec] \nrcu_free_sheaf+0x38/0x170\n[ 9316.514528] [c000000d0dcb7d50] [c000000000334570] \nrcu_do_batch+0x2ec/0xfa8\n[ 9316.514538] [c000000d0dcb7e50] [c000000000339a08] rcu_core+0x22c/0x48c\n[ 9316.514548] [c000000d0dcb7ec0] [c0000000001cfeac] \nhandle_softirqs+0x1f4/0x74c\n[ 9316.514559] [c000000d0dcb7fe0] [c00000000001b0cc] \ndo_softirq_own_stack+0x60/0x7c\n[ 9316.514570] [c0000000096c7930] [c00000000001b0b8] \ndo_softirq_own_stack+0x4c/0x7c\n[ 9316.514581] [c0000000096c7960] [c0000000001cf168] \n__irq_exit_rcu+0x268/0x308\n[ 9316.514592] [c0000000096c79a0] [c0000000001d0be4] irq_exit+0x20/0x38\n[ 9316.514602] [c0000000096c79c0] [c0000000000315f4] \ninterrupt_async_exit_prepare.constprop.0+0x18/0x2c\n[ 9316.514614] [c0000000096c79e0] [c000000000009ffc] \ndecrementer_common_virt+0x28c/0x290\n[ 9316.514626] ---- interrupt: 900 at plpar_hcall_norets_notrace+0x18/0x2c\n[ 9316.514635] NIP: c00000000012d9f0 LR: c00000000135c0a8 CTR: \n0000000000000000\n[ 9316.514642] REGS: c0000000096c7a10 TRAP: 0900 Tainted: G  W    \n   (7.0.0-rc1+)\n[ 9316.514649] MSR: 800000000280b033 <SF,VEC,VSX,EE,FP,ME,IR,DR,RI,LE> \nCR: 24000804 XER: 00000000\n[ 9316.514678] CFAR: 0000000000000000 IRQMASK: 0\n[ 9316.514678] GPR00: 0000000000000000 c0000000096c7cb0 c00000000243a500 \n0000000000000000\n[ 9316.514678] GPR04: 0000000000000000 800400002fe6fc10 0000000000000000 \n0000000000000001\n[ 9316.514678] GPR08: 0000000000000030 0000000000000000 0000000000000090 \n0000000000000001\n[ 9316.514678] GPR12: 800400002fe6fc00 c000000d0ddf4700 0000000000000000 \n000000002ef01a00\n[ 9316.514678] GPR16: 0000000000000000 0000000000000000 0000000000000000 \n0000000000000000\n[ 9316.514678] GPR20: 0000000000000000 0000000000000000 0000000000000000 \n0000000000000001\n[ 9316.514678] GPR24: 0000000000000000 c000000004d7a760 000008792ad04b82 \n0000000000000000\n[ 9316.514678] GPR28: 0000000000000000 0000000000000001 c0000000032b18d8 \nc0000000032b18e0\n[ 9316.514774] NIP [c00000000012d9f0] plpar_hcall_norets_notrace+0x18/0x2c\n[ 9316.514782] LR [c00000000135c0a8] cede_processor.isra.0+0x1c/0x34\n[ 9316.514792] ---- interrupt: 900\n[ 9316.514797] [c0000000096c7cb0] [c0000000096c7cf0] 0xc0000000096c7cf0 \n(unreliable)\n[ 9316.514808] [c0000000096c7d10] [c0000000019af170] \ndedicated_cede_loop+0x90/0x170\n[ 9316.514819] [c0000000096c7d60] [c0000000019aeb20] \ncpuidle_enter_state+0x394/0x480\n[ 9316.514830] [c0000000096c7e00] [c00000000135864c] cpuidle_enter+0x64/0x9c\n[ 9316.514840] [c0000000096c7e50] [c000000000284b0c] call_cpuidle+0x7c/0xf8\n[ 9316.514852] [c0000000096c7e90] [c0000000002903e8] \ncpuidle_idle_call+0x1c4/0x2b4\n[ 9316.514862] [c0000000096c7f00] [c00000000029060c] do_idle+0x134/0x208\n[ 9316.514872] [c0000000096c7f50] [c000000000290a5c] \ncpu_startup_entry+0x60/0x64\n[ 9316.514882] [c0000000096c7f80] [c000000000074738] \nstart_secondary+0x3fc/0x400\n[ 9316.514894] [c0000000096c7fe0] [c00000000000e258] \nstart_secondary_prolog+0x10/0x14\n[ 9316.514904] Code: eba962a0 4bfffe40 60000000 387e0008 4bfae7c1 \n60000000 ebbe0008 38800008 7fa3eb78 4bfafe85 60000000 39200001 \n<7d40e8a8> 7d495214 7d40e9ad 40c2fff4\n[ 9316.514941] ---[ end trace 0000000000000000 ]---\n\n\nRegards,\n\nVenkat.",
          "reply_to": "Harry Yoo",
          "message_date": "2026-02-24"
        },
        {
          "author": "Harry Yoo (author)",
          "summary": "Author acknowledges that the original patch did not fully address the memory ordering issue, and is considering additional cases where it may be a problem. They are introducing heavy memory barriers to ensure updates to stride are visible before obj_exts. A fix is planned.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "acknowledges a fix is needed",
            "planning to revise the patch"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Oops, thanks for confirming that it's still reproduced!\nThat's really helpful.\n\nPerhaps I should start considering cases where it's not a memory\nordering issue, but let's check one more thing before moving on.\ncould you please test if it still reproduces with the following patch?\n\nIf it's still reproducible, it should not be due to the memory ordering\nissue between obj_exts and stride.\n\n---8<---\nFrom: Harry Yoo <harry.yoo@oracle.com>\nDate: Mon, 23 Feb 2026 16:58:09 +0900\nSubject: mm/slab: enforce slab->stride -> slab->obj_exts ordering\n\nI tried to avoid unnecessary memory barriers for efficiency,\nbut the original bug is still reproducible.\n\nProbably I missed a case where an object is allocated on a CPU\nand then freed on a different CPU without involving spinlock.\n\nI'm not sure if I did not cover edge cases or if it's caused by\nsomething other than memory ordering issue.\n\nAnyway, let's find out by introducing heavy memory barriers!\n\nAlways ensure that updates to stride is visible before obj_exts.\n\n---\n mm/slab.h |  1 +\n mm/slub.c | 10 +++++++---\n 2 files changed, 8 insertions(+), 3 deletions(-)\n\ndiff --git a/mm/slab.h b/mm/slab.h\nindex 71c7261bf822..aacdd9f4e509 100644\n--- a/mm/slab.h\n+++ b/mm/slab.h\n@@ -565,6 +565,7 @@ static inline void slab_set_stride(struct slab *slab, unsigned short stride)\n }\n static inline unsigned short slab_get_stride(struct slab *slab)\n {\n+\tsmp_rmb();\n \treturn slab->stride;\n }\n #else\ndiff --git a/mm/slub.c b/mm/slub.c\nindex 862642c165ed..c7c8b660a994 100644\n--- a/mm/slub.c\n+++ b/mm/slub.c\n@@ -2196,7 +2196,6 @@ int alloc_slab_obj_exts(struct slab *slab, struct kmem_cache *s,\n retry:\n \told_exts = READ_ONCE(slab->obj_exts);\n \thandle_failed_objexts_alloc(old_exts, vec, objects);\n-\tslab_set_stride(slab, sizeof(struct slabobj_ext));\n\n \tif (new_slab) {\n \t\t/*\n@@ -2272,6 +2271,10 @@ static void alloc_slab_obj_exts_early(struct kmem_cache *s, struct slab *slab)\n \tvoid *addr;\n \tunsigned long obj_exts;\n\n+\tslab_set_stride(slab, sizeof(struct slabobj_ext));\n+\t/* pairs with smp_rmb() in slab_get_stride() */\n+\tsmp_wmb();\n+\n \tif (!need_slab_obj_exts(s))\n \t\treturn;\n\n@@ -2288,7 +2291,6 @@ static void alloc_slab_obj_exts_early(struct kmem_cache *s, struct slab *slab)\n \t\tobj_exts |= MEMCG_DATA_OBJEXTS;\n #endif\n \t\tslab->obj_exts = obj_exts;\n-\t\tslab_set_stride(slab, sizeof(struct slabobj_ext));\n \t} else if (s->flags & SLAB_OBJ_EXT_IN_OBJ) {\n \t\tunsigned int offset = obj_exts_offset_in_object(s);\n\n@@ -2305,8 +2307,10 @@ static void alloc_slab_obj_exts_early(struct kmem_cache *s, struct slab *slab)\n #ifdef CONFIG_MEMCG\n \t\tobj_exts |= MEMCG_DATA_OBJEXTS;\n #endif\n-\t\tslab->obj_exts = obj_exts;\n \t\tslab_set_stride(slab, s->size);\n+\t\t/* pairs with smp_rmb() in slab_get_stride() */\n+\t\tsmp_wmb();\n+\t\tslab->obj_exts = obj_exts;\n \t}\n }\n\n--\n2.43.0",
          "reply_to": "Venkat Bagalkote",
          "message_date": "2026-02-24"
        }
      ],
      "analysis_source": "llm-per-reviewer"
    }
  }
}