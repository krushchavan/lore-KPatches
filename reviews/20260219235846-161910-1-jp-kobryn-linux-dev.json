{
  "thread_id": "20260219235846.161910-1-jp.kobryn@linux.dev",
  "subject": "[PATCH v5] mm: move pgscan, pgsteal, pgrefill to node stats",
  "url": "https://lore.kernel.org/all/20260219235846.161910-1-jp.kobryn@linux.dev/",
  "dates": {
    "2026-02-19": {
      "report_file": "2026-02-19_ollama_llama3.1-8b.html",
      "developer": "JP Kobryn",
      "reviews": [
        {
          "author": "Zi Yan",
          "summary": "Gave Acked-by",
          "sentiment": "neutral",
          "sentiment_signals": [],
          "has_inline_review": true,
          "tags_given": [
            "Acked-by"
          ],
          "analysis_source": "heuristic",
          "raw_body": "On 19 Feb 2026, at 18:58, JP Kobryn (Meta) wrote:\n\n> There are situations where reclaim kicks in on a system with free memory.\n> One possible cause is a NUMA imbalance scenario where one or more nodes are\n> under pressure. It would help if we could easily identify such nodes.\n>\n> Move the pgscan, pgsteal, and pgrefill counters from vm_event_item to\n> node_stat_item to provide per-node reclaim visibility. With these counters\n> as node stats, the values are now displayed in the per-node section of\n> /proc/zoneinfo, which allows for quick identification of the affected\n> nodes.\n>\n> /proc/vmstat continues to report the same counters, aggregated across all\n> nodes. But the ordering of these items within the readout changes as they\n> move from the vm events section to the node stats section.\n>\n> Memcg accounting of these counters is preserved. The relocated counters\n> remain visible in memory.stat alongside the existing aggregate pgscan and\n> pgsteal counters.\n>\n> However, this change affects how the global counters are accumulated.\n> Previously, the global event count update was gated on !cgroup_reclaim(),\n> excluding memcg-based reclaim from /proc/vmstat. Now that\n> mod_lruvec_state() is being used to update the counters, the global\n> counters will include all reclaim. This is consistent with how pgdemote\n> counters are already tracked.\n>\n> Finally, the virtio_balloon driver is updated to use\n> global_node_page_state() to fetch the counters, as they are no longer\n> accessible through the vm_events array.\n>\n> Signed-off-by: JP Kobryn <jp.kobryn@linux.dev>\n> Suggested-by: Johannes Weiner <hannes@cmpxchg.org>\n> Acked-by: Michael S. Tsirkin <mst@redhat.com>\n> Reviewed-by: Vlastimil Babka (SUSE) <vbabka@kernel.org>\n> ---\n> v5:\n> \t- rebase onto mm/mm-new\n>\n> v4: https://lore.kernel.org/linux-mm/20260219171124.19053-1-jp.kobryn@linux.dev/\n> \t- remove unused memcg var from scan_folios()\n>\n> v3: https://lore.kernel.org/linux-mm/20260218222652.108411-1-jp.kobryn@linux.dev/\n> \t- additionally move PGREFILL to node stats\n>\n> v2: https://lore.kernel.org/linux-mm/20260218032941.225439-1-jp.kobryn@linux.dev/\n> \t- update commit message\n> \t- add entries to memory_stats array\n> \t- add switch cases in memcg_page_state_output_unit()\n>\n> v1: https://lore.kernel.org/linux-mm/20260212045109.255391-3-inwardvessel@gmail.com/\n>\n>  drivers/virtio/virtio_balloon.c |  8 ++---\n>  include/linux/mmzone.h          | 13 ++++++++\n>  include/linux/vm_event_item.h   | 13 --------\n>  mm/memcontrol.c                 | 56 +++++++++++++++++++++++----------\n>  mm/vmscan.c                     | 39 ++++++++---------------\n>  mm/vmstat.c                     | 26 +++++++--------\n>  6 files changed, 82 insertions(+), 73 deletions(-)\n>\n\nAcked-by: Zi Yan <ziy@nvidia.com>\n\nBest Regards,\nYan, Zi\n",
          "reply_to": "",
          "message_date": "2026-02-19",
          "message_id": ""
        }
      ],
      "analysis_source": "heuristic",
      "patch_summary": "There are situations where reclaim kicks in on a system with free memory. One possible cause is a NUMA imbalance scenario where one or more nodes are under pressure. It would help if we could easily identify such nodes.\n\nMove the pgscan, pgsteal, and pgrefill counters from vm_event_item to node_stat_item to provide per-node reclaim visibility. With these counters as node stats, the values are now displayed in the per-node section of /proc/zoneinfo, which allows for quick identification of the affected nodes.\n\n/proc/vmstat continues to report the same counters, aggregated across all nodes. But the ordering of these items within the readout changes as they move from the vm events section to the node stats section.\n\nMemcg accounting of these counters is preserved. The relocated counters remain visible in memory.stat alongside the existing aggregate pgscan and pgsteal counters."
    },
    "2026-02-20": {
      "report_file": "2026-02-20.html",
      "developer": "JP Kobryn",
      "reviews": [
        {
          "author": "Johannes Weiner",
          "summary": "Gave Acked-by",
          "sentiment": "neutral",
          "sentiment_signals": [],
          "has_inline_review": true,
          "tags_given": [
            "Acked-by"
          ],
          "analysis_source": "heuristic",
          "raw_body": "On Thu, Feb 19, 2026 at 03:58:46PM -0800, JP Kobryn (Meta) wrote:\n> There are situations where reclaim kicks in on a system with free memory.\n> One possible cause is a NUMA imbalance scenario where one or more nodes are\n> under pressure. It would help if we could easily identify such nodes.\n> \n> Move the pgscan, pgsteal, and pgrefill counters from vm_event_item to\n> node_stat_item to provide per-node reclaim visibility. With these counters\n> as node stats, the values are now displayed in the per-node section of\n> /proc/zoneinfo, which allows for quick identification of the affected\n> nodes.\n> \n> /proc/vmstat continues to report the same counters, aggregated across all\n> nodes. But the ordering of these items within the readout changes as they\n> move from the vm events section to the node stats section.\n> \n> Memcg accounting of these counters is preserved. The relocated counters\n> remain visible in memory.stat alongside the existing aggregate pgscan and\n> pgsteal counters.\n> \n> However, this change affects how the global counters are accumulated.\n> Previously, the global event count update was gated on !cgroup_reclaim(),\n> excluding memcg-based reclaim from /proc/vmstat. Now that\n> mod_lruvec_state() is being used to update the counters, the global\n> counters will include all reclaim. This is consistent with how pgdemote\n> counters are already tracked.\n> \n> Finally, the virtio_balloon driver is updated to use\n> global_node_page_state() to fetch the counters, as they are no longer\n> accessible through the vm_events array.\n> \n> Signed-off-by: JP Kobryn <jp.kobryn@linux.dev>\n> Suggested-by: Johannes Weiner <hannes@cmpxchg.org>\n> Acked-by: Michael S. Tsirkin <mst@redhat.com>\n> Reviewed-by: Vlastimil Babka (SUSE) <vbabka@kernel.org>\n\nAcked-by: Johannes Weiner <hannes@cmpxchg.org>\n",
          "reply_to": "",
          "message_date": "2026-02-20",
          "message_id": ""
        },
        {
          "author": "Shakeel Butt",
          "summary": "Yeah this difference always confused me.",
          "sentiment": "neutral",
          "sentiment_signals": [],
          "has_inline_review": true,
          "tags_given": [
            "Acked-by"
          ],
          "analysis_source": "heuristic",
          "raw_body": "On Thu, Feb 19, 2026 at 03:58:46PM -0800, JP Kobryn (Meta) wrote:\n> There are situations where reclaim kicks in on a system with free memory.\n> One possible cause is a NUMA imbalance scenario where one or more nodes are\n> under pressure. It would help if we could easily identify such nodes.\n> \n> Move the pgscan, pgsteal, and pgrefill counters from vm_event_item to\n> node_stat_item to provide per-node reclaim visibility. With these counters\n> as node stats, the values are now displayed in the per-node section of\n> /proc/zoneinfo, which allows for quick identification of the affected\n> nodes.\n> \n> /proc/vmstat continues to report the same counters, aggregated across all\n> nodes. But the ordering of these items within the readout changes as they\n> move from the vm events section to the node stats section.\n> \n> Memcg accounting of these counters is preserved. The relocated counters\n> remain visible in memory.stat alongside the existing aggregate pgscan and\n> pgsteal counters.\n> \n> However, this change affects how the global counters are accumulated.\n> Previously, the global event count update was gated on !cgroup_reclaim(),\n> excluding memcg-based reclaim from /proc/vmstat. Now that\n> mod_lruvec_state() is being used to update the counters, the global\n> counters will include all reclaim. This is consistent with how pgdemote\n> counters are already tracked.\n\nYeah this difference always confused me.\n\n> \n> Finally, the virtio_balloon driver is updated to use\n> global_node_page_state() to fetch the counters, as they are no longer\n> accessible through the vm_events array.\n> \n> Signed-off-by: JP Kobryn <jp.kobryn@linux.dev>\n> Suggested-by: Johannes Weiner <hannes@cmpxchg.org>\n> Acked-by: Michael S. Tsirkin <mst@redhat.com>\n> Reviewed-by: Vlastimil Babka (SUSE) <vbabka@kernel.org>\n\nAcked-by: Shakeel Butt <shakeel.butt@linux.dev>\n",
          "reply_to": "",
          "message_date": "2026-02-20",
          "message_id": ""
        }
      ],
      "analysis_source": "heuristic",
      "patch_summary": "There are situations where reclaim kicks in on a system with free memory. One possible cause is a NUMA imbalance scenario where one or more nodes are under pressure. It would help if we could easily identify such nodes.\n\nMove the pgscan, pgsteal, and pgrefill counters from vm_event_item to node_stat_item to provide per-node reclaim visibility. With these counters as node stats, the values are now displayed in the per-node section of /proc/zoneinfo, which allows for quick identification of the affected nodes.\n\n/proc/vmstat continues to report the same counters, aggregated across all nodes. But the ordering of these items within the readout changes as they move from the vm events section to the node stats section.\n\nMemcg accounting of these counters is preserved. The relocated counters remain visible in memory.stat alongside the existing aggregate pgscan and pgsteal counters."
    },
    "2026-02-23": {
      "report_file": "2026-02-23.html",
      "developer": "JP Kobryn",
      "reviews": [
        {
          "author": "Michal Hocko",
          "summary": "Gave Acked-by",
          "sentiment": "neutral",
          "sentiment_signals": [],
          "has_inline_review": true,
          "tags_given": [
            "Acked-by"
          ],
          "analysis_source": "heuristic",
          "raw_body": "On Thu 19-02-26 15:58:46, JP Kobryn (Meta) wrote:\n> There are situations where reclaim kicks in on a system with free memory.\n> One possible cause is a NUMA imbalance scenario where one or more nodes are\n> under pressure. It would help if we could easily identify such nodes.\n> \n> Move the pgscan, pgsteal, and pgrefill counters from vm_event_item to\n> node_stat_item to provide per-node reclaim visibility. With these counters\n> as node stats, the values are now displayed in the per-node section of\n> /proc/zoneinfo, which allows for quick identification of the affected\n> nodes.\n> \n> /proc/vmstat continues to report the same counters, aggregated across all\n> nodes. But the ordering of these items within the readout changes as they\n> move from the vm events section to the node stats section.\n> \n> Memcg accounting of these counters is preserved. The relocated counters\n> remain visible in memory.stat alongside the existing aggregate pgscan and\n> pgsteal counters.\n> \n> However, this change affects how the global counters are accumulated.\n> Previously, the global event count update was gated on !cgroup_reclaim(),\n> excluding memcg-based reclaim from /proc/vmstat. Now that\n> mod_lruvec_state() is being used to update the counters, the global\n> counters will include all reclaim. This is consistent with how pgdemote\n> counters are already tracked.\n> \n> Finally, the virtio_balloon driver is updated to use\n> global_node_page_state() to fetch the counters, as they are no longer\n> accessible through the vm_events array.\n> \n> Signed-off-by: JP Kobryn <jp.kobryn@linux.dev>\n> Suggested-by: Johannes Weiner <hannes@cmpxchg.org>\n> Acked-by: Michael S. Tsirkin <mst@redhat.com>\n> Reviewed-by: Vlastimil Babka (SUSE) <vbabka@kernel.org>\n\nAcked-by: Michal Hocko <mhocko@suse.com>\nThanks\n\n> ---\n> v5:\n> \t- rebase onto mm/mm-new\n> \n> v4: https://lore.kernel.org/linux-mm/20260219171124.19053-1-jp.kobryn@linux.dev/\n> \t- remove unused memcg var from scan_folios()\n> \n> v3: https://lore.kernel.org/linux-mm/20260218222652.108411-1-jp.kobryn@linux.dev/\n> \t- additionally move PGREFILL to node stats\n> \n> v2: https://lore.kernel.org/linux-mm/20260218032941.225439-1-jp.kobryn@linux.dev/\n> \t- update commit message\n> \t- add entries to memory_stats array\n> \t- add switch cases in memcg_page_state_output_unit()\n> \n> v1: https://lore.kernel.org/linux-mm/20260212045109.255391-3-inwardvessel@gmail.com/\n> \n>  drivers/virtio/virtio_balloon.c |  8 ++---\n>  include/linux/mmzone.h          | 13 ++++++++\n>  include/linux/vm_event_item.h   | 13 --------\n>  mm/memcontrol.c                 | 56 +++++++++++++++++++++++----------\n>  mm/vmscan.c                     | 39 ++++++++---------------\n>  mm/vmstat.c                     | 26 +++++++--------\n>  6 files changed, 82 insertions(+), 73 deletions(-)\n> \n> diff --git a/drivers/virtio/virtio_balloon.c b/drivers/virtio/virtio_balloon.c\n> index 4e549abe59ff..ab945532ceef 100644\n> --- a/drivers/virtio/virtio_balloon.c\n> +++ b/drivers/virtio/virtio_balloon.c\n> @@ -369,13 +369,13 @@ static inline unsigned int update_balloon_vm_stats(struct virtio_balloon *vb)\n>  \tupdate_stat(vb, idx++, VIRTIO_BALLOON_S_ALLOC_STALL, stall);\n>  \n>  \tupdate_stat(vb, idx++, VIRTIO_BALLOON_S_ASYNC_SCAN,\n> -\t\t    pages_to_bytes(events[PGSCAN_KSWAPD]));\n> +\t\t    pages_to_bytes(global_node_page_state(PGSCAN_KSWAPD)));\n>  \tupdate_stat(vb, idx++, VIRTIO_BALLOON_S_DIRECT_SCAN,\n> -\t\t    pages_to_bytes(events[PGSCAN_DIRECT]));\n> +\t\t    pages_to_bytes(global_node_page_state(PGSCAN_DIRECT)));\n>  \tupdate_stat(vb, idx++, VIRTIO_BALLOON_S_ASYNC_RECLAIM,\n> -\t\t    pages_to_bytes(events[PGSTEAL_KSWAPD]));\n> +\t\t    pages_to_bytes(global_node_page_state(PGSTEAL_KSWAPD)));\n>  \tupdate_stat(vb, idx++, VIRTIO_BALLOON_S_DIRECT_RECLAIM,\n> -\t\t    pages_to_bytes(events[PGSTEAL_DIRECT]));\n> +\t\t    pages_to_bytes(global_node_page_state(PGSTEAL_DIRECT)));\n>  \n>  #ifdef CONFIG_HUGETLB_PAGE\n>  \tupdate_stat(vb, idx++, VIRTIO_BALLOON_S_HTLB_PGALLOC,\n> diff --git a/include/linux/mmzone.h b/include/linux/mmzone.h\n> index 3e51190a55e4..546bca95ca40 100644\n> --- a/include/linux/mmzone.h\n> +++ b/include/linux/mmzone.h\n> @@ -255,6 +255,19 @@ enum node_stat_item {\n>  \tPGDEMOTE_DIRECT,\n>  \tPGDEMOTE_KHUGEPAGED,\n>  \tPGDEMOTE_PROACTIVE,\n> +\tPGSTEAL_KSWAPD,\n> +\tPGSTEAL_DIRECT,\n> +\tPGSTEAL_KHUGEPAGED,\n> +\tPGSTEAL_PROACTIVE,\n> +\tPGSTEAL_ANON,\n> +\tPGSTEAL_FILE,\n> +\tPGSCAN_KSWAPD,\n> +\tPGSCAN_DIRECT,\n> +\tPGSCAN_KHUGEPAGED,\n> +\tPGSCAN_PROACTIVE,\n> +\tPGSCAN_ANON,\n> +\tPGSCAN_FILE,\n> +\tPGREFILL,\n>  #ifdef CONFIG_HUGETLB_PAGE\n>  \tNR_HUGETLB,\n>  #endif\n> diff --git a/include/linux/vm_event_item.h b/include/linux/vm_event_item.h\n> index 22a139f82d75..03fe95f5a020 100644\n> --- a/include/linux/vm_event_item.h\n> +++ b/include/linux/vm_event_item.h\n> @@ -38,21 +38,8 @@ enum vm_event_item { PGPGIN, PGPGOUT, PSWPIN, PSWPOUT,\n>  \t\tPGFREE, PGACTIVATE, PGDEACTIVATE, PGLAZYFREE,\n>  \t\tPGFAULT, PGMAJFAULT,\n>  \t\tPGLAZYFREED,\n> -\t\tPGREFILL,\n>  \t\tPGREUSE,\n> -\t\tPGSTEAL_KSWAPD,\n> -\t\tPGSTEAL_DIRECT,\n> -\t\tPGSTEAL_KHUGEPAGED,\n> -\t\tPGSTEAL_PROACTIVE,\n> -\t\tPGSCAN_KSWAPD,\n> -\t\tPGSCAN_DIRECT,\n> -\t\tPGSCAN_KHUGEPAGED,\n> -\t\tPGSCAN_PROACTIVE,\n>  \t\tPGSCAN_DIRECT_THROTTLE,\n> -\t\tPGSCAN_ANON,\n> -\t\tPGSCAN_FILE,\n> -\t\tPGSTEAL_ANON,\n> -\t\tPGSTEAL_FILE,\n>  #ifdef CONFIG_NUMA\n>  \t\tPGSCAN_ZONE_RECLAIM_SUCCESS,\n>  \t\tPGSCAN_ZONE_RECLAIM_FAILED,\n> diff --git a/mm/memcontrol.c b/mm/memcontrol.c\n> index 6fb9c999347b..0d834c47706f 100644\n> --- a/mm/memcontrol.c\n> +++ b/mm/memcontrol.c\n> @@ -331,6 +331,19 @@ static const unsigned int memcg_node_stat_items[] = {\n>  \tPGDEMOTE_DIRECT,\n>  \tPGDEMOTE_KHUGEPAGED,\n>  \tPGDEMOTE_PROACTIVE,\n> +\tPGSTEAL_KSWAPD,\n> +\tPGSTEAL_DIRECT,\n> +\tPGSTEAL_KHUGEPAGED,\n> +\tPGSTEAL_PROACTIVE,\n> +\tPGSTEAL_ANON,\n> +\tPGSTEAL_FILE,\n> +\tPGSCAN_KSWAPD,\n> +\tPGSCAN_DIRECT,\n> +\tPGSCAN_KHUGEPAGED,\n> +\tPGSCAN_PROACTIVE,\n> +\tPGSCAN_ANON,\n> +\tPGSCAN_FILE,\n> +\tPGREFILL,\n>  #ifdef CONFIG_HUGETLB_PAGE\n>  \tNR_HUGETLB,\n>  #endif\n> @@ -444,17 +457,8 @@ static const unsigned int memcg_vm_event_stat[] = {\n>  #endif\n>  \tPSWPIN,\n>  \tPSWPOUT,\n> -\tPGSCAN_KSWAPD,\n> -\tPGSCAN_DIRECT,\n> -\tPGSCAN_KHUGEPAGED,\n> -\tPGSCAN_PROACTIVE,\n> -\tPGSTEAL_KSWAPD,\n> -\tPGSTEAL_DIRECT,\n> -\tPGSTEAL_KHUGEPAGED,\n> -\tPGSTEAL_PROACTIVE,\n>  \tPGFAULT,\n>  \tPGMAJFAULT,\n> -\tPGREFILL,\n>  \tPGACTIVATE,\n>  \tPGDEACTIVATE,\n>  \tPGLAZYFREE,\n> @@ -1401,6 +1405,15 @@ static const struct memory_stat memory_stats[] = {\n>  \t{ \"pgdemote_direct\",\t\tPGDEMOTE_DIRECT\t\t},\n>  \t{ \"pgdemote_khugepaged\",\tPGDEMOTE_KHUGEPAGED\t},\n>  \t{ \"pgdemote_proactive\",\t\tPGDEMOTE_PROACTIVE\t},\n> +\t{ \"pgsteal_kswapd\",\t\tPGSTEAL_KSWAPD\t\t},\n> +\t{ \"pgsteal_direct\",\t\tPGSTEAL_DIRECT\t\t},\n> +\t{ \"pgsteal_khugepaged\",\t\tPGSTEAL_KHUGEPAGED\t},\n> +\t{ \"pgsteal_proactive\",\t\tPGSTEAL_PROACTIVE\t},\n> +\t{ \"pgscan_kswapd\",\t\tPGSCAN_KSWAPD\t\t},\n> +\t{ \"pgscan_direct\",\t\tPGSCAN_DIRECT\t\t},\n> +\t{ \"pgscan_khugepaged\",\t\tPGSCAN_KHUGEPAGED\t},\n> +\t{ \"pgscan_proactive\",\t\tPGSCAN_PROACTIVE\t},\n> +\t{ \"pgrefill\",\t\t\tPGREFILL\t\t},\n>  #ifdef CONFIG_NUMA_BALANCING\n>  \t{ \"pgpromote_success\",\t\tPGPROMOTE_SUCCESS\t},\n>  #endif\n> @@ -1444,6 +1457,15 @@ static int memcg_page_state_output_unit(int item)\n>  \tcase PGDEMOTE_DIRECT:\n>  \tcase PGDEMOTE_KHUGEPAGED:\n>  \tcase PGDEMOTE_PROACTIVE:\n> +\tcase PGSTEAL_KSWAPD:\n> +\tcase PGSTEAL_DIRECT:\n> +\tcase PGSTEAL_KHUGEPAGED:\n> +\tcase PGSTEAL_PROACTIVE:\n> +\tcase PGSCAN_KSWAPD:\n> +\tcase PGSCAN_DIRECT:\n> +\tcase PGSCAN_KHUGEPAGED:\n> +\tcase PGSCAN_PROACTIVE:\n> +\tcase PGREFILL:\n>  #ifdef CONFIG_NUMA_BALANCING\n>  \tcase PGPROMOTE_SUCCESS:\n>  #endif\n> @@ -1562,15 +1584,15 @@ static void memcg_stat_format(struct mem_cgroup *memcg, struct seq_buf *s)\n>  \n>  \t/* Accumulated memory events */\n>  \tmemcg_seq_buf_print_stat(s, NULL, \"pgscan\", ' ',\n> -\t\t\t\t memcg_events(memcg, PGSCAN_KSWAPD) +\n> -\t\t\t\t memcg_events(memcg, PGSCAN_DIRECT) +\n> -\t\t\t\t memcg_events(memcg, PGSCAN_PROACTIVE) +\n> -\t\t\t\t memcg_events(memcg, PGSCAN_KHUGEPAGED));\n> +\t\t\t\t memcg_page_state(memcg, PGSCAN_KSWAPD) +\n> +\t\t\t\t memcg_page_state(memcg, PGSCAN_DIRECT) +\n> +\t\t\t\t memcg_page_state(memcg, PGSCAN_PROACTIVE) +\n> +\t\t\t\t memcg_page_state(memcg, PGSCAN_KHUGEPAGED));\n>  \tmemcg_seq_buf_print_stat(s, NULL, \"pgsteal\", ' ',\n> -\t\t\t\t memcg_events(memcg, PGSTEAL_KSWAPD) +\n> -\t\t\t\t memcg_events(memcg, PGSTEAL_DIRECT) +\n> -\t\t\t\t memcg_events(memcg, PGSTEAL_PROACTIVE) +\n> -\t\t\t\t memcg_events(memcg, PGSTEAL_KHUGEPAGED));\n> +\t\t\t\t memcg_page_state(memcg, PGSTEAL_KSWAPD) +\n> +\t\t\t\t memcg_page_state(memcg, PGSTEAL_DIRECT) +\n> +\t\t\t\t memcg_page_state(memcg, PGSTEAL_PROACTIVE) +\n> +\t\t\t\t memcg_page_state(memcg, PGSTEAL_KHUGEPAGED));\n>  \n>  \tfor (i = 0; i < ARRAY_SIZE(memcg_vm_event_stat); i++) {\n>  #ifdef CONFIG_MEMCG_V1\n> diff --git a/mm/vmscan.c b/mm/vmscan.c\n> index 5fa6e6bd6540..c3dc7c7befac 100644\n> --- a/mm/vmscan.c\n> +++ b/mm/vmscan.c\n> @@ -1984,7 +1984,7 @@ static unsigned long shrink_inactive_list(unsigned long nr_to_scan,\n>  \tunsigned long nr_taken;\n>  \tstruct reclaim_stat stat;\n>  \tbool file = is_file_lru(lru);\n> -\tenum vm_event_item item;\n> +\tenum node_stat_item item;\n>  \tstruct pglist_data *pgdat = lruvec_pgdat(lruvec);\n>  \tbool stalled = false;\n>  \n> @@ -2010,10 +2010,8 @@ static unsigned long shrink_inactive_list(unsigned long nr_to_scan,\n>  \n>  \t__mod_node_page_state(pgdat, NR_ISOLATED_ANON + file, nr_taken);\n>  \titem = PGSCAN_KSWAPD + reclaimer_offset(sc);\n> -\tif (!cgroup_reclaim(sc))\n> -\t\t__count_vm_events(item, nr_scanned);\n> -\tcount_memcg_events(lruvec_memcg(lruvec), item, nr_scanned);\n> -\t__count_vm_events(PGSCAN_ANON + file, nr_scanned);\n> +\tmod_lruvec_state(lruvec, item, nr_scanned);\n> +\tmod_lruvec_state(lruvec, PGSCAN_ANON + file, nr_scanned);\n>  \n>  \tspin_unlock_irq(&lruvec->lru_lock);\n>  \n> @@ -2030,10 +2028,8 @@ static unsigned long shrink_inactive_list(unsigned long nr_to_scan,\n>  \t\t\t\t\tstat.nr_demoted);\n>  \t__mod_node_page_state(pgdat, NR_ISOLATED_ANON + file, -nr_taken);\n>  \titem = PGSTEAL_KSWAPD + reclaimer_offset(sc);\n> -\tif (!cgroup_reclaim(sc))\n> -\t\t__count_vm_events(item, nr_reclaimed);\n> -\tcount_memcg_events(lruvec_memcg(lruvec), item, nr_reclaimed);\n> -\t__count_vm_events(PGSTEAL_ANON + file, nr_reclaimed);\n> +\tmod_lruvec_state(lruvec, item, nr_reclaimed);\n> +\tmod_lruvec_state(lruvec, PGSTEAL_ANON + file, nr_reclaimed);\n>  \n>  \tlru_note_cost_unlock_irq(lruvec, file, stat.nr_pageout,\n>  \t\t\t\t\tnr_scanned - nr_reclaimed);\n> @@ -2120,9 +2116,7 @@ static void shrink_active_list(unsigned long nr_to_scan,\n>  \n>  \t__mod_node_page_state(pgdat, NR_ISOLATED_ANON + file, nr_taken);\n>  \n> -\tif (!cgroup_reclaim(sc))\n> -\t\t__count_vm_events(PGREFILL, nr_scanned);\n> -\tcount_memcg_events(lruvec_memcg(lruvec), PGREFILL, nr_scanned);\n> +\tmod_lruvec_state(lruvec, PGREFILL, nr_scanned);\n>  \n>  \tspin_unlock_irq(&lruvec->lru_lock);\n>  \n> @@ -4537,7 +4531,7 @@ static int scan_folios(unsigned long nr_to_scan, struct lruvec *lruvec,\n>  {\n>  \tint i;\n>  \tint gen;\n> -\tenum vm_event_item item;\n> +\tenum node_stat_item item;\n>  \tint sorted = 0;\n>  \tint scanned = 0;\n>  \tint isolated = 0;\n> @@ -4545,7 +4539,6 @@ static int scan_folios(unsigned long nr_to_scan, struct lruvec *lruvec,\n>  \tint scan_batch = min(nr_to_scan, MAX_LRU_BATCH);\n>  \tint remaining = scan_batch;\n>  \tstruct lru_gen_folio *lrugen = &lruvec->lrugen;\n> -\tstruct mem_cgroup *memcg = lruvec_memcg(lruvec);\n>  \n>  \tVM_WARN_ON_ONCE(!list_empty(list));\n>  \n> @@ -4596,13 +4589,9 @@ static int scan_folios(unsigned long nr_to_scan, struct lruvec *lruvec,\n>  \t}\n>  \n>  \titem = PGSCAN_KSWAPD + reclaimer_offset(sc);\n> -\tif (!cgroup_reclaim(sc)) {\n> -\t\t__count_vm_events(item, isolated);\n> -\t\t__count_vm_events(PGREFILL, sorted);\n> -\t}\n> -\tcount_memcg_events(memcg, item, isolated);\n> -\tcount_memcg_events(memcg, PGREFILL, sorted);\n> -\t__count_vm_events(PGSCAN_ANON + type, isolated);\n> +\tmod_lruvec_state(lruvec, item, isolated);\n> +\tmod_lruvec_state(lruvec, PGREFILL, sorted);\n> +\tmod_lruvec_state(lruvec, PGSCAN_ANON + type, isolated);\n>  \ttrace_mm_vmscan_lru_isolate(sc->reclaim_idx, sc->order, scan_batch,\n>  \t\t\t\tscanned, skipped, isolated,\n>  \t\t\t\ttype ? LRU_INACTIVE_FILE : LRU_INACTIVE_ANON);\n> @@ -4705,7 +4694,7 @@ static int evict_folios(unsigned long nr_to_scan, struct lruvec *lruvec,\n>  \tLIST_HEAD(clean);\n>  \tstruct folio *folio;\n>  \tstruct folio *next;\n> -\tenum vm_event_item item;\n> +\tenum node_stat_item item;\n>  \tstruct reclaim_stat stat;\n>  \tstruct lru_gen_mm_walk *walk;\n>  \tbool skip_retry = false;\n> @@ -4769,10 +4758,8 @@ static int evict_folios(unsigned long nr_to_scan, struct lruvec *lruvec,\n>  \t\t\t\t\tstat.nr_demoted);\n>  \n>  \titem = PGSTEAL_KSWAPD + reclaimer_offset(sc);\n> -\tif (!cgroup_reclaim(sc))\n> -\t\t__count_vm_events(item, reclaimed);\n> -\tcount_memcg_events(memcg, item, reclaimed);\n> -\t__count_vm_events(PGSTEAL_ANON + type, reclaimed);\n> +\tmod_lruvec_state(lruvec, item, reclaimed);\n> +\tmod_lruvec_state(lruvec, PGSTEAL_ANON + type, reclaimed);\n>  \n>  \tspin_unlock_irq(&lruvec->lru_lock);\n>  \n> diff --git a/mm/vmstat.c b/mm/vmstat.c\n> index 86b14b0f77b5..44bbb7752f11 100644\n> --- a/mm/vmstat.c\n> +++ b/mm/vmstat.c\n> @@ -1276,6 +1276,19 @@ const char * const vmstat_text[] = {\n>  \t[I(PGDEMOTE_DIRECT)]\t\t\t= \"pgdemote_direct\",\n>  \t[I(PGDEMOTE_KHUGEPAGED)]\t\t= \"pgdemote_khugepaged\",\n>  \t[I(PGDEMOTE_PROACTIVE)]\t\t\t= \"pgdemote_proactive\",\n> +\t[I(PGSTEAL_KSWAPD)]\t\t\t= \"pgsteal_kswapd\",\n> +\t[I(PGSTEAL_DIRECT)]\t\t\t= \"pgsteal_direct\",\n> +\t[I(PGSTEAL_KHUGEPAGED)]\t\t\t= \"pgsteal_khugepaged\",\n> +\t[I(PGSTEAL_PROACTIVE)]\t\t\t= \"pgsteal_proactive\",\n> +\t[I(PGSTEAL_ANON)]\t\t\t= \"pgsteal_anon\",\n> +\t[I(PGSTEAL_FILE)]\t\t\t= \"pgsteal_file\",\n> +\t[I(PGSCAN_KSWAPD)]\t\t\t= \"pgscan_kswapd\",\n> +\t[I(PGSCAN_DIRECT)]\t\t\t= \"pgscan_direct\",\n> +\t[I(PGSCAN_KHUGEPAGED)]\t\t\t= \"pgscan_khugepaged\",\n> +\t[I(PGSCAN_PROACTIVE)]\t\t\t= \"pgscan_proactive\",\n> +\t[I(PGSCAN_ANON)]\t\t\t= \"pgscan_anon\",\n> +\t[I(PGSCAN_FILE)]\t\t\t= \"pgscan_file\",\n> +\t[I(PGREFILL)]\t\t\t\t= \"pgrefill\",\n>  #ifdef CONFIG_HUGETLB_PAGE\n>  \t[I(NR_HUGETLB)]\t\t\t\t= \"nr_hugetlb\",\n>  #endif\n> @@ -1318,21 +1331,8 @@ const char * const vmstat_text[] = {\n>  \t[I(PGMAJFAULT)]\t\t\t\t= \"pgmajfault\",\n>  \t[I(PGLAZYFREED)]\t\t\t= \"pglazyfreed\",\n>  \n> -\t[I(PGREFILL)]\t\t\t\t= \"pgrefill\",\n>  \t[I(PGREUSE)]\t\t\t\t= \"pgreuse\",\n> -\t[I(PGSTEAL_KSWAPD)]\t\t\t= \"pgsteal_kswapd\",\n> -\t[I(PGSTEAL_DIRECT)]\t\t\t= \"pgsteal_direct\",\n> -\t[I(PGSTEAL_KHUGEPAGED)]\t\t\t= \"pgsteal_khugepaged\",\n> -\t[I(PGSTEAL_PROACTIVE)]\t\t\t= \"pgsteal_proactive\",\n> -\t[I(PGSCAN_KSWAPD)]\t\t\t= \"pgscan_kswapd\",\n> -\t[I(PGSCAN_DIRECT)]\t\t\t= \"pgscan_direct\",\n> -\t[I(PGSCAN_KHUGEPAGED)]\t\t\t= \"pgscan_khugepaged\",\n> -\t[I(PGSCAN_PROACTIVE)]\t\t\t= \"pgscan_proactive\",\n>  \t[I(PGSCAN_DIRECT_THROTTLE)]\t\t= \"pgscan_direct_throttle\",\n> -\t[I(PGSCAN_ANON)]\t\t\t= \"pgscan_anon\",\n> -\t[I(PGSCAN_FILE)]\t\t\t= \"pgscan_file\",\n> -\t[I(PGSTEAL_ANON)]\t\t\t= \"pgsteal_anon\",\n> -\t[I(PGSTEAL_FILE)]\t\t\t= \"pgsteal_file\",\n>  \n>  #ifdef CONFIG_NUMA\n>  \t[I(PGSCAN_ZONE_RECLAIM_SUCCESS)]\t= \"zone_reclaim_success\",\n> -- \n> 2.47.3\n\n-- \nMichal Hocko\nSUSE Labs\n\n",
          "reply_to": "",
          "message_date": "2026-02-23",
          "message_id": ""
        }
      ],
      "analysis_source": "heuristic",
      "patch_summary": "There are situations where reclaim kicks in on a system with free memory. One possible cause is a NUMA imbalance scenario where one or more nodes are under pressure. It would help if we could easily identify such nodes.\n\nMove the pgscan, pgsteal, and pgrefill counters from vm_event_item to node_stat_item to provide per-node reclaim visibility. With these counters as node stats, the values are now displayed in the per-node section of /proc/zoneinfo, which allows for quick identification of the affected nodes.\n\n/proc/vmstat continues to report the same counters, aggregated across all nodes. But the ordering of these items within the readout changes as they move from the vm events section to the node stats section.\n\nMemcg accounting of these counters is preserved. The relocated counters remain visible in memory.stat alongside the existing aggregate pgscan and pgsteal counters."
    }
  }
}