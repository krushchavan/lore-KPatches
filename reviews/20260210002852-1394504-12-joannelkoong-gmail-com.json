{
  "thread_id": "20260210002852.1394504-12-joannelkoong@gmail.com",
  "subject": "[PATCH v1 11/11] io_uring/cmd: set selected buffer index in __io_uring_cmd_done()",
  "url": "https://lore.kernel.org/all/20260210002852.1394504-12-joannelkoong@gmail.com/",
  "dates": {
    "2026-02-18": {
      "report_file": "2026-02-18_ollama_llama3.1-8b.html",
      "developer": "Joanne Koong",
      "reviews": [
        {
          "author": "Pavel Begunkov",
          "summary": "Pavel Begunkov noted that buffer rings are not suitable for storage read/write requests because they bind to a buffer immediately, whereas other types of requests like recv allow io_uring to first poll the socket and then take a buffer from the ring. He also pointed out that someone needs to return buffers back into the private kernel ring, which is currently assumed to be handled by the fuse driver but poses an issue for normal rw requests.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Provided buffer rings are not useful for storage read/write requests\nbecause they bind to a buffer right away, that's in contrast to some\nrecv request, where io_uring will first poll the socket to confirm\nthe data is there, and only then take a buffer from the buffer ring\nand copy into it. With storage rw it makes more sense to specify\nthe buffer directly gain control over where exactly data lands\nIOW, instead of the usual \"read data into a given pointer\" request\nsemantics like what read(2) gives you, buffer rings are rather\n\"read data somewhere and return a pointer to where you placed it\".\n\nAnother problem is that someone needs to return buffers back into\nthe buffer ring, and it's a kernel private ring. For this patchset\nit's assumed the fuse driver is going to be doing that, but there\nis no one for normal rw requests.",
          "reply_to": "Christoph Hellwig",
          "message_date": "2026-02-18"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "Reviewer Pavel Begunkov suggested replacing the current buffer management system with IORING_MEM_REGION, which provides buffers/memory without extra semantics, or creating a standalone registered buffer extension that reuses regions internally.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Yes. You only need buffers, and it'll be better to base on sth that\ngives you buffers/memory without extra semantics, i.e.\nIORING_MEM_REGION. Or it can be a standalone registered buffer\nextension, likely reusing regions internally. That might even yield\na finer API.\n\n-- \nPavel Begunkov",
          "reply_to": "Christoph Hellwig",
          "message_date": "2026-02-18"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "reviewer questioned whether kernel-managed buffer rings can be used with other requests, specifically IORING_OP_RECV with IOSQE_BUFFER_SELECT",
          "sentiment": "neutral",
          "sentiment_signals": [
            "question",
            "clarification"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Oops, typo. I was asking whether the buffer rings (not buffers) are\nsupposed to be used with other requests. E.g. submitting a\nIORING_OP_RECV with IOSQE_BUFFER_SELECT set and the bgid specifying\nyour kernel-managed buffer ring.",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-18"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "The reviewer has two separate concerns: first, they suggest that buffers should not be inseparable from buffer rings in the io_uring user API, and second, they propose allowing optional user memory for buffer creation by passing an argument to the region creation function.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "no objection",
            "trivial implementation"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "There are two separate arguments. The first is about not making buffers\ninseparable from buffer rings in the io_uring user API. Whether it's\nIORING_REGISTER_MEM_REGION or something else is not that important.\nI have no objection if it's a part of fuse instead though, e.g. if\nfuse binds two objects together when you register it with fuse, or even\nif fuse create a buffer ring internally (assuming it doesn't indirectly\nleak into io_uring uapi).\n\nAnd the second was about optionally allowing user memory for buffer\ncreation as you're reusing the region abstraction. You can find pros\nand cons for both modes, and funnily enough, SQ/CQ were first kernel\nallocated and then people asked for backing it by user memory, and IIRC\nit was in the reverse order for pbuf rings.\n\nImplementing this is trivial as well, you just need to pass an argument\nwhile creating a region. All new region users use struct\nio_uring_region_desc for uapi and forward it to io_create_region()\nwithout caring if it's user or kernel allocated memory.",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-18"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "reviewer questioned the necessity of io_uring API for kernel-managed buffer rings, suggesting it could be simpler to implement in fuse or as an implementation detail within io_uring",
          "sentiment": "neutral",
          "sentiment_signals": [
            "questioning necessity",
            "simplification suggestion"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "The stress is on why it's an _io_uring_ API. It doesn't matter to me\nwhether it's a separate opcode or not. Currently, buffer rings don't give\nyou anything that can't be pure fuse, and it might be simpler to have\nit implemented in fuse than binding to some io_uring object. Or it could\ncreate buffer rings internally to reuse code but it doesn't become an\nio_uring uapi but rather implementation detail. And that predicates on\nwhether km rings are intended to be used with other / non-fuse requests.",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-18"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "The reviewer believes the current implementation is too specific to fuse and suggests making km rings reusable by allowing registration of pure regions without buffer notion, which would allow fuse to chunk it later.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes",
            "suggested alternative approach"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "I believe the source of disagreement is that you're thinking\nabout how it's going to look like for fuse specifically, and I\nbelieve you that it'll be nicer for the fuse use case. However,\non the other hand it's an io_uring uapi, and if it is an io_uring\nuapi, we need reusable blocks that are not specific to particular\nusers.\n\nIf it km rings has to stay an io_uring uapi, I guess a middle\nground would be to allow registering km rings together with memory,\nbut make it a pure region without a notion of a buffer, and let\nfuse to chunk it. Later, we can make payload memory allocation\noptional.",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-18"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "Reviewer noted that the patch introduces a non-generic io_uring API by assuming fuse-specific behavior, and requested that the code be revised to avoid these assumptions.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "non-generic assumption",
            "fuse uapi"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Right, intentionally so, because otherwise it's a fuse uapi that\npretends to be a generic io_uring uapi but it's not because of\nall assumptions in different places.",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-18"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "The reviewer noted that the current implementation of __io_uring_cmd_done() only sets the buffer ring depth but does not account for the actual memory allocated by the user space, which could lead to inconsistencies if the buffer ring size is different from the allocated memory. The reviewer suggested considering scenarios where more memory might be added at runtime or when buffers are recycled.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "inconsistency",
            "potential issue"
          ],
          "has_inline_review": true,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Not really, it tells the buffer ring depth but says nothing about\nhow much memory user space allocated and how it's pushed. It's a\nreasonable default but they could be different. For example, if you\nexpect adding more memory at runtime, you might create the buffer\nring a bit larger. Or when server processing takes a while and you\ncan't recycle until it finishes, you might have more buffers than\nyou need ring entries. Or you might might decide to split buffers\nand as you mentioned incremental consumption, which is an entire\nseparate topic because it doesn't do de-fragmentation and you'd\nneed to have it in fuse, just like user space does with pbufs.",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-18"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "reviewer suggested rethinking io_uring uapi by having it request a large chunk of memory from fuse, which would then be divided into buffer rings",
          "sentiment": "neutral",
          "sentiment_signals": [
            "no clear technical objection or suggestion"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "My entire point is that we're making lots of assumptions for io_uring\nuapi, and if it's moved to fuse because it knows better what it\nneeds, it should be a win.\n\nIOW, it sounds better if instead of passing the number of buffers to\nio_uring, you just ask it to create a large chunk of memory, and then\nfuse chunks it up and puts into the ring.",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-18"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "reviewer agreed with the patch but noted that adding memory would require a new mechanism, not necessarily tied to IORING_REGISTER_MEM_REGION",
          "sentiment": "neutral",
          "sentiment_signals": [
            "agreement",
            "additional consideration"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "I agree, and you'd need something new in either case to add more\nmemory, and it doesn't need to be IORING_REGISTER_MEM_REGION\nspecifically.",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-18"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "Reviewer noted that unregistering a kernel-managed buffer ring does not guarantee there are no inflight requests using its buffers, and suggested synchronizing with all other io_uring requests to ensure proper cleanup.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "potential data corruption",
            "incomplete cleanup"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Unregistering a buffer ring doesn't guarantee that there are no\ninflight requests that are still using buffers that came out of\nthe buffer ring. The fuse driver can wait/terminate its requests\nbefore unregisteration, but allow userspace issued IORING_OP_RECV\nto use this km buffer ring, and you'll need to somehow synchronise\nwith all other io_uring requests.\n\n-- \nPavel Begunkov",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-18"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "Author acknowledged that a fix is needed for the selected buffer index in __io_uring_cmd_done() and promised to modify it in v2.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "acknowledged a fix is needed",
            "promised to modify"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Sorry, I submitted v2 last night thinking the conversation on this\nthread had died. After reading through your reply, I'll modify v2.",
          "reply_to": "Pavel Begunkov",
          "message_date": "2026-02-18"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "Author acknowledged that kernel-managed buffer rings are intended for use with other io-uring requests, confirming the reviewer's understanding of the patch's purpose.",
          "sentiment": "positive",
          "sentiment_signals": [
            "acknowledged",
            "confirmed"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Yes the buffer rings are intended to be used with other io-uring\nrequests. The ideal scenario is that the user can then do the\nequivalent of IORING_OP_READ/WRITE_FIXED operations on the\nkernel-managed buffers and avoid the per-i/o page pinning overhead\ncosts.",
          "reply_to": "Pavel Begunkov",
          "message_date": "2026-02-18"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "Author Joanne Koong addressed Pavel Begunkov's feedback about the design of kernel-managed buffer rings, agreeing that having buffers owned by the ring and tied to its lifetime is more generically useful, but also acknowledging potential future user needs for complete control over backing buffers. She proposed a revised approach where io-uring normal requests use registered memory regions and guarantee their stability.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "acknowledged potential design flaw",
            "proposed alternative solution"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "I agree 100%. The api we add should be what's best for io-uring, not fuse.\n\nFor the majority of use cases, it seemed to me that having the buffers\nseparated from the buffer rings didn't yield perceptible benefits but\nadded complexity and more restrictions like having to statically know\nup front how big the mem region needs to be across the lifetime of the\nio-uring for anything the io-uring might use the mem region for. It\nseems more generically useful as a concept to have the buffers owned\nby the ring and tied to the lifetime of the ring. I like how with this\ndesign everything is self-contained and multiple subsystems can use it\nwithout having to reimplement functionality locally in the subsystem.\nOn the other hand, I see your point about how it might be something\nusers want in the future if they want complete control over which\nparts of the mem region get used as the backing buffers to do stuff\nlike PMD optimizations.\n\nI think this is a matter of opinion/preference and I think in general\nfor anything io-uring related, yours should take precedence.\n\nWith it going through a mem region, I don't think it should even go\nthrough the \"pbuf ring\" interface then if it's not going to specify\nthe number of entries and buffer sizes upfront, if support is added\nfor io-uring normal requests (eg IORING_OP_READ/WRITE) to use the\nbacking pages from a memory region and if we're able to guarantee that\nthe registered memory region will never be able to be unregistered by\nthe user. I think if we repurpose the\n\nunion {\n  __u64 addr; /* pointer to buffer or iovecs */\n  __u64 splice_off_in;\n};\n\nfields in the struct io_uring_sqe to\n\nunion {\n  __u64 addr; /* pointer to buffer or iovecs */\n  __u64 splice_off_in;\n  __u64 offset; /* offset into registered mem region */\n};\n\nand add some IOSQE_ flag to indicate it should find the pages from the\nregistered mem region, then that should work for normal requests.\nWhere on the kernel side, it looks up the associated pages stored in\nthe io_mapped_region's pages array for the offset passed in.\n\nRight now there's only a uapi to register a memory region and none to\nunregister one. Is it guaranteed that io-uring will never add\nsomething in the future that will let userspace unregister the memory\nregion or at least unregister it while it's being used (eg if we add\nfuture refcounting to it to track active uses of it)?\n\nIf so, then end-to-end, with it going through the mem region, it would\nbe something like:\n* user creates a mem region for the io-uring\n* user mmaps the mem region\n* user passes in offset into region, length of each buffer, and number\nof entries in the ring to the subsystem\n* subsystem creates a locally managed bufring and adds buffers to that\nring from the mem region\n* on the cqe side, it sends the buffer id of the registered mem region\nthrough the same \"IORING_CQE_F_BUFFER |  (buf_id <<\nIORING_CQE_BUFFER_SHIFT)\" mechanism\n\nDoes this design match what you had in mind / prefer?\n\nI think the above works for Christoph's use case too (as his and my\nuse case are the same) but if not, please let me know.\n\nThanks,\nJoanne",
          "reply_to": "Pavel Begunkov",
          "message_date": "2026-02-18"
        }
      ],
      "analysis_source": "llm-per-reviewer",
      "patch_summary": "This patch sets the selected buffer index in __io_uring_cmd_done(), a function responsible for completing io_uring commands. The change is part of a larger series that introduces kernel-managed buffer rings, where the kernel allocates and manages buffers on behalf of applications. This allows for more efficient use of system resources and simplifies buffer management for applications using io_uring. The patch builds upon previous changes in the series, including support for kernel-managed buffer rings and recycling of buffers. By setting the selected buffer index, this patch enables proper completion of commands that involve buffer selection."
    },
    "2026-02-20": {
      "report_file": "2026-02-20_ollama_llama3.1-8b.html",
      "developer": "Joanne Koong",
      "reviews": [
        {
          "author": "Pavel Begunkov",
          "summary": "Pavel Begunkov questioned whether a server or user space program can issue I/O requests that consume buffers/entries from kernel-managed buffer rings without involving fuse kernel code, and asked for clarification on the expected use case.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested clarification",
            "seeking understanding"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "You mention OP_READ_FIXED and below agreed not exposing km rings\nan io_uring uapi, which makes me believe we're still talking about\ndifferent things.\n\nCorrect me if I'm wrong. Currently, only fuse cmds use the buffer\nring itself, I'm not talking about buffer, i.e. fuse cmds consume\nentries from the ring (!!! that's the part I'm interested in), then\nprocess them and tell the server \"this offset in the region has user\ndata to process or should be populated with data\".\n\nNaturally, the server should be able to use the buffers to issue\nsome I/O and process it in other ways, whether it's a normal\nOP_READ to which you pass the user space address (you can since\nit's mmap()'ed by the server) or something else is important but\na separate question than the one I'm trying to understand.\n\nSo I'm asking whether you expect that a server or other user space\nprogram should be able to issue a READ_OP_RECV, READ_OP_READ or any\nother similar request, which would consume buffers/entries from the\nkm ring without any fuse kernel code involved? Do you have some\nuse case for that in mind?\n\nUnderstanding that is the key in deciding whether km rings should\nbe exposed as io_uring uapi or not, regardless of where buffers\nto populate the ring come from.\n\n...",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-20"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "Pavel Begunkov noted that the new mechanism for setting the selected buffer index in __io_uring_cmd_done() can be replaced by reusing registered buffers, which are already optimized for I/O and similar to zero-copy internally registered buffers. He suggested creating a registered buffer out of the mmap'ed region pointer using io_uring_register_buffers(), and provided pseudo code for this approach.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes",
            "alternative solution"
          ],
          "has_inline_review": true,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "So you already can do all that using the mmap()'ed region user\npointer, and you just want it to be more efficient, right?\nFor that let's just reuse registered buffers, we don't need a\nnew mechanism that needs to be propagated to all request types.\nAnd registered buffer are already optimised for I/O in a bunch\nof ways. And as a bonus, it'll be similar to the zero-copy\ninternally registered buffers if you still plan to add them.\n\nThe simplest way to do that is to create a registered buffer out\nof the mmap'ed region pointer. Pseudo code:\n\n// mmap'ed if it's kernel allocated.\n{region_ptr, region_size} = create_region();\n\nstruct iovec iov;\niov.iov_base = region_ptr;\niov.iov_len = region_size;\nio_uring_register_buffers(ring, &iov, 1);\n\n// later instead of this:\nptr = region_ptr + off;\nio_uring_prep_read(sqe, fd, ptr, ...);\n\n// you use registered buffers as usual:\nio_uring_prep_read_fixed(sqe, fd, off, regbuf_idx, ...);\n\n\nIIRC the registration would fail because it doesn't allow file\nbacked pages, but it should be fine if we know it's io_uring\nregion memory, so that would need to be patched.\n\nThere might be a bunch of other ways you can do that like\ncreate a kernel allocated registered buffer like what Cristoph\nwants, and then register it as a region. Or allow creating\nregistered buffers out of a region. etc.\n\nI wanted to unify registered buffers and regions internally\nat some point, but then drifted away from active io_uring core\ninfrastructure development, so I guess that could've been useful.",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-20"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "reviewer noted that kernel-managed buffer rings would hold page references or need to pin regions, potentially causing issues if registered buffers are used instead",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "potential issue",
            "alternative approach"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Let's talk about it when it's needed or something changes, but if\nyou do registered buffers instead as per above, they'll be holding\npage references and or have to pin the region in some other way.",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-20"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "reviewer suggested adding a liburing helper to handle mmap'ing for the fuse server, eliminating the need for it to directly manage buffers",
          "sentiment": "neutral",
          "sentiment_signals": [
            "suggestion",
            "alternative solution"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "FWIW, we should just add a liburing helper, so that fuse server\ndoesn't need to deal with mmap'ing.",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-20"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "reviewer expressed conditional approval, requesting confirmation that the patch allows for desired fast path optimizations",
          "sentiment": "neutral",
          "sentiment_signals": [
            "conditional approval",
            "request for confirmation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "That's sounds clean to me _if_ it allows you to achieve all\n(fast path) optimisations you want to have. I hope it does?\n\n-- \nPavel Begunkov",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-20"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "Author acknowledged a potential future optimization for fuse servers, but noted that kernel-managed buffer rings are not exclusive to fuse and could be useful in other scenarios.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "acknowledged a potential future optimization",
            "noted broader applicability"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Thanks for clarifying your question. Yes, this would be a useful\noptimization in the future for fuse servers with certain workload\ncharacteristics (eg network-backed servers with high concurrency and\nunpredictable latencies). I don't think the concept of kmbufrings is\nexclusively fuse-specific though (for example, Christoph's use case\nbeing a recent instance); I think other subsystems/users that'll use\nkmbuf rings would also generically find it useful to have the option\nof READ_OP_RECV/READ_OP_READ operating directly on the ring.",
          "reply_to": "Pavel Begunkov",
          "message_date": "2026-02-20"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "Author expressed concerns about added complexity in the interface, feeling that it muddies concepts and introduces unnecessary relationships between them. They questioned the need for kernel-managed buffers when memory regions could be used instead, suggesting a more straightforward approach.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "questioning the design",
            "expressing concerns about added complexity"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "I feel like this design makes the interface more convoluted and now\nmuddies different concepts together by adding new complexity /\nrelationships between them whereas they were otherwise cleanly\nisolated. Maybe I'm just not seeing/understanding the overarching\nvision for why conceptually it makes sense for them to be tied\ntogether besides as a mechanism to tell io-uring requests where to\ncopy from by reusing what exists for fixed buffer ids. There's more\ncomplexity now on the kernel side (eg having to detect if the buffer\npassed in is kernel-allocated to know whether to pin the pages /\ncharge it against the user's RLIMIT_MEMLOCK limit) but I'm not\nunderstanding what we gain from it. I got the sense from your previous\ncomments that memory regions are the de facto way to go and should be\ndecoupled from other structures, so if that's the case, why doesn't it\nmake sense for io-uring to add native support for using memory regions\nfor io-uring requests? I feel like from the userspace side it makes\nthings more confusing with this extra layer of indirection that now\nhas to go through a fixed buffer.",
          "reply_to": "Pavel Begunkov",
          "message_date": "2026-02-20"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "The author is addressing Pavel Begunkov's concern that the caller cannot guarantee the memory region will be registered as a fixed buffer, and she explains that this would introduce significant overhead for every I/O operation. She suggests adding pinning to a registered memory region as an alternative solution.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "acknowledges fix is needed",
            "proposes alternative solution"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "I don't think we can guarantee that the caller will register the\nmemory region as a fixed buffer (eg if it doesn't need/want to use the\nbuffer for normal io-uring requests). On the kernel side, the internal\nbuffer entry uses the kaddr of the registered memory region buffer for\nany memcpys. If it's not guaranteed that registered memory regions\npersist for the lifetime of the ring, there'll have to be extra\noverhead for every I/O (eg grab the io-uring lock, checking if the mem\nregion is still registered, grab a refcount to that mem region, unlock\nthe ring, do the memcpy to the kaddr, then grab the io-uring lock\nagain, decrement the refcount, and unlock). Or I guess we could add\npinning to a registered memory region.\n\nThanks,\nJoanne",
          "reply_to": "Pavel Begunkov",
          "message_date": "2026-02-20"
        }
      ],
      "analysis_source": "llm-per-reviewer",
      "patch_summary": "This patch sets the selected buffer index in __io_uring_cmd_done(), a function responsible for completing io_uring commands. The change is part of a larger series that introduces kernel-managed buffer rings, where the kernel allocates and manages buffers on behalf of applications. This allows for more efficient use of system resources and simplifies buffer management for applications using io_uring. The patch builds upon previous changes in the series, including support for kernel-managed buffer rings and recycling of buffers. By setting the selected buffer index, this patch enables proper completion of commands that involve buffer selection."
    },
    "2026-02-09": {
      "report_file": "2026-02-18_ollama_llama3.1-8b.html",
      "developer": "Joanne Koong",
      "reviews": [
        {
          "author": "Joanne Koong (author)",
          "summary": "The author is addressing a concern about the refactoring of io_register_pbuf_ring() into generic helpers, specifically the logic for handling user arguments and buffer registration parameters. The author has provided three new helper functions: io_copy_and_validate_buf_reg(), io_alloc_new_buffer_list(), and io_setup_pbuf_ring(). These changes are preparatory for upcoming kernel-managed buffer ring support.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "new helper functions",
            "preparatory change"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Refactor the logic in io_register_pbuf_ring() into generic helpers:\n- io_copy_and_validate_buf_reg(): Copy out user arg and validate user\n  arg and buffer registration parameters\n- io_alloc_new_buffer_list(): Allocate and initialize a new buffer\n  list for the given buffer group ID\n- io_setup_pbuf_ring(): Sets up the physical buffer ring region and\n  handles memory mapping for provided buffer rings\n\nThis is a preparatory change for upcoming kernel-managed buffer ring\nsupport which will need to reuse some of these helpers.\n\nSigned-off-by: Joanne Koong <joannelkoong@gmail.com>\n---\n io_uring/kbuf.c | 129 +++++++++++++++++++++++++++++++-----------------\n 1 file changed, 85 insertions(+), 44 deletions(-)\n\ndiff --git a/io_uring/kbuf.c b/io_uring/kbuf.c\nindex 67d4fe576473..850b836f32ee 100644\n--- a/io_uring/kbuf.c\n+++ b/io_uring/kbuf.c\n@@ -596,55 +596,73 @@ int io_manage_buffers_legacy(struct io_kiocb *req, unsigned int issue_flags)\n \treturn IOU_COMPLETE;\n }\n \n-int io_register_pbuf_ring(struct io_ring_ctx *ctx, void __user *arg)\n+static int io_copy_and_validate_buf_reg(const void __user *arg,\n+\t\t\t\t\tstruct io_uring_buf_reg *reg,\n+\t\t\t\t\tunsigned int permitted_flags)\n {\n-\tstruct io_uring_buf_reg reg;\n-\tstruct io_buffer_list *bl;\n-\tstruct io_uring_region_desc rd;\n-\tstruct io_uring_buf_ring *br;\n-\tunsigned long mmap_offset;\n-\tunsigned long ring_size;\n-\tint ret;\n-\n-\tlockdep_assert_held(&ctx->uring_lock);\n-\n-\tif (copy_from_user(&reg, arg, sizeof(reg)))\n+\tif (copy_from_user(reg, arg, sizeof(*reg)))\n \t\treturn -EFAULT;\n-\tif (!mem_is_zero(reg.resv, sizeof(reg.resv)))\n+\n+\tif (!mem_is_zero(reg->resv, sizeof(reg->resv)))\n \t\treturn -EINVAL;\n-\tif (reg.flags & ~(IOU_PBUF_RING_MMAP | IOU_PBUF_RING_INC))\n+\tif (reg->flags & ~permitted_flags)\n \t\treturn -EINVAL;\n-\tif (!is_power_of_2(reg.ring_entries))\n+\tif (!is_power_of_2(reg->ring_entries))\n \t\treturn -EINVAL;\n \t/* cannot disambiguate full vs empty due to head/tail size */\n-\tif (reg.ring_entries >= 65536)\n+\tif (reg->ring_entries >= 65536)\n \t\treturn -EINVAL;\n+\treturn 0;\n+}\n \n-\tbl = io_buffer_get_list(ctx, reg.bgid);\n-\tif (bl) {\n+static struct io_buffer_list *\n+io_alloc_new_buffer_list(struct io_ring_ctx *ctx,\n+\t\t\t const struct io_uring_buf_reg *reg)\n+{\n+\tstruct io_buffer_list *list;\n+\n+\tlist = io_buffer_get_list(ctx, reg->bgid);\n+\tif (list) {\n \t\t/* if mapped buffer ring OR classic exists, don't allow */\n-\t\tif (bl->flags & IOBL_BUF_RING || !list_empty(&bl->buf_list))\n-\t\t\treturn -EEXIST;\n-\t\tio_destroy_bl(ctx, bl);\n+\t\tif (list->flags & IOBL_BUF_RING || !list_empty(&list->buf_list))\n+\t\t\treturn ERR_PTR(-EEXIST);\n+\t\tio_destroy_bl(ctx, list);\n \t}\n \n-\tbl = kzalloc(sizeof(*bl), GFP_KERNEL_ACCOUNT);\n-\tif (!bl)\n-\t\treturn -ENOMEM;\n+\tlist = kzalloc(sizeof(*list), GFP_KERNEL_ACCOUNT);\n+\tif (!list)\n+\t\treturn ERR_PTR(-ENOMEM);\n+\n+\tlist->nr_entries = reg->ring_entries;\n+\tlist->mask = reg->ring_entries - 1;\n+\tlist->flags = IOBL_BUF_RING;\n+\n+\treturn list;\n+}\n+\n+static int io_setup_pbuf_ring(struct io_ring_ctx *ctx,\n+\t\t\t      const struct io_uring_buf_reg *reg,\n+\t\t\t      struct io_buffer_list *bl)\n+{\n+\tstruct io_uring_region_desc rd;\n+\tunsigned long mmap_offset;\n+\tunsigned long ring_size;\n+\tint ret;\n \n-\tmmap_offset = (unsigned long)reg.bgid << IORING_OFF_PBUF_SHIFT;\n-\tring_size = flex_array_size(br, bufs, reg.ring_entries);\n+\tmmap_offset = (unsigned long)reg->bgid << IORING_OFF_PBUF_SHIFT;\n+\tring_size = flex_array_size(bl->buf_ring, bufs, reg->ring_entries);\n \n \tmemset(&rd, 0, sizeof(rd));\n \trd.size = PAGE_ALIGN(ring_size);\n-\tif (!(reg.flags & IOU_PBUF_RING_MMAP)) {\n-\t\trd.user_addr = reg.ring_addr;\n+\tif (!(reg->flags & IOU_PBUF_RING_MMAP)) {\n+\t\trd.user_addr = reg->ring_addr;\n \t\trd.flags |= IORING_MEM_REGION_TYPE_USER;\n \t}\n+\n \tret = io_create_region(ctx, &bl->region, &rd, mmap_offset);\n \tif (ret)\n-\t\tgoto fail;\n-\tbr = io_region_get_ptr(&bl->region);\n+\t\treturn ret;\n+\tbl->buf_ring = io_region_get_ptr(&bl->region);\n \n #ifdef SHM_COLOUR\n \t/*\n@@ -656,25 +674,48 @@ int io_register_pbuf_ring(struct io_ring_ctx *ctx, void __user *arg)\n \t * should use IOU_PBUF_RING_MMAP instead, and liburing will handle\n \t * this transparently.\n \t */\n-\tif (!(reg.flags & IOU_PBUF_RING_MMAP) &&\n-\t    ((reg.ring_addr | (unsigned long)br) & (SHM_COLOUR - 1))) {\n-\t\tret = -EINVAL;\n-\t\tgoto fail;\n+\tif (!(reg->flags & IOU_PBUF_RING_MMAP) &&\n+\t    ((reg->ring_addr | (unsigned long)bl->buf_ring) &\n+\t     (SHM_COLOUR - 1))) {\n+\t\tio_free_region(ctx->user, &bl->region);\n+\t\treturn -EINVAL;\n \t}\n #endif\n \n-\tbl->nr_entries = reg.ring_entries;\n-\tbl->mask = reg.ring_entries - 1;\n-\tbl->flags |= IOBL_BUF_RING;\n-\tbl->buf_ring = br;\n-\tif (reg.flags & IOU_PBUF_RING_INC)\n+\tif (reg->flags & IOU_PBUF_RING_INC)\n \t\tbl->flags |= IOBL_INC;\n+\n+\treturn 0;\n+}\n+\n+int io_register_pbuf_ring(struct io_ring_ctx *ctx, void __user *arg)\n+{\n+\tunsigned int permitted_flags;\n+\tstruct io_uring_buf_reg reg;\n+\tstruct io_buffer_list *bl;\n+\tint ret;\n+\n+\tlockdep_assert_held(&ctx->uring_lock);\n+\n+\tpermitted_flags = IOU_PBUF_RING_MMAP | IOU_PBUF_RING_INC;\n+\tret = io_copy_and_validate_buf_reg(arg, &reg, permitted_flags);\n+\tif (ret)\n+\t\treturn ret;\n+\n+\tbl = io_alloc_new_buffer_list(ctx, &reg);\n+\tif (IS_ERR(bl))\n+\t\treturn PTR_ERR(bl);\n+\n+\tret = io_setup_pbuf_ring(ctx, &reg, bl);\n+\tif (ret) {\n+\t\tkfree(bl);\n+\t\treturn ret;\n+\t}\n+\n \tret = io_buffer_add_list(ctx, bl, reg.bgid);\n-\tif (!ret)\n-\t\treturn 0;\n-fail:\n-\tio_free_region(ctx->user, &bl->region);\n-\tkfree(bl);\n+\tif (ret)\n+\t\tio_put_bl(ctx, bl);\n+\n \treturn ret;\n }\n \n-- \n2.47.3",
          "reply_to": "",
          "message_date": "2026-02-09"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "The author addressed a concern about the naming consistency of io_unregister_pbuf_ring() and its upcoming use for both provided buffer rings and kernel-managed buffer rings. The author agreed to rename it to io_unregister_buf_ring() as a preparatory change for upcoming kernel-managed buffer ring support.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "preparatory change",
            "upcoming support"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Use the more generic name io_unregister_buf_ring() as this function will\nbe used for unregistering both provided buffer rings and kernel-managed\nbuffer rings.\n\nThis is a preparatory change for upcoming kernel-managed buffer ring\nsupport.\n\nSigned-off-by: Joanne Koong <joannelkoong@gmail.com>\n---\n io_uring/kbuf.c     | 2 +-\n io_uring/kbuf.h     | 2 +-\n io_uring/register.c | 2 +-\n 3 files changed, 3 insertions(+), 3 deletions(-)\n\ndiff --git a/io_uring/kbuf.c b/io_uring/kbuf.c\nindex 850b836f32ee..aa9b70b72db4 100644\n--- a/io_uring/kbuf.c\n+++ b/io_uring/kbuf.c\n@@ -719,7 +719,7 @@ int io_register_pbuf_ring(struct io_ring_ctx *ctx, void __user *arg)\n \treturn ret;\n }\n \n-int io_unregister_pbuf_ring(struct io_ring_ctx *ctx, void __user *arg)\n+int io_unregister_buf_ring(struct io_ring_ctx *ctx, void __user *arg)\n {\n \tstruct io_uring_buf_reg reg;\n \tstruct io_buffer_list *bl;\ndiff --git a/io_uring/kbuf.h b/io_uring/kbuf.h\nindex bf15e26520d3..40b44f4fdb15 100644\n--- a/io_uring/kbuf.h\n+++ b/io_uring/kbuf.h\n@@ -74,7 +74,7 @@ int io_provide_buffers_prep(struct io_kiocb *req, const struct io_uring_sqe *sqe\n int io_manage_buffers_legacy(struct io_kiocb *req, unsigned int issue_flags);\n \n int io_register_pbuf_ring(struct io_ring_ctx *ctx, void __user *arg);\n-int io_unregister_pbuf_ring(struct io_ring_ctx *ctx, void __user *arg);\n+int io_unregister_buf_ring(struct io_ring_ctx *ctx, void __user *arg);\n int io_register_pbuf_status(struct io_ring_ctx *ctx, void __user *arg);\n \n bool io_kbuf_recycle_legacy(struct io_kiocb *req, unsigned issue_flags);\ndiff --git a/io_uring/register.c b/io_uring/register.c\nindex 594b1f2ce875..0882cb34f851 100644\n--- a/io_uring/register.c\n+++ b/io_uring/register.c\n@@ -841,7 +841,7 @@ static int __io_uring_register(struct io_ring_ctx *ctx, unsigned opcode,\n \t\tret = -EINVAL;\n \t\tif (!arg || nr_args != 1)\n \t\t\tbreak;\n-\t\tret = io_unregister_pbuf_ring(ctx, arg);\n+\t\tret = io_unregister_buf_ring(ctx, arg);\n \t\tbreak;\n \tcase IORING_REGISTER_SYNC_CANCEL:\n \t\tret = -EINVAL;\n-- \n2.47.3",
          "reply_to": "",
          "message_date": "2026-02-09"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "Author addressed a concern about the implementation of kernel-managed buffer rings, explaining that they follow the same pattern as pbuf ring registration and reusing validation and buffer list allocation helpers.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Add support for kernel-managed buffer rings (kmbuf rings), which allow\nthe kernel to allocate and manage the backing buffers for a buffer\nring, rather than requiring the application to provide and manage them.\n\nThis introduces two new registration opcodes:\n- IORING_REGISTER_KMBUF_RING: Register a kernel-managed buffer ring\n- IORING_UNREGISTER_KMBUF_RING: Unregister a kernel-managed buffer ring\n\nThe existing io_uring_buf_reg structure is extended with a union to\nsupport both application-provided buffer rings (pbuf) and kernel-managed\nbuffer rings (kmbuf):\n- For pbuf rings: ring_addr specifies the user-provided ring address\n- For kmbuf rings: buf_size specifies the size of each buffer. buf_size\n  must be non-zero and page-aligned.\n\nThe implementation follows the same pattern as pbuf ring registration,\nreusing the validation and buffer list allocation helpers introduced in\nearlier refactoring. The IOBL_KERNEL_MANAGED flag marks buffer lists as\nkernel-managed for appropriate handling in the I/O path.\n\nSigned-off-by: Joanne Koong <joannelkoong@gmail.com>\n---\n include/uapi/linux/io_uring.h |  15 ++++-\n io_uring/kbuf.c               |  81 ++++++++++++++++++++++++-\n io_uring/kbuf.h               |   7 ++-\n io_uring/memmap.c             | 111 ++++++++++++++++++++++++++++++++++\n io_uring/memmap.h             |   4 ++\n io_uring/register.c           |   7 +++\n 6 files changed, 219 insertions(+), 6 deletions(-)\n\ndiff --git a/include/uapi/linux/io_uring.h b/include/uapi/linux/io_uring.h\nindex fc473af6feb4..a0889c1744bd 100644\n--- a/include/uapi/linux/io_uring.h\n+++ b/include/uapi/linux/io_uring.h\n@@ -715,6 +715,10 @@ enum io_uring_register_op {\n \t/* register bpf filtering programs */\n \tIORING_REGISTER_BPF_FILTER\t\t= 37,\n \n+\t/* register/unregister kernel-managed ring buffer group */\n+\tIORING_REGISTER_KMBUF_RING\t\t= 38,\n+\tIORING_UNREGISTER_KMBUF_RING\t\t= 39,\n+\n \t/* this goes last */\n \tIORING_REGISTER_LAST,\n \n@@ -891,9 +895,16 @@ enum io_uring_register_pbuf_ring_flags {\n \tIOU_PBUF_RING_INC\t= 2,\n };\n \n-/* argument for IORING_(UN)REGISTER_PBUF_RING */\n+/* argument for IORING_(UN)REGISTER_PBUF_RING and\n+ * IORING_(UN)REGISTER_KMBUF_RING\n+ */\n struct io_uring_buf_reg {\n-\t__u64\tring_addr;\n+\tunion {\n+\t\t/* used for pbuf rings */\n+\t\t__u64\tring_addr;\n+\t\t/* used for kmbuf rings */\n+\t\t__u32   buf_size;\n+\t};\n \t__u32\tring_entries;\n \t__u16\tbgid;\n \t__u16\tflags;\ndiff --git a/io_uring/kbuf.c b/io_uring/kbuf.c\nindex aa9b70b72db4..9bc36451d083 100644\n--- a/io_uring/kbuf.c\n+++ b/io_uring/kbuf.c\n@@ -427,10 +427,13 @@ static int io_remove_buffers_legacy(struct io_ring_ctx *ctx,\n \n static void io_put_bl(struct io_ring_ctx *ctx, struct io_buffer_list *bl)\n {\n-\tif (bl->flags & IOBL_BUF_RING)\n+\tif (bl->flags & IOBL_BUF_RING) {\n \t\tio_free_region(ctx->user, &bl->region);\n-\telse\n+\t\tif (bl->flags & IOBL_KERNEL_MANAGED)\n+\t\t\tkfree(bl->buf_ring);\n+\t} else {\n \t\tio_remove_buffers_legacy(ctx, bl, -1U);\n+\t}\n \n \tkfree(bl);\n }\n@@ -779,3 +782,77 @@ struct io_mapped_region *io_pbuf_get_region(struct io_ring_ctx *ctx,\n \t\treturn NULL;\n \treturn &bl->region;\n }\n+\n+static int io_setup_kmbuf_ring(struct io_ring_ctx *ctx,\n+\t\t\t       struct io_buffer_list *bl,\n+\t\t\t       struct io_uring_buf_reg *reg)\n+{\n+\tstruct io_uring_buf_ring *ring;\n+\tunsigned long ring_size;\n+\tvoid *buf_region;\n+\tunsigned int i;\n+\tint ret;\n+\n+\t/* allocate pages for the ring structure */\n+\tring_size = flex_array_size(ring, bufs, bl->nr_entries);\n+\tring = kzalloc(ring_size, GFP_KERNEL_ACCOUNT);\n+\tif (!ring)\n+\t\treturn -ENOMEM;\n+\n+\tret = io_create_region_multi_buf(ctx, &bl->region, bl->nr_entries,\n+\t\t\t\t\t reg->buf_size);\n+\tif (ret) {\n+\t\tkfree(ring);\n+\t\treturn ret;\n+\t}\n+\n+\t/* initialize ring buf entries to point to the buffers */\n+\tbuf_region = bl->region.ptr;\n+\tfor (i = 0; i < bl->nr_entries; i++) {\n+\t\tstruct io_uring_buf *buf = &ring->bufs[i];\n+\n+\t\tbuf->addr = (u64)(uintptr_t)buf_region;\n+\t\tbuf->len = reg->buf_size;\n+\t\tbuf->bid = i;\n+\n+\t\tbuf_region += reg->buf_size;\n+\t}\n+\tring->tail = bl->nr_entries;\n+\n+\tbl->buf_ring = ring;\n+\tbl->flags |= IOBL_KERNEL_MANAGED;\n+\n+\treturn 0;\n+}\n+\n+int io_register_kmbuf_ring(struct io_ring_ctx *ctx, void __user *arg)\n+{\n+\tstruct io_uring_buf_reg reg;\n+\tstruct io_buffer_list *bl;\n+\tint ret;\n+\n+\tlockdep_assert_held(&ctx->uring_lock);\n+\n+\tret = io_copy_and_validate_buf_reg(arg, &reg, 0);\n+\tif (ret)\n+\t\treturn ret;\n+\n+\tif (!reg.buf_size || !PAGE_ALIGNED(reg.buf_size))\n+\t\treturn -EINVAL;\n+\n+\tbl = io_alloc_new_buffer_list(ctx, &reg);\n+\tif (IS_ERR(bl))\n+\t\treturn PTR_ERR(bl);\n+\n+\tret = io_setup_kmbuf_ring(ctx, bl, &reg);\n+\tif (ret) {\n+\t\tkfree(bl);\n+\t\treturn ret;\n+\t}\n+\n+\tret = io_buffer_add_list(ctx, bl, reg.bgid);\n+\tif (ret)\n+\t\tio_put_bl(ctx, bl);\n+\n+\treturn ret;\n+}\ndiff --git a/io_uring/kbuf.h b/io_uring/kbuf.h\nindex 40b44f4fdb15..62c80a1ebf03 100644\n--- a/io_uring/kbuf.h\n+++ b/io_uring/kbuf.h\n@@ -7,9 +7,11 @@\n \n enum {\n \t/* ring mapped provided buffers */\n-\tIOBL_BUF_RING\t= 1,\n+\tIOBL_BUF_RING\t\t= 1,\n \t/* buffers are consumed incrementally rather than always fully */\n-\tIOBL_INC\t= 2,\n+\tIOBL_INC\t\t= 2,\n+\t/* buffers are kernel managed */\n+\tIOBL_KERNEL_MANAGED\t= 4,\n };\n \n struct io_buffer_list {\n@@ -74,6 +76,7 @@ int io_provide_buffers_prep(struct io_kiocb *req, const struct io_uring_sqe *sqe\n int io_manage_buffers_legacy(struct io_kiocb *req, unsigned int issue_flags);\n \n int io_register_pbuf_ring(struct io_ring_ctx *ctx, void __user *arg);\n+int io_register_kmbuf_ring(struct io_ring_ctx *ctx, void __user *arg);\n int io_unregister_buf_ring(struct io_ring_ctx *ctx, void __user *arg);\n int io_register_pbuf_status(struct io_ring_ctx *ctx, void __user *arg);\n \ndiff --git a/io_uring/memmap.c b/io_uring/memmap.c\nindex 89f56609e50a..8d37e93c0433 100644\n--- a/io_uring/memmap.c\n+++ b/io_uring/memmap.c\n@@ -15,6 +15,28 @@\n #include \"rsrc.h\"\n #include \"zcrx.h\"\n \n+static void release_multi_buf_pages(struct page **pages, unsigned long nr_pages)\n+{\n+\tstruct page *page;\n+\tunsigned int nr, i = 0;\n+\n+\twhile (nr_pages) {\n+\t\tpage = pages[i];\n+\n+\t\tif (!page || WARN_ON_ONCE(page != compound_head(page)))\n+\t\t\treturn;\n+\n+\t\tnr = compound_nr(page);\n+\t\tput_page(page);\n+\n+\t\tif (WARN_ON_ONCE(nr > nr_pages))\n+\t\t\treturn;\n+\n+\t\ti += nr;\n+\t\tnr_pages -= nr;\n+\t}\n+}\n+\n static bool io_mem_alloc_compound(struct page **pages, int nr_pages,\n \t\t\t\t  size_t size, gfp_t gfp)\n {\n@@ -86,6 +108,8 @@ enum {\n \tIO_REGION_F_USER_PROVIDED\t\t= 2,\n \t/* only the first page in the array is ref'ed */\n \tIO_REGION_F_SINGLE_REF\t\t\t= 4,\n+\t/* pages in the array belong to multiple discrete allocations */\n+\tIO_REGION_F_MULTI_BUF\t\t\t= 8,\n };\n \n void io_free_region(struct user_struct *user, struct io_mapped_region *mr)\n@@ -98,6 +122,8 @@ void io_free_region(struct user_struct *user, struct io_mapped_region *mr)\n \n \t\tif (mr->flags & IO_REGION_F_USER_PROVIDED)\n \t\t\tunpin_user_pages(mr->pages, nr_refs);\n+\t\telse if (mr->flags & IO_REGION_F_MULTI_BUF)\n+\t\t\trelease_multi_buf_pages(mr->pages, nr_refs);\n \t\telse\n \t\t\trelease_pages(mr->pages, nr_refs);\n \n@@ -149,6 +175,54 @@ static int io_region_pin_pages(struct io_mapped_region *mr,\n \treturn 0;\n }\n \n+static int io_region_allocate_pages_multi_buf(struct io_mapped_region *mr,\n+\t\t\t\t\t      unsigned int nr_bufs,\n+\t\t\t\t\t      unsigned int buf_size)\n+{\n+\tgfp_t gfp = GFP_USER | __GFP_ACCOUNT | __GFP_ZERO | __GFP_NOWARN;\n+\tstruct page **pages, **cur_pages;\n+\tunsigned int nr_allocated;\n+\tunsigned int buf_pages;\n+\tunsigned int i;\n+\n+\tif (!PAGE_ALIGNED(buf_size))\n+\t\treturn -EINVAL;\n+\n+\tbuf_pages = buf_size >> PAGE_SHIFT;\n+\n+\tpages = kvmalloc_array(mr->nr_pages, sizeof(*pages), gfp);\n+\tif (!pages)\n+\t\treturn -ENOMEM;\n+\n+\tcur_pages = pages;\n+\n+\tfor (i = 0; i < nr_bufs; i++) {\n+\t\tif (io_mem_alloc_compound(cur_pages, buf_pages, buf_size,\n+\t\t\t\t\t  gfp)) {\n+\t\t\tcur_pages += buf_pages;\n+\t\t\tcontinue;\n+\t\t}\n+\n+\t\tnr_allocated = alloc_pages_bulk_node(gfp, NUMA_NO_NODE,\n+\t\t\t\t\t\t     buf_pages, cur_pages);\n+\t\tif (nr_allocated != buf_pages) {\n+\t\t\tunsigned int total =\n+\t\t\t\t(cur_pages - pages) + nr_allocated;\n+\n+\t\t\trelease_multi_buf_pages(pages, total);\n+\t\t\tkvfree(pages);\n+\t\t\treturn -ENOMEM;\n+\t\t}\n+\n+\t\tcur_pages += buf_pages;\n+\t}\n+\n+\tmr->flags |= IO_REGION_F_MULTI_BUF;\n+\tmr->pages = pages;\n+\n+\treturn 0;\n+}\n+\n static int io_region_allocate_pages(struct io_mapped_region *mr,\n \t\t\t\t    struct io_uring_region_desc *reg,\n \t\t\t\t    unsigned long mmap_offset)\n@@ -181,6 +255,43 @@ static int io_region_allocate_pages(struct io_mapped_region *mr,\n \treturn 0;\n }\n \n+int io_create_region_multi_buf(struct io_ring_ctx *ctx,\n+\t\t\t       struct io_mapped_region *mr,\n+\t\t\t       unsigned int nr_bufs, unsigned int buf_size)\n+{\n+\tunsigned int nr_pages;\n+\tint ret;\n+\n+\tif (WARN_ON_ONCE(mr->pages || mr->ptr || mr->nr_pages))\n+\t\treturn -EFAULT;\n+\n+\tif (WARN_ON_ONCE(!nr_bufs || !buf_size || !PAGE_ALIGNED(buf_size)))\n+\t\treturn -EINVAL;\n+\n+\tif (check_mul_overflow(buf_size >> PAGE_SHIFT, nr_bufs, &nr_pages))\n+\t\treturn -EINVAL;\n+\n+\tif (ctx->user) {\n+\t\tret = __io_account_mem(ctx->user, nr_pages);\n+\t\tif (ret)\n+\t\t\treturn ret;\n+\t}\n+\tmr->nr_pages = nr_pages;\n+\n+\tret = io_region_allocate_pages_multi_buf(mr, nr_bufs, buf_size);\n+\tif (ret)\n+\t\tgoto out_free;\n+\n+\tret = io_region_init_ptr(mr);\n+\tif (ret)\n+\t\tgoto out_free;\n+\n+\treturn 0;\n+out_free:\n+\tio_free_region(ctx->user, mr);\n+\treturn ret;\n+}\n+\n int io_create_region(struct io_ring_ctx *ctx, struct io_mapped_region *mr,\n \t\t     struct io_uring_region_desc *reg,\n \t\t     unsigned long mmap_offset)\ndiff --git a/io_uring/memmap.h b/io_uring/memmap.h\nindex f4cfbb6b9a1f..3aa1167462ae 100644\n--- a/io_uring/memmap.h\n+++ b/io_uring/memmap.h\n@@ -22,6 +22,10 @@ int io_create_region(struct io_ring_ctx *ctx, struct io_mapped_region *mr,\n \t\t     struct io_uring_region_desc *reg,\n \t\t     unsigned long mmap_offset);\n \n+int io_create_region_multi_buf(struct io_ring_ctx *ctx,\n+\t\t\t       struct io_mapped_region *mr,\n+\t\t\t       unsigned int nr_bufs, unsigned int buf_size);\n+\n static inline void *io_region_get_ptr(struct io_mapped_region *mr)\n {\n \treturn mr->ptr;\ndiff --git a/io_uring/register.c b/io_uring/register.c\nindex 0882cb34f851..2db8daaf8fde 100644\n--- a/io_uring/register.c\n+++ b/io_uring/register.c\n@@ -837,7 +837,14 @@ static int __io_uring_register(struct io_ring_ctx *ctx, unsigned opcode,\n \t\t\tbreak;\n \t\tret = io_register_pbuf_ring(ctx, arg);\n \t\tbreak;\n+\tcase IORING_REGISTER_KMBUF_RING:\n+\t\tret = -EINVAL;\n+\t\tif (!arg || nr_args != 1)\n+\t\t\tbreak;\n+\t\tret = io_register_kmbuf_ring(ctx, arg);\n+\t\tbreak;\n \tcase IORING_UNREGISTER_PBUF_RING:\n+\tcase IORING_UNREGISTER_KMBUF_RING:\n \t\tret = -EINVAL;\n \t\tif (!arg || nr_args != 1)\n \t\t\tbreak;\n-- \n2.47.3",
          "reply_to": "",
          "message_date": "2026-02-09"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "The author addressed a concern about the implementation of kernel-managed buffer rings (kmbuf) and their interaction with mmap(), specifically the handling of the mmap offset to identify which buffer ring to map. The author explained that kmbuf rings use the same pattern as application-provided buffer rings, but introduced new constants for the mmap offset. They also updated the io_buf_get_region() helper to retrieve the appropriate region based on the bgid shifted by IORING_OFF_KMBUF_SHIFT.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Add support for mmapping kernel-managed buffer rings (kmbuf) to\nuserspace, allowing applications to access the kernel-allocated buffers.\n\nSimilar to application-provided buffer rings (pbuf), kmbuf rings use the\nbuffer group ID encoded in the mmap offset to identify which buffer ring\nto map. The implementation follows the same pattern as pbuf rings.\n\nNew mmap offset constants are introduced:\n  - IORING_OFF_KMBUF_RING (0x88000000): Base offset for kmbuf mappings\n  - IORING_OFF_KMBUF_SHIFT (16): Shift value to encode buffer group ID\n\nThe mmap offset encodes the bgid shifted by IORING_OFF_KMBUF_SHIFT.\nThe io_buf_get_region() helper retrieves the appropriate region.\n\nThis allows userspace to mmap the kernel-allocated buffer region and\naccess the buffers directly.\n\nSigned-off-by: Joanne Koong <joannelkoong@gmail.com>\n---\n include/uapi/linux/io_uring.h |  2 ++\n io_uring/kbuf.c               | 11 +++++++++--\n io_uring/kbuf.h               |  5 +++--\n io_uring/memmap.c             |  5 ++++-\n 4 files changed, 18 insertions(+), 5 deletions(-)\n\ndiff --git a/include/uapi/linux/io_uring.h b/include/uapi/linux/io_uring.h\nindex a0889c1744bd..42a2812c9922 100644\n--- a/include/uapi/linux/io_uring.h\n+++ b/include/uapi/linux/io_uring.h\n@@ -545,6 +545,8 @@ struct io_uring_cqe {\n #define IORING_OFF_SQES\t\t\t0x10000000ULL\n #define IORING_OFF_PBUF_RING\t\t0x80000000ULL\n #define IORING_OFF_PBUF_SHIFT\t\t16\n+#define IORING_OFF_KMBUF_RING\t\t0x88000000ULL\n+#define IORING_OFF_KMBUF_SHIFT\t\t16\n #define IORING_OFF_MMAP_MASK\t\t0xf8000000ULL\n \n /*\ndiff --git a/io_uring/kbuf.c b/io_uring/kbuf.c\nindex 9bc36451d083..ccf5b213087b 100644\n--- a/io_uring/kbuf.c\n+++ b/io_uring/kbuf.c\n@@ -770,16 +770,23 @@ int io_register_pbuf_status(struct io_ring_ctx *ctx, void __user *arg)\n \treturn 0;\n }\n \n-struct io_mapped_region *io_pbuf_get_region(struct io_ring_ctx *ctx,\n-\t\t\t\t\t    unsigned int bgid)\n+struct io_mapped_region *io_buf_get_region(struct io_ring_ctx *ctx,\n+\t\t\t\t\t   unsigned int bgid,\n+\t\t\t\t\t   bool kernel_managed)\n {\n \tstruct io_buffer_list *bl;\n+\tbool is_kernel_managed;\n \n \tlockdep_assert_held(&ctx->mmap_lock);\n \n \tbl = xa_load(&ctx->io_bl_xa, bgid);\n \tif (!bl || !(bl->flags & IOBL_BUF_RING))\n \t\treturn NULL;\n+\n+\tis_kernel_managed = !!(bl->flags & IOBL_KERNEL_MANAGED);\n+\tif (is_kernel_managed != kernel_managed)\n+\t\treturn NULL;\n+\n \treturn &bl->region;\n }\n \ndiff --git a/io_uring/kbuf.h b/io_uring/kbuf.h\nindex 62c80a1ebf03..11d165888b8e 100644\n--- a/io_uring/kbuf.h\n+++ b/io_uring/kbuf.h\n@@ -88,8 +88,9 @@ unsigned int __io_put_kbufs(struct io_kiocb *req, struct io_buffer_list *bl,\n bool io_kbuf_commit(struct io_kiocb *req,\n \t\t    struct io_buffer_list *bl, int len, int nr);\n \n-struct io_mapped_region *io_pbuf_get_region(struct io_ring_ctx *ctx,\n-\t\t\t\t\t    unsigned int bgid);\n+struct io_mapped_region *io_buf_get_region(struct io_ring_ctx *ctx,\n+\t\t\t\t\t   unsigned int bgid,\n+\t\t\t\t\t   bool kernel_managed);\n \n static inline bool io_kbuf_recycle_ring(struct io_kiocb *req,\n \t\t\t\t\tstruct io_buffer_list *bl)\ndiff --git a/io_uring/memmap.c b/io_uring/memmap.c\nindex 8d37e93c0433..916315122323 100644\n--- a/io_uring/memmap.c\n+++ b/io_uring/memmap.c\n@@ -356,7 +356,10 @@ static struct io_mapped_region *io_mmap_get_region(struct io_ring_ctx *ctx,\n \t\treturn &ctx->sq_region;\n \tcase IORING_OFF_PBUF_RING:\n \t\tid = (offset & ~IORING_OFF_MMAP_MASK) >> IORING_OFF_PBUF_SHIFT;\n-\t\treturn io_pbuf_get_region(ctx, id);\n+\t\treturn io_buf_get_region(ctx, id, false);\n+\tcase IORING_OFF_KMBUF_RING:\n+\t\tid = (offset & ~IORING_OFF_MMAP_MASK) >> IORING_OFF_KMBUF_SHIFT;\n+\t\treturn io_buf_get_region(ctx, id, true);\n \tcase IORING_MAP_OFF_PARAM_REGION:\n \t\treturn &ctx->param_region;\n \tcase IORING_MAP_OFF_ZCRX_REGION:\n-- \n2.47.3",
          "reply_to": "",
          "message_date": "2026-02-09"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "The author addressed a concern about distinguishing between kernel-managed buffer addresses and negative values in error checking, explaining that the io_br_sel struct needs to be modified to separate address and value fields for kernel-managed buffers.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Allow kernel-managed buffers to be selected. This requires modifying the\nio_br_sel struct to separate the fields for address and val, since a\nkernel address cannot be distinguished from a negative val when error\nchecking.\n\nAuto-commit any selected kernel-managed buffer.\n\nSigned-off-by: Joanne Koong <joannelkoong@gmail.com>\n---\n include/linux/io_uring_types.h |  8 ++++----\n io_uring/kbuf.c                | 16 ++++++++++++----\n 2 files changed, 16 insertions(+), 8 deletions(-)\n\ndiff --git a/include/linux/io_uring_types.h b/include/linux/io_uring_types.h\nindex 3e4a82a6f817..36cc2e0346d9 100644\n--- a/include/linux/io_uring_types.h\n+++ b/include/linux/io_uring_types.h\n@@ -93,13 +93,13 @@ struct io_mapped_region {\n  */\n struct io_br_sel {\n \tstruct io_buffer_list *buf_list;\n-\t/*\n-\t * Some selection parts return the user address, others return an error.\n-\t */\n \tunion {\n+\t\t/* for classic/ring provided buffers */\n \t\tvoid __user *addr;\n-\t\tssize_t val;\n+\t\t/* for kernel-managed buffers */\n+\t\tvoid *kaddr;\n \t};\n+\tssize_t val;\n };\n \n \ndiff --git a/io_uring/kbuf.c b/io_uring/kbuf.c\nindex ccf5b213087b..1e8395270227 100644\n--- a/io_uring/kbuf.c\n+++ b/io_uring/kbuf.c\n@@ -155,7 +155,8 @@ static int io_provided_buffers_select(struct io_kiocb *req, size_t *len,\n \treturn 1;\n }\n \n-static bool io_should_commit(struct io_kiocb *req, unsigned int issue_flags)\n+static bool io_should_commit(struct io_kiocb *req, struct io_buffer_list *bl,\n+\t\t\t     unsigned int issue_flags)\n {\n \t/*\n \t* If we came in unlocked, we have no choice but to consume the\n@@ -170,7 +171,11 @@ static bool io_should_commit(struct io_kiocb *req, unsigned int issue_flags)\n \tif (issue_flags & IO_URING_F_UNLOCKED)\n \t\treturn true;\n \n-\t/* uring_cmd commits kbuf upfront, no need to auto-commit */\n+\t/* kernel-managed buffers are auto-committed */\n+\tif (bl->flags & IOBL_KERNEL_MANAGED)\n+\t\treturn true;\n+\n+\t/* multishot uring_cmd commits kbuf upfront, no need to auto-commit */\n \tif (!io_file_can_poll(req) && req->opcode != IORING_OP_URING_CMD)\n \t\treturn true;\n \treturn false;\n@@ -200,9 +205,12 @@ static struct io_br_sel io_ring_buffer_select(struct io_kiocb *req, size_t *len,\n \treq->flags |= REQ_F_BUFFER_RING | REQ_F_BUFFERS_COMMIT;\n \treq->buf_index = READ_ONCE(buf->bid);\n \tsel.buf_list = bl;\n-\tsel.addr = u64_to_user_ptr(READ_ONCE(buf->addr));\n+\tif (bl->flags & IOBL_KERNEL_MANAGED)\n+\t\tsel.kaddr = (void *)(uintptr_t)READ_ONCE(buf->addr);\n+\telse\n+\t\tsel.addr = u64_to_user_ptr(READ_ONCE(buf->addr));\n \n-\tif (io_should_commit(req, issue_flags)) {\n+\tif (io_should_commit(req, bl, issue_flags)) {\n \t\tio_kbuf_commit(req, sel.buf_list, *len, 1);\n \t\tsel.buf_list = NULL;\n \t}\n-- \n2.47.3",
          "reply_to": "",
          "message_date": "2026-02-09"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "The author addressed a concern about userspace unregistering a buffer ring while it is pinned by the kernel, explaining that adding kernel APIs to pin and unpin buffer rings provides a mechanism for kernel subsystems to safely access buffer ring contents.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "preparatory change"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Add kernel APIs to pin and unpin buffer rings, preventing userspace from\nunregistering a buffer ring while it is pinned by the kernel.\n\nThis provides a mechanism for kernel subsystems to safely access buffer\nring contents while ensuring the buffer ring remains valid. A pinned\nbuffer ring cannot be unregistered until explicitly unpinned. On the\nuserspace side, trying to unregister a pinned buffer will return -EBUSY.\n\nThis is a preparatory change for upcoming fuse usage of kernel-managed\nbuffer rings. It is necessary for fuse to pin the buffer ring because\nfuse may need to select a buffer in atomic contexts, which it can only\ndo so by using the underlying buffer list pointer.\n\nSigned-off-by: Joanne Koong <joannelkoong@gmail.com>\n---\n include/linux/io_uring/cmd.h | 17 +++++++++++++\n io_uring/kbuf.c              | 48 ++++++++++++++++++++++++++++++++++++\n io_uring/kbuf.h              |  5 ++++\n 3 files changed, 70 insertions(+)\n\ndiff --git a/include/linux/io_uring/cmd.h b/include/linux/io_uring/cmd.h\nindex 375fd048c4cb..702b1903e6ee 100644\n--- a/include/linux/io_uring/cmd.h\n+++ b/include/linux/io_uring/cmd.h\n@@ -84,6 +84,10 @@ struct io_br_sel io_uring_cmd_buffer_select(struct io_uring_cmd *ioucmd,\n bool io_uring_mshot_cmd_post_cqe(struct io_uring_cmd *ioucmd,\n \t\t\t\t struct io_br_sel *sel, unsigned int issue_flags);\n \n+int io_uring_buf_ring_pin(struct io_uring_cmd *cmd, unsigned buf_group,\n+\t\t\t  unsigned issue_flags, struct io_buffer_list **bl);\n+int io_uring_buf_ring_unpin(struct io_uring_cmd *cmd, unsigned buf_group,\n+\t\t\t    unsigned issue_flags);\n #else\n static inline int\n io_uring_cmd_import_fixed(u64 ubuf, unsigned long len, int rw,\n@@ -126,6 +130,19 @@ static inline bool io_uring_mshot_cmd_post_cqe(struct io_uring_cmd *ioucmd,\n {\n \treturn true;\n }\n+static inline int io_uring_buf_ring_pin(struct io_uring_cmd *cmd,\n+\t\t\t\t\tunsigned buf_group,\n+\t\t\t\t\tunsigned issue_flags,\n+\t\t\t\t\tstruct io_buffer_list **bl)\n+{\n+\treturn -EOPNOTSUPP;\n+}\n+static inline int io_uring_buf_ring_unpin(struct io_uring_cmd *cmd,\n+\t\t\t\t\t  unsigned buf_group,\n+\t\t\t\t\t  unsigned issue_flags)\n+{\n+\treturn -EOPNOTSUPP;\n+}\n #endif\n \n static inline struct io_uring_cmd *io_uring_cmd_from_tw(struct io_tw_req tw_req)\ndiff --git a/io_uring/kbuf.c b/io_uring/kbuf.c\nindex 1e8395270227..dee1764ed19f 100644\n--- a/io_uring/kbuf.c\n+++ b/io_uring/kbuf.c\n@@ -9,6 +9,7 @@\n #include <linux/poll.h>\n #include <linux/vmalloc.h>\n #include <linux/io_uring.h>\n+#include <linux/io_uring/cmd.h>\n \n #include <uapi/linux/io_uring.h>\n \n@@ -237,6 +238,51 @@ struct io_br_sel io_buffer_select(struct io_kiocb *req, size_t *len,\n \treturn sel;\n }\n \n+int io_uring_buf_ring_pin(struct io_uring_cmd *cmd, unsigned buf_group,\n+\t\t\t  unsigned issue_flags, struct io_buffer_list **bl)\n+{\n+\tstruct io_ring_ctx *ctx = cmd_to_io_kiocb(cmd)->ctx;\n+\tstruct io_buffer_list *buffer_list;\n+\tint ret = -EINVAL;\n+\n+\tio_ring_submit_lock(ctx, issue_flags);\n+\n+\tbuffer_list = io_buffer_get_list(ctx, buf_group);\n+\tif (buffer_list && (buffer_list->flags & IOBL_BUF_RING)) {\n+\t\tif (unlikely(buffer_list->flags & IOBL_PINNED)) {\n+\t\t\tret = -EALREADY;\n+\t\t} else {\n+\t\t\tbuffer_list->flags |= IOBL_PINNED;\n+\t\t\tret = 0;\n+\t\t\t*bl = buffer_list;\n+\t\t}\n+\t}\n+\n+\tio_ring_submit_unlock(ctx, issue_flags);\n+\treturn ret;\n+}\n+EXPORT_SYMBOL_GPL(io_uring_buf_ring_pin);\n+\n+int io_uring_buf_ring_unpin(struct io_uring_cmd *cmd, unsigned buf_group,\n+\t\t       unsigned issue_flags)\n+{\n+\tstruct io_ring_ctx *ctx = cmd_to_io_kiocb(cmd)->ctx;\n+\tstruct io_buffer_list *bl;\n+\tint ret = -EINVAL;\n+\n+\tio_ring_submit_lock(ctx, issue_flags);\n+\n+\tbl = io_buffer_get_list(ctx, buf_group);\n+\tif (bl && (bl->flags & IOBL_BUF_RING) && (bl->flags & IOBL_PINNED)) {\n+\t\tbl->flags &= ~IOBL_PINNED;\n+\t\tret = 0;\n+\t}\n+\n+\tio_ring_submit_unlock(ctx, issue_flags);\n+\treturn ret;\n+}\n+EXPORT_SYMBOL_GPL(io_uring_buf_ring_unpin);\n+\n /* cap it at a reasonable 256, will be one page even for 4K */\n #define PEEK_MAX_IMPORT\t\t256\n \n@@ -747,6 +793,8 @@ int io_unregister_buf_ring(struct io_ring_ctx *ctx, void __user *arg)\n \t\treturn -ENOENT;\n \tif (!(bl->flags & IOBL_BUF_RING))\n \t\treturn -EINVAL;\n+\tif (bl->flags & IOBL_PINNED)\n+\t\treturn -EBUSY;\n \n \tscoped_guard(mutex, &ctx->mmap_lock)\n \t\txa_erase(&ctx->io_bl_xa, bl->bgid);\ndiff --git a/io_uring/kbuf.h b/io_uring/kbuf.h\nindex 11d165888b8e..781630c2cc10 100644\n--- a/io_uring/kbuf.h\n+++ b/io_uring/kbuf.h\n@@ -12,6 +12,11 @@ enum {\n \tIOBL_INC\t\t= 2,\n \t/* buffers are kernel managed */\n \tIOBL_KERNEL_MANAGED\t= 4,\n+\t/*\n+\t * buffer ring is pinned and cannot be unregistered by userspace until\n+\t * it has been unpinned\n+\t */\n+\tIOBL_PINNED\t\t= 8,\n };\n \n struct io_buffer_list {\n-- \n2.47.3",
          "reply_to": "",
          "message_date": "2026-02-09"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "The author addressed a concern about the lack of an interface for recycling buffers back into kernel-managed buffer rings, and added such an interface in this new patch.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "preparatory"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Add an interface for buffers to be recycled back into a kernel-managed\nbuffer ring.\n\nThis is a preparatory patch for fuse over io-uring.\n\nSigned-off-by: Joanne Koong <joannelkoong@gmail.com>\n---\n include/linux/io_uring/cmd.h | 11 +++++++++\n io_uring/kbuf.c              | 44 ++++++++++++++++++++++++++++++++++++\n 2 files changed, 55 insertions(+)\n\ndiff --git a/include/linux/io_uring/cmd.h b/include/linux/io_uring/cmd.h\nindex 702b1903e6ee..a488e945f883 100644\n--- a/include/linux/io_uring/cmd.h\n+++ b/include/linux/io_uring/cmd.h\n@@ -88,6 +88,10 @@ int io_uring_buf_ring_pin(struct io_uring_cmd *cmd, unsigned buf_group,\n \t\t\t  unsigned issue_flags, struct io_buffer_list **bl);\n int io_uring_buf_ring_unpin(struct io_uring_cmd *cmd, unsigned buf_group,\n \t\t\t    unsigned issue_flags);\n+\n+int io_uring_kmbuf_recycle(struct io_uring_cmd *cmd, unsigned int buf_group,\n+\t\t\t   u64 addr, unsigned int len, unsigned int bid,\n+\t\t\t   unsigned int issue_flags);\n #else\n static inline int\n io_uring_cmd_import_fixed(u64 ubuf, unsigned long len, int rw,\n@@ -143,6 +147,13 @@ static inline int io_uring_buf_ring_unpin(struct io_uring_cmd *cmd,\n {\n \treturn -EOPNOTSUPP;\n }\n+static inline int io_uring_kmbuf_recycle(struct io_uring_cmd *cmd,\n+\t\t\t\t\t unsigned int buf_group, u64 addr,\n+\t\t\t\t\t unsigned int len, unsigned int bid,\n+\t\t\t\t\t unsigned int issue_flags)\n+{\n+\treturn -EOPNOTSUPP;\n+}\n #endif\n \n static inline struct io_uring_cmd *io_uring_cmd_from_tw(struct io_tw_req tw_req)\ndiff --git a/io_uring/kbuf.c b/io_uring/kbuf.c\nindex dee1764ed19f..17b6178be4ce 100644\n--- a/io_uring/kbuf.c\n+++ b/io_uring/kbuf.c\n@@ -102,6 +102,50 @@ void io_kbuf_drop_legacy(struct io_kiocb *req)\n \treq->kbuf = NULL;\n }\n \n+int io_uring_kmbuf_recycle(struct io_uring_cmd *cmd, unsigned int buf_group,\n+\t\t\t   u64 addr, unsigned int len, unsigned int bid,\n+\t\t\t   unsigned int issue_flags)\n+{\n+\tstruct io_kiocb *req = cmd_to_io_kiocb(cmd);\n+\tstruct io_ring_ctx *ctx = req->ctx;\n+\tstruct io_uring_buf_ring *br;\n+\tstruct io_uring_buf *buf;\n+\tstruct io_buffer_list *bl;\n+\tint ret = -EINVAL;\n+\n+\tif (WARN_ON_ONCE(req->flags & REQ_F_BUFFERS_COMMIT))\n+\t\treturn ret;\n+\n+\tio_ring_submit_lock(ctx, issue_flags);\n+\n+\tbl = io_buffer_get_list(ctx, buf_group);\n+\n+\tif (!bl || WARN_ON_ONCE(!(bl->flags & IOBL_BUF_RING)) ||\n+\t    WARN_ON_ONCE(!(bl->flags & IOBL_KERNEL_MANAGED)))\n+\t\tgoto done;\n+\n+\tbr = bl->buf_ring;\n+\n+\tif (WARN_ON_ONCE((br->tail - bl->head) >= bl->nr_entries))\n+\t\tgoto done;\n+\n+\tbuf = &br->bufs[(br->tail) & bl->mask];\n+\n+\tbuf->addr = addr;\n+\tbuf->len = len;\n+\tbuf->bid = bid;\n+\n+\treq->flags &= ~REQ_F_BUFFER_RING;\n+\n+\tbr->tail++;\n+\tret = 0;\n+\n+done:\n+\tio_ring_submit_unlock(ctx, issue_flags);\n+\treturn ret;\n+}\n+EXPORT_SYMBOL_GPL(io_uring_kmbuf_recycle);\n+\n bool io_kbuf_recycle_legacy(struct io_kiocb *req, unsigned issue_flags)\n {\n \tstruct io_ring_ctx *ctx = req->ctx;\n-- \n2.47.3",
          "reply_to": "",
          "message_date": "2026-02-09"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "Author addressed a concern about the implementation of io_uring_is_kmbuf_ring() and its interaction with fuse kernel-managed buffer support, explaining that it returns true if there is a kernel-managed buffer ring at the specified buffer group. The author added code to implement this function, which checks for the presence of a kernel-managed buffer ring by looking for the IOBL_KERNEL_MANAGED flag in the io_buffer_list structure.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "io_uring_is_kmbuf_ring() returns true if there is a kernel-managed\nbuffer ring at the specified buffer group.\n\nThis is a preparatory patch for upcoming fuse kernel-managed buffer\nsupport, which needs to ensure the buffer ring registered by the server\nis a kernel-managed buffer ring.\n\nSigned-off-by: Joanne Koong <joannelkoong@gmail.com>\n---\n include/linux/io_uring/cmd.h |  9 +++++++++\n io_uring/kbuf.c              | 20 ++++++++++++++++++++\n 2 files changed, 29 insertions(+)\n\ndiff --git a/include/linux/io_uring/cmd.h b/include/linux/io_uring/cmd.h\nindex a488e945f883..04a937f6f4d3 100644\n--- a/include/linux/io_uring/cmd.h\n+++ b/include/linux/io_uring/cmd.h\n@@ -92,6 +92,9 @@ int io_uring_buf_ring_unpin(struct io_uring_cmd *cmd, unsigned buf_group,\n int io_uring_kmbuf_recycle(struct io_uring_cmd *cmd, unsigned int buf_group,\n \t\t\t   u64 addr, unsigned int len, unsigned int bid,\n \t\t\t   unsigned int issue_flags);\n+\n+bool io_uring_is_kmbuf_ring(struct io_uring_cmd *cmd, unsigned int buf_group,\n+\t\t\t    unsigned int issue_flags);\n #else\n static inline int\n io_uring_cmd_import_fixed(u64 ubuf, unsigned long len, int rw,\n@@ -154,6 +157,12 @@ static inline int io_uring_kmbuf_recycle(struct io_uring_cmd *cmd,\n {\n \treturn -EOPNOTSUPP;\n }\n+static inline bool io_uring_is_kmbuf_ring(struct io_uring_cmd *cmd,\n+\t\t\t\t\t  unsigned int buf_group,\n+\t\t\t\t\t  unsigned int issue_flags)\n+{\n+\treturn false;\n+}\n #endif\n \n static inline struct io_uring_cmd *io_uring_cmd_from_tw(struct io_tw_req tw_req)\ndiff --git a/io_uring/kbuf.c b/io_uring/kbuf.c\nindex 17b6178be4ce..797cc2f0a5e9 100644\n--- a/io_uring/kbuf.c\n+++ b/io_uring/kbuf.c\n@@ -963,3 +963,23 @@ int io_register_kmbuf_ring(struct io_ring_ctx *ctx, void __user *arg)\n \n \treturn ret;\n }\n+\n+bool io_uring_is_kmbuf_ring(struct io_uring_cmd *cmd, unsigned int buf_group,\n+\t\t\t    unsigned int issue_flags)\n+{\n+\tstruct io_ring_ctx *ctx = cmd_to_io_kiocb(cmd)->ctx;\n+\tstruct io_buffer_list *bl;\n+\tbool is_kmbuf_ring = false;\n+\n+\tio_ring_submit_lock(ctx, issue_flags);\n+\n+\tbl = io_buffer_get_list(ctx, buf_group);\n+\tif (likely(bl) && (bl->flags & IOBL_KERNEL_MANAGED)) {\n+\t\tWARN_ON_ONCE(!(bl->flags & IOBL_BUF_RING));\n+\t\tis_kmbuf_ring = true;\n+\t}\n+\n+\tio_ring_submit_unlock(ctx, issue_flags);\n+\treturn is_kmbuf_ring;\n+}\n+EXPORT_SYMBOL_GPL(io_uring_is_kmbuf_ring);\n-- \n2.47.3",
          "reply_to": "",
          "message_date": "2026-02-09"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "The author is addressing a concern about the io_uring/cmd: set selected buffer index in __io_uring_cmd_done() patch, specifically that it doesn't export the io_ring_buffer_select function to allow callers who pass in a pinned bufring to use it without grabbing the io_uring mutex. The author agrees with this feedback and is adding an export for the function.",
          "sentiment": "positive",
          "sentiment_signals": [
            "agreed",
            "added_export"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Export io_ring_buffer_select() so that it may be used by callers who\npass in a pinned bufring without needing to grab the io_uring mutex.\n\nThis is a preparatory patch that will be needed by fuse io-uring, which\nwill need to select a buffer from a kernel-managed bufring while the\nuring mutex may already be held by in-progress commits, and may need to\nselect a buffer in atomic contexts.\n\nSigned-off-by: Joanne Koong <joannelkoong@gmail.com>\n---\n include/linux/io_uring/cmd.h | 14 ++++++++++++++\n io_uring/kbuf.c              |  7 ++++---\n 2 files changed, 18 insertions(+), 3 deletions(-)\n\ndiff --git a/include/linux/io_uring/cmd.h b/include/linux/io_uring/cmd.h\nindex 04a937f6f4d3..d4b5943bdeb1 100644\n--- a/include/linux/io_uring/cmd.h\n+++ b/include/linux/io_uring/cmd.h\n@@ -95,6 +95,10 @@ int io_uring_kmbuf_recycle(struct io_uring_cmd *cmd, unsigned int buf_group,\n \n bool io_uring_is_kmbuf_ring(struct io_uring_cmd *cmd, unsigned int buf_group,\n \t\t\t    unsigned int issue_flags);\n+\n+struct io_br_sel io_ring_buffer_select(struct io_kiocb *req, size_t *len,\n+\t\t\t\t       struct io_buffer_list *bl,\n+\t\t\t\t       unsigned int issue_flags);\n #else\n static inline int\n io_uring_cmd_import_fixed(u64 ubuf, unsigned long len, int rw,\n@@ -163,6 +167,16 @@ static inline bool io_uring_is_kmbuf_ring(struct io_uring_cmd *cmd,\n {\n \treturn false;\n }\n+static inline struct io_br_sel io_ring_buffer_select(struct io_kiocb *req,\n+\t\t\t\t\t\t     size_t *len,\n+\t\t\t\t\t\t     struct io_buffer_list *bl,\n+\t\t\t\t\t\t     unsigned int issue_flags)\n+{\n+\tstruct io_br_sel sel = {\n+\t\t.val = -EOPNOTSUPP,\n+\t};\n+\treturn sel;\n+}\n #endif\n \n static inline struct io_uring_cmd *io_uring_cmd_from_tw(struct io_tw_req tw_req)\ndiff --git a/io_uring/kbuf.c b/io_uring/kbuf.c\nindex 797cc2f0a5e9..9a93f10d3214 100644\n--- a/io_uring/kbuf.c\n+++ b/io_uring/kbuf.c\n@@ -226,9 +226,9 @@ static bool io_should_commit(struct io_kiocb *req, struct io_buffer_list *bl,\n \treturn false;\n }\n \n-static struct io_br_sel io_ring_buffer_select(struct io_kiocb *req, size_t *len,\n-\t\t\t\t\t      struct io_buffer_list *bl,\n-\t\t\t\t\t      unsigned int issue_flags)\n+struct io_br_sel io_ring_buffer_select(struct io_kiocb *req, size_t *len,\n+\t\t\t\t       struct io_buffer_list *bl,\n+\t\t\t\t       unsigned int issue_flags)\n {\n \tstruct io_uring_buf_ring *br = bl->buf_ring;\n \t__u16 tail, head = bl->head;\n@@ -261,6 +261,7 @@ static struct io_br_sel io_ring_buffer_select(struct io_kiocb *req, size_t *len,\n \t}\n \treturn sel;\n }\n+EXPORT_SYMBOL_GPL(io_ring_buffer_select);\n \n struct io_br_sel io_buffer_select(struct io_kiocb *req, size_t *len,\n \t\t\t\t  unsigned buf_group, unsigned int issue_flags)\n-- \n2.47.3",
          "reply_to": "",
          "message_date": "2026-02-09"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "The author addressed a concern about the io_uring_cmd_buffer_select() function not returning the selected buffer's id. The author agreed to modify the function to return the id, as needed for kernel-managed buffer rings.",
          "sentiment": "positive",
          "sentiment_signals": [
            "agreed",
            "modify"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Return the id of the selected buffer in io_buffer_select(). This is\nneeded for kernel-managed buffer rings to later recycle the selected\nbuffer.\n\nSigned-off-by: Joanne Koong <joannelkoong@gmail.com>\n---\n include/linux/io_uring/cmd.h   | 2 +-\n include/linux/io_uring_types.h | 2 ++\n io_uring/kbuf.c                | 7 +++++--\n 3 files changed, 8 insertions(+), 3 deletions(-)\n\ndiff --git a/include/linux/io_uring/cmd.h b/include/linux/io_uring/cmd.h\nindex d4b5943bdeb1..94df2bdebe77 100644\n--- a/include/linux/io_uring/cmd.h\n+++ b/include/linux/io_uring/cmd.h\n@@ -71,7 +71,7 @@ void io_uring_cmd_issue_blocking(struct io_uring_cmd *ioucmd);\n \n /*\n  * Select a buffer from the provided buffer group for multishot uring_cmd.\n- * Returns the selected buffer address and size.\n+ * Returns the selected buffer address, size, and id.\n  */\n struct io_br_sel io_uring_cmd_buffer_select(struct io_uring_cmd *ioucmd,\n \t\t\t\t\t    unsigned buf_group, size_t *len,\ndiff --git a/include/linux/io_uring_types.h b/include/linux/io_uring_types.h\nindex 36cc2e0346d9..5a56bb341337 100644\n--- a/include/linux/io_uring_types.h\n+++ b/include/linux/io_uring_types.h\n@@ -100,6 +100,8 @@ struct io_br_sel {\n \t\tvoid *kaddr;\n \t};\n \tssize_t val;\n+\t/* id of the selected buffer */\n+\tunsigned buf_id;\n };\n \n \ndiff --git a/io_uring/kbuf.c b/io_uring/kbuf.c\nindex 9a93f10d3214..24c1e34ea23e 100644\n--- a/io_uring/kbuf.c\n+++ b/io_uring/kbuf.c\n@@ -250,6 +250,7 @@ struct io_br_sel io_ring_buffer_select(struct io_kiocb *req, size_t *len,\n \treq->flags |= REQ_F_BUFFER_RING | REQ_F_BUFFERS_COMMIT;\n \treq->buf_index = READ_ONCE(buf->bid);\n \tsel.buf_list = bl;\n+\tsel.buf_id = req->buf_index;\n \tif (bl->flags & IOBL_KERNEL_MANAGED)\n \t\tsel.kaddr = (void *)(uintptr_t)READ_ONCE(buf->addr);\n \telse\n@@ -274,10 +275,12 @@ struct io_br_sel io_buffer_select(struct io_kiocb *req, size_t *len,\n \n \tbl = io_buffer_get_list(ctx, buf_group);\n \tif (likely(bl)) {\n-\t\tif (bl->flags & IOBL_BUF_RING)\n+\t\tif (bl->flags & IOBL_BUF_RING) {\n \t\t\tsel = io_ring_buffer_select(req, len, bl, issue_flags);\n-\t\telse\n+\t\t} else {\n \t\t\tsel.addr = io_provided_buffer_select(req, len, bl);\n+\t\t\tsel.buf_id = req->buf_index;\n+\t\t}\n \t}\n \tio_ring_submit_unlock(req->ctx, issue_flags);\n \treturn sel;\n-- \n2.47.3",
          "reply_to": "",
          "message_date": "2026-02-09"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "Author addressed a concern that the completion queue entry should indicate which buffer was selected, and responded by adding code to set IORING_CQE_F_BUFFER on the completed entry and encode the buffer index if a buffer was selected.",
          "sentiment": "positive",
          "sentiment_signals": [
            "acknowledged the need for change",
            "added code to address the issue"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "When uring_cmd operations select a buffer, the completion queue entry\nshould indicate which buffer was selected.\n\nSet IORING_CQE_F_BUFFER on the completed entry and encode the buffer\nindex if a buffer was selected.\n\nThis will be needed for fuse, which needs to relay to userspace which\nselected buffer contains the data.\n\nSigned-off-by: Joanne Koong <joannelkoong@gmail.com>\n---\n io_uring/uring_cmd.c | 6 +++++-\n 1 file changed, 5 insertions(+), 1 deletion(-)\n\ndiff --git a/io_uring/uring_cmd.c b/io_uring/uring_cmd.c\nindex ee7b49f47cb5..6d38df1a812d 100644\n--- a/io_uring/uring_cmd.c\n+++ b/io_uring/uring_cmd.c\n@@ -151,6 +151,7 @@ void __io_uring_cmd_done(struct io_uring_cmd *ioucmd, s32 ret, u64 res2,\n \t\t       unsigned issue_flags, bool is_cqe32)\n {\n \tstruct io_kiocb *req = cmd_to_io_kiocb(ioucmd);\n+\tu32 cflags = 0;\n \n \tif (WARN_ON_ONCE(req->flags & REQ_F_APOLL_MULTISHOT))\n \t\treturn;\n@@ -160,7 +161,10 @@ void __io_uring_cmd_done(struct io_uring_cmd *ioucmd, s32 ret, u64 res2,\n \tif (ret < 0)\n \t\treq_set_fail(req);\n \n-\tio_req_set_res(req, ret, 0);\n+\tif (req->flags & (REQ_F_BUFFER_SELECTED | REQ_F_BUFFER_RING))\n+\t\tcflags |= IORING_CQE_F_BUFFER |\n+\t\t\t(req->buf_index << IORING_CQE_BUFFER_SHIFT);\n+\tio_req_set_res(req, ret, cflags);\n \tif (is_cqe32) {\n \t\tif (req->ctx->flags & IORING_SETUP_CQE_MIXED)\n \t\t\treq->cqe.flags |= IORING_CQE_F_32;\n-- \n2.47.3",
          "reply_to": "",
          "message_date": "2026-02-09"
        },
        {
          "author": "Jens Axboe",
          "summary": "Reviewer Jens Axboe suggested adding a WARN_ON_ONCE() check to prevent int promotion from affecting the calculation of (br->tail - bl->head) >= bl->nr_entries, and noted that this is not a critical issue but rather something to be addressed later.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes"
          ],
          "has_inline_review": true,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "I think you want:\n\n\tif (WARN_ON_ONCE((__u16)(br->tail - bl->head) >= bl->nr_entries))\n\nhere to avoid int promotion from messing this up if tail has wrapped.\n\nIn general, across the patches for the WARN_ON_ONCE(), it's not a huge\nissue to have a litter of them for now. Hopefully we can prune some of\nthese down the line, however.\n\n-- \nJens Axboe",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-09"
        },
        {
          "author": "Jens Axboe",
          "summary": "Reviewer Jens Axboe questioned the need to set the selected buffer index in __io_uring_cmd_done(), suggesting that req->buf_index could be used instead, but acknowledged a possible oversight.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "possible oversight",
            "suggestion"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "I'm probably missing something here, but why can't the caller just use\nreq->buf_index for this?\n\n-- \nJens Axboe",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-09"
        },
        {
          "author": "Jens Axboe",
          "summary": "Reviewer Jens Axboe requested a branch with all patches and users applied, suggesting it would be easier for cross-referencing and making a good judgment on the helpers.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "requested information",
            "suggested improvement"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Generally looks pretty good - for context, do you have a branch with\nthese patches and the users on top too? Makes it a bit easier for cross\nreferencing, as some of these really do need an exposed user to make a\ngood judgement on the helpers.\n\nI know there's the older series, but I'm assuming the latter patches\nchanged somewhat too, and it'd be nicer to look at a current set rather\nthan go back to the older ones.\n\n-- \nJens Axboe",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-09"
        },
        {
          "author": "Jens Axboe",
          "summary": "Reviewer Jens Axboe suggested refactoring io_pbuf_get_region() to handle kernel-managed buffer rings by adding a new helper function, io_kbuf_get_region(), and modifying the existing function to check for the IOBL_KERNEL_MANAGED flag.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "requested changes",
            "minor nit"
          ],
          "has_inline_review": true,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "For this, I think just add another helper - leave io_pbuf_get_region()\nand add a bl->flags & IOBL_KERNEL_MANAGED error check in there, and\nadd a io_kbuf_get_region() or similar and have a !(bl->flags &\nIOBL_KERNEL_MANAGED) error check in that one.\n\nThat's easier to read, and there's little reason to avoid duplicating\nthe xa_load() part.\n\nMinor nit, but imho it's more readable that way.\n\n-- \nJens Axboe",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-09"
        },
        {
          "author": "Jens Axboe",
          "summary": "Reviewer Jens Axboe suggested using a pointer to struct io_buffer_list instead of a double pointer, and recommended either returning an error pointer or renaming the passed parameter to indicate it's a return value.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes"
          ],
          "has_inline_review": true,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Probably use the usual struct io_buffer_list *bl here and either use an\nERR_PTR return, or rename the passed on **bl to **blret or something.",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-09"
        },
        {
          "author": "Jens Axboe",
          "summary": "Jens Axboe suggested a more efficient way to check if a buffer is both a kernel-managed ring and pinned, by using a bitwise AND operation on the buffer's flags. He also recommended adding an early return for the case where the buffer is null.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "requested changes",
            "suggested improvement"
          ],
          "has_inline_review": true,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Usually done as:\n\n\tif ((bl->flags & (IOBL_BUF_RING|IOBL_PINNED)) == (IOBL_BUF_RING|IOBL_PINNED))\n\nand maybe then just have an earlier\n\n\tif (!bl)\n\t\tgoto err;",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-09"
        },
        {
          "author": "Jens Axboe",
          "summary": "Reviewer Jens Axboe suggested that the patch should not enforce a character limit on io_uring command strings, citing that exceeding 80 characters is acceptable in this context.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "requested change"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "to avoid making it way too long. For io_uring, it's fine to exceed 80\nchars where it makes sense.\n\n-- \nJens Axboe",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-09"
        }
      ],
      "analysis_source": "llm-per-reviewer",
      "patch_summary": "This patch sets the selected buffer index in __io_uring_cmd_done(), a function responsible for completing io_uring commands. The change is part of a larger series that introduces kernel-managed buffer rings, where the kernel allocates and manages buffers on behalf of applications. This allows for more efficient use of system resources and simplifies buffer management for applications using io_uring. The patch builds upon previous changes in the series, including support for kernel-managed buffer rings and recycling of buffers. By setting the selected buffer index, this patch enables proper completion of commands that involve buffer selection."
    },
    "2026-02-10": {
      "report_file": "2026-02-18_ollama_llama3.1-8b.html",
      "developer": "Joanne Koong",
      "reviews": [
        {
          "author": "Pavel Begunkov",
          "summary": "reviewer noted that the patch fences itself off from existing optimizations for huge pages, and suggested allowing regions to work with user-passed memory",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "optimization",
            "huge_pages"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "If you're creating a region, there should be no reason why it\ncan't work with user passed memory. You're fencing yourself off\noptimisations that are already there like huge pages.",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-10"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "Reviewer Pavel Begunkov noted that io_create_region() should be used instead of allocating buffers directly in IORING_REGISTER_KMBUF_RING, as it violates abstractions and suggested stripping buffer allocation from this function, replacing *_REGISTER_KMBUF_RING with *_REGISTER_PBUF_RING + a new flag or creating the buffer ring internally via an internal API. Additionally, he recommended requiring users to register a memory region of appropriate size using IORING_REGISTER_MEM_REGION.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes",
            "suggested improvements"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Please use io_create_region(), the new function does nothing new\nand only violates abstractions.\n\nProvided buffer rings with kernel addresses could be an interesting\nabstraction, but why is it also responsible for allocating buffers?\nWhat I'd do:\n\n1. Strip buffer allocation from IORING_REGISTER_KMBUF_RING.\n2. Replace *_REGISTER_KMBUF_RING with *_REGISTER_PBUF_RING + a new flag.\n    Or maybe don't expose it to the user at all and create it from\n    fuse via internal API.\n3. Require the user to register a memory region of appropriate size,\n    see IORING_REGISTER_MEM_REGION, ctx->param_region. Make fuse\n    populating the buffer ring using the memory region.\n\nI wanted to make regions shareable anyway (need it for other purposes),\nI can toss patches for that tomorrow.\n\nA separate question is whether extending buffer rings is the right\napproach as it seems like you're only using it for fuse requests and\nnot for passing buffers to normal requests, but I don't see the\nbig picture here.",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-10"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "reviewer noted that the patch's alignment requirement for buffers is unnecessary since io_create_region_multi_buf() has been removed, potentially wasting a lot of memory due to 64KB page alignment",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "wasted memory",
            "unnecessary alignment"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "With io_create_region_multi_buf() gone, you shouldn't need\nto align every buffer, that could be a lot of wasted memory\n(thinking about 64KB pages).",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-10"
        },
        {
          "author": "Caleb Mateos",
          "summary": "Reviewer Caleb Mateos noted that the patch's optimization in __io_uring_cmd_done() is unnecessary, as modern compilers will automatically perform this optimization and potentially optimize it further.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "optimization",
            "compiler"
          ],
          "has_inline_review": true,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "FWIW, modern compilers will perform this optimization automatically.\nThey'll even optimize it further to !(~bl->flags &\n(IOBL_BUF_RING|IOBL_PINNED)): https://godbolt.org/z/xGoP4TfhP\n\nBest,\nCaleb",
          "reply_to": "Jens Axboe",
          "message_date": "2026-02-10"
        },
        {
          "author": "Jens Axboe",
          "summary": "Reviewer Jens Axboe suggested that the patch should follow a common convention for setting selected buffer indices, making it easier to read and understand, and noted that the example in the patch is already following this convention.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "suggested improvement"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Sure, it's not about that, it's more about the common way of doing it,\nwhich makes it easier to read for people. FWIW, your example is easier\nto read too than the original.\n\n-- \nJens Axboe",
          "reply_to": "Caleb Mateos",
          "message_date": "2026-02-10"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "Author responded to a question about whether kernel-allocated buffers would limit optimizations possible with user-allocated buffers, specifically for huge pages, and noted that the kernel can already handle this through alloc_pages()",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "question"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Are there any optimizations with user-allocated buffers that wouldn't\nbe possible with kernel-allocated buffers? For huge pages, can't the\nkernel do this as well (eg I see in io_mem_alloc_compound(), it calls\ninto alloc_pages() with order > 0)?",
          "reply_to": "Pavel Begunkov",
          "message_date": "2026-02-10"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "Author Joanne Koong responded to Pavel Begunkov's feedback that the patch should only use io_create_region(), explaining that separate checks are needed between io_create_region() and io_create_region_multi_buf() for different allocation calls.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "There's separate checks needed between io_create_region() and\nio_create_region_multi_buf() (eg IORING_MEM_REGION_TYPE_USER flag\nchecking) and different allocation calls (eg\nio_region_allocate_pages() vs io_region_allocate_pages_multi_buf()).\nMaybe I'm misinterpreting your comment (or the code), but I'm not\nseeing how this can just use io_create_region().",
          "reply_to": "Pavel Begunkov",
          "message_date": "2026-02-10"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "Author Joanne Koong is responding to feedback about kernel-managed buffer rings, specifically addressing concerns about allocating buffers from userspace. She explains that registering buffers from userspace introduces additional complications and guarantees contiguity of pages when allocating from the kernel-side.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "request_for_clarification"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Conceptually, I think it makes the interface and lifecycle management\nsimpler/cleaner. With registering it from userspace, imo there's\nadditional complications with no tangible benefits, eg it's not\nguaranteed that the memory regions registered for the buffers are the\nsame size, with allocating it from the kernel-side we can guarantee\nthat the pages are allocated physically contiguously, userspace setup\nwith user-allocated buffers is less straightforward, etc. In general,\nI'm just not really seeing what advantages there are in allocating the\nbuffers from userspace. Could you elaborate on that part more?",
          "reply_to": "Pavel Begunkov",
          "message_date": "2026-02-10"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "Author addressed Pavel Begunkov's concern about squashing kernel-managed buffer rings into existing pbuf rings by explaining that pbuf rings would need to support pinning, which was previously dropped due to reviewer feedback.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "acknowledged a technical challenge",
            "explained reasoning"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "If kmbuf rings are squashed into pbuf rings, then pbuf rings will need\nto support pinning. In fuse, there are some contexts where you can't\ngrab the uring mutex because you're running in atomic context and this\ncan be encountered while recycling the buffer. I originally had a\npatch adding pinning to pbuf rings (to mitigate the overhead of\nregistered buffers lookups) but dropped it when Jens and Caleb didn't\nlike the idea. But for kmbuf rings, pinning will be necessary for\nfuse.",
          "reply_to": "Pavel Begunkov",
          "message_date": "2026-02-10"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "Author responded to Pavel Begunkov's feedback by clarifying that the term 'normal requests' is specific to fuse's use case and does not apply to other types of requests.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "no clear resolution signal"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "What are 'normal requests'? For fuse's use case, there are only fuse requests.\n\nThanks,\nJoanne",
          "reply_to": "Pavel Begunkov",
          "message_date": "2026-02-10"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "Author acknowledged that accessing the buffer index from the cmd_to_iocb_kiocb() function may be cumbersome and offered to add a helper function, but prefers returning the buf id as part of the io_br_sel struct.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "acknowledged a potential issue",
            "offered an alternative solution"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "The caller can, but from the caller side they only have access to the\ncmd so they would need to do something like\n\nstruct io_kiocb *req = cmd_to_iocb_kiocb(ent->cmd);\nbuf_id = req->buf_index;\n\nwhich may be kind of ugly with looking inside io-uring internals.\nMaybe a helper here would be nicer, something like\nio_uring_cmd_buf_id() or io_uring_req_buf_id(). It seemed cleaner to\nme to just return the buf id as part of the io_br_sel struct, but I'm\nhappy to do it another way if you have a preference.\n\nThanks,\nJoanne",
          "reply_to": "Jens Axboe",
          "message_date": "2026-02-10"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "Author acknowledged that further changes are needed and will address them in v2, including the reviewer's comments from other messages.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "acknowledged need for further changes",
            "will address in v2"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Thanks for reviewing the patches. The branch containing the userside\nchanges on top of these patches is in [1]. I'll make the changes you\npointed out in your other comments as part of v2. Once the discussion\nwith Pavel is resolved / figured out with the changes he wants for v2,\nI'll submit v2.\n\nThanks,\nJoanne\n\n[1] https://github.com/joannekoong/linux/commits/fuse_zero_copy/",
          "reply_to": "Jens Axboe",
          "message_date": "2026-02-10"
        }
      ],
      "analysis_source": "llm-per-reviewer",
      "patch_summary": "This patch sets the selected buffer index in __io_uring_cmd_done(), a function responsible for completing io_uring commands. The change is part of a larger series that introduces kernel-managed buffer rings, where the kernel allocates and manages buffers on behalf of applications. This allows for more efficient use of system resources and simplifies buffer management for applications using io_uring. The patch builds upon previous changes in the series, including support for kernel-managed buffer rings and recycling of buffers. By setting the selected buffer index, this patch enables proper completion of commands that involve buffer selection."
    },
    "2026-02-11": {
      "report_file": "2026-02-18_ollama_llama3.1-8b.html",
      "developer": "Joanne Koong",
      "reviews": [
        {
          "author": "Pavel Begunkov",
          "summary": "Reviewer noted that allocating 1MB in kernel space won't result in a PMD mappable huge page, unlike user space allocation which can register a 2MB buffer and reuse the remaining 1MB for other purposes.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested change to kernel memory allocation"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Yes, there is handful of differences. To name one, 1MB allocation won't\nget you a PMD mappable huge page, while user space can allocate 2MB,\nregister the first 1MB and reuse the rest for other purposes.",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-11"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "Pavel Begunkov suggested that instead of changing io_create_region() to be less strict, the caller should filter arguments to ensure only necessary types are passed",
          "sentiment": "neutral",
          "sentiment_signals": [
            "requested changes",
            "suggested alternative solution"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "If io_create_region() is too strict, let's discuss that in\nexamples if there are any, but it's likely not a good idea changing\nthat. If it's too lax, filter arguments in the caller. IOW, don't\npass IORING_MEM_REGION_TYPE_USER if it's not used.",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-11"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "Reviewer Pavel Begunkov noted that the memmap.c changes in the patch can be dropped as they are not necessary for kernel-managed buffer rings, and suggested that using io_create_region() would achieve similar results without introducing additional complexity.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes"
          ],
          "has_inline_review": true,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "I saw that and saying that all memmap.c changes can get dropped.\nYou're using it as one big virtually contig kernel memory range then\nchunked into buffers, and that's pretty much what you're getting with\nnormal io_create_region(). I get that you only need it to be\ncontiguous within a single buffer, but that's not what you're doing,\nand it'll be only worse than default io_create_region() e.g.\neffectively disabling any usefulness of io_mem_alloc_compound(),\nand ultimately you don't need to care.\n\nRegions shouldn't know anything about your buffers, how it's\nsubdivided after, etc.",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-11"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "Reviewer Pavel Begunkov suggested adding support for user-provided memory by setting the 'user_addr' field in the io_uring_region_desc structure when use_user_memory is true, and also set the IORING_MEM_REGION_TYPE_USER flag.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes"
          ],
          "has_inline_review": true,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "struct io_uring_region_desc rd = {};\ntotal_size = nr_bufs * buf_size;\nrd.size = PAGE_ALIGN(total_size);\nio_create_region(&region, &rd);\n\nAdd something like this for user provided memory:\n\nif (use_user_memory) {\n\trd.user_addr = uaddr;\n\trd.flags |= IORING_MEM_REGION_TYPE_USER;\n}",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-11"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "Pavel Begunkov suggested separating ring population from kernel API, noting that fuse module could control ring population and achieve same layout as current implementation",
          "sentiment": "neutral",
          "sentiment_signals": [
            "suggested separation",
            "noted potential for reuse"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "I don't think I follow. I'm saying that it might be interesting\nto separate rings from how and with what they're populated on the\nkernel API level, but the fuse kernel module can do the population\nand get exactly same layout as you currently have:\n\nint fuse_create_ring(size_t region_offset /* user space argument */) {\n\tstruct io_mapped_region *mr = get_mem_region(ctx);\n\t// that can take full control of the ring\n\tring = grab_empty_ring(io_uring_ctx);\n\n\tsize = nr_bufs * buf_size;\n\tif (region_offset + size > get_size(mr)) // + other validation\n\t\treturn error;\n\n\tbuf = mr_get_ptr(mr) + offset;\n\tfor (i = 0; i < nr_bufs; i++) {\n\t\tring_push_buffer(ring, buf, buf_size);\n\t\tbuf += buf_size;\n\t}\n}\n\nfuse might not care, but with empty rings other users will get a\nchannel they can use to do IO (e.g. read requests) using their\nkernel addresses in the future.",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-11"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "Reviewer Pavel Begunkov suggested that instead of introducing a new set of UAPI functions for kernel-managed buffer rings, the existing pbuf implementation could be modified to include a flag indicating whether the ring is kernel-managed, and then use this flag to gate pinning and other operations. This approach would simplify the code and avoid duplicating UAPI functions.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes"
          ],
          "has_inline_review": true,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "It'd change uapi but not internals, you already piggy back it\non pbuf implementation and differentiate with a flag.\n\nIt could basically be:\n\nif (flags & IOU_PBUF_RING_KM)\n\tbl->flags |= IOBL_KERNEL_MANAGED;\n\nPinning can be gated on that flag as well. Pretty likely uapi\nand internals will be a bit cleaner, but that's not a huge deal,\njust don't see why would you roll out a separate set of uapi\n([un]register, offsets, etc.) when essentially it can be treated\nas the same thing.",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-11"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "Reviewer Pavel Begunkov noted that the patch incorrectly pins the registered buffer table instead of providing buffer rings, and suggested an alternative approach where all memory is kept in one larger registered buffer.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes"
          ],
          "has_inline_review": true,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "IIRC, you was pinning the registered buffer table and not provided\nbuffer rings? Which would indeed be a bad idea. Thinking about it,\nfwiw, instead of creating multiple registered buffers and trying to\nlock the entire table, you could've kept all memory in one larger\nregistered buffer and pinned only it. It's already refcounted, so\nshouldn't have been much of a problem.",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-11"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "Reviewer Pavel Begunkov expressed concerns that creating many small regions for kernel-managed buffer rings would lead to unnecessary mmap()s, extra user space management, and wasted space, also raising suspicions about ring bound memory and buffer lifetimes.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "To explain why, I don't think that creating many small regions\nis a good direction going forward. In case of kernel allocation,\nit's extra mmap()s, extra user space management, and wasted space.\nFor user provided memory it's over-accounting and extra memory\nfootprint. It'll also give you better lifecycle guarantees, i.e.\nyou won't be able to free buffers while there are requests for the\ncontext. I'm not so sure about ring bound memory, let's say I have\nmy suspicions, and you'd need to be extra careful about buffer\nlifetimes even after a fuse instance dies.",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-11"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "reviewer suggested that kernel-managed buffer rings would be beneficial for operations like read and recv, which could utilize the filled rings without requiring opcode-specific code changes in kbuf.c",
          "sentiment": "neutral",
          "sentiment_signals": [
            "suggested improvement",
            "no clear objection"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Any kind of read/recv/etc. that can use provided buffers. It's\nwhere kernel memory filled rings would shine, as you'd be able\nto use them together without changing any opcode specific code.\nI.e. not changes in read request implementation, only kbuf.c\n\n-- \nPavel Begunkov",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-11"
        },
        {
          "author": "Christoph Hellwig",
          "summary": "Christoph Hellwig noted that pages mapped to userspace can be allocated in the kernel, allowing for a buffer ring that is only mapped read-only into userspace, enabling zero-copy raids if the device requires stable pages for checksumming or raid.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "neutral comment about design",
            "positive tone towards the design"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Any pages mapped to userspace can be allocated in the kernel as well.\n\nAnd I really do like this design, because it means we can have a\nbuffer ring that is only mapped read-only into userspace.  That way\nwe can still do zero-copy raids if the device requires stable pages\nfor checksumming or raid.  I was going to implement this as soon\nas this series lands upstream.",
          "reply_to": "Pavel Begunkov",
          "message_date": "2026-02-11"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "Author Joanne Koong addressed Pavel Begunkov's concern that using io_region_allocate_pages() in __io_uring_cmd_done() would fail due to excessive memory allocation, explaining that the current implementation bypasses this issue by allocating one buffer at a time. No fix is planned.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "explained reasoning",
            "no clear resolution"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "When I originally implemented it, I had it use\nio_region_allocate_pages() but this fails because it's allocating way\ntoo much memory at once. For fuse's use case, each buffer is usually\nat least 1 MB if not more. Allocating the memory one buffer a time in\nio_region_allocate_pages_multi_buf() bypasses the allocation errors I\nwas seeing. That's the main reason I don't think this can just use\nio_create_region().",
          "reply_to": "Pavel Begunkov",
          "message_date": "2026-02-11"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "Author clarifies her understanding of reviewer's feedback, confirming that she and Christoph thought the user should allocate buffers, but now realizes the kernel can allocate them through IORING_REGISTER_MEM_REGION.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "understanding"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Oh okay, from your first message I (and I think christoph too) thought\nwhat you were saying is that the user should be responsible for\nallocating the buffers with complete ownership over them, and then\njust pass those allocated to the kernel to use. But what you're saying\nis that just use a different way for getting the kernel to allocate\nthe buffers (eg through the IORING_REGISTER_MEM_REGION interface). Am\nI reading this correctly?",
          "reply_to": "Pavel Begunkov",
          "message_date": "2026-02-11"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "Author addressed a concern about code complexity and maintainability, agreeing that separating kernel-managed buffer rings from the pbuf API makes things clearer. They plan to restructure in v2 unless someone objects.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "acknowledged a fix is needed",
            "agreed to restructure"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "imo, it looked cleaner as a separate api because it has different\nexpectations and behaviors and squashing kmbuf into the pbuf api makes\nthe pbuf api needlessly more complex. Though I guess from the\nuserspace pov, liburing could have a wrapper that takes care of\nsetting up the pbuf details for kernel-managed pbufs. But in my head,\nhaving pbufs vs. kmbufs makes it clearer what each one does vs regular\npbufs vs. pbufs that are kernel-managed.\n\nEspecially with now having kmbufs go through the ioring mem region\ninterface, it makes things more confusing imo if they're combined, eg\npbufs that are kernel-managed are created empty and then populated\nfrom the kernel side by whatever subsystem is using them. Right now\nthere's only one mem region supported per ring, but in the future if\nthere's the possibility that multiple mem regions can be registered\n(eg if userspace doesn't know upfront what mem region length they'll\nneed), then we should also probably add in a region id param for the\nregistration arg, which if kmbuf rings go through the pbuf ring\nregistration api, is not possible to do.\n\nBut I'm happy to combine the interfaces and go with your suggestion.\nI'll make this change for v2 unless someone else objects.",
          "reply_to": "Pavel Begunkov",
          "message_date": "2026-02-11"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "The author acknowledged that they previously dropped a patch to pin the registered buffer table, not the pbuf ring, and no fix is planned.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "acknowledgment of prior mistake",
            "no clear resolution signal"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Yeah, you're right I misremembered and the objections / patch I\ndropped was pinning the registered buffer table, not the pbuf ring",
          "reply_to": "Pavel Begunkov",
          "message_date": "2026-02-11"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "Author is addressing Pavel Begunkov's feedback about how to handle sparse buffers populated by the kernel. She expresses uncertainty about implementing this idea and mentions potential issues with user experience, but does not commit to a fix or reversion.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "uncertainty",
            "no clear resolution"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Hmm, I'm not sure this idea would work for sparse buffers populated by\nthe kernel, unless those are automatically pinned too but then from\nthe user POV for unregistration they'd need to unregister buffers\nindividually instead of just calling IORING_UNREGISTER_BUFFERS but it\nmight be annoying for them to now need to know which buffers are\npinned vs not. When i benchmarked the fuse code with vs without pinned\nregistered buffers, it didn't seem to make much of a difference\nperformance-wise thankfully, so I just dropped it.",
          "reply_to": "Pavel Begunkov",
          "message_date": "2026-02-11"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "The author is addressing concerns about buffer allocation, specifically whether individual buffers should be allocated separately by the kernel. The author clarifies their intention and explains that having separate allocations allows for better physical contiguity of the entire buffer region.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "To clarify, is this in reply to why the individual buffers shouldn't\nbe allocated separately by the kernel?\nI added a comment about this above in the discussion about\nio_region_allocate_pages_multi_buf(), and if the memory allocation\nissue I was seeing is bypassable and the region can be allocated all\nat once, I'm happy to make that change. With having the allocation be\nseparate buffers though, I'm not sure I agree that there are extra\nmmaps / userspace management. All the pages across the buffers are\nvmapped together and the userspace just needs to do 1 mmap call for\nthem. On the userspace side, I don't think there's more management\nsince the mmapped address represents the range across all the buffers.\nI'm not seeing how there's wasted space either since the only\nrequirement is that the buffer size is page aligned. I think also\nthere's a higher chance of the entire buffer region being physically\ncontiguous if each buffer is allocated separately vs. all the buffers\nare allocated as 1 region. I don't feel strongly about this either way\nand I'm happy to allocate the entire region at once if that's\npossible.",
          "reply_to": "Pavel Begunkov",
          "message_date": "2026-02-11"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "Author asked for clarification on reviewer's concerns about over-accounting and extra memory footprint in kernel-managed buffer rings.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarifying question",
            "request for explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Just out of curiosity, could you elaborate on the over-accounting and\nextra memory footprint? I was under the impression it would be the\nsame since the accounting gets adjusted by the total bytes allocated?\nFor the extra memory footprint, is the extra footprint from the\nmetadata to describe each buffer region, or are you referring to\nsomething else?",
          "reply_to": "Pavel Begunkov",
          "message_date": "2026-02-11"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "Author is addressing feedback from Pavel Begunkov and others regarding the io_uring buffer rings series. She acknowledges that changes are needed in v2 to address concerns about API consistency, kernel-managed buffer allocation, and user-space interaction. Specifically, she plans to remove the KMBUF_RING API, have users use PBUF_RING with a flag for kernel-managed rings, and add APIs for subsystems to populate kernel-managed buffer rings.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "acknowledges fix is needed",
            "plans changes in v2"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Thanks for your input on the series. To iterate / sum up, these are\nchanges for v2 I'll be making:\n- api-wise from userspace/liburing: get rid of KMBUF_RING api\ninterface and have users go through PBUF_RING api instead with a flag\nindicating the ring is kernel-managed\n- have kernel buffer allocation go through IORING_REGISTER_MEM_REGION\ninstead, which means when the pbuf ring is created and the\nkernel-managed flag is set, the ring will be empty. The memory region\nwill need to be registered before the mmap call to the ring fd.\n- add apis for subsystems to populate a kernel-managed buffer ring\nwith addresses from the registered mem region\n\nDoes this align with your understanding of the conversation as well or\nis there anything I'm missing?\n\nAnd Christoph, do these changes for v2 work for your use case as well?\n\nThanks,\nJoanne",
          "reply_to": "Pavel Begunkov",
          "message_date": "2026-02-11"
        }
      ],
      "analysis_source": "llm-per-reviewer",
      "patch_summary": "This patch sets the selected buffer index in __io_uring_cmd_done(), a function responsible for completing io_uring commands. The change is part of a larger series that introduces kernel-managed buffer rings, where the kernel allocates and manages buffers on behalf of applications. This allows for more efficient use of system resources and simplifies buffer management for applications using io_uring. The patch builds upon previous changes in the series, including support for kernel-managed buffer rings and recycling of buffers. By setting the selected buffer index, this patch enables proper completion of commands that involve buffer selection."
    },
    "2026-02-12": {
      "report_file": "2026-02-18_ollama_llama3.1-8b.html",
      "developer": "Joanne Koong",
      "reviews": [
        {
          "author": "Christoph Hellwig",
          "summary": "Christoph Hellwig expressed concerns that the current implementation does not meet his use case requirements, where the kernel fully controls buffer allocation and guarantees user processes can only read from allocated memory.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "I'm arguing exactly against this.  For my use case I need a setup\nwhere the kernel controls the allocation fully and guarantees user\nprocesses can only read the memory but never write to it.  I'd love\nto be able to piggy back than onto your work.",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-12"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "reviewer pointed out that using power-of-2 round ups for memory allocations will result in wasted memory, as 1MB allocations will not become 2MB huge pages, and also raised concerns about 1GB huge pages, suggesting the user should be able to make informed placement decisions",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "waste of memory",
            "user control"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "pow2 round ups will waste memory. 1MB allocations will never\nbecome 2MB huge pages. And there is a separate question of\n1GB huge pages. The user can be smarter about all placement\ndecisions.",
          "reply_to": "Christoph Hellwig",
          "message_date": "2026-02-12"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "The reviewer suggests that the io_uring uapi should include fields for optional user-provided memory, and is neutral about fuse refusing to bind to buffer rings it doesn't like.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "neutral opinion on uapi design",
            "no strong stance on fuse behavior"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "That's an interesting case. To be clear, user provided memory is\nan optional feature for pbuf rings / regions / etc., and I think\nthe io_uring uapi should leave fields for the feature. However, I\nhave nothing against fuse refusing to bind to buffer rings it\ndoesn't like.\n\n-- \nPavel Begunkov",
          "reply_to": "Christoph Hellwig",
          "message_date": "2026-02-12"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "Reviewer Pavel Begunkov suggested modifying IORING_REGISTER_MEM_REGION to support read-only registrations, and proposed adding a new registration flag or rejecting unsupported setups during initialization.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "request for clarification",
            "no clear objection"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "IORING_REGISTER_MEM_REGION supports both types of allocations. It can\nhave a new registration flag for read-only, and then you either make\nthe bounce avoidance optional or reject binding fuse to unsupported\nsetups during init. Any arguments against that? I need to go over\nJoanne's reply, but I don't see any contradiction in principal with\nyour use case.\n\n-- \nPavel Begunkov",
          "reply_to": "Christoph Hellwig",
          "message_date": "2026-02-12"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "Author clarified that kernel-managed buffer rings can be used internally by the kernel without explicit user registration, addressing concerns about semantic equivalence to IORING_REGISTER_MEM_REGION.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarifying question",
            "explaining reasoning"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "By \"control the allocation fully\" do you mean for your use case, the\nallocation/setup isn't triggered by userspace but is initiated by the\nkernel (eg user never explicitly registers any kbuf ring, the kernel\njust uses the kbuf ring data structure internally and users can read\nthe buffer contents)? If userspace initiates the setup of the kbuf\nring, going through IORING_REGISTER_MEM_REGION would be semantically\nthe same, except the buffer allocation by the kernel now happens\nbefore the ring is created and then later populated into the ring.\nuserspace would still need to make an mmap call to the region and the\nkernel could enforce that as read-only. But if userspace doesn't\ninitiate the setup, then going through IORING_REGISTER_MEM_REGION gets\nuglier.",
          "reply_to": "Pavel Begunkov",
          "message_date": "2026-02-12"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "Author acknowledged a potential over-engineering of the current design, suggesting an alternative approach where a straightforward kmbuf ring uses the pbuf interface and a future interface for IORING_REGISTERED_MEM_REGIONS is added if needed.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "overkill",
            "over-engineered"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "So i guess the flow would have to be:\na) user calls io_uring_register_region(&ring, &mem_region_reg) with\nmem_region_reg.region_uptr's size field set to the total buffer size\n(and mem_region_reg.flags read-only bit set if needed)\n     kernel allocates region\nb) user calls mmap() to get the address of the region. If read-only\nbit was set, it gets a read-only address\nc) user calls io_uring_register_buf_ring(&ring, &buf_reg, flags) with\nbuf_reg.flags |= IOU_PBUF_RING_KERNEL_MANAGED\n     kernel creates an empty kernel-managed ring. None of the buffers\nare populated\nd) user tells X subsystem to populate the ring starting from offset Z\nin the registered mem region\ne) on the kernel side, the subsystem populates the ring starting from\noffset Z, filling it up using the buf_size and ring_entries values\nthat the user registered the ring with in c)\n\nTo be completely honest, the more I look at this the more this feels\nlike overkill / over-engineered to me. I get that now the user can do\nthe PMD optimization, but does that actually lead to noticeable\nperformance benefits? It seems especially confusing with them going\nthrough the same pbuf ring interface but having totally different\nexpectations.\n\nWhat about adding a straightforward kmbuf ring that goes through the\npbuf interface (eg the design in this patchset) and then in the future\nadding an interface for pbuf rings (both kernel-managed and\nnon-kernel-managed) to go through IORING_REGISTERED_MEM_REGIONS if\nusers end up needing/wanting to have their rings populated that way?\n\nThanks,\nJoanne",
          "reply_to": "Pavel Begunkov",
          "message_date": "2026-02-12"
        },
        {
          "author": "Christoph Hellwig",
          "summary": "Reviewer noted that instead of optimizing for buffer selection, it would be simpler and more effective to use a multiple of PTE levels to mitigate TLB pressure, as this approach is easier to implement and maintain.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "requested alternative solution"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Sure.  But if the application cares that much about TLB pressure\nI'd just round up to nice multtiple of PTE levels.",
          "reply_to": "Pavel Begunkov",
          "message_date": "2026-02-12"
        },
        {
          "author": "Christoph Hellwig",
          "summary": "Christoph Hellwig questioned the meaning of 'pbuf' in the patch description, expressing confusion about the fixed buffer API and its relation to io_uring_register_buffers*",
          "sentiment": "neutral",
          "sentiment_signals": [
            "confusion",
            "lack of clarity"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Can you clarify what you mean with 'pbuf'?  The only fixed buffer API I\nknow is io_uring_register_buffers* which always takes user provided\nbuffers, so I have a hard time parsing what you're saying there.  But\nthat might just be sign that I'm no expert in io_uring APIs, and that\nweb searches have degraded to the point of not being very useful\nanymore.",
          "reply_to": "Pavel Begunkov",
          "message_date": "2026-02-12"
        },
        {
          "author": "Christoph Hellwig",
          "summary": "Reviewer noted that IORING_REGISTER_MEM_REGION's purpose is unclear, as it is described in both the commit message and public documentation as related to cqs (completion queues), but this seems inconsistent.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "inconsistency",
            "unclear"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "IORING_REGISTER_MEM_REGION seems to be all about cqs from both your\ncommit message and the public documentation.  I'm confused.",
          "reply_to": "Pavel Begunkov",
          "message_date": "2026-02-12"
        },
        {
          "author": "Christoph Hellwig",
          "summary": "reviewer noted that the patch does not address their specific use case of block and file system I/O, which is unrelated to the fuse over io_uring series",
          "sentiment": "neutral",
          "sentiment_signals": [
            "use case mismatch"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "My use case is not about fuse, but good old block and file system\nI/O.",
          "reply_to": "Pavel Begunkov",
          "message_date": "2026-02-12"
        },
        {
          "author": "Christoph Hellwig",
          "summary": "Christoph Hellwig noted that io_uring_register_buffers() only pins memory, allowing applications or other processes to modify it, which can cause issues for file systems and storage devices that need to verify checksums or rebuild data from parity.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "The idea is that the application tells the kernel that it wants to use\na fixed buffer pool for reads.  Right now the application does this\nusing io_uring_register_buffers().  The problem with that is that\nio_uring_register_buffers ends up just doing a pin of the memory,\nbut the application or, in case of shared memory, someone else could\nstill modify the memory.  If the underlying file system or storage\ndevice needs verify checksums, or worse rebuild data from parity\n(or uncompress), it needs to ensure that the memory it is operating\non can't be modified by someone else.\n\nSo I've been thinking of a version of io_uring_register_buffers where\nthe buffers are not provided by the application, but instead by the\nkernel and mapped into the application address space read-only for\na while, and I thought I could implement this on top of your series,\nbut I have to admit I haven't really looked into the details all\nthat much.",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-12"
        },
        {
          "author": "Christoph Hellwig",
          "summary": "reviewer noted that the patch's focus on PMD mappings is not relevant to all architectures, specifically mentioning AMD and ARM",
          "sentiment": "neutral",
          "sentiment_signals": [
            "NEEDS_WORK",
            "POSITIVE"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Yes.  The PMD mapping also is not that relevant.  Both AMD (implicit)\nand ARM (explicit) have optimizations for contiguous PTEs that are\nalmost as valuable.",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-12"
        }
      ],
      "analysis_source": "llm-per-reviewer",
      "patch_summary": "This patch sets the selected buffer index in __io_uring_cmd_done(), a function responsible for completing io_uring commands. The change is part of a larger series that introduces kernel-managed buffer rings, where the kernel allocates and manages buffers on behalf of applications. This allows for more efficient use of system resources and simplifies buffer management for applications using io_uring. The patch builds upon previous changes in the series, including support for kernel-managed buffer rings and recycling of buffers. By setting the selected buffer index, this patch enables proper completion of commands that involve buffer selection."
    },
    "2026-02-13": {
      "report_file": "2026-02-18_ollama_llama3.1-8b.html",
      "developer": "Joanne Koong",
      "reviews": [
        {
          "author": "Pavel Begunkov",
          "summary": "The reviewer questioned the inflexibility of the current implementation, where payload buffers are created together with the ring and via a new io_uring uapi, which requires a fixed number of buffers matching the ring entries. This leads to potential issues such as buffer memory having different lifetimes than the ring object, making it difficult to use the km buffer ring with other types of io_uring requests like recv.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "infelicities in design",
            "potential for kernel crashes"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Registered, aka fixed, buffers are the ones you pass to\nIORING_OP_[READ,WRITE]_FIXED and some other requests. It's normally\ncreated by io_uring_register_buffers*() / IORING_REGISTER_BUFFERS*\nwith user memory, but there are special cases when it's installed\ninternally by other kernel components, e.g. ublk.\nThis series has nothing to do with them, and relevant parts of\nthe discussion here don't mention them either.\n\nProvided buffer rings, a.k.a pbuf rings, IORING_REGISTER_PBUF_RING\nis a kernel-user shared ring. The entries are user buffers\n{uaddr, size}. The user space adds entries, the kernel (io_uring\nrequests) consumes them and issues I/O using the user addresses.\nE.g. you can issue a IORING_OP_RECV request (+IOSQE_BUFFER_SELECT)\nand it'll grab a buffer from the ring instead of using sqe->addr.\n\npbuf rings, IORING_REGISTER_MEM_REGION, completion/submission\nqueues and all other kernel-user rings/etc. are internally based\non so called regions. All of them support both user allocated\nmemory and kernel allocations + mmap.\n\nThis series essentially creates provided buffer rings, where\n1. the ring now contains kernel addresses\n2. the ring itself is in-kernel only and not shared with user space\n3. it also allocates kernel buffers (as a region), populates the ring\n    with them, and allows mapping the buffers into the user space.\n\nFuse is doing both adding (kernel) buffers to the ring and consuming\nthem. At which point it's not clear:\n\n1. Why it even needs io_uring provided buffer rings, it can be all\n    contained in fuse. Maybe it's trying to reuse pbuf ring code as\n    basically an internal memory allocator, but then why expose buffer\n    rings as an io_uring uapi instead of keeping it internally.\n\n    That's also why I mentioned whether those buffers are supposed to\n    be used with other types of io_uring requests like recv, etc.\n\n2. Why making io_uring to allocate payload memory. The answer to which\n    is probably to reuse the region api with mmap and so on. And why\n    payload buffers are inseparably created together with the ring\n    and via a new io_uring uapi.\n\n    And yes, I believe in the current form it's inflexible, it requires\n    a new io_uring uapi. It requires the number of buffers to match\n    the number of ring entries, which are related but not the same\n    thing. You can't easily add more memory as it's bound to the ring\n    object. The buffer memory won't even have same lifetime as the\n    ring object -- allow using that km buffer ring with recv requests\n    and highly likely I'll most likely give you a way to crash the\n    kernel.\n\nBut hey, I'm tired. I don't have any beef here and am only trying\nto make it a bit cleaner and flexible for fuse in the first place\nwithout even questioning the I/O path. If everyone believes\neverything is right, just ask Jens to merge it.\n\n-- \nPavel Begunkov",
          "reply_to": "Christoph Hellwig",
          "message_date": "2026-02-13"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "Pavel Begunkov noted that the current implementation of kernel-managed buffer rings in this patchset uses io_uring regions for huge payload buffers, which was not intended by the original design.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "huge payload buffers",
            "not intended"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Think of it as an area of memory for kernel-user communication. Used\nfor syscall parameters passing to avoid copy_from_user, but I added\nit for a bunch of use cases. We'll hopefully get support at some\npoint for passing request arguments like struct iovec. BPF patches\nuse it for communication. I need to respin patches placing SQ/CQ onto\nit (avoid some memory waste).\n\nTbh, I never meant it nor io_uring regions to be used for huge\npayload buffers, but this series already uses regions for that.",
          "reply_to": "Christoph Hellwig",
          "message_date": "2026-02-13"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "Reviewer Pavel Begunkov questioned the feasibility of kernel-managed buffer rings in io_uring without a kernel component returning buffers into the ring, and suggested that this might be addressed through an additional API.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes",
            "additional API"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Then I'm confused. Take a look at the other reply, this series is\nabout buffer rings with kernel memory, it can't work without a kernel\ncomponent returning buffers into the ring, and io_uring doesn't do\nthat. But maybe you're thinking about adding some more elaborate API.\n\nIIUC, Joanne also wants to add support for fuse installing registered\nbuffers, which would allow zero-copy, but those got split out of\nthis series.\n\n-- \nPavel Begunkov",
          "reply_to": "Christoph Hellwig",
          "message_date": "2026-02-13"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "reviewer suggested working around a potential issue in __io_uring_cmd_done() by wrapping the problematic code into a loop, and noted that the feature is intended for metadata like fuse headers and payloads",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested change",
            "potential issue"
          ],
          "has_inline_review": true,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Let's fix that then. For now, just work it around by wrapping\ninto a loop.\n\nBtw, I thought you're going to use it for metadata like some\nfuse headers and payloads would be zero copied by installing\nit as registered buffers.\n\n...",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-13"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "Reviewer Pavel Begunkov noted that the patch should disentangle memory allocation from ring creation in the io_uring uapi and move ring population into fuse, where it can be populated by the kernel without user space access to the ring.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "no clear signal"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "The main point is disentangling memory allocation from ring\ncreation in the io_uring uapi, and moving ring population\ninto fuse instead of doing it at creation. And it'll still be\npopulated by the kernel (fuse), user space doesn't have access\nto the ring. IORING_REGISTER_MEM_REGION is just the easiest way\nto achieve that without any extra uapi.\n\n...",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-13"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "Reviewer noted that the differences between the two buffer allocation methods are minimal and suggested making them a single opcode if possible",
          "sentiment": "neutral",
          "sentiment_signals": [
            "no strong opinion",
            "open to suggestion"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "It appeared to me that they're different because of special\nregion path and embedded buffer allocations, and otherwise\ndifferences would be minimal. But if you think it's still\nbetter to be made as a separate opcode, I'm not opposing it,\ngo for it.",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-13"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "The reviewer questioned how buffer rings are looked up from io_uring by fuse, suggesting a control path io-uring command to bind buffer rings and passing necessary parameters through it. They also proposed that the ring part does not need to be exposed as an io_uring uapi.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes",
            "suggested improvements"
          ],
          "has_inline_review": true,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Not having patches using the functionality is inconvenient. How\nfuse looks up the buffer ring from io_uring? I could imagine you\nhave some control path io-uring command:\n\ncase FUSE_CMD_BIND_BUFFER_RING:\n\treturn bind_queue(params);\n\nThen you can pass all necessary parameters to it, pseudo code:\n\nstruct fuse_bind_kmbuf_ring_params {\n\tregion_id;\n\tbuf_ring_id;\n\t...\n};\n\nbind_queue(cmd, struct fuse_bind_kmbuf_ring_params *p)\n{\n\tregion = io_uring_get_region(cmd, p->region_id);\n\t// get exclusive access:\n\tbuf_ring = io_uring_get_buf_ring(cmd, p->buf_ring_id);\n\n\tif (!validate_buf_ring(buf_ring))\n\t\treturn NOTSUPPORTED;\n\n\tio_uring_pin(buf_ring);\n\tfuse_populate_buf_ring(buf_ring, region, ...);\n}\n\nDoes that match expectations? I don't think you even need\nthe ring part exposed as an io_uring uapi, tbh, as it\nstays completely in fuse and doesn't meaningfully interact\nwith the rest of io_uring.\n\n...",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-13"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "reviewer pointed out that the patch is unrelated to their previous discussion about using IORING_REGISTER_MEM_REGION instead of a separate region, and that this change is independent from whether buffers should be bound to the ring",
          "sentiment": "neutral",
          "sentiment_signals": [
            "unrelated discussion",
            "independent issue"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "That was about an argument for using IORING_REGISTER_MEM_REGION\ninstead a separate region. And it's separate from whether\nbuffers should be bound to the ring.",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-13"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "reviewer noted that when allocating huge pages for non-power-of-2 buffer sizes, the kernel may allocate a larger page than needed, potentially wasting memory",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "potential memory waste",
            "non-standard allocation size"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "I shouldn't affect you much since you have such large buffers,\nbut imagine the total allocation size is not being pow2, and\nthe kernel allocating it as a single folio. E.g. 3 buffers,\n0.5 MB each, total = 1.5MB, and the kernel allocates a 2MB\nhuge page.\n\n-- \nPavel Begunkov",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-13"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "reviewer argued that the series does not address registered buffers and suggested separating buffer allocation for io_uring",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "There is nothing about registered buffers in this series. And even\nif you try to reuse buffer allocation out of it, it'll come with\na circular buffer you'll have no need for. And I'm pretty much\narguing about separating those for io_uring.\n\n-- \nPavel Begunkov",
          "reply_to": "Christoph Hellwig",
          "message_date": "2026-02-13"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "Reviewer Pavel Begunkov suggested reusing regions for allocations and mmap()ing, wrapping them into a registered buffer to avoid vmap'ing, which is not needed.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "FWIW, the easiest solution is to internally reuse regions for\nallocations and mmap()'ing and wrap it into a registered buffer.\nIt just need to make vmap'ing optional as it won't be needed.\n\n-- \nPavel Begunkov",
          "reply_to": "",
          "message_date": "2026-02-13"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "Pavel Begunkov noted that the io_uring uapi should not be tied to fuse-specific requirements, such as uniform buffer sizes, matching ring size, and kernel-allocated buffers, which restricts its use with other requests like recv/read. He suggested separating payload buffers and rings in the uapi perspective.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "No, it's mainly about not keeping payload buffers and rings in the same\nobject from the io_uring uapi perspective.\n\n1. If it's an io_uring uapi, it shouldn't be fuse specific or with\na bunch of use case specific expectations attached. Why does it\nrequire all buffers to be uniform in size? Why does it require\nthe ring size to match the number of buffers? Why does it require\nbuffers to be allocated by io_uring in the first place? Maybe some\nsubsystem got memory from somewhere else and wants to do use it\nwith io_uring. Why does it need to know the total size at creation,\nand what would you do if you want to add more memory at runtime\nwhile using the same ring?\n\n2. If it's meant to be fuse specific and _not_ used with other requests\nlike recv/read/etc., then what's the point of having it as an io_uring\nuapi? Which also adds additional trouble like the once you're solving\nwith pinning.\n\nIf it's supposed to be used with other requests, then buffers and\nrings will have different in-kernel lifetime expectations imposed\nby io_uring, so having them together won't even help with\nmanagement.\n\nI have a strong opinion about the memmap.c change. For the\nrest, if you believe it's fine, just send it out and let Jens\ndecide.",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-13"
        },
        {
          "author": "Pavel Begunkov",
          "summary": "reviewer questioned the assumption that buffer rings and buffers are separate entities, citing uncertainty about differing expectations between in-kernel kernel-managed buffers and user-visible buffers",
          "sentiment": "neutral",
          "sentiment_signals": [
            "uncertainty",
            "questioning"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "It's predicated on separating buffers from rings, see above,\nand assuming that I'm not sure what expectations are different\napart from one being in-kernel with kernel addresses and the\nother user visible with user addresses.\n\n-- \nPavel Begunkov",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-13"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "Author addressed Pavel Begunkov's concern about wasted space in io_ring buffers by explaining the benefits of using a circular buffer, specifically for Christoph's use case and fuse's needs.",
          "sentiment": "positive",
          "sentiment_signals": [
            "acknowledged benefit",
            "explained reasoning"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "I think the circular buffer will be useful for Christoph's use case in\nthe same way it'll be useful for fuse's. The read payload could be\ndifferently sized across requests, so it's a lot of wasted space to\nhave to allocate a buffer large enough to support the max-size request\nper entry in the io_ring. With using a circular buffer, buffers have a\nway to be shared across entries, which means we can significantly\nreduce how much memory needs to be allocated.\n\nThanks,\nJoanne",
          "reply_to": "Pavel Begunkov",
          "message_date": "2026-02-13"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "Author acknowledged that Christoph Hellwig's use case requires read-only buffers and agreed that their proposed solution benefits from incremental buffer consumption, but did not explicitly state whether a fix is planned.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "acknowledged same use case",
            "agreed on memory wins"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "(resending because I hit reply instead of reply-all)\n\nI think we have the exact same use case, except your buffers need to\nbe read-only. I think your use case benefits from the same memory wins\nwe'll get with incremental buffer consumption, which is the primary\nreason fuse is using a bufring instead of fixed buffers.",
          "reply_to": "Christoph Hellwig",
          "message_date": "2026-02-13"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "Author addressed Christoph's concern about how to handle read-only mappings for kernel-managed buffer rings, proposing a solution involving passing a read-only flag from userspace and checking it when the mmap call is made.",
          "sentiment": "positive",
          "sentiment_signals": [
            "author offered a specific solution",
            "expressed willingness to add patch"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "I think you can and it'll be very easy to do so. All that would be\nneeded is to pass in a read-only flag from the userspace side when it\nregisters the bufring, and then when userspace makes the mmap call to\nthe bufring, the kernel checks if that read-only flag is set on the\nbufring and if so returns a read-only mapping. I'm happy to add that\npatch to this series if that would make things easier for you. The\nio_uring_register_buffers() api registers fixed buffers (which have to\nbe user-allocated memory) so you would need to go through the\nio_uring_register_buf_ring() api once kmbufs are squashed into the\npbuf interface.\n\nWith going through IORING_MEM_REGION, this would work for your use\ncase as well. The user would have to register the mem region with\nio_uring_register_region() and pass in a read-only flag, and then the\nkernel will allocate the memory region. Then userspace would mmap the\nmemory region and on the kernel side, it would set the mapping to be\nread-only. When the kmbufring then gets registered, the buffers in it\nwill be empty. The filesystem will then have to populate the buffers\nin it from the mem region that was previously registered.\n\nThanks,\nJoanne",
          "reply_to": "Christoph Hellwig",
          "message_date": "2026-02-13"
        },
        {
          "author": "Bernd Schubert",
          "summary": "Reviewer questioned the purpose of sharing buffers across io_uring entries, suggesting it would only reduce the ring size and not provide any benefits.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "questioning the design",
            "expressed skepticism"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Dunno, what we actually want is requests of multiple sizes. Sharing\nbuffers across entries sounds like just reducing the ring size - I\npersonally don't see the point here.\n\n\nThanks,\nBernd",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-13"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "Author clarified that kernel-managed buffer rings allow concurrent access to different regions of a shared buffer, responding to a question about sharing buffers across entries.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "By \"sharing buffers across entries\" what I mean is different regions\nof the buffer can now be used concurrently by multiple entries.\n\nThanks,\nJoanne",
          "reply_to": "Bernd Schubert",
          "message_date": "2026-02-13"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "The author addressed Pavel Begunkov's concern about the need for kernel-managed buffer rings, explaining that fuse requires the kernel to control buffer recycling due to its use case of passing data between the kernel and server.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "The most important part and the whole reason fuse needs the buffer\nring to be kernel-managed is because the kernel needs to control when\nbuffers get recycled back into the ring. For fuse's use case, the\nbuffer is used for passing data between the kernel and the server. We\ncan't have the server recycle the buffer because the server writes\nback data to the kernel in that buffer when it submits the sqe. After\nfuse receives the sqe and reads the reply from the server, it then\nneeds to recycle that buffer back into the ring so it can be reused\nfor a future cqe (eg sending a future request).",
          "reply_to": "Pavel Begunkov",
          "message_date": "2026-02-13"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "Author acknowledged that the selected buffer index needs to be set in __io_uring_cmd_done() for userspace/server side io-uring operations, and agreed to modify the code accordingly.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "acknowledged a fix is needed",
            "agreed to modify the code"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "On the userspace/server side, it uses the buffers for other io-uring\noperations (eg reading or writing the contents from/to a\nlocally-backed file).",
          "reply_to": "Pavel Begunkov",
          "message_date": "2026-02-13"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "The author addressed Pavel's feedback about using a registered memory region, stating that she doesn't think most use cases of kmbufs benefit from the optimizations it provides, and prefers to keep the implementation simple.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "acknowledged a potential optimization",
            "expressed concern about added complexity"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "My main motivation for this is simplicity. I see (and thanks for\nexplaining) that using a registered mem region allows the use of some\noptimizations (the only one I know of right now is the PMD one you\nmentioned but maybe there's more I'm missing) that could be useful for\nsome workloads, but I don't think (and this could just be my lack of\nunderstanding of what more optimizations there are) most use cases of\nkmbufs benefit from those optimizations, so to me it feels like we're\nadding non-trivial complexity for no noticeable benefit.\n\nI feel like we get the best of both worlds by letting users have both:\nthe simple kernel-managed pbuf where the kernel allocates the buffers\nand the buffers are tied to the lifecycle of the ring, and the more\nadvanced kernel-managed pbuf where buffers are tied to a registered\nmemory region that the subsystem is responsible for later populating\nthe ring with.",
          "reply_to": "Pavel Begunkov",
          "message_date": "2026-02-13"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "Author addressed Pavel Begunkov's concern that combining kernel-managed buffer rings (kmbufs) and user-provided buffer rings (pbufs) in a single interface would be confusing, particularly if IORING_MEM_REGION is used. The author agrees with the suggestion to separate kmbufs from pbufs and plans to make this change in v2 by having kmbufs go through the pbuf uapi.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "acknowledges a fix is needed",
            "plans to restructure in v2"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "imo it felt cleaner to have a new uapi for it because kmbufs and pbufs\nhave different expectations and behaviors (eg pbufs only work with\nuser-provided buffers and requires userspace to populate the ring\nbefore using it, whereas for kmbufs the kernel allocates the buffers\nand populates it for you; pbufs require userspace to recycle back the\nbuffer, whereas for kmbufs the kernel is the one in control of\nrecycling) and from the user pov it seemed confusing to have kmbufs as\npart of the pbuf ring uapi, instead of separating it out as a\ndifferent type of ringbuffer with a different expectation and\nbehavior. I was trying to make the point that combining the interface\nif we go with IORING_MEM_REGION gets even more confusing because now\npbufs that are kernel-managed are also empty at initialization and\nonly can point to areas inside a registered mem region and the\nresponsibility of populating it is now on whatever subsystem is using\nit.\n\nI still have this opinion but I also think in general, you likely know\nbetter than I do what kind of io-uring uapi is best for io-uring's\nusers. For v2 I'll have kmbufs go through the pbuf uapi.",
          "reply_to": "Pavel Begunkov",
          "message_date": "2026-02-13"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "Author responded to feedback that existing code for non-kernel managed pbuf rings uses ring_entries as a marker for supported buffer count, and suggested this can be easily fixed by passing the number of buffers from uapi for kernel-managed pbuf rings.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "I'm not really seeing what the purpose of having a ring entry with no\nbuffer associated with it is. In the existing code for non-kernel\nmanaged pbuf rings, there's the same tie between reg->ring_entries\nbeing used as the marker for how many buffers the ring supports. But\nif the number of buffers should be different than the number of ring\nentries, this can be easily fixed by passing in the number of buffers\nfrom the uapi for kernel-managed pbuf rings.",
          "reply_to": "Pavel Begunkov",
          "message_date": "2026-02-13"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "Author acknowledges that adding more memory to a registered mem region is difficult, but doesn't explicitly address Pavel's concern about the selected buffer index in __io_uring_cmd_done().",
          "sentiment": "neutral",
          "sentiment_signals": [
            "acknowledging a challenge",
            "explaining complexity"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "To play devil's advocate, we also can't easily add more memory to the\nmem region once it's been registered. I think there's also a worse\npenalty where the user needs to know upfront how much memory to\nallocate for the mem region for the lifetime of the ring, which imo\nmay be hard to do (eg if a kernel-managed buf ring only needs to be\nregistered for some code paths and not others, the mem region\nregistration would still have to allocate the memory a potential kbuf\nring would use).",
          "reply_to": "Pavel Begunkov",
          "message_date": "2026-02-13"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "Author Joanne Koong responded to feedback from Pavel Begunkov by clarifying that buffer memory has the same lifetime as the ring object, and only gets freed when the ring itself is freed.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "I'm a bit confused by this part. The buffer memory does have the same\nlifetime as the ring object, no? The buffers only get freed when the\nring itself is freed.",
          "reply_to": "Pavel Begunkov",
          "message_date": "2026-02-13"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "Author is addressing feedback about whether kernel-managed buffer rings should be supported in a simple interface or also through a registered memory region, and is open to revising the patch based on reviewer's preference.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "open to revision",
            "no clear resolution signal"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "I appreciate you looking at this and giving your feedback and insight.\nThank you for doing so. I don't want to merge in something you're\nunhappy with.\n\nAre you open to having support for both a simple kernel-managed pbuf\ninterface and later on if/when the need arises, a kernel-managed pbuf\ninterface that goes through a registered memory region? If the answer\nis no, then I'll make the change to have kmbufs go through the\nregistered memory region.\n\nThanks,\nJoanne",
          "reply_to": "Pavel Begunkov",
          "message_date": "2026-02-13"
        }
      ],
      "analysis_source": "llm-per-reviewer",
      "patch_summary": "This patch sets the selected buffer index in __io_uring_cmd_done(), a function responsible for completing io_uring commands. The change is part of a larger series that introduces kernel-managed buffer rings, where the kernel allocates and manages buffers on behalf of applications. This allows for more efficient use of system resources and simplifies buffer management for applications using io_uring. The patch builds upon previous changes in the series, including support for kernel-managed buffer rings and recycling of buffers. By setting the selected buffer index, this patch enables proper completion of commands that involve buffer selection."
    }
  }
}