{
  "thread_id": "aZuR6_Mm9uqt_6Fp@linux.dev",
  "subject": "Re: [next-20260216]NULL pointer dereference in drain_obj_stock() (RCU free path)",
  "url": "https://lore.kernel.org/all/aZuR6_Mm9uqt_6Fp@linux.dev/",
  "dates": {
    "2026-02-18": {
      "report_file": "2026-02-22_ollama_llama3.1-8b.html",
      "developer": "Shakeel Butt",
      "reviews": [
        {
          "author": "Vlastimil Babka",
          "summary": "Reviewer Vlastimil Babka suspects a NULL pointer dereference in drain_obj_stock() due to either a bogus objext pointer or locking issues in the rcu_free_sheaf() context, which is new for memcg and exposing existing problems",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "locking issue",
            "rcu_free_sheaf() context"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "CCing memcg and slab folks.\nWould be nice to figure out where in drain_obj_stock things got wrong. Any\nchange for e.g. ./scripts/faddr2line ?\n\nI wonder if we have either some bogus objext pointer, or maybe the\nrcu_free_sheaf() context is new (or previously rare) for memcg and we have\nsome locking issues being exposed in refill/drain.",
          "reply_to": "Carlos Maiolino",
          "message_date": "2026-02-18"
        },
        {
          "author": "Shakeel Butt",
          "summary": "Reviewer Shakeel Butt requested the output of ./scripts/faddr2line to help identify potential issues in the refill/drain path, indicating a need for further investigation and analysis.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "request_for_additional_info"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Yes output of ./scripts/faddr2line would be really helpful. I can't think of\nanything that might go wrong in refill/drain.",
          "reply_to": "Vlastimil Babka",
          "message_date": "2026-02-18"
        }
      ],
      "analysis_source": "llm-per-reviewer"
    },
    "2026-02-22": {
      "report_file": "2026-02-22_ollama_llama3.1-8b.html",
      "developer": "Shakeel Butt",
      "reviews": [
        {
          "author": "Venkat Bagalkote (author)",
          "summary": "The author is addressing a concern about the NULL pointer dereference in drain_obj_stock() (RCU free path) by providing additional information that the issue also occurs on mainline repo, and including stack traces to help identify the problem.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "additional_info",
            "stack_traces"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "This issue also got reproduced on mainline repo.\n\n\nTraces:\n\n\n[ 8058.036083] Kernel attempted to read user page (0) - exploit attempt? \n(uid: 0)\n[ 8058.036116] BUG: Kernel NULL pointer dereference on read at 0x00000000\n[ 8058.036127] Faulting instruction address: 0xc0000000008b018c\n[ 8058.036137] Oops: Kernel access of bad area, sig: 11 [#1]\n[ 8058.036147] LE PAGE_SIZE=64K MMU=Radix SMP NR_CPUS=8192 NUMA pSeries\n[ 8058.036159] Modules linked in: overlay dm_zero dm_thin_pool \ndm_persistent_data dm_bio_prison dm_snapshot dm_bufio dm_flakey xfs loop \ndm_mod nft_fib_inet nft_fib_ipv4 nft_fib_ipv6 nft_fib nft_reject_inet \nnf_reject_ipv4 nf_reject_ipv6 nft_reject nft_ct nft_chain_nat nf_nat \nnf_conntrack nf_defrag_ipv6 nf_defrag_ipv4 ip_set bonding nf_tables tls \nrfkill sunrpc nfnetlink pseries_rng vmx_crypto dax_pmem fuse ext4 crc16 \nmbcache jbd2 nd_pmem papr_scm sd_mod libnvdimm sg ibmvscsi ibmveth \nscsi_transport_srp pseries_wdt [last unloaded: scsi_debug]\n[ 8058.036339] CPU: 19 UID: 0 PID: 115 Comm: ksoftirqd/19 Kdump: loaded \nNot tainted 6.19.0+ #1 PREEMPTLAZY\n[ 8058.036361] Hardware name: IBM,9080-HEX Power11 (architected) \n0x820200 0xf000007 of:IBM,FW1110.01 (NH1110_069) hv:phyp pSeries\n[ 8058.036379] NIP: c0000000008b018c LR: c0000000008b0180 CTR: \nc00000000036d680\n[ 8058.036395] REGS: c00000000b5976c0 TRAP: 0300 Not tainted (6.19.0+)\n[ 8058.036411] MSR: 800000000280b033 <SF,VEC,VSX,EE,FP,ME,IR,DR,RI,LE> \nCR: 84042002 XER: 20040000\n[ 8058.036482] CFAR: c000000000862cf4 DAR: 0000000000000000 DSISR: \n40000000 IRQMASK: 0\n[ 8058.036482] GPR00: c0000000008b0180 c00000000b597960 c00000000243a500 \n0000000000000001\n[ 8058.036482] GPR04: 0000000000000008 0000000000000001 c0000000008b0180 \n0000000000000001\n[ 8058.036482] GPR08: a80e000000000000 0000000000000001 0000000000000007 \na80e000000000000\n[ 8058.036482] GPR12: c00e00000120f8d5 c000000d0ddf0b00 c000000073567780 \n0000000000000006\n[ 8058.036482] GPR16: c000000007012fa0 c000000007012fa4 c000000005160980 \nc000000007012f88\n[ 8058.036482] GPR20: c00c000001c3daac c000000d0d10f008 0000000000000001 \nffffffffffffff78\n[ 8058.036482] GPR24: 0000000000000005 c000000d0d58f180 c00000000cd6f580 \nc000000d0d10f01c\n[ 8058.036482] GPR28: c000000d0d10f008 c000000d0d10f010 c00000000cd6f588 \n0000000000000000\n[ 8058.036628] NIP [c0000000008b018c] drain_obj_stock+0x620/0xa48\n[ 8058.036646] LR [c0000000008b0180] drain_obj_stock+0x614/0xa48\n[ 8058.036659] Call Trace:\n[ 8058.036665] [c00000000b597960] [c0000000008b0180] \ndrain_obj_stock+0x614/0xa48 (unreliable)\n[ 8058.036688] [c00000000b597a10] [c0000000008b2a64] \nrefill_obj_stock+0x104/0x680\n[ 8058.036715] [c00000000b597a90] [c0000000008b94b8] \n__memcg_slab_free_hook+0x238/0x3ec\n[ 8058.036738] [c00000000b597b60] [c0000000007f3c10] \n__rcu_free_sheaf_prepare+0x314/0x3e8\n[ 8058.036763] [c00000000b597c10] [c0000000007fbf70] \nrcu_free_sheaf_nobarn+0x38/0x78\n[ 8058.036788] [c00000000b597c40] [c000000000334550] \nrcu_do_batch+0x2ec/0xfa8\n[ 8058.036812] [c00000000b597d40] [c0000000003399e8] rcu_core+0x22c/0x48c\n[ 8058.036835] [c00000000b597db0] [c0000000001cfe6c] \nhandle_softirqs+0x1f4/0x74c\n[ 8058.036862] [c00000000b597ed0] [c0000000001d0458] run_ksoftirqd+0x94/0xb8\n[ 8058.036885] [c00000000b597f00] [c00000000022a130] \nsmpboot_thread_fn+0x450/0x648\n[ 8058.036912] [c00000000b597f80] [c000000000218408] kthread+0x244/0x28c\n[ 8058.036927] [c00000000b597fe0] [c00000000000ded8] \nstart_kernel_thread+0x14/0x18\n[ 8058.036943] Code: 60000000 3bda0008 7fc3f378 4bfb148d 60000000 \nebfa0008 38800008 7fe3fb78 4bfb2b51 60000000 7c0004ac 39200001 \n<7d40f8a8> 7d495050 7d40f9ad 40c2fff4\n[ 8058.037000] ---[ end trace 0000000000000000 ]---\n\n\nAnd below is the corresponding o/p from faddr2line.\n\n\ndrain_obj_stock+0x620/0xa48:\narch_atomic64_sub_return_relaxed at arch/powerpc/include/asm/atomic.h:272\n(inlined by) raw_atomic64_sub_return at \ninclude/linux/atomic/atomic-arch-fallback.h:2917\n(inlined by) raw_atomic64_sub_and_test at \ninclude/linux/atomic/atomic-arch-fallback.h:4386\n(inlined by) raw_atomic_long_sub_and_test at \ninclude/linux/atomic/atomic-long.h:1551\n(inlined by) atomic_long_sub_and_test at \ninclude/linux/atomic/atomic-instrumented.h:4522\n(inlined by) percpu_ref_put_many at include/linux/percpu-refcount.h:334\n(inlined by) percpu_ref_put at include/linux/percpu-refcount.h:351\n(inlined by) obj_cgroup_put at include/linux/memcontrol.h:794\n(inlined by) drain_obj_stock at mm/memcontrol.c:3059\ndrain_obj_stock+0x614/0xa48:\ninstrument_atomic_read_write at include/linux/instrumented.h:112\n(inlined by) atomic_long_sub_and_test at \ninclude/linux/atomic/atomic-instrumented.h:4521\n(inlined by) percpu_ref_put_many at include/linux/percpu-refcount.h:334\n(inlined by) percpu_ref_put at include/linux/percpu-refcount.h:351\n(inlined by) obj_cgroup_put at include/linux/memcontrol.h:794\n(inlined by) drain_obj_stock at mm/memcontrol.c:3059\nrefill_obj_stock+0x104/0x680:\n__preempt_count_add at include/asm-generic/preempt.h:54\n(inlined by) __rcu_read_lock at include/linux/rcupdate.h:103\n(inlined by) rcu_read_lock at include/linux/rcupdate.h:848\n(inlined by) percpu_ref_get_many at include/linux/percpu-refcount.h:202\n(inlined by) percpu_ref_get at include/linux/percpu-refcount.h:222\n(inlined by) obj_cgroup_get at include/linux/memcontrol.h:782\n(inlined by) refill_obj_stock at mm/memcontrol.c:3099\n__memcg_slab_free_hook+0x238/0x3ec:\n__preempt_count_add at include/asm-generic/preempt.h:54\n(inlined by) __rcu_read_lock at include/linux/rcupdate.h:103\n(inlined by) rcu_read_lock at include/linux/rcupdate.h:848\n(inlined by) percpu_ref_put_many at include/linux/percpu-refcount.h:330\n(inlined by) percpu_ref_put at include/linux/percpu-refcount.h:351\n(inlined by) obj_cgroup_put at include/linux/memcontrol.h:794\n(inlined by) __memcg_slab_free_hook at mm/memcontrol.c:3284\n__rcu_free_sheaf_prepare+0x314/0x3e8:\nmemcg_slab_free_hook at mm/slub.c:2486\n(inlined by) __rcu_free_sheaf_prepare at mm/slub.c:2914\nrcu_free_sheaf_nobarn+0x38/0x78:\nsheaf_flush_unused at mm/slub.c:2893\n(inlined by) rcu_free_sheaf_nobarn at mm/slub.c:2941\nrcu_do_batch+0x2ec/0xfa8:\nrcu_do_batch at kernel/rcu/tree.c:2617\nrcu_core+0x22c/0x48c:\nrcu_core at kernel/rcu/tree.c:2871\nhandle_softirqs+0x1f4/0x74c:\nhandle_softirqs at kernel/softirq.c:622\nrun_ksoftirqd+0x94/0xb8:\narch_local_irq_enable at arch/powerpc/include/asm/hw_irq.h:201\n(inlined by) ksoftirqd_run_end at kernel/softirq.c:479\n(inlined by) run_ksoftirqd at kernel/softirq.c:1064\n(inlined by) run_ksoftirqd at kernel/softirq.c:1055\nsmpboot_thread_fn+0x450/0x648:\nsmpboot_thread_fn at kernel/smpboot.c:160 (discriminator 3)\nkthread+0x244/0x28c:\nkthread at kernel/kthread.c:467\nstart_kernel_thread+0x14/0x18:\nstart_kernel_thread at arch/powerpc/kernel/interrupt_64.S:771\n\n\nRegards,\n\nVenkat.",
          "reply_to": "Vlastimil Babka",
          "message_date": "2026-02-22"
        },
        {
          "author": "Harry Yoo",
          "summary": "Reviewer Harry Yoo suspected a NULL pointer dereference in drain_obj_stock(), hypothesizing that the stock->objcg was never valid, and suggested it might be due to mis-refcounting of objcgs.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "mis-refcounting",
            "NULL pointer dereference"
          ],
          "has_inline_review": true,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "It seems it crashed while dereferencing objcg->ref->data->count.\nI think that implies that obj_cgroup_release()->percpu_ref_exit()\nis already called due to the refcount reaching zero and set\nref->data = NULL.\n\nWait, was the stock->objcg ever a valid objcg?\nI think it should be valid when refilling the obj stock, otherwise\nit should have crashed in refill_obj_stock() -> obj_cgroup_get() path\nin the first place, rather than crashing when draining.\n\nAnd that sounds like we're somehow calling obj_cgroup_put() more times\nthan obj_cgroup_get().\n\nAnyway, this is my theory that it may be due to mis-refcounting of objcgs.",
          "reply_to": "Venkat Bagalkote",
          "message_date": "2026-02-22"
        },
        {
          "author": "Shakeel Butt",
          "summary": "Reviewer noted that the NULL pointer dereference in drain_obj_stock() is caused by a missing check for RCU read-side critical section, and requested the addition of a lock annotation to indicate this.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "missing RCU read-side critical section",
            "lock annotation"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "On Sun, Feb 22, 2026 at 08:47:03PM +0900, Harry Yoo wrote:\n[...]",
          "reply_to": "Harry Yoo",
          "message_date": "2026-02-22"
        },
        {
          "author": "Shakeel Butt",
          "summary": "Reviewer Shakeel Butt noted that the `slab_set_stride()` function is being unconditionally overwritten, which may be an issue or unrelated to the NULL pointer dereference in `drain_obj_stock()`, and requested further investigation into recent SLUB changes.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "issue",
            "unrelated"
          ],
          "has_inline_review": true,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "I have not looked deeper into recent slub changes (sheafs or obj_exts savings)\nbut one thing looks weird to me:\n\nallocate_slab() // for cache with SLAB_OBJ_EXT_IN_OBJ\n\t-> alloc_slab_obj_exts_early()\n\t\t-> slab_set_stride(slab, s->size)\n\t-> account_slab()\n\t\t-> alloc_slab_obj_exts()\n\t\t\t-> slab_set_stride(slab, sizeof(struct slabobj_ext));\n\nUnconditional overwrite of stride. Not sure if it is issue or even related to\nthis crash but looks odd.",
          "reply_to": "Harry Yoo",
          "message_date": "2026-02-22"
        },
        {
          "author": "Shakeel Butt",
          "summary": "Reviewer Shakeel Butt identified a NULL pointer dereference in drain_obj_stock() due to stride corruption caused by an unconditional stride overwrite in alloc_slab_obj_exts(). The bug is triggered when the slab was created with SLAB_OBJ_EXT_IN_OBJ mode and later alloc_slab_obj_exts() is called, corrupting the stride. This leads to incorrect obj_ext calculation in slab_obj_ext(), causing reference underflow on victim objcg, early obj_cgroup_release(), and eventually a crash in drain_obj_stock(). Shakeel also pointed out a missing safety check in slab_obj_ext() and a critical memory ordering bug on PowerPC due to lack of memory barrier between stride store and obj_exts visibility.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "NULL pointer dereference",
            "stride corruption"
          ],
          "has_inline_review": true,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "I asked AI to debug this crash report along with a nudge towards to look for\nstride corruption, it gave me the following output:\n\n\n# Stride Corruption Bug Analysis\n\n## Bug Report Context\n\n- **Crash Location**: `drain_obj_stock+0x620/0xa48` in `obj_cgroup_put(old)` at mm/memcontrol.c:3059\n- **Root Cause**: `percpu_ref.data` is NULL, meaning `obj_cgroup_release()` already ran\n- **Platform**: IBM Power11 (pSeries LPAR, Radix MMU, LE, 64K pages, kernel 6.19.0-next-20260216)\n- **Trigger**: xfstests generic/428\n\n## Identified Bug: Unconditional Stride Overwrite\n\n### Location: mm/slub.c lines 2196-2223 (alloc_slab_obj_exts)\n\n```c\nretry:\n    old_exts = READ_ONCE(slab->obj_exts);\n    handle_failed_objexts_alloc(old_exts, vec, objects);\n    slab_set_stride(slab, sizeof(struct slabobj_ext));  // BUG: UNCONDITIONALLY SET\n\n    if (new_slab) {\n        slab->obj_exts = new_exts;\n    } else if (old_exts & ~OBJEXTS_FLAGS_MASK) {\n        // obj_exts already exists, BUT stride was already modified above!\n        mark_objexts_empty(vec);\n        kfree(vec);\n        return 0;\n    } else if (cmpxchg(&slab->obj_exts, old_exts, new_exts) != old_exts) {\n        goto retry;\n    }\n```\n\n### The Problem\n\nThe stride is set to `sizeof(struct slabobj_ext)` **BEFORE** checking if `obj_exts` already\nexists. If a slab was created with `SLAB_OBJ_EXT_IN_OBJ` mode (where stride = `s->size`),\nand later `alloc_slab_obj_exts` is called for any reason, the stride gets corrupted.\n\n### Stride Modes\n\nThere are two stride modes (see alloc_slab_obj_exts_early):\n\n1. **Normal mode**: stride = `sizeof(struct slabobj_ext)` (~16 bytes)\n   - obj_exts is a separate array or in slab leftover space\n\n2. **SLAB_OBJ_EXT_IN_OBJ mode**: stride = `s->size` (object size, e.g., 64-256+ bytes)\n   - obj_ext is embedded within each object at a fixed offset\n\n### Consequences of Wrong Stride\n\nWhen `slab_obj_ext` is later called:\n```c\nobj_ext = (struct slabobj_ext *)(obj_exts + slab_get_stride(slab) * index);\n```\n\nWith corrupted stride (16 instead of 256):\n- **Expected**: `obj_exts + 256 * 5 = obj_exts + 1280` (correct obj_ext for object 5)\n- **Actual**: `obj_exts + 16 * 5 = obj_exts + 80` (WRONG obj_ext - belongs to object 0!)\n\nThis causes:\n1. Reading wrong object's objcg pointer\n2. Releasing wrong objcg reference (`obj_cgroup_put`)\n3. Reference underflow on victim objcg\n4. Early `obj_cgroup_release()` \\u2192 `percpu_ref_exit()` \\u2192 `data = NULL`\n5. Stock still caches the objcg pointer\n6. Later `drain_obj_stock()` tries to put it \\u2192 **CRASH**\n\n## Missing Safety Check\n\n`slab_obj_ext()` in mm/slab.h has **no bounds checking**:\n\n```c\nstatic inline struct slabobj_ext *slab_obj_ext(struct slab *slab,\n                                               unsigned long obj_exts,\n                                               unsigned int index)\n{\n    struct slabobj_ext *obj_ext;\n\n    VM_WARN_ON_ONCE(obj_exts != slab_obj_exts(slab));\n    // MISSING: VM_WARN_ON_ONCE(index >= slab->objects);\n\n    obj_ext = (struct slabobj_ext *)(obj_exts +\n                                     slab_get_stride(slab) * index);\n    return kasan_reset_tag(obj_ext);\n}\n```\n\n## CRITICAL: Memory Ordering Bug on PowerPC (Likely Root Cause)\n\n### The Problem\n\nIn `alloc_slab_obj_exts` (mm/slub.c lines 2199-2220), there is **NO memory barrier**\nbetween the stride store and the obj_exts visibility via cmpxchg:\n\n```c\nslab_set_stride(slab, sizeof(struct slabobj_ext));  // Store to stride (line 2199)\n                                                     // NO MEMORY BARRIER HERE!\nif (new_slab) {\n    slab->obj_exts = new_exts;                       // Store to obj_exts (line 2207)\n} else if (...) {\n} else if (cmpxchg(&slab->obj_exts, ...) != ...) {   // Atomic on obj_exts (line 2220)\n    goto retry;\n}\n```\n\n### Why This Crashes on PowerPC\n\nPowerPC has a **weakly-ordered memory model**. Stores can be reordered and may not be\nimmediately visible to other processors. The cmpxchg provides a barrier AFTER it\nexecutes, but the stride store BEFORE cmpxchg may not be visible when obj_exts becomes\nvisible.\n\n**Race Scenario:**\n1. CPU A: `slab_set_stride(slab, 16)` (store to stride, in CPU A's store buffer)\n2. CPU A: `cmpxchg(&slab->obj_exts, 0, new_exts)` succeeds, obj_exts is now visible\n3. CPU B: Sees `obj_exts` is set (from step 2)\n4. CPU B: Reads `slab->stride` \\u2192 **sees OLD value (0 or garbage)** due to reordering!\n5. CPU B: `slab_obj_ext` calculates `obj_exts + 0 * index = obj_exts` for ALL indices!\n6. **All objects appear to share the same obj_ext at offset 0**\n\n### Consequences\n\n- Object 0's objcg is correct\n- Object 1..N all read object 0's objcg (WRONG!)\n- When freeing multiple objects, we `obj_cgroup_put` the SAME objcg multiple times\n- Reference count underflows \\u2192 early `obj_cgroup_release()`\n- `percpu_ref_exit()` sets `data = NULL`\n- Later stock drain tries to put the objcg \\u2192 **CRASH in `drain_obj_stock`**\n\n### Why This Matches the Bug Report\n\n- **Platform**: IBM Power11 (PowerPC) - weakly ordered memory\n- **Trigger**: xfstests generic/428 - creates high filesystem activity with many allocations\n- **Crash location**: `drain_obj_stock` \\u2192 `obj_cgroup_put` with NULL data\n- **Pattern**: Stock has cached objcg that was prematurely released\n\n### Proposed Fix\n\nAdd a write memory barrier to ensure stride is visible before obj_exts:\n\n```c\nslab_set_stride(slab, sizeof(struct slabobj_ext));\nsmp_wmb();  // Ensure stride is visible before obj_exts\n\nif (new_slab) {\n    slab->obj_exts = new_exts;\n} else if (...) {\n} else if (cmpxchg(&slab->obj_exts, old_exts, new_exts) != old_exts) {\n    goto retry;\n}\n```\n\nAnd correspondingly, the reader side should use a read barrier:\n```c\nstatic inline unsigned short slab_get_stride(struct slab *slab)\n{\n    // Need acquire semantics when reading stride after seeing obj_exts\n    return smp_load_acquire(&slab->stride);\n}\n```\n\nOr use `smp_store_release` / `smp_load_acquire` pairs for proper ordering.\n\n### Also Applies to alloc_slab_obj_exts_early\n\nThe same issue exists in `alloc_slab_obj_exts_early` (lines 2290-2291 and 2308-2309):\n\n```c\nslab->obj_exts = obj_exts;                           // Store obj_exts\nslab_set_stride(slab, sizeof(struct slabobj_ext));   // Store stride AFTER!\n```\n\nHere the order is **reversed** - obj_exts is set BEFORE stride! This is even worse\nfor memory ordering, as other CPUs could see obj_exts before stride is set.\n\n## Original Theory: Unconditional Stride Overwrite\n\n(Kept for reference - less likely to be the root cause on this specific crash)\n\nThe stride is set to `sizeof(struct slabobj_ext)` **BEFORE** checking if `obj_exts`\nalready exists. However, analysis shows this is protected by the TOCTOU check in\ncallers (`!slab_obj_exts(slab)`).\n\n## Trigger Scenarios\n\n1. **Memory ordering on PowerPC** (MOST LIKELY): Stride not visible when obj_exts\n   becomes visible due to missing memory barriers.\n\n2. **Race between alloc_slab_obj_exts calls**: Two CPUs trying to allocate obj_exts\n   for the same slab simultaneously.\n\n3. **Interaction with RCU free path**: Objects in RCU sheaf being processed when\n   stride is stale/zero.\n\n## Confirmed Code Analysis (CONFIG_64BIT)\n\nOn 64-bit systems (including IBM Power11), the stride is stored dynamically:\n\n**mm/slab.h:562-569**:\n```c\n#ifdef CONFIG_64BIT\nstatic inline void slab_set_stride(struct slab *slab, unsigned short stride)\n{\n    slab->stride = stride;  // Plain store - NO memory ordering!\n}\nstatic inline unsigned short slab_get_stride(struct slab *slab)\n{\n    return slab->stride;    // Plain load - NO memory ordering!\n}\n```\n\n**mm/slab.h:533-548** (`slab_obj_exts`):\n```c\nstatic inline unsigned long slab_obj_exts(struct slab *slab)\n{\n    unsigned long obj_exts = READ_ONCE(slab->obj_exts);  // Only compiler barrier!\n    // ... validation ...\n    return obj_exts & ~OBJEXTS_FLAGS_MASK;\n}\n```\n\n`READ_ONCE` only provides compiler ordering, NOT CPU memory ordering. There's no\nacquire barrier to ensure the stride read happens after seeing obj_exts.\n\n## Complete Fix Using Release/Acquire Semantics\n\n### Fix 1: Reader side - slab_obj_exts (mm/slab.h)\n\nChange `READ_ONCE` to `smp_load_acquire`:\n\n```c\nstatic inline unsigned long slab_obj_exts(struct slab *slab)\n{\n    unsigned long obj_exts = smp_load_acquire(&slab->obj_exts);  // Acquire barrier\n    // ... validation ...\n    return obj_exts & ~OBJEXTS_FLAGS_MASK;\n}\n```\n\n### Fix 2: Writer side - alloc_slab_obj_exts (mm/slub.c:2196-2223)\n\nUse `smp_store_release` for obj_exts after setting stride:\n\n```c\nretry:\n    old_exts = READ_ONCE(slab->obj_exts);\n    handle_failed_objexts_alloc(old_exts, vec, objects);\n\n    if (new_slab) {\n        slab_set_stride(slab, sizeof(struct slabobj_ext));\n        smp_store_release(&slab->obj_exts, new_exts);  // Release barrier\n    } else if (old_exts & ~OBJEXTS_FLAGS_MASK) {\n        mark_objexts_empty(vec);\n        kfree(vec);\n        return 0;\n    } else {\n        slab_set_stride(slab, sizeof(struct slabobj_ext));\n        // cmpxchg already provides release semantics, but stride must be\n        // visible before cmpxchg. Need explicit barrier:\n        smp_wmb();\n        if (cmpxchg(&slab->obj_exts, old_exts, new_exts) != old_exts)\n            goto retry;\n    }\n```\n\n### Fix 3: Writer side - alloc_slab_obj_exts_early (mm/slub.c:2290-2291, 2308-2309)\n\nThe order is REVERSED here - obj_exts is set BEFORE stride! Fix by using\n`smp_store_release`:\n\n```c\n// For normal obj_exts (lines 2290-2291):\nslab_set_stride(slab, sizeof(struct slabobj_ext));  // Set stride FIRST\nsmp_store_release(&slab->obj_exts, obj_exts);       // Then release obj_exts\n\n// For SLAB_OBJ_EXT_IN_OBJ (lines 2308-2309):\nslab_set_stride(slab, s->size);                     // Set stride FIRST\nsmp_store_release(&slab->obj_exts, obj_exts);       // Then release obj_exts\n```\n\n## Why This Fixes the Crash\n\nWith proper release/acquire ordering:\n\n1. **Writer** (CPU A): Sets stride, then `smp_store_release(&obj_exts, ...)` ensures\n   stride is visible to all CPUs before obj_exts becomes visible\n\n2. **Reader** (CPU B): `smp_load_acquire(&obj_exts)` ensures that if obj_exts is\n   seen as set, the subsequent stride read will see the correct value\n\nThis prevents the race where CPU B sees obj_exts but reads stale/zero stride,\nwhich caused all objects to appear to share obj_ext at offset 0, leading to\nmultiple `obj_cgroup_put` calls on the same objcg \\u2192 reference underflow \\u2192 crash.\n\n## Additional Safety: Bounds Check in slab_obj_ext\n\nAdd bounds check to catch any remaining issues:\n```c\nVM_WARN_ON_ONCE(index >= slab->objects);\n```",
          "reply_to": "",
          "message_date": "2026-02-22"
        }
      ],
      "analysis_source": "llm-per-reviewer"
    },
    "2026-02-23": {
      "report_file": "2026-02-22_ollama_llama3.1-8b.html",
      "developer": "Shakeel Butt",
      "reviews": [
        {
          "author": "Harry Yoo",
          "summary": "Reviewer Harry Yoo noted that stride corruption cannot occur because obj_exts is not allocated if already present, but also acknowledged a potential memory ordering issue as another valid analysis.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "acknowledged multiple perspectives",
            "no clear disagreement"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Thanks!\n\nTLDR; I think stride corruption cannot happen because we don't try to\nallocate obj_exts if we already have it (w/ SLAB_OBJ_EXT_IN_OBJ).\n\nBut the other analysis saying it's memory ordering issue seems\nvery relevant.",
          "reply_to": "Shakeel Butt",
          "message_date": "2026-02-23"
        },
        {
          "author": "Harry Yoo",
          "summary": "Reviewer Harry Yoo questioned the necessity of calling alloc_slab_obj_exts() after obj_exts saving is applied during slab allocation and initialization, arguing that if it benefits from obj_exts savings, there's no corruption risk.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "questioning code necessity"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "I think this part is bogus.\n\nIt's not a bug because obj_exts saving is applied only during slab\nallocation and initialization. If it benefits from the obj_exts savings,\nno need to call alloc_slab_obj_exts() later, thus no corruption.\n\nIf doesn't benefit from the obj_exts savings, the stride size is always\nsizeof(struct slabobj_ext).",
          "reply_to": "Shakeel Butt",
          "message_date": "2026-02-23"
        },
        {
          "author": "Harry Yoo",
          "summary": "Reviewer Harry Yoo noted that when __GFP_ACCOUNT is set, objects can be allocated without specifying SLAB_ACCOUNT in the cache, leading to potential NULL pointer dereferences due to charging objects from different CPUs' sheaves.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "potential bug",
            "requested change"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Yes, that could actually happen, especially when the cache doesn't\nspecify SLAB_ACCOUNT but allocate objects with __GFP_ACCOUNT set\n(e.g. xarray does that).\n\nWith sheaves for all, objects can be in different CPUs' sheaves and they\ncould try to allocate obj_exts and charge objects from the same slab.",
          "reply_to": "Shakeel Butt",
          "message_date": "2026-02-23"
        },
        {
          "author": "Harry Yoo",
          "summary": "The reviewer noted that the patch does not address the root cause of the NULL pointer dereference issue and suggested that reading the wrong stride value is the path to mis-refcounting.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "mis-refcounting",
            "root cause"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Yes, reading the wrong stride value is the path to mis-refcounting\nobjcgs :P",
          "reply_to": "Shakeel Butt",
          "message_date": "2026-02-23"
        },
        {
          "author": "Harry Yoo",
          "summary": "Reviewer Harry Yoo suggested that additional memory barriers are needed to ensure visibility of stride and obj_exts changes across CPUs, specifically before the slab is accessible by other CPUs.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes"
          ],
          "has_inline_review": true,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "I would say this is an overkill. Something like this should suffice:\n\ndiff --git a/mm/slub.c b/mm/slub.c\nindex 865bc050f654..8db93a88bbbf 100644\n--- a/mm/slub.c\n+++ b/mm/slub.c\n@@ -2196,7 +2196,6 @@ int alloc_slab_obj_exts(struct slab *slab, struct kmem_cache *s,\n retry:\n \told_exts = READ_ONCE(slab->obj_exts);\n \thandle_failed_objexts_alloc(old_exts, vec, objects);\n-\tslab_set_stride(slab, sizeof(struct slabobj_ext));\n\n \tif (new_slab) {\n \t\t/*\n@@ -2272,6 +2271,12 @@ static void alloc_slab_obj_exts_early(struct kmem_cache *s, struct slab *slab)\n \tvoid *addr;\n \tunsigned long obj_exts;\n\n+\t/*\n+\t * Initialize stride unconditionally,\n+\t * but override if SLAB_OBJ_EXT_IN_OBJ is set.\n+\t */\n+\tslab_set_stride(slab, sizeof(struct slabobj_ext));\n+\n \tif (!need_slab_obj_exts(s))\n \t\treturn;\n\n@@ -2288,7 +2293,6 @@ static void alloc_slab_obj_exts_early(struct kmem_cache *s, struct slab *slab)\n \t\tobj_exts |= MEMCG_DATA_OBJEXTS;\n #endif\n \t\tslab->obj_exts = obj_exts;\n-\t\tslab_set_stride(slab, sizeof(struct slabobj_ext));\n \t} else if (s->flags & SLAB_OBJ_EXT_IN_OBJ) {\n \t\tunsigned int offset = obj_exts_offset_in_object(s);\n\nThere should be enough memory barriers to ensure the stride and obj_exts\nare visible to other CPUs before the slab is accessible by other CPUs\n(by acquiring/releasing n->list_lock)",
          "reply_to": "Shakeel Butt",
          "message_date": "2026-02-23"
        }
      ],
      "analysis_source": "llm-per-reviewer"
    }
  }
}