<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Review Comments: Re: [PATCH v6 0/9] dax/hmem, cxl: Coordinate Soft Reserved handling with CXL and HMEM</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
                         "Helvetica Neue", Arial, sans-serif;
            background: #f5f5f5;
            color: #333;
            line-height: 1.6;
            padding: 20px;
            max-width: 900px;
            margin: 0 auto;
        }
        .home-link { margin-bottom: 12px; display: block; }
        .home-link a { color: #0366d6; text-decoration: none; font-size: 0.9em; }
        .home-link a:hover { text-decoration: underline; }

        h1 { font-size: 1.3em; margin-bottom: 2px; color: #1a1a1a; line-height: 1.3; }

        .lore-link { font-size: 0.85em; margin: 4px 0 6px; display: block; }
        .lore-link a { color: #0366d6; text-decoration: none; }
        .lore-link a:hover { text-decoration: underline; }

        .date-range {
            font-size: 0.8em;
            color: #888;
            margin-bottom: 16px;
        }
        .date-range a { color: #0366d6; text-decoration: none; }
        .date-range a:hover { text-decoration: underline; }

        /* thread-node scroll margin so the card isn't clipped at the top */
        .thread-node { scroll-margin-top: 8px; }

        /* ── Patch summary ──────────────────────────────────────────── */
        .patch-summary-block {
            background: #fff;
            border-radius: 8px;
            padding: 12px 16px;
            margin-bottom: 20px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.08);
            border-left: 3px solid #4a90d9;
        }
        .patch-summary-label {
            font-size: 0.72em;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 0.06em;
            color: #4a90d9;
            margin-bottom: 4px;
        }
        .patch-summary-text {
            font-size: 0.88em;
            color: #444;
            line-height: 1.55;
        }

        /* ── Thread tree ────────────────────────────────────────────── */
        .thread-tree {
            display: flex;
            flex-direction: column;
            gap: 6px;
        }

        /* Depth indentation via left border */
        .thread-node { position: relative; }
        .thread-children {
            margin-left: 20px;
            padding-left: 12px;
            border-left: 2px solid #e0e0e0;
            margin-top: 6px;
            display: flex;
            flex-direction: column;
            gap: 6px;
        }

        /* ── Review comment card ────────────────────────────────────── */
        .review-comment {
            background: #fff;
            border-radius: 6px;
            padding: 10px 14px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.08);
            font-size: 0.88em;
        }
        .review-comment-header {
            display: flex;
            flex-wrap: wrap;
            align-items: center;
            gap: 6px;
            margin-bottom: 5px;
        }
        .review-author {
            font-weight: 700;
            color: #1a1a1a;
            font-size: 0.95em;
        }

        /* Date chip — links back to the daily report */
        .date-chip {
            font-size: 0.75em;
            color: #777;
            background: #f0f0f0;
            border-radius: 10px;
            padding: 1px 7px;
            text-decoration: none;
            white-space: nowrap;
        }
        a.date-chip:hover { background: #e0e8f5; color: #0366d6; }

        .badge {
            display: inline-block;
            padding: 1px 8px;
            border-radius: 10px;
            font-size: 0.75em;
            font-weight: 600;
        }
        .inline-review-badge {
            display: inline-block;
            padding: 0 6px;
            border-radius: 8px;
            font-size: 0.78em;
            font-weight: 500;
            background: #e3f2fd;
            color: #1565c0;
        }
        .review-tag-badge {
            display: inline-block;
            padding: 0 6px;
            border-radius: 8px;
            font-size: 0.78em;
            font-weight: 500;
            background: #e8f5e9;
            color: #2e7d32;
        }
        .analysis-source-badge {
            display: inline-block;
            padding: 1px 7px;
            border-radius: 10px;
            font-size: 0.72em;
            font-weight: 600;
            border: 1px solid rgba(0,0,0,0.1);
        }

        .review-comment-text {
            color: #444;
            line-height: 1.55;
            margin-bottom: 4px;
        }
        .review-comment-signals {
            margin-top: 3px;
            font-size: 0.85em;
            color: #aaa;
            font-style: italic;
        }

        /* ── Collapsible raw body ───────────────────────────────────── */
        .raw-body-toggle {
            margin-top: 5px;
            font-size: 0.85em;
        }
        .raw-body-toggle summary {
            cursor: pointer;
            color: #888;
            padding: 2px 0;
            font-weight: 500;
            font-size: 0.9em;
            list-style: none;
        }
        .raw-body-toggle summary::-webkit-details-marker { display: none; }
        .raw-body-toggle summary::before { content: "▶ "; font-size: 0.7em; }
        .raw-body-toggle[open] summary::before { content: "▼ "; }
        .raw-body-toggle summary:hover { color: #555; }
        .raw-body-text {
            white-space: pre-wrap;
            font-size: 0.95em;
            background: #f8f8f8;
            padding: 8px 10px;
            border-radius: 4px;
            max-height: 360px;
            overflow-y: auto;
            margin-top: 4px;
            line-height: 1.5;
            color: #444;
            border: 1px solid #e8e8e8;
        }

        .no-reviews {
            color: #aaa;
            font-size: 0.85em;
            font-style: italic;
            padding: 8px 0;
        }

        footer {
            text-align: center;
            color: #bbb;
            font-size: 0.78em;
            margin-top: 36px;
            padding: 16px;
        }
    </style>
</head>
<body>
    <div class="home-link"><a href="../">&larr; Back to reports</a></div>
    <h1>Re: [PATCH v6 0/9] dax/hmem, cxl: Coordinate Soft Reserved handling with CXL and HMEM</h1>
    <div class="lore-link"><a href="https://lore.kernel.org/all/aY8vf75vVQ-poVBN@gourry-fedora-PF4VCD3F/" target="_blank">View on lore.kernel.org &rarr;</a></div>
    <div class="date-range">Active on: <a href="#2026-02-13">2026-02-13</a></div>
    
    <div class="thread-tree">
<div class="thread-node depth-0" id="2026-02-13">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Smita Koralahalli (author)</span>
<a class="date-chip" href="../2026-02-13_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="inline-review-badge">Inline Review</span>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The reviewer raised concerns about the patch&#x27;s handling of Soft Reserved ranges and CXL drivers, specifically that MODULE_SOFTDEP() does not guarantee timely loading of dependencies.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">From: Dan Williams &lt;dan.j.williams@intel.com&gt;

Ensure cxl_acpi has published CXL Window resources before HMEM walks Soft
Reserved ranges.

Replace MODULE_SOFTDEP(&quot;pre: cxl_acpi&quot;) with an explicit, synchronous
request_module(&quot;cxl_acpi&quot;). MODULE_SOFTDEP() only guarantees eventual
loading, it does not enforce that the dependency has finished init
before the current module runs. This can cause HMEM to start before
cxl_acpi has populated the resource tree, breaking detection of overlaps
between Soft Reserved and CXL Windows.

Also, request cxl_pci before HMEM walks Soft Reserved ranges. Unlike
cxl_acpi, cxl_pci attach is asynchronous and creates dependent devices
that trigger further module loads. Asynchronous probe flushing
(wait_for_device_probe()) is added later in the series in a deferred
context before HMEM makes ownership decisions for Soft Reserved ranges.

Add an additional explicit Kconfig ordering so that CXL_ACPI and CXL_PCI
must be initialized before DEV_DAX_HMEM. This prevents HMEM from consuming
Soft Reserved ranges before CXL drivers have had a chance to claim them.

Signed-off-by: Dan Williams &lt;dan.j.williams@intel.com&gt;
Signed-off-by: Smita Koralahalli &lt;Smita.KoralahalliChannabasappa@amd.com&gt;
Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
Reviewed-by: Jonathan Cameron &lt;jonathan.cameron@huawei.com&gt;
---
 drivers/dax/Kconfig     |  2 ++
 drivers/dax/hmem/hmem.c | 17 ++++++++++-------
 2 files changed, 12 insertions(+), 7 deletions(-)

diff --git a/drivers/dax/Kconfig b/drivers/dax/Kconfig
index d656e4c0eb84..3683bb3f2311 100644
--- a/drivers/dax/Kconfig
+++ b/drivers/dax/Kconfig
@@ -48,6 +48,8 @@ config DEV_DAX_CXL
 	tristate &quot;CXL DAX: direct access to CXL RAM regions&quot;
 	depends on CXL_BUS &amp;&amp; CXL_REGION &amp;&amp; DEV_DAX
 	default CXL_REGION &amp;&amp; DEV_DAX
+	depends on CXL_ACPI &gt;= DEV_DAX_HMEM
+	depends on CXL_PCI &gt;= DEV_DAX_HMEM
 	help
 	  CXL RAM regions are either mapped by platform-firmware
 	  and published in the initial system-memory map as &quot;System RAM&quot;, mapped
diff --git a/drivers/dax/hmem/hmem.c b/drivers/dax/hmem/hmem.c
index 1cf7c2a0ee1c..008172fc3607 100644
--- a/drivers/dax/hmem/hmem.c
+++ b/drivers/dax/hmem/hmem.c
@@ -139,6 +139,16 @@ static __init int dax_hmem_init(void)
 {
 	int rc;
 
+	/*
+	 * Ensure that cxl_acpi and cxl_pci have a chance to kick off
+	 * CXL topology discovery at least once before scanning the
+	 * iomem resource tree for IORES_DESC_CXL resources.
+	 */
+	if (IS_ENABLED(CONFIG_DEV_DAX_CXL)) {
+		request_module(&quot;cxl_acpi&quot;);
+		request_module(&quot;cxl_pci&quot;);
+	}
+
 	rc = platform_driver_register(&amp;dax_hmem_platform_driver);
 	if (rc)
 		return rc;
@@ -159,13 +169,6 @@ static __exit void dax_hmem_exit(void)
 module_init(dax_hmem_init);
 module_exit(dax_hmem_exit);
 
-/* Allow for CXL to define its own dax regions */
-#if IS_ENABLED(CONFIG_CXL_REGION)
-#if IS_MODULE(CONFIG_CXL_ACPI)
-MODULE_SOFTDEP(&quot;pre: cxl_acpi&quot;);
-#endif
-#endif
-
 MODULE_ALIAS(&quot;platform:hmem*&quot;);
 MODULE_ALIAS(&quot;platform:hmem_platform*&quot;);
 MODULE_DESCRIPTION(&quot;HMEM DAX: direct access to &#x27;specific purpose&#x27; memory&quot;);
-- 
2.17.1



---

This series aims to address long-standing conflicts between HMEM and
CXL when handling Soft Reserved memory ranges.

Reworked from Dan&#x27;s patch:
https://git.kernel.org/pub/scm/linux/kernel/git/cxl/cxl.git/patch/?id=ab70c6227ee6165a562c215d9dcb4a1c55620d5d

Previous work:
https://lore.kernel.org/all/20250715180407.47426-1-Smita.KoralahalliChannabasappa@amd.com/

Link to v5:
https://lore.kernel.org/all/20260122045543.218194-1-Smita.KoralahalliChannabasappa@amd.com

The series is based on branch &quot;for-7.0/cxl-init&quot; and base-commit is
base-commit: bc62f5b308cbdedf29132fe96e9d591e526527e1

[1] After offlining the memory I can tear down the regions and recreate
them back. dax_cxl creates dax devices and onlines memory.
850000000-284fffffff : CXL Window 0
  850000000-284fffffff : region0
    850000000-284fffffff : dax0.0
      850000000-284fffffff : System RAM (kmem)

[2] With CONFIG_CXL_REGION disabled, all the resources are handled by
HMEM. Soft Reserved range shows up in /proc/iomem, no regions come up
and dax devices are created from HMEM.
850000000-284fffffff : CXL Window 0
  850000000-284fffffff : Soft Reserved
    850000000-284fffffff : dax0.0
      850000000-284fffffff : System RAM (kmem)

[3] Region assembly failure works same as [2].

[4] REGISTER path:
When CXL_BUS = y (with CXL_ACPI, CXL_PCI, CXL_PORT, CXL_MEM = y),
the dax_cxl driver is probed and completes initialization before dax_hmem
probes. This scenario was tested with CXL = y, DAX_CXL = m and
DAX_HMEM = m. To validate the REGISTER path, I forced REGISTER even in
cases where SR completely overlaps the CXL region as I did not have access
to a system where the CXL region range is smaller than the SR range.

850000000-284fffffff : Soft Reserved
  850000000-284fffffff : CXL Window 0
    850000000-280fffffff : region0
      850000000-284fffffff : dax0.0
        850000000-284fffffff : System RAM (kmem)

&quot;path&quot;:&quot;\/platform\/ACPI0017:00\/root0\/decoder0.0\/region0\/dax_region0&quot;,
&quot;id&quot;:0,
&quot;size&quot;:&quot;128.00 GiB (137.44 GB)&quot;,
&quot;align&quot;:2097152

[   35.961707] cxl-dax: cxl_dax_region_init()
[   35.961713] cxl-dax: registering driver.
[   35.961715] cxl-dax: dax_hmem work flushed.
[   35.961754] alloc_dev_dax_range:  dax0.0: alloc range[0]:
0x000000850000000:0x000000284fffffff
[   35.976622] hmem: hmem_platform probe started.
[   35.980821] cxl_bus_probe: cxl_dax_region dax_region0: probe: 0
[   36.819566] hmem_platform hmem_platform.0: Soft Reserved not fully
contained in CXL; using HMEM
[   36.819569] hmem_register_device: hmem_platform hmem_platform.0:
registering CXL range: [mem 0x850000000-0x284fffffff flags 0x80000200]
[   36.934156] alloc_dax_region: hmem hmem.6: dax_region resource conflict
for [mem 0x850000000-0x284fffffff]
[   36.989310] hmem hmem.6: probe with driver hmem failed with error -12

[5] When CXL_BUS = m (with CXL_ACPI, CXL_PCI, CXL_PORT, CXL_MEM = m),
DAX_CXL = m and DAX_HMEM = y the results are as expected. To validate the
REGISTER path, I forced REGISTER even in cases where SR completely
overlaps the CXL region as I did not have access to a system where the
CXL region range is smaller than the SR range.

850000000-284fffffff : Soft Reserved
  850000000-284fffffff : CXL Window 0
    850000000-280fffffff : region0
      850000000-284fffffff : dax6.0
        850000000-284fffffff : System RAM (kmem)

&quot;path&quot;:&quot;\/platform\/hmem.6&quot;,
&quot;id&quot;:6,
&quot;size&quot;:&quot;128.00 GiB (137.44 GB)&quot;,
&quot;align&quot;:2097152

[   30.897665] devm_cxl_add_dax_region: cxl_region region0: region0:
register dax_region0
[   30.921015] hmem: hmem_platform probe started.
[   31.017946] hmem_platform hmem_platform.0: Soft Reserved not fully
contained in CXL; using HMEM
[   31.056310] alloc_dev_dax_range:  dax6.0: alloc range[0]:
0x0000000850000000:0x000000284fffffff
[   34.781516] cxl-dax: cxl_dax_region_init()
[   34.781522] cxl-dax: registering driver.
[   34.781523] cxl-dax: dax_hmem work flushed.
[   34.781549] alloc_dax_region: cxl_dax_region dax_region0: dax_region
resource conflict for [mem 0x850000000-0x284fffffff]
[   34.781552] cxl_bus_probe: cxl_dax_region dax_region0: probe: -12
[   34.781554] cxl_dax_region dax_region0: probe with driver cxl_dax_region
failed with error -12

v6 updates:
- Patch 1-3 no changes.
- New Patches 4-5.
- (void *)res -&gt; res.
- cxl_region_contains_soft_reserve -&gt; region_contains_soft_reserve.
- New file include/cxl/cxl.h
- Introduced singleton workqueue.
- hmem to queue the work and cxl to flush.
- cxl_contains_soft_reserve() -&gt; soft_reserve_has_cxl_match().
- Included descriptions for dax_cxl_mode.
- kzalloc -&gt; kmalloc in add_soft_reserve_into_iomem()
- dax_cxl_mode is exported to CXL.
- Introduced hmem_register_cxl_device() for walking only CXL
intersected SR ranges the second time.

v5 updates:
- Patch 1 dropped as its been merged for-7.0/cxl-init.
- Added Reviewed-by tags.
- Shared dax_cxl_mode between dax/cxl.c and dax/hmem.c and used
  -EPROBE_DEFER to defer dax_cxl.
- CXL_REGION_F_AUTO check for resetting decoders.
- Teardown all CXL regions if any one CXL region doesn&#x27;t fully contain
  the Soft Reserved range.
- Added helper cxl_region_contains_sr() to determine Soft Reserved
  ownership.
- bus_rescan_devices() to retry dax_cxl.
- Added guard(rwsem_read)(&amp;cxl_rwsem.region).

v4 updates:
- No changes patches 1-3.
- New patches 4-7.
- handle_deferred_cxl() has been enhanced to handle case where CXL
  regions do not contiguously and fully cover Soft Reserved ranges.
- Support added to defer cxl_dax registration.
- Support added to teardown cxl regions.

v3 updates:
 - Fixed two &quot;From&quot;.

v2 updates:
 - Removed conditional check on CONFIG_EFI_SOFT_RESERVE as dax_hmem
   depends on CONFIG_EFI_SOFT_RESERVE. (Zhijian)
 - Added TODO note. (Zhijian)
 - Included region_intersects_soft_reserve() inside CONFIG_EFI_SOFT_RESERVE
   conditional check. (Zhijian)
 - insert_resource_late() -&gt; insert_resource_expand_to_fit() and
   __insert_resource_expand_to_fit() replacement. (Boris)
 - Fixed Co-developed and Signed-off by. (Dan)
 - Combined 2/6 and 3/6 into a single patch. (Zhijian).
 - Skip local variable in remove_soft_reserved. (Jonathan)
 - Drop kfree with __free(). (Jonathan)
 - return 0 -&gt; return dev_add_action_or_reset(host...) (Jonathan)
 - Dropped 6/6.
 - Reviewed-by tags (Dave, Jonathan)

Dan Williams (3):
  dax/hmem: Request cxl_acpi and cxl_pci before walking Soft Reserved
    ranges
  dax/hmem: Gate Soft Reserved deferral on DEV_DAX_CXL
  dax/cxl, hmem: Initialize hmem early and defer dax_cxl binding

Smita Koralahalli (6):
  cxl/region: Skip decoder reset on detach for autodiscovered regions
  dax: Track all dax_region allocations under a global resource tree
  cxl/region: Add helper to check Soft Reserved containment by CXL
    regions
  dax: Add deferred-work helpers for dax_hmem and dax_cxl coordination
  dax/hmem, cxl: Defer and resolve ownership of Soft Reserved memory
    ranges
  dax/hmem: Reintroduce Soft Reserved ranges back into the iomem tree

 drivers/cxl/core/region.c |  34 +++++++++-
 drivers/dax/Kconfig       |   2 +
 drivers/dax/Makefile      |   3 +-
 drivers/dax/bus.c         |  84 ++++++++++++++++++++++++-
 drivers/dax/bus.h         |  26 ++++++++
 drivers/dax/cxl.c         |  28 ++++++++-
 drivers/dax/hmem/hmem.c   | 129 ++++++++++++++++++++++++++++++++++----
 include/cxl/cxl.h         |  15 +++++
 8 files changed, 303 insertions(+), 18 deletions(-)
 create mode 100644 include/cxl/cxl.h

-- 
2.17.1



---

From: Dan Williams &lt;dan.j.williams@intel.com&gt;

Move hmem/ earlier in the dax Makefile so that hmem_init() runs before
dax_cxl.

In addition, defer registration of the dax_cxl driver to a workqueue
instead of using module_cxl_driver(). This ensures that dax_hmem has
an opportunity to initialize and register its deferred callback and make
ownership decisions before dax_cxl begins probing and claiming Soft
Reserved ranges.

Mark the dax_cxl driver as PROBE_PREFER_ASYNCHRONOUS so its probe runs
out of line from other synchronous probing avoiding ordering
dependencies while coordinating ownership decisions with dax_hmem.

Signed-off-by: Dan Williams &lt;dan.j.williams@intel.com&gt;
Signed-off-by: Smita Koralahalli &lt;Smita.KoralahalliChannabasappa@amd.com&gt;
---
 drivers/dax/Makefile |  3 +--
 drivers/dax/cxl.c    | 27 ++++++++++++++++++++++++++-
 2 files changed, 27 insertions(+), 3 deletions(-)

diff --git a/drivers/dax/Makefile b/drivers/dax/Makefile
index 5ed5c39857c8..70e996bf1526 100644
--- a/drivers/dax/Makefile
+++ b/drivers/dax/Makefile
@@ -1,4 +1,5 @@
 # SPDX-License-Identifier: GPL-2.0
+obj-y += hmem/
 obj-$(CONFIG_DAX) += dax.o
 obj-$(CONFIG_DEV_DAX) += device_dax.o
 obj-$(CONFIG_DEV_DAX_KMEM) += kmem.o
@@ -10,5 +11,3 @@ dax-y += bus.o
 device_dax-y := device.o
 dax_pmem-y := pmem.o
 dax_cxl-y := cxl.o
-
-obj-y += hmem/
diff --git a/drivers/dax/cxl.c b/drivers/dax/cxl.c
index 13cd94d32ff7..a2136adfa186 100644
--- a/drivers/dax/cxl.c
+++ b/drivers/dax/cxl.c
@@ -38,10 +38,35 @@ static struct cxl_driver cxl_dax_region_driver = {
 	.id = CXL_DEVICE_DAX_REGION,
 	.drv = {
 		.suppress_bind_attrs = true,
+		.probe_type = PROBE_PREFER_ASYNCHRONOUS,
 	},
 };
 
-module_cxl_driver(cxl_dax_region_driver);
+static void cxl_dax_region_driver_register(struct work_struct *work)
+{
+	cxl_driver_register(&amp;cxl_dax_region_driver);
+}
+
+static DECLARE_WORK(cxl_dax_region_driver_work, cxl_dax_region_driver_register);
+
+static int __init cxl_dax_region_init(void)
+{
+	/*
+	 * Need to resolve a race with dax_hmem wanting to drive regions
+	 * instead of CXL
+	 */
+	queue_work(system_long_wq, &amp;cxl_dax_region_driver_work);
+	return 0;
+}
+module_init(cxl_dax_region_init);
+
+static void __exit cxl_dax_region_exit(void)
+{
+	flush_work(&amp;cxl_dax_region_driver_work);
+	cxl_driver_unregister(&amp;cxl_dax_region_driver);
+}
+module_exit(cxl_dax_region_exit);
+
 MODULE_ALIAS_CXL(CXL_DEVICE_DAX_REGION);
 MODULE_DESCRIPTION(&quot;CXL DAX: direct access to CXL regions&quot;);
 MODULE_LICENSE(&quot;GPL&quot;);
-- 
2.17.1



---

__cxl_decoder_detach() currently resets decoder programming whenever a
region is detached if cxl_config_state is beyond CXL_CONFIG_ACTIVE. For
autodiscovered regions, this can incorrectly tear down decoder state
that may be relied upon by other consumers or by subsequent ownership
decisions.

Skip cxl_region_decode_reset() during detach when CXL_REGION_F_AUTO is
set.

Signed-off-by: Smita Koralahalli &lt;Smita.KoralahalliChannabasappa@amd.com&gt;
Reviewed-by: Jonathan Cameron &lt;jonathan.cameron@huawei.com&gt;
Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
Reviewed-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
---
 drivers/cxl/core/region.c | 4 +++-
 1 file changed, 3 insertions(+), 1 deletion(-)

diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
index ae899f68551f..45ee598daf95 100644
--- a/drivers/cxl/core/region.c
+++ b/drivers/cxl/core/region.c
@@ -2178,7 +2178,9 @@ __cxl_decoder_detach(struct cxl_region *cxlr,
 		cxled-&gt;part = -1;
 
 	if (p-&gt;state &gt; CXL_CONFIG_ACTIVE) {
-		cxl_region_decode_reset(cxlr, p-&gt;interleave_ways);
+		if (!test_bit(CXL_REGION_F_AUTO, &amp;cxlr-&gt;flags))
+			cxl_region_decode_reset(cxlr, p-&gt;interleave_ways);
+
 		p-&gt;state = CXL_CONFIG_ACTIVE;
 	}
 
-- 
2.17.1



---

Introduce a global &quot;DAX Regions&quot; resource root and register each
dax_region-&gt;res under it via request_resource(). Release the resource on
dax_region teardown.

By enforcing a single global namespace for dax_region allocations, this
ensures only one of dax_hmem or dax_cxl can successfully register a
dax_region for a given range.

Co-developed-by: Dan Williams &lt;dan.j.williams@intel.com&gt;
Signed-off-by: Dan Williams &lt;dan.j.williams@intel.com&gt;
Signed-off-by: Smita Koralahalli &lt;Smita.KoralahalliChannabasappa@amd.com&gt;
---
 drivers/dax/bus.c | 23 ++++++++++++++++++++---
 1 file changed, 20 insertions(+), 3 deletions(-)

diff --git a/drivers/dax/bus.c b/drivers/dax/bus.c
index fde29e0ad68b..5f387feb95f0 100644
--- a/drivers/dax/bus.c
+++ b/drivers/dax/bus.c
@@ -10,6 +10,7 @@
 #include &quot;dax-private.h&quot;
 #include &quot;bus.h&quot;
 
+static struct resource dax_regions = DEFINE_RES_MEM_NAMED(0, -1, &quot;DAX Regions&quot;);
 static DEFINE_MUTEX(dax_bus_lock);
 
 /*
@@ -625,6 +626,8 @@ static void dax_region_unregister(void *region)
 {
 	struct dax_region *dax_region = region;
 
+	scoped_guard(rwsem_write, &amp;dax_region_rwsem)
+		release_resource(&amp;dax_region-&gt;res);
 	sysfs_remove_groups(&amp;dax_region-&gt;dev-&gt;kobj,
 			dax_region_attribute_groups);
 	dax_region_put(dax_region);
@@ -635,6 +638,7 @@ struct dax_region *alloc_dax_region(struct device *parent, int region_id,
 		unsigned long flags)
 {
 	struct dax_region *dax_region;
+	int rc;
 
 	/*
 	 * The DAX core assumes that it can store its private data in
@@ -667,14 +671,27 @@ struct dax_region *alloc_dax_region(struct device *parent, int region_id,
 		.flags = IORESOURCE_MEM | flags,
 	};
 
-	if (sysfs_create_groups(&amp;parent-&gt;kobj, dax_region_attribute_groups)) {
-		kfree(dax_region);
-		return NULL;
+	scoped_guard(rwsem_write, &amp;dax_region_rwsem)
+		rc = request_resource(&amp;dax_regions, &amp;dax_region-&gt;res);
+	if (rc) {
+		dev_dbg(parent, &quot;dax_region resource conflict for %pR\n&quot;,
+			&amp;dax_region-&gt;res);
+		goto err_res;
 	}
 
+	if (sysfs_create_groups(&amp;parent-&gt;kobj, dax_region_attribute_groups))
+		goto err_sysfs;
+
 	if (devm_add_action_or_reset(parent, dax_region_unregister, dax_region))
 		return NULL;
 	return dax_region;
+
+err_sysfs:
+	scoped_guard(rwsem_write, &amp;dax_region_rwsem)
+		release_resource(&amp;dax_region-&gt;res);
+err_res:
+	kfree(dax_region);
+	return NULL;
 }
 EXPORT_SYMBOL_GPL(alloc_dax_region);
 
-- 
2.17.1



---

Add a helper to determine whether a given Soft Reserved memory range is
fully contained within the committed CXL region.

This helper provides a primitive for policy decisions in subsequent
patches such as co-ordination with dax_hmem to determine whether CXL has
fully claimed ownership of Soft Reserved memory ranges.

Signed-off-by: Smita Koralahalli &lt;Smita.KoralahalliChannabasappa@amd.com&gt;
Reviewed-by: Jonathan Cameron &lt;jonathan.cameron@huawei.com&gt;
Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
---
 drivers/cxl/core/region.c | 30 ++++++++++++++++++++++++++++++
 include/cxl/cxl.h         | 15 +++++++++++++++
 2 files changed, 45 insertions(+)
 create mode 100644 include/cxl/cxl.h

diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
index 45ee598daf95..96ed550bfd2e 100644
--- a/drivers/cxl/core/region.c
+++ b/drivers/cxl/core/region.c
@@ -12,6 +12,7 @@
 #include &lt;linux/idr.h&gt;
 #include &lt;linux/memory-tiers.h&gt;
 #include &lt;linux/string_choices.h&gt;
+#include &lt;cxl/cxl.h&gt;
 #include &lt;cxlmem.h&gt;
 #include &lt;cxl.h&gt;
 #include &quot;core.h&quot;
@@ -3875,6 +3876,35 @@ static int cxl_region_debugfs_poison_clear(void *data, u64 offset)
 DEFINE_DEBUGFS_ATTRIBUTE(cxl_poison_clear_fops, NULL,
 			 cxl_region_debugfs_poison_clear, &quot;%llx\n&quot;);
 
+static int region_contains_soft_reserve(struct device *dev, void *data)
+{
+	struct resource *res = data;
+	struct cxl_region *cxlr;
+	struct cxl_region_params *p;
+
+	if (!is_cxl_region(dev))
+		return 0;
+
+	cxlr = to_cxl_region(dev);
+	p = &amp;cxlr-&gt;params;
+
+	if (p-&gt;state != CXL_CONFIG_COMMIT)
+		return 0;
+
+	if (!p-&gt;res)
+		return 0;
+
+	return resource_contains(p-&gt;res, res) ? 1 : 0;
+}
+
+bool cxl_region_contains_soft_reserve(struct resource *res)
+{
+	guard(rwsem_read)(&amp;cxl_rwsem.region);
+	return bus_for_each_dev(&amp;cxl_bus_type, NULL, res,
+				region_contains_soft_reserve) != 0;
+}
+EXPORT_SYMBOL_GPL(cxl_region_contains_soft_reserve);
+
 static int cxl_region_can_probe(struct cxl_region *cxlr)
 {
 	struct cxl_region_params *p = &amp;cxlr-&gt;params;
diff --git a/include/cxl/cxl.h b/include/cxl/cxl.h
new file mode 100644
index 000000000000..db1f588e106c
--- /dev/null
+++ b/include/cxl/cxl.h
@@ -0,0 +1,15 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+/* Copyright (c) 2026 Advanced Micro Devices, Inc. */
+#ifndef _CXL_H_
+#define _CXL_H_
+
+#ifdef CONFIG_CXL_REGION
+bool cxl_region_contains_soft_reserve(struct resource *res);
+#else
+static inline bool cxl_region_contains_soft_reserve(struct resource *res)
+{
+	return false;
+}
+#endif
+
+#endif /* _CXL_H_ */
-- 
2.17.1



---

Reworked from a patch by Alison Schofield &lt;alison.schofield@intel.com&gt;

Reintroduce Soft Reserved range into the iomem_resource tree for HMEM
to consume.

This restores visibility in /proc/iomem for ranges actively in use, while
avoiding the early-boot conflicts that occurred when Soft Reserved was
published into iomem before CXL window and region discovery.

Link: https://lore.kernel.org/linux-cxl/29312c0765224ae76862d59a17748c8188fb95f1.1692638817.git.alison.schofield@intel.com/
Co-developed-by: Alison Schofield &lt;alison.schofield@intel.com&gt;
Signed-off-by: Alison Schofield &lt;alison.schofield@intel.com&gt;
Co-developed-by: Zhijian Li &lt;lizhijian@fujitsu.com&gt;
Signed-off-by: Zhijian Li &lt;lizhijian@fujitsu.com&gt;
Signed-off-by: Smita Koralahalli &lt;Smita.KoralahalliChannabasappa@amd.com&gt;
Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
Reviewed-by: Jonathan Cameron &lt;jonathan.cameron@huawei.com&gt;
Reviewed-by: Dan Williams &lt;dan.j.williams@intel.com&gt;
---
 drivers/dax/hmem/hmem.c | 32 +++++++++++++++++++++++++++++++-
 1 file changed, 31 insertions(+), 1 deletion(-)

diff --git a/drivers/dax/hmem/hmem.c b/drivers/dax/hmem/hmem.c
index 85854e25254b..c07bf5fe833d 100644
--- a/drivers/dax/hmem/hmem.c
+++ b/drivers/dax/hmem/hmem.c
@@ -59,6 +59,34 @@ static void release_hmem(void *pdev)
 	platform_device_unregister(pdev);
 }
 
+static void remove_soft_reserved(void *r)
+{
+	remove_resource(r);
+	kfree(r);
+}
+
+static int add_soft_reserve_into_iomem(struct device *host,
+				       const struct resource *res)
+{
+	int rc;
+
+	struct resource *soft __free(kfree) =
+		kmalloc(sizeof(*res), GFP_KERNEL);
+	if (!soft)
+		return -ENOMEM;
+
+	*soft = DEFINE_RES_NAMED_DESC(res-&gt;start, (res-&gt;end - res-&gt;start + 1),
+				      &quot;Soft Reserved&quot;, IORESOURCE_MEM,
+				      IORES_DESC_SOFT_RESERVED);
+
+	rc = insert_resource(&amp;iomem_resource, soft);
+	if (rc)
+		return rc;
+
+	return devm_add_action_or_reset(host, remove_soft_reserved,
+					no_free_ptr(soft));
+}
+
 static int hmem_register_device(struct device *host, int target_nid,
 				const struct resource *res)
 {
@@ -88,7 +116,9 @@ static int hmem_register_device(struct device *host, int target_nid,
 	if (rc != REGION_INTERSECTS)
 		return 0;
 
-	/* TODO: Add Soft-Reserved memory back to iomem */
+	rc = add_soft_reserve_into_iomem(host, res);
+	if (rc)
+		return rc;
 
 	id = memregion_alloc(GFP_KERNEL);
 	if (id &lt; 0) {
-- 
2.17.1



---

Add helpers to register, queue and flush the deferred work.

These helpers allow dax_hmem to execute ownership resolution outside the
probe context before dax_cxl binds.

Signed-off-by: Smita Koralahalli &lt;Smita.KoralahalliChannabasappa@amd.com&gt;
---
 drivers/dax/bus.c | 58 +++++++++++++++++++++++++++++++++++++++++++++++
 drivers/dax/bus.h |  7 ++++++
 2 files changed, 65 insertions(+)

diff --git a/drivers/dax/bus.c b/drivers/dax/bus.c
index 5f387feb95f0..92b88952ede1 100644
--- a/drivers/dax/bus.c
+++ b/drivers/dax/bus.c
@@ -25,6 +25,64 @@ DECLARE_RWSEM(dax_region_rwsem);
  */
 DECLARE_RWSEM(dax_dev_rwsem);
 
+static DEFINE_MUTEX(dax_hmem_lock);
+static dax_hmem_deferred_fn hmem_deferred_fn;
+static void *dax_hmem_data;
+
+static void hmem_deferred_work(struct work_struct *work)
+{
+	dax_hmem_deferred_fn fn;
+	void *data;
+
+	scoped_guard(mutex, &amp;dax_hmem_lock) {
+		fn = hmem_deferred_fn;
+		data = dax_hmem_data;
+	}
+
+	if (fn)
+		fn(data);
+}
+
+static DECLARE_WORK(dax_hmem_work, hmem_deferred_work);
+
+int dax_hmem_register_work(dax_hmem_deferred_fn fn, void *data)
+{
+	guard(mutex)(&amp;dax_hmem_lock);
+
+	if (hmem_deferred_fn)
+		return -EINVAL;
+
+	hmem_deferred_fn = fn;
+	dax_hmem_data = data;
+	return 0;
+}
+EXPORT_SYMBOL_GPL(dax_hmem_register_work);
+
+int dax_hmem_unregister_work(dax_hmem_deferred_fn fn, void *data)
+{
+	guard(mutex)(&amp;dax_hmem_lock);
+
+	if (hmem_deferred_fn != fn || dax_hmem_data != data)
+		return -EINVAL;
+
+	hmem_deferred_fn = NULL;
+	dax_hmem_data = NULL;
+	return 0;
+}
+EXPORT_SYMBOL_GPL(dax_hmem_unregister_work);
+
+void dax_hmem_queue_work(void)
+{
+	queue_work(system_long_wq, &amp;dax_hmem_work);
+}
+EXPORT_SYMBOL_GPL(dax_hmem_queue_work);
+
+void dax_hmem_flush_work(void)
+{
+	flush_work(&amp;dax_hmem_work);
+}
+EXPORT_SYMBOL_GPL(dax_hmem_flush_work);
+
 #define DAX_NAME_LEN 30
 struct dax_id {
 	struct list_head list;
diff --git a/drivers/dax/bus.h b/drivers/dax/bus.h
index cbbf64443098..b58a88e8089c 100644
--- a/drivers/dax/bus.h
+++ b/drivers/dax/bus.h
@@ -41,6 +41,13 @@ struct dax_device_driver {
 	void (*remove)(struct dev_dax *dev);
 };
 
+typedef void (*dax_hmem_deferred_fn)(void *data);
+
+int dax_hmem_register_work(dax_hmem_deferred_fn fn, void *data);
+int dax_hmem_unregister_work(dax_hmem_deferred_fn fn, void *data);
+void dax_hmem_queue_work(void);
+void dax_hmem_flush_work(void);
+
 int __dax_driver_register(struct dax_device_driver *dax_drv,
 		struct module *module, const char *mod_name);
 #define dax_driver_register(driver) \
-- 
2.17.1



---

The current probe time ownership check for Soft Reserved memory based
solely on CXL window intersection is insufficient. dax_hmem probing is not
always guaranteed to run after CXL enumeration and region assembly, which
can lead to incorrect ownership decisions before the CXL stack has
finished publishing windows and assembling committed regions.

Introduce deferred ownership handling for Soft Reserved ranges that
intersect CXL windows. When such a range is encountered during dax_hmem
probe, schedule deferred work and wait for the CXL stack to complete
enumeration and region assembly before deciding ownership.

Evaluate ownership of Soft Reserved ranges based on CXL region
containment.

   - If all Soft Reserved ranges are fully contained within committed CXL
     regions, DROP handling Soft Reserved ranges from dax_hmem and allow
     dax_cxl to bind.

   - If any Soft Reserved range is not fully claimed by committed CXL
     region, REGISTER the Soft Reserved ranges with dax_hmem.

Use dax_cxl_mode to coordinate ownership decisions for Soft Reserved
ranges. Once, ownership resolution is complete, flush the deferred work
from dax_cxl before allowing dax_cxl to bind.

This enforces a strict ownership. Either CXL fully claims the Soft
reserved ranges or it relinquishes it entirely.

Co-developed-by: Dan Williams &lt;dan.j.williams@intel.com&gt;
Signed-off-by: Dan Williams &lt;dan.j.williams@intel.com&gt;
Signed-off-by: Smita Koralahalli &lt;Smita.KoralahalliChannabasappa@amd.com&gt;
---
 drivers/dax/bus.c       |  3 ++
 drivers/dax/bus.h       | 19 ++++++++++
 drivers/dax/cxl.c       |  1 +
 drivers/dax/hmem/hmem.c | 78 +++++++++++++++++++++++++++++++++++++++--
 4 files changed, 99 insertions(+), 2 deletions(-)

diff --git a/drivers/dax/bus.c b/drivers/dax/bus.c
index 92b88952ede1..81985bcc70f9 100644
--- a/drivers/dax/bus.c
+++ b/drivers/dax/bus.c
@@ -25,6 +25,9 @@ DECLARE_RWSEM(dax_region_rwsem);
  */
 DECLARE_RWSEM(dax_dev_rwsem);
 
+enum dax_cxl_mode dax_cxl_mode = DAX_CXL_MODE_DEFER;
+EXPORT_SYMBOL_NS_GPL(dax_cxl_mode, &quot;CXL&quot;);
+
 static DEFINE_MUTEX(dax_hmem_lock);
 static dax_hmem_deferred_fn hmem_deferred_fn;
 static void *dax_hmem_data;
diff --git a/drivers/dax/bus.h b/drivers/dax/bus.h
index b58a88e8089c..82616ff52fd1 100644
--- a/drivers/dax/bus.h
+++ b/drivers/dax/bus.h
@@ -41,6 +41,25 @@ struct dax_device_driver {
 	void (*remove)(struct dev_dax *dev);
 };
 
+/*
+ * enum dax_cxl_mode - State machine to determine ownership for CXL
+ * tagged Soft Reserved memory ranges.
+ * @DAX_CXL_MODE_DEFER: Ownership resolution pending. Set while waiting
+ * for CXL enumeration and region assembly to complete.
+ * @DAX_CXL_MODE_REGISTER: CXL regions do not fully cover Soft Reserved
+ * ranges. Fall back to registering those ranges via dax_hmem.
+ * @DAX_CXL_MODE_DROP: All Soft Reserved ranges intersecting CXL windows
+ * are fully contained within committed CXL regions. Drop HMEM handling
+ * and allow dax_cxl to bind.
+ */
+enum dax_cxl_mode {
+	DAX_CXL_MODE_DEFER,
+	DAX_CXL_MODE_REGISTER,
+	DAX_CXL_MODE_DROP,
+};
+
+extern enum dax_cxl_mode dax_cxl_mode;
+
 typedef void (*dax_hmem_deferred_fn)(void *data);
 
 int dax_hmem_register_work(dax_hmem_deferred_fn fn, void *data);
diff --git a/drivers/dax/cxl.c b/drivers/dax/cxl.c
index a2136adfa186..3ab39b77843d 100644
--- a/drivers/dax/cxl.c
+++ b/drivers/dax/cxl.c
@@ -44,6 +44,7 @@ static struct cxl_driver cxl_dax_region_driver = {
 
 static void cxl_dax_region_driver_register(struct work_struct *work)
 {
+	dax_hmem_flush_work();
 	cxl_driver_register(&amp;cxl_dax_region_driver);
 }
 
diff --git a/drivers/dax/hmem/hmem.c b/drivers/dax/hmem/hmem.c
index 1e3424358490..85854e25254b 100644
--- a/drivers/dax/hmem/hmem.c
+++ b/drivers/dax/hmem/hmem.c
@@ -3,6 +3,7 @@
 #include &lt;linux/memregion.h&gt;
 #include &lt;linux/module.h&gt;
 #include &lt;linux/dax.h&gt;
+#include &lt;cxl/cxl.h&gt;
 #include &quot;../bus.h&quot;
 
 static bool region_idle;
@@ -69,8 +70,18 @@ static int hmem_register_device(struct device *host, int target_nid,
 	if (IS_ENABLED(CONFIG_DEV_DAX_CXL) &amp;&amp;
 	    region_intersects(res-&gt;start, resource_size(res), IORESOURCE_MEM,
 			      IORES_DESC_CXL) != REGION_DISJOINT) {
-		dev_dbg(host, &quot;deferring range to CXL: %pr\n&quot;, res);
-		return 0;
+		switch (dax_cxl_mode) {
+		case DAX_CXL_MODE_DEFER:
+			dev_dbg(host, &quot;deferring range to CXL: %pr\n&quot;, res);
+			dax_hmem_queue_work();
+			return 0;
+		case DAX_CXL_MODE_REGISTER:
+			dev_dbg(host, &quot;registering CXL range: %pr\n&quot;, res);
+			break;
+		case DAX_CXL_MODE_DROP:
+			dev_dbg(host, &quot;dropping CXL range: %pr\n&quot;, res);
+			return 0;
+		}
 	}
 
 	rc = region_intersects_soft_reserve(res-&gt;start, resource_size(res));
@@ -123,8 +134,70 @@ static int hmem_register_device(struct device *host, int target_nid,
 	return rc;
 }
 
+static int hmem_register_cxl_device(struct device *host, int target_nid,
+				    const struct resource *res)
+{
+	if (region_intersects(res-&gt;start, resource_size(res), IORESOURCE_MEM,
+			      IORES_DESC_CXL) != REGION_DISJOINT)
+		return hmem_register_device(host, target_nid, res);
+
+	return 0;
+}
+
+static int soft_reserve_has_cxl_match(struct device *host, int target_nid,
+				      const struct resource *res)
+{
+	if (region_intersects(res-&gt;start, resource_size(res), IORESOURCE_MEM,
+			      IORES_DESC_CXL) != REGION_DISJOINT) {
+		if (!cxl_region_contains_soft_reserve((struct resource *)res))
+			return 1;
+	}
+
+	return 0;
+}
+
+static void process_defer_work(void *data)
+{
+	struct platform_device *pdev = data;
+	int rc;
+
+	/* relies on cxl_acpi and cxl_pci having had a chance to load */
+	wait_for_device_probe();
+
+	rc = walk_hmem_resources(&amp;pdev-&gt;dev, soft_reserve_has_cxl_match);
+
+	if (!rc) {
+		dax_cxl_mode = DAX_CXL_MODE_DROP;
+		dev_dbg(&amp;pdev-&gt;dev, &quot;All Soft Reserved ranges claimed by CXL\n&quot;);
+	} else {
+		dax_cxl_mode = DAX_CXL_MODE_REGISTER;
+		dev_warn(&amp;pdev-&gt;dev,
+			 &quot;Soft Reserved not fully contained in CXL; using HMEM\n&quot;);
+	}
+
+	walk_hmem_resources(&amp;pdev-&gt;dev, hmem_register_cxl_device);
+}
+
+static void kill_defer_work(void *data)
+{
+	struct platform_device *pdev = data;
+
+	dax_hmem_flush_work();
+	dax_hmem_unregister_work(process_defer_work, pdev);
+}
+
 static int dax_hmem_platform_probe(struct platform_device *pdev)
 {
+	int rc;
+
+	rc = dax_hmem_register_work(process_defer_work, pdev);
+	if (rc)
+		return rc;
+
+	rc = devm_add_action_or_reset(&amp;pdev-&gt;dev, kill_defer_work, pdev);
+	if (rc)
+		return rc;
+
 	return walk_hmem_resources(&amp;pdev-&gt;dev, hmem_register_device);
 }
 
@@ -174,3 +247,4 @@ MODULE_ALIAS(&quot;platform:hmem_platform*&quot;);
 MODULE_DESCRIPTION(&quot;HMEM DAX: direct access to &#x27;specific purpose&#x27; memory&quot;);
 MODULE_LICENSE(&quot;GPL v2&quot;);
 MODULE_AUTHOR(&quot;Intel Corporation&quot;);
+MODULE_IMPORT_NS(&quot;CXL&quot;);
-- 
2.17.1

</pre>
</details>
<div class="review-comment-signals">Signals: requested changes</div>
</div>
<div class="thread-children">
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Alison Schofield</span>
<a class="date-chip" href="../2026-02-13_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The reviewer, Alison Schofield, raised concerns about the removal of region teardown in the patch and asked for clarification on the new approach. She also pointed out a potential issue with disabled regions and DAX children.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">On Tue, Feb 10, 2026 at 06:44:52AM +0000, Smita Koralahalli wrote:
&gt; This series aims to address long-standing conflicts between HMEM and
&gt; CXL when handling Soft Reserved memory ranges.
&gt; 
&gt; Reworked from Dan&#x27;s patch:
&gt; https://git.kernel.org/pub/scm/linux/kernel/git/cxl/cxl.git/patch/?id=ab70c6227ee6165a562c215d9dcb4a1c55620d5d
&gt; 
&gt; Previous work:
&gt; https://lore.kernel.org/all/20250715180407.47426-1-Smita.KoralahalliChannabasappa@amd.com/
&gt; 
&gt; Link to v5:
&gt; https://lore.kernel.org/all/20260122045543.218194-1-Smita.KoralahalliChannabasappa@amd.com
&gt; 
&gt; The series is based on branch &quot;for-7.0/cxl-init&quot; and base-commit is
&gt; base-commit: bc62f5b308cbdedf29132fe96e9d591e526527e1
&gt; 
&gt; [1] After offlining the memory I can tear down the regions and recreate
&gt; them back. dax_cxl creates dax devices and onlines memory.
&gt; 850000000-284fffffff : CXL Window 0
&gt;   850000000-284fffffff : region0
&gt;     850000000-284fffffff : dax0.0
&gt;       850000000-284fffffff : System RAM (kmem)
&gt; 
&gt; [2] With CONFIG_CXL_REGION disabled, all the resources are handled by
&gt; HMEM. Soft Reserved range shows up in /proc/iomem, no regions come up
&gt; and dax devices are created from HMEM.
&gt; 850000000-284fffffff : CXL Window 0
&gt;   850000000-284fffffff : Soft Reserved
&gt;     850000000-284fffffff : dax0.0
&gt;       850000000-284fffffff : System RAM (kmem)
&gt; 
&gt; [3] Region assembly failure works same as [2].
&gt; 
&gt; [4] REGISTER path:
&gt; When CXL_BUS = y (with CXL_ACPI, CXL_PCI, CXL_PORT, CXL_MEM = y),
&gt; the dax_cxl driver is probed and completes initialization before dax_hmem
&gt; probes. This scenario was tested with CXL = y, DAX_CXL = m and
&gt; DAX_HMEM = m. To validate the REGISTER path, I forced REGISTER even in
&gt; cases where SR completely overlaps the CXL region as I did not have access
&gt; to a system where the CXL region range is smaller than the SR range.
&gt; 
&gt; 850000000-284fffffff : Soft Reserved
&gt;   850000000-284fffffff : CXL Window 0
&gt;     850000000-280fffffff : region0
&gt;       850000000-284fffffff : dax0.0
&gt;         850000000-284fffffff : System RAM (kmem)
&gt; 
&gt; &quot;path&quot;:&quot;\/platform\/ACPI0017:00\/root0\/decoder0.0\/region0\/dax_region0&quot;,
&gt; &quot;id&quot;:0,
&gt; &quot;size&quot;:&quot;128.00 GiB (137.44 GB)&quot;,
&gt; &quot;align&quot;:2097152
&gt; 
&gt; [   35.961707] cxl-dax: cxl_dax_region_init()
&gt; [   35.961713] cxl-dax: registering driver.
&gt; [   35.961715] cxl-dax: dax_hmem work flushed.
&gt; [   35.961754] alloc_dev_dax_range:  dax0.0: alloc range[0]:
&gt; 0x000000850000000:0x000000284fffffff
&gt; [   35.976622] hmem: hmem_platform probe started.
&gt; [   35.980821] cxl_bus_probe: cxl_dax_region dax_region0: probe: 0
&gt; [   36.819566] hmem_platform hmem_platform.0: Soft Reserved not fully
&gt; contained in CXL; using HMEM
&gt; [   36.819569] hmem_register_device: hmem_platform hmem_platform.0:
&gt; registering CXL range: [mem 0x850000000-0x284fffffff flags 0x80000200]
&gt; [   36.934156] alloc_dax_region: hmem hmem.6: dax_region resource conflict
&gt; for [mem 0x850000000-0x284fffffff]
&gt; [   36.989310] hmem hmem.6: probe with driver hmem failed with error -12
&gt; 
&gt; [5] When CXL_BUS = m (with CXL_ACPI, CXL_PCI, CXL_PORT, CXL_MEM = m),
&gt; DAX_CXL = m and DAX_HMEM = y the results are as expected. To validate the
&gt; REGISTER path, I forced REGISTER even in cases where SR completely
&gt; overlaps the CXL region as I did not have access to a system where the
&gt; CXL region range is smaller than the SR range.
&gt; 
&gt; 850000000-284fffffff : Soft Reserved
&gt;   850000000-284fffffff : CXL Window 0
&gt;     850000000-280fffffff : region0
&gt;       850000000-284fffffff : dax6.0
&gt;         850000000-284fffffff : System RAM (kmem)
&gt; 
&gt; &quot;path&quot;:&quot;\/platform\/hmem.6&quot;,
&gt; &quot;id&quot;:6,
&gt; &quot;size&quot;:&quot;128.00 GiB (137.44 GB)&quot;,
&gt; &quot;align&quot;:2097152
&gt; 
&gt; [   30.897665] devm_cxl_add_dax_region: cxl_region region0: region0:
&gt; register dax_region0
&gt; [   30.921015] hmem: hmem_platform probe started.
&gt; [   31.017946] hmem_platform hmem_platform.0: Soft Reserved not fully
&gt; contained in CXL; using HMEM
&gt; [   31.056310] alloc_dev_dax_range:  dax6.0: alloc range[0]:
&gt; 0x0000000850000000:0x000000284fffffff
&gt; [   34.781516] cxl-dax: cxl_dax_region_init()
&gt; [   34.781522] cxl-dax: registering driver.
&gt; [   34.781523] cxl-dax: dax_hmem work flushed.
&gt; [   34.781549] alloc_dax_region: cxl_dax_region dax_region0: dax_region
&gt; resource conflict for [mem 0x850000000-0x284fffffff]
&gt; [   34.781552] cxl_bus_probe: cxl_dax_region dax_region0: probe: -12
&gt; [   34.781554] cxl_dax_region dax_region0: probe with driver cxl_dax_region
&gt; failed with error -12
&gt; 
&gt; v6 updates:
&gt; - Patch 1-3 no changes.
&gt; - New Patches 4-5.
&gt; - (void *)res -&gt; res.
&gt; - cxl_region_contains_soft_reserve -&gt; region_contains_soft_reserve.
&gt; - New file include/cxl/cxl.h
&gt; - Introduced singleton workqueue.
&gt; - hmem to queue the work and cxl to flush.
&gt; - cxl_contains_soft_reserve() -&gt; soft_reserve_has_cxl_match().
&gt; - Included descriptions for dax_cxl_mode.
&gt; - kzalloc -&gt; kmalloc in add_soft_reserve_into_iomem()
&gt; - dax_cxl_mode is exported to CXL.
&gt; - Introduced hmem_register_cxl_device() for walking only CXL
&gt; intersected SR ranges the second time.

During v5 review of this patch:

[PATCH v5 6/7] dax/hmem, cxl: Defer and resolve ownership of Soft Reserved memory ranges

there was discussion around handling region teardown. It&#x27;s not mentioned
in the changelog, and the teardown is completely removed from the patch.

The discussion seemed to be leaning towards not tearing down &#x27;all&#x27;, but
it&#x27;s not clear to me that we decided not to tear down anything - which
this update now does. 

And, as you may be guessing, I&#x27;m seeing disabled regions with DAX children
and figuring out what can be done with them.

Can you explain the new approach so I can test against that intention?

FYI - I am able to confirm the dax regions are back for no-soft-reserved
case, and my basic hotplug flow works with v6.

-- Alison


---

On Tue, Feb 10, 2026 at 06:44:53AM +0000, Smita Koralahalli wrote:
&gt; From: Dan Williams &lt;dan.j.williams@intel.com&gt;
&gt; 
&gt; Ensure cxl_acpi has published CXL Window resources before HMEM walks Soft
&gt; Reserved ranges.
&gt; 
&gt; Replace MODULE_SOFTDEP(&quot;pre: cxl_acpi&quot;) with an explicit, synchronous
&gt; request_module(&quot;cxl_acpi&quot;). MODULE_SOFTDEP() only guarantees eventual
&gt; loading, it does not enforce that the dependency has finished init
&gt; before the current module runs. This can cause HMEM to start before
&gt; cxl_acpi has populated the resource tree, breaking detection of overlaps
&gt; between Soft Reserved and CXL Windows.
&gt; 
&gt; Also, request cxl_pci before HMEM walks Soft Reserved ranges. Unlike
&gt; cxl_acpi, cxl_pci attach is asynchronous and creates dependent devices
&gt; that trigger further module loads. Asynchronous probe flushing
&gt; (wait_for_device_probe()) is added later in the series in a deferred
&gt; context before HMEM makes ownership decisions for Soft Reserved ranges.
&gt; 
&gt; Add an additional explicit Kconfig ordering so that CXL_ACPI and CXL_PCI
&gt; must be initialized before DEV_DAX_HMEM. This prevents HMEM from consuming
&gt; Soft Reserved ranges before CXL drivers have had a chance to claim them.

Reviewed-by: Alison Schofield &lt;alison.schofield@intel.com&gt;

snip



---

On Tue, Feb 10, 2026 at 06:44:54AM +0000, Smita Koralahalli wrote:
&gt; From: Dan Williams &lt;dan.j.williams@intel.com&gt;
&gt; 
&gt; Replace IS_ENABLED(CONFIG_CXL_REGION) with IS_ENABLED(CONFIG_DEV_DAX_CXL)
&gt; so that HMEM only defers Soft Reserved ranges when CXL DAX support is
&gt; enabled. This makes the coordination between HMEM and the CXL stack more
&gt; precise and prevents deferral in unrelated CXL configurations.


Reviewed-by: Alison Schofield &lt;alison.schofield@intel.com&gt;

snip


---

On Tue, Feb 10, 2026 at 06:44:55AM +0000, Smita Koralahalli wrote:
&gt; __cxl_decoder_detach() currently resets decoder programming whenever a
&gt; region is detached if cxl_config_state is beyond CXL_CONFIG_ACTIVE. For

Not sure &#x27;detached&#x27; is the right word. Unregistered maybe?

&gt; autodiscovered regions, this can incorrectly tear down decoder state
&gt; that may be relied upon by other consumers or by subsequent ownership
&gt; decisions.
&gt; 
&gt; Skip cxl_region_decode_reset() during detach when CXL_REGION_F_AUTO is
&gt; set.

I get how this is needed in the failover to DAX case, yet I&#x27;m not clear
how it fits in with folks that just want to destroy that auto region
and resuse the pieces.

Your other recent patch cxl/hdm: Avoid DVSEC fallback after region teardown[1],
showed me that the memdevs, when left with the endpoint decoders not reset,
will keep trying to create another region when reprobed.

[1] https://lore.kernel.org/linux-cxl/aY6pTk63ivjkanlR@aschofie-mobl2.lan/

I think the patch does what it says it does. Perhaps expand on why that 
is always the right thing to do.

--Alison


&gt; 
&gt; Signed-off-by: Smita Koralahalli &lt;Smita.KoralahalliChannabasappa@amd.com&gt;
&gt; Reviewed-by: Jonathan Cameron &lt;jonathan.cameron@huawei.com&gt;
&gt; Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
&gt; Reviewed-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; ---
&gt;  drivers/cxl/core/region.c | 4 +++-
&gt;  1 file changed, 3 insertions(+), 1 deletion(-)
&gt; 
&gt; diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
&gt; index ae899f68551f..45ee598daf95 100644
&gt; --- a/drivers/cxl/core/region.c
&gt; +++ b/drivers/cxl/core/region.c
&gt; @@ -2178,7 +2178,9 @@ __cxl_decoder_detach(struct cxl_region *cxlr,
&gt;  		cxled-&gt;part = -1;
&gt;  
&gt;  	if (p-&gt;state &gt; CXL_CONFIG_ACTIVE) {
&gt; -		cxl_region_decode_reset(cxlr, p-&gt;interleave_ways);
&gt; +		if (!test_bit(CXL_REGION_F_AUTO, &amp;cxlr-&gt;flags))
&gt; +			cxl_region_decode_reset(cxlr, p-&gt;interleave_ways);
&gt; +
&gt;  		p-&gt;state = CXL_CONFIG_ACTIVE;
&gt;  	}
&gt;  
&gt; -- 
&gt; 2.17.1
&gt; 
</pre>
</details>
<div class="review-comment-signals">Signals: requested changes, clarification needed</div>
</div>
<div class="thread-children">
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Koralahalli Smita</span>
<a class="date-chip" href="../2026-02-13_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The reviewer, Smita Koralahalli, discussed the patch&#x27;s approach to handling Soft Reserved ranges and clarified that the disabled regions on the CXL side are expected due to HMEM claiming the range first.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Hi Alison,

On 2/10/2026 11:16 AM, Alison Schofield wrote:
&gt; On Tue, Feb 10, 2026 at 06:44:52AM +0000, Smita Koralahalli wrote:
&gt;&gt; This series aims to address long-standing conflicts between HMEM and
&gt;&gt; CXL when handling Soft Reserved memory ranges.
&gt;&gt;
&gt;&gt; Reworked from Dan&#x27;s patch:
&gt;&gt; https://git.kernel.org/pub/scm/linux/kernel/git/cxl/cxl.git/patch/?id=ab70c6227ee6165a562c215d9dcb4a1c55620d5d
&gt;&gt;
&gt;&gt; Previous work:
&gt;&gt; https://lore.kernel.org/all/20250715180407.47426-1-Smita.KoralahalliChannabasappa@amd.com/
&gt;&gt;
&gt;&gt; Link to v5:
&gt;&gt; https://lore.kernel.org/all/20260122045543.218194-1-Smita.KoralahalliChannabasappa@amd.com
&gt;&gt;
&gt;&gt; The series is based on branch &quot;for-7.0/cxl-init&quot; and base-commit is
&gt;&gt; base-commit: bc62f5b308cbdedf29132fe96e9d591e526527e1
&gt;&gt;
&gt;&gt; [1] After offlining the memory I can tear down the regions and recreate
&gt;&gt; them back. dax_cxl creates dax devices and onlines memory.
&gt;&gt; 850000000-284fffffff : CXL Window 0
&gt;&gt;    850000000-284fffffff : region0
&gt;&gt;      850000000-284fffffff : dax0.0
&gt;&gt;        850000000-284fffffff : System RAM (kmem)
&gt;&gt;
&gt;&gt; [2] With CONFIG_CXL_REGION disabled, all the resources are handled by
&gt;&gt; HMEM. Soft Reserved range shows up in /proc/iomem, no regions come up
&gt;&gt; and dax devices are created from HMEM.
&gt;&gt; 850000000-284fffffff : CXL Window 0
&gt;&gt;    850000000-284fffffff : Soft Reserved
&gt;&gt;      850000000-284fffffff : dax0.0
&gt;&gt;        850000000-284fffffff : System RAM (kmem)
&gt;&gt;
&gt;&gt; [3] Region assembly failure works same as [2].
&gt;&gt;
&gt;&gt; [4] REGISTER path:
&gt;&gt; When CXL_BUS = y (with CXL_ACPI, CXL_PCI, CXL_PORT, CXL_MEM = y),
&gt;&gt; the dax_cxl driver is probed and completes initialization before dax_hmem
&gt;&gt; probes. This scenario was tested with CXL = y, DAX_CXL = m and
&gt;&gt; DAX_HMEM = m. To validate the REGISTER path, I forced REGISTER even in
&gt;&gt; cases where SR completely overlaps the CXL region as I did not have access
&gt;&gt; to a system where the CXL region range is smaller than the SR range.
&gt;&gt;
&gt;&gt; 850000000-284fffffff : Soft Reserved
&gt;&gt;    850000000-284fffffff : CXL Window 0
&gt;&gt;      850000000-280fffffff : region0
&gt;&gt;        850000000-284fffffff : dax0.0
&gt;&gt;          850000000-284fffffff : System RAM (kmem)
&gt;&gt;
&gt;&gt; &quot;path&quot;:&quot;\/platform\/ACPI0017:00\/root0\/decoder0.0\/region0\/dax_region0&quot;,
&gt;&gt; &quot;id&quot;:0,
&gt;&gt; &quot;size&quot;:&quot;128.00 GiB (137.44 GB)&quot;,
&gt;&gt; &quot;align&quot;:2097152
&gt;&gt;
&gt;&gt; [   35.961707] cxl-dax: cxl_dax_region_init()
&gt;&gt; [   35.961713] cxl-dax: registering driver.
&gt;&gt; [   35.961715] cxl-dax: dax_hmem work flushed.
&gt;&gt; [   35.961754] alloc_dev_dax_range:  dax0.0: alloc range[0]:
&gt;&gt; 0x000000850000000:0x000000284fffffff
&gt;&gt; [   35.976622] hmem: hmem_platform probe started.
&gt;&gt; [   35.980821] cxl_bus_probe: cxl_dax_region dax_region0: probe: 0
&gt;&gt; [   36.819566] hmem_platform hmem_platform.0: Soft Reserved not fully
&gt;&gt; contained in CXL; using HMEM
&gt;&gt; [   36.819569] hmem_register_device: hmem_platform hmem_platform.0:
&gt;&gt; registering CXL range: [mem 0x850000000-0x284fffffff flags 0x80000200]
&gt;&gt; [   36.934156] alloc_dax_region: hmem hmem.6: dax_region resource conflict
&gt;&gt; for [mem 0x850000000-0x284fffffff]
&gt;&gt; [   36.989310] hmem hmem.6: probe with driver hmem failed with error -12
&gt;&gt;
&gt;&gt; [5] When CXL_BUS = m (with CXL_ACPI, CXL_PCI, CXL_PORT, CXL_MEM = m),
&gt;&gt; DAX_CXL = m and DAX_HMEM = y the results are as expected. To validate the
&gt;&gt; REGISTER path, I forced REGISTER even in cases where SR completely
&gt;&gt; overlaps the CXL region as I did not have access to a system where the
&gt;&gt; CXL region range is smaller than the SR range.
&gt;&gt;
&gt;&gt; 850000000-284fffffff : Soft Reserved
&gt;&gt;    850000000-284fffffff : CXL Window 0
&gt;&gt;      850000000-280fffffff : region0
&gt;&gt;        850000000-284fffffff : dax6.0
&gt;&gt;          850000000-284fffffff : System RAM (kmem)
&gt;&gt;
&gt;&gt; &quot;path&quot;:&quot;\/platform\/hmem.6&quot;,
&gt;&gt; &quot;id&quot;:6,
&gt;&gt; &quot;size&quot;:&quot;128.00 GiB (137.44 GB)&quot;,
&gt;&gt; &quot;align&quot;:2097152
&gt;&gt;
&gt;&gt; [   30.897665] devm_cxl_add_dax_region: cxl_region region0: region0:
&gt;&gt; register dax_region0
&gt;&gt; [   30.921015] hmem: hmem_platform probe started.
&gt;&gt; [   31.017946] hmem_platform hmem_platform.0: Soft Reserved not fully
&gt;&gt; contained in CXL; using HMEM
&gt;&gt; [   31.056310] alloc_dev_dax_range:  dax6.0: alloc range[0]:
&gt;&gt; 0x0000000850000000:0x000000284fffffff
&gt;&gt; [   34.781516] cxl-dax: cxl_dax_region_init()
&gt;&gt; [   34.781522] cxl-dax: registering driver.
&gt;&gt; [   34.781523] cxl-dax: dax_hmem work flushed.
&gt;&gt; [   34.781549] alloc_dax_region: cxl_dax_region dax_region0: dax_region
&gt;&gt; resource conflict for [mem 0x850000000-0x284fffffff]
&gt;&gt; [   34.781552] cxl_bus_probe: cxl_dax_region dax_region0: probe: -12
&gt;&gt; [   34.781554] cxl_dax_region dax_region0: probe with driver cxl_dax_region
&gt;&gt; failed with error -12
&gt;&gt;
&gt;&gt; v6 updates:
&gt;&gt; - Patch 1-3 no changes.
&gt;&gt; - New Patches 4-5.
&gt;&gt; - (void *)res -&gt; res.
&gt;&gt; - cxl_region_contains_soft_reserve -&gt; region_contains_soft_reserve.
&gt;&gt; - New file include/cxl/cxl.h
&gt;&gt; - Introduced singleton workqueue.
&gt;&gt; - hmem to queue the work and cxl to flush.
&gt;&gt; - cxl_contains_soft_reserve() -&gt; soft_reserve_has_cxl_match().
&gt;&gt; - Included descriptions for dax_cxl_mode.
&gt;&gt; - kzalloc -&gt; kmalloc in add_soft_reserve_into_iomem()
&gt;&gt; - dax_cxl_mode is exported to CXL.
&gt;&gt; - Introduced hmem_register_cxl_device() for walking only CXL
&gt;&gt; intersected SR ranges the second time.
&gt; 
&gt; During v5 review of this patch:
&gt; 
&gt; [PATCH v5 6/7] dax/hmem, cxl: Defer and resolve ownership of Soft Reserved memory ranges
&gt; 
&gt; there was discussion around handling region teardown. It&#x27;s not mentioned
&gt; in the changelog, and the teardown is completely removed from the patch.
&gt; 
&gt; The discussion seemed to be leaning towards not tearing down &#x27;all&#x27;, but
&gt; it&#x27;s not clear to me that we decided not to tear down anything - which
&gt; this update now does.
&gt; 
&gt; And, as you may be guessing, I&#x27;m seeing disabled regions with DAX children
&gt; and figuring out what can be done with them.
&gt; 
&gt; Can you explain the new approach so I can test against that intention?
&gt; 
&gt; FYI - I am able to confirm the dax regions are back for no-soft-reserved
&gt; case, and my basic hotplug flow works with v6.
&gt; 
&gt; -- Alison

Hi Alison,

Thanks for the test and confirming the no-soft-reserved and hotplug 
cases work.

You&#x27;re right that cxl_region_teardown_all() was removed in v6. I should 
have called this out more clearly in the changelog. Here&#x27;s what I learnt 
from v5 review. Correct me if I misunderstood.

During v5 review, regarding dropping teardown (comments from Dan):

&quot;If we go with the alloc_dax_region() observation in my other mail it 
means that the HPA space will already be claimed and 
cxl_dax_region_probe() will fail. If we can get to that point of &quot;all 
HMEM registered, and all CXL regions failing to attach their
cxl_dax_region devices&quot; that is a good stopping point. Then can decide 
if a follow-on patch is needed to cleanup that state 
(cxl_region_teardown_all()) , or if it can just idle that way in the 
messy state and wait for userspace to cleanup if it wants.&quot;

https://lore.kernel.org/all/697aad9546542_30951007c@dwillia2-mobl4.notmuch/

Also:

&quot;In other words, I thought total teardown would be simpler, but as the 
feedback keeps coming in, I think that brings a different set of 
complexity. So just inject failures for dax_cxl to trip over and then we 
can go further later to effect total teardown if that proves to not be 
enough.&quot;

https://lore.kernel.org/all/697a9d46b147e_309510027@dwillia2-mobl4.notmuch/

The v6 approach replaces teardown with the alloc_dax_region() resource 
exclusion in patch 5. When HMEM wins the ownership decision (REGISTER 
path), it successfully claims the dax_region resource range first. When 
dax_cxl later tries to probe, its alloc_dax_region() call hits a 
resource conflict and fails, leaving the cxl_dax_region device in a 
disabled state.

(There is a separate ordering issue when CXL is built-in and HMEM is a 
module, where dax_cxl may claim the dax_region first as observed in 
experiments [4] and [5], but that is an independent topic and might not 
be relevant here.)

So the disabled regions with DAX children you are seeing on the CXL side 
are likely expected as Dan mentioned - they show that CXL tried to claim 
the range but HMEM got there first. Though the cxl region remains 
committed, no dax_region gets created for it because the HPA space is 
already taken.

Thanks
Smita

</pre>
</details>
<div class="review-comment-signals">Signals: clarification, explanation</div>
</div>
<div class="thread-children">
<div class="thread-node depth-3">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Alison Schofield</span>
<a class="date-chip" href="../2026-02-13_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Alison Schofield raised concerns that the patch does not accurately reflect the memory topology, and suggested a different approach to handle Soft Reserved deferral.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">On Tue, Feb 10, 2026 at 11:49:04AM -0800, Koralahalli Channabasappa, Smita wrote:
&gt; Hi Alison,
&gt; 
&gt; On 2/10/2026 11:16 AM, Alison Schofield wrote:
&gt; &gt; On Tue, Feb 10, 2026 at 06:44:52AM +0000, Smita Koralahalli wrote:
&gt; &gt; &gt; This series aims to address long-standing conflicts between HMEM and
&gt; &gt; &gt; CXL when handling Soft Reserved memory ranges.
&gt; &gt; &gt; 
&gt; &gt; &gt; Reworked from Dan&#x27;s patch:
&gt; &gt; &gt; https://git.kernel.org/pub/scm/linux/kernel/git/cxl/cxl.git/patch/?id=ab70c6227ee6165a562c215d9dcb4a1c55620d5d
&gt; &gt; &gt; 
&gt; &gt; &gt; Previous work:
&gt; &gt; &gt; https://lore.kernel.org/all/20250715180407.47426-1-Smita.KoralahalliChannabasappa@amd.com/
&gt; &gt; &gt; 
&gt; &gt; &gt; Link to v5:
&gt; &gt; &gt; https://lore.kernel.org/all/20260122045543.218194-1-Smita.KoralahalliChannabasappa@amd.com
&gt; &gt; &gt; 
&gt; &gt; &gt; The series is based on branch &quot;for-7.0/cxl-init&quot; and base-commit is
&gt; &gt; &gt; base-commit: bc62f5b308cbdedf29132fe96e9d591e526527e1
&gt; &gt; &gt; 
&gt; &gt; &gt; [1] After offlining the memory I can tear down the regions and recreate
&gt; &gt; &gt; them back. dax_cxl creates dax devices and onlines memory.
&gt; &gt; &gt; 850000000-284fffffff : CXL Window 0
&gt; &gt; &gt;    850000000-284fffffff : region0
&gt; &gt; &gt;      850000000-284fffffff : dax0.0
&gt; &gt; &gt;        850000000-284fffffff : System RAM (kmem)
&gt; &gt; &gt; 
&gt; &gt; &gt; [2] With CONFIG_CXL_REGION disabled, all the resources are handled by
&gt; &gt; &gt; HMEM. Soft Reserved range shows up in /proc/iomem, no regions come up
&gt; &gt; &gt; and dax devices are created from HMEM.
&gt; &gt; &gt; 850000000-284fffffff : CXL Window 0
&gt; &gt; &gt;    850000000-284fffffff : Soft Reserved
&gt; &gt; &gt;      850000000-284fffffff : dax0.0
&gt; &gt; &gt;        850000000-284fffffff : System RAM (kmem)
&gt; &gt; &gt; 
&gt; &gt; &gt; [3] Region assembly failure works same as [2].
&gt; &gt; &gt; 
&gt; &gt; &gt; [4] REGISTER path:
&gt; &gt; &gt; When CXL_BUS = y (with CXL_ACPI, CXL_PCI, CXL_PORT, CXL_MEM = y),
&gt; &gt; &gt; the dax_cxl driver is probed and completes initialization before dax_hmem
&gt; &gt; &gt; probes. This scenario was tested with CXL = y, DAX_CXL = m and
&gt; &gt; &gt; DAX_HMEM = m. To validate the REGISTER path, I forced REGISTER even in
&gt; &gt; &gt; cases where SR completely overlaps the CXL region as I did not have access
&gt; &gt; &gt; to a system where the CXL region range is smaller than the SR range.
&gt; &gt; &gt; 
&gt; &gt; &gt; 850000000-284fffffff : Soft Reserved
&gt; &gt; &gt;    850000000-284fffffff : CXL Window 0
&gt; &gt; &gt;      850000000-280fffffff : region0
&gt; &gt; &gt;        850000000-284fffffff : dax0.0
&gt; &gt; &gt;          850000000-284fffffff : System RAM (kmem)
&gt; &gt; &gt; 
&gt; &gt; &gt; &quot;path&quot;:&quot;\/platform\/ACPI0017:00\/root0\/decoder0.0\/region0\/dax_region0&quot;,
&gt; &gt; &gt; &quot;id&quot;:0,
&gt; &gt; &gt; &quot;size&quot;:&quot;128.00 GiB (137.44 GB)&quot;,
&gt; &gt; &gt; &quot;align&quot;:2097152
&gt; &gt; &gt; 
&gt; &gt; &gt; [   35.961707] cxl-dax: cxl_dax_region_init()
&gt; &gt; &gt; [   35.961713] cxl-dax: registering driver.
&gt; &gt; &gt; [   35.961715] cxl-dax: dax_hmem work flushed.
&gt; &gt; &gt; [   35.961754] alloc_dev_dax_range:  dax0.0: alloc range[0]:
&gt; &gt; &gt; 0x000000850000000:0x000000284fffffff
&gt; &gt; &gt; [   35.976622] hmem: hmem_platform probe started.
&gt; &gt; &gt; [   35.980821] cxl_bus_probe: cxl_dax_region dax_region0: probe: 0
&gt; &gt; &gt; [   36.819566] hmem_platform hmem_platform.0: Soft Reserved not fully
&gt; &gt; &gt; contained in CXL; using HMEM
&gt; &gt; &gt; [   36.819569] hmem_register_device: hmem_platform hmem_platform.0:
&gt; &gt; &gt; registering CXL range: [mem 0x850000000-0x284fffffff flags 0x80000200]
&gt; &gt; &gt; [   36.934156] alloc_dax_region: hmem hmem.6: dax_region resource conflict
&gt; &gt; &gt; for [mem 0x850000000-0x284fffffff]
&gt; &gt; &gt; [   36.989310] hmem hmem.6: probe with driver hmem failed with error -12
&gt; &gt; &gt; 
&gt; &gt; &gt; [5] When CXL_BUS = m (with CXL_ACPI, CXL_PCI, CXL_PORT, CXL_MEM = m),
&gt; &gt; &gt; DAX_CXL = m and DAX_HMEM = y the results are as expected. To validate the
&gt; &gt; &gt; REGISTER path, I forced REGISTER even in cases where SR completely
&gt; &gt; &gt; overlaps the CXL region as I did not have access to a system where the
&gt; &gt; &gt; CXL region range is smaller than the SR range.
&gt; &gt; &gt; 
&gt; &gt; &gt; 850000000-284fffffff : Soft Reserved
&gt; &gt; &gt;    850000000-284fffffff : CXL Window 0
&gt; &gt; &gt;      850000000-280fffffff : region0
&gt; &gt; &gt;        850000000-284fffffff : dax6.0
&gt; &gt; &gt;          850000000-284fffffff : System RAM (kmem)
&gt; &gt; &gt; 
&gt; &gt; &gt; &quot;path&quot;:&quot;\/platform\/hmem.6&quot;,
&gt; &gt; &gt; &quot;id&quot;:6,
&gt; &gt; &gt; &quot;size&quot;:&quot;128.00 GiB (137.44 GB)&quot;,
&gt; &gt; &gt; &quot;align&quot;:2097152
&gt; &gt; &gt; 
&gt; &gt; &gt; [   30.897665] devm_cxl_add_dax_region: cxl_region region0: region0:
&gt; &gt; &gt; register dax_region0
&gt; &gt; &gt; [   30.921015] hmem: hmem_platform probe started.
&gt; &gt; &gt; [   31.017946] hmem_platform hmem_platform.0: Soft Reserved not fully
&gt; &gt; &gt; contained in CXL; using HMEM
&gt; &gt; &gt; [   31.056310] alloc_dev_dax_range:  dax6.0: alloc range[0]:
&gt; &gt; &gt; 0x0000000850000000:0x000000284fffffff
&gt; &gt; &gt; [   34.781516] cxl-dax: cxl_dax_region_init()
&gt; &gt; &gt; [   34.781522] cxl-dax: registering driver.
&gt; &gt; &gt; [   34.781523] cxl-dax: dax_hmem work flushed.
&gt; &gt; &gt; [   34.781549] alloc_dax_region: cxl_dax_region dax_region0: dax_region
&gt; &gt; &gt; resource conflict for [mem 0x850000000-0x284fffffff]
&gt; &gt; &gt; [   34.781552] cxl_bus_probe: cxl_dax_region dax_region0: probe: -12
&gt; &gt; &gt; [   34.781554] cxl_dax_region dax_region0: probe with driver cxl_dax_region
&gt; &gt; &gt; failed with error -12
&gt; &gt; &gt; 
&gt; &gt; &gt; v6 updates:
&gt; &gt; &gt; - Patch 1-3 no changes.
&gt; &gt; &gt; - New Patches 4-5.
&gt; &gt; &gt; - (void *)res -&gt; res.
&gt; &gt; &gt; - cxl_region_contains_soft_reserve -&gt; region_contains_soft_reserve.
&gt; &gt; &gt; - New file include/cxl/cxl.h
&gt; &gt; &gt; - Introduced singleton workqueue.
&gt; &gt; &gt; - hmem to queue the work and cxl to flush.
&gt; &gt; &gt; - cxl_contains_soft_reserve() -&gt; soft_reserve_has_cxl_match().
&gt; &gt; &gt; - Included descriptions for dax_cxl_mode.
&gt; &gt; &gt; - kzalloc -&gt; kmalloc in add_soft_reserve_into_iomem()
&gt; &gt; &gt; - dax_cxl_mode is exported to CXL.
&gt; &gt; &gt; - Introduced hmem_register_cxl_device() for walking only CXL
&gt; &gt; &gt; intersected SR ranges the second time.
&gt; &gt; 
&gt; &gt; During v5 review of this patch:
&gt; &gt; 
&gt; &gt; [PATCH v5 6/7] dax/hmem, cxl: Defer and resolve ownership of Soft Reserved memory ranges
&gt; &gt; 
&gt; &gt; there was discussion around handling region teardown. It&#x27;s not mentioned
&gt; &gt; in the changelog, and the teardown is completely removed from the patch.
&gt; &gt; 
&gt; &gt; The discussion seemed to be leaning towards not tearing down &#x27;all&#x27;, but
&gt; &gt; it&#x27;s not clear to me that we decided not to tear down anything - which
&gt; &gt; this update now does.
&gt; &gt; 
&gt; &gt; And, as you may be guessing, I&#x27;m seeing disabled regions with DAX children
&gt; &gt; and figuring out what can be done with them.
&gt; &gt; 
&gt; &gt; Can you explain the new approach so I can test against that intention?
&gt; &gt; 
&gt; &gt; FYI - I am able to confirm the dax regions are back for no-soft-reserved
&gt; &gt; case, and my basic hotplug flow works with v6.
&gt; &gt; 
&gt; &gt; -- Alison
&gt; 
&gt; Hi Alison,
&gt; 
&gt; Thanks for the test and confirming the no-soft-reserved and hotplug cases
&gt; work.
&gt; 
&gt; You&#x27;re right that cxl_region_teardown_all() was removed in v6. I should have
&gt; called this out more clearly in the changelog. Here&#x27;s what I learnt from v5
&gt; review. Correct me if I misunderstood.
&gt; 
&gt; During v5 review, regarding dropping teardown (comments from Dan):
&gt; 
&gt; &quot;If we go with the alloc_dax_region() observation in my other mail it means
&gt; that the HPA space will already be claimed and cxl_dax_region_probe() will
&gt; fail. If we can get to that point of &quot;all HMEM registered, and all CXL
&gt; regions failing to attach their
&gt; cxl_dax_region devices&quot; that is a good stopping point. Then can decide if a
&gt; follow-on patch is needed to cleanup that state (cxl_region_teardown_all())
&gt; , or if it can just idle that way in the messy state and wait for userspace
&gt; to cleanup if it wants.&quot;
&gt; 
&gt; https://lore.kernel.org/all/697aad9546542_30951007c@dwillia2-mobl4.notmuch/
&gt; 
&gt; Also:
&gt; 
&gt; &quot;In other words, I thought total teardown would be simpler, but as the
&gt; feedback keeps coming in, I think that brings a different set of complexity.
&gt; So just inject failures for dax_cxl to trip over and then we can go further
&gt; later to effect total teardown if that proves to not be enough.&quot;
&gt; 
&gt; https://lore.kernel.org/all/697a9d46b147e_309510027@dwillia2-mobl4.notmuch/
&gt; 
&gt; The v6 approach replaces teardown with the alloc_dax_region() resource
&gt; exclusion in patch 5. When HMEM wins the ownership decision (REGISTER path),
&gt; it successfully claims the dax_region resource range first. When dax_cxl
&gt; later tries to probe, its alloc_dax_region() call hits a resource conflict
&gt; and fails, leaving the cxl_dax_region device in a disabled state.
&gt; 
&gt; (There is a separate ordering issue when CXL is built-in and HMEM is a
&gt; module, where dax_cxl may claim the dax_region first as observed in
&gt; experiments [4] and [5], but that is an independent topic and might not be
&gt; relevant here.)
&gt; 
&gt; So the disabled regions with DAX children you are seeing on the CXL side are
&gt; likely expected as Dan mentioned - they show that CXL tried to claim the
&gt; range but HMEM got there first. Though the cxl region remains committed, no
&gt; dax_region gets created for it because the HPA space is already taken.

Hi Smita,

The disable regions I&#x27;m seeing are the remnants of failed region assemblies
where HMEM rightfully took over. So the take over is good, but the expected
view shown way above and repasted below is not what I&#x27;m seeing. Case [3]
is not the same as Case [2], but have a region btw the SR and DAX.


&gt; &gt; &gt; [2] With CONFIG_CXL_REGION disabled, all the resources are handled by
&gt; &gt; &gt; HMEM. Soft Reserved range shows up in /proc/iomem, no regions come up
&gt; &gt; &gt; and dax devices are created from HMEM.
&gt; &gt; &gt; 850000000-284fffffff : CXL Window 0
&gt; &gt; &gt;    850000000-284fffffff : Soft Reserved
&gt; &gt; &gt;      850000000-284fffffff : dax0.0
&gt; &gt; &gt;        850000000-284fffffff : System RAM (kmem)
&gt; &gt; &gt; 
&gt; &gt; &gt; [3] Region assembly failure works same as [2].
&gt; &gt; &gt; 

I posted a patch[1] that I think gets us to what is expected.
FWIW I do agree with abandoning the teardown all approach. In this
patch I still don&#x27;t suggest tearing down the region. It can stay for
&#x27;forensics&#x27;, but I do think we should make /proc/iomem accurately
reflect the memory topology.

[1] https://lore.kernel.org/linux-cxl/20260212062250.1219043-1-alison.schofield@intel.com/

-- Alison

&gt; 
&gt; Thanks
&gt; Smita
&gt; 
</pre>
</details>
<div class="review-comment-signals">Signals: requested changes, suggested alternative solution</div>
</div>
</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Tomasz Wolski</span>
<a class="date-chip" href="../2026-02-13_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The reviewer, Tomasz Wolski, asked for clarification on the scenario where the patch is needed, specifically in cases without Soft Reserve and with CXL memory installed or hot-plugged after OS start.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">&gt;
&gt;FYI - I am able to confirm the dax regions are back for no-soft-reserved
&gt;case, and my basic hotplug flow works with v6.
&gt;
&gt;-- Alison

Hello Alison,

I wanted to ask about this scenario.
Is my understanding correct that this fix is needed for cases without Soft Reserve and:
1) CXL memory is installed in the server (no hotplug) and OS is started
2) CXL memory is hot-plugged after the OS starts
3) Tests with cxl-test driver

In such case either the admin fails to manually create region via cxl cli (if there
was no auto-regions) or regions fails to be created automatically during driver probe

Is this correct?

Best regards,
Tomasz
</pre>
</details>
<div class="review-comment-signals">Signals: clarification requested</div>
</div>
<div class="thread-children">
<div class="thread-node depth-3">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Alison Schofield</span>
<a class="date-chip" href="../2026-02-13_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Alison Schofield pointed out a discrepancy in Soft Reserved handling between CXL and HMEM, stating that the CXL region is created but the DAX region is not.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">On Thu, Feb 12, 2026 at 03:44:15PM +0100, Tomasz Wolski wrote:
&gt; &gt;
&gt; &gt;FYI - I am able to confirm the dax regions are back for no-soft-reserved
&gt; &gt;case, and my basic hotplug flow works with v6.
&gt; &gt;
&gt; &gt;-- Alison
&gt; 
&gt; Hello Alison,
&gt; 
&gt; I wanted to ask about this scenario.
&gt; Is my understanding correct that this fix is needed for cases without Soft Reserve and:
&gt; 1) CXL memory is installed in the server (no hotplug) and OS is started
&gt; 2) CXL memory is hot-plugged after the OS starts
&gt; 3) Tests with cxl-test driver 
                               or QEMU

&gt; 
&gt; In such case either the admin fails to manually create region via cxl cli (if there
&gt; was no auto-regions) or regions fails to be created automatically during driver probe

The CXL region creates &#x27;OK&#x27;. It is the DAX region that is not created.

&gt; 
&gt; Is this correct?
&gt; 
&gt; Best regards,
&gt; Tomasz
</pre>
</details>
<div class="review-comment-signals">Signals: discrepancy, requested clarification</div>
</div>
</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Yasunori (Fujitsu)</span>
<a class="date-chip" href="../2026-02-13_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The reviewer, Yasunori, questioned why Linux drivers must handle a specific case where the platform firmware does not define EFI_MEMORY_SP, and asked if any actual machines have been released with such firmware.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Hello, Alison-san,

I would like to clarify your answer a bit more.

&gt; On Thu, Feb 12, 2026 at 03:44:15PM +0100, Tomasz Wolski wrote:
&gt; &gt; &gt;
&gt; &gt; &gt;FYI - I am able to confirm the dax regions are back for
&gt; &gt; &gt;no-soft-reserved case, and my basic hotplug flow works with v6.
&gt; &gt; &gt;
&gt; &gt; &gt;-- Alison
&gt; &gt;
&gt; &gt; Hello Alison,
&gt; &gt;
&gt; &gt; I wanted to ask about this scenario.
&gt; &gt; Is my understanding correct that this fix is needed for cases without Soft
&gt; Reserve and:
&gt; &gt; 1) CXL memory is installed in the server (no hotplug) and OS is
&gt; &gt; started
&gt; &gt; 2) CXL memory is hot-plugged after the OS starts
&gt; &gt; 3) Tests with cxl-test driver
&gt;                                or QEMU

Though I can understand that cases 2) and 3) include QEMU, I&#x27;m not sure why Linux drivers must handle case 1).
In such a case, I feel that the platform vendor should modify the firmware to define EFI_MEMORY_SP.

In the past, I actually encountered another issue between our platform firmware and a Linux driver:
https://lore.kernel.org/linux-cxl/OS9PR01MB12421AEA8B27BF942CD0F18B19057A@OS9PR01MB12421.jpnprd01.prod.outlook.com/
In that case, I asked our firmware team to modify the firmware, and the issue was resolved.

Therefore, I would like to confirm why case 1) must be handled.
Have any actual machines already been released with such firmware?
Otherwise, is this just to prepare for a platform whose firmware cannot be fixed on the firmware side?

Thanks,
---
Yasunori Goto




---


&gt; On Fri, Feb 13, 2026 at 07:47:08AM +0000, Yasunori Goto (Fujitsu) wrote:
&gt; &gt; Hello, Alison-san,
&gt; &gt;
&gt; &gt; I would like to clarify your answer a bit more.
&gt; &gt;
&gt; &gt; &gt; On Thu, Feb 12, 2026 at 03:44:15PM +0100, Tomasz Wolski wrote:
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt;FYI - I am able to confirm the dax regions are back for
&gt; &gt; &gt; &gt; &gt;no-soft-reserved case, and my basic hotplug flow works with v6.
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt;-- Alison
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; Hello Alison,
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; I wanted to ask about this scenario.
&gt; &gt; &gt; &gt; Is my understanding correct that this fix is needed for cases
&gt; &gt; &gt; &gt; without Soft
&gt; &gt; &gt; Reserve and:
&gt; &gt; &gt; &gt; 1) CXL memory is installed in the server (no hotplug) and OS is
&gt; &gt; &gt; &gt; started
&gt; &gt; &gt; &gt; 2) CXL memory is hot-plugged after the OS starts
&gt; &gt; &gt; &gt; 3) Tests with cxl-test driver
&gt; &gt; &gt;                                or QEMU
&gt; &gt;
&gt; &gt; Though I can understand that cases 2) and 3) include QEMU, I&#x27;m not sure
&gt; why Linux drivers must handle case 1).
&gt; &gt; In such a case, I feel that the platform vendor should modify the firmware to
&gt; define EFI_MEMORY_SP.
&gt; &gt;
&gt; &gt; In the past, I actually encountered another issue between our platform
&gt; firmware and a Linux driver:
&gt; &gt;
&gt; https://lore.kernel.org/linux-cxl/OS9PR01MB12421AEA8B27BF942CD0F18B1
&gt; 90
&gt; &gt; 57A@OS9PR01MB12421.jpnprd01.prod.outlook.com/
&gt; &gt; In that case, I asked our firmware team to modify the firmware, and the issue
&gt; was resolved.
&gt; &gt;
&gt; &gt; Therefore, I would like to confirm why case 1) must be handled.
&gt; &gt; Have any actual machines already been released with such firmware?
&gt; &gt; Otherwise, is this just to prepare for a platform whose firmware cannot be
&gt; fixed on the firmware side?
&gt; 
&gt; Maybe I&#x27;m misunderstanding Tomasz&#x27;s Case 1), because this is not a
&gt; work-around for a firmware issue.
&gt; 
&gt; The CXL driver always tries to create DAX regions out of RAM regions.
&gt; That happens if the CXL region is BIOS defined &#x27;auto&#x27; region or a region
&gt; requested via userspace. That is irregardless of Soft Reserved existence.
&gt; Soft-Reserved is not a requirement for CXL or DAX region creation.

I misunderstood it 
I&#x27;ll re-check the specifications.
Sorry for the noise.

&gt; 
&gt; That piece broke in an earlier rev of this patchset [1] where the calls to
&gt; devm_cxl_add_dax_region(cxlr) started returning EPROBE_DEFER.
&gt; 
&gt; I intended to point out to Smita, that behavior is restored in v6.

Thank you very much.

-----
Yasunori Goto
</pre>
</details>
<div class="review-comment-signals">Signals: questioning, request for clarification</div>
</div>
<div class="thread-children">
<div class="thread-node depth-3">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Alison Schofield</span>
<a class="date-chip" href="../2026-02-13_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Alison Schofield questioned the patch&#x27;s logic, pointing out that the CXL driver creates DAX regions regardless of Soft Reserved existence and that this behavior was restored in v6.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">On Fri, Feb 13, 2026 at 07:47:08AM +0000, Yasunori Goto (Fujitsu) wrote:
&gt; Hello, Alison-san,
&gt; 
&gt; I would like to clarify your answer a bit more.
&gt; 
&gt; &gt; On Thu, Feb 12, 2026 at 03:44:15PM +0100, Tomasz Wolski wrote:
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt;FYI - I am able to confirm the dax regions are back for
&gt; &gt; &gt; &gt;no-soft-reserved case, and my basic hotplug flow works with v6.
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt;-- Alison
&gt; &gt; &gt;
&gt; &gt; &gt; Hello Alison,
&gt; &gt; &gt;
&gt; &gt; &gt; I wanted to ask about this scenario.
&gt; &gt; &gt; Is my understanding correct that this fix is needed for cases without Soft
&gt; &gt; Reserve and:
&gt; &gt; &gt; 1) CXL memory is installed in the server (no hotplug) and OS is
&gt; &gt; &gt; started
&gt; &gt; &gt; 2) CXL memory is hot-plugged after the OS starts
&gt; &gt; &gt; 3) Tests with cxl-test driver
&gt; &gt;                                or QEMU
&gt; 
&gt; Though I can understand that cases 2) and 3) include QEMU, I&#x27;m not sure why Linux drivers must handle case 1).
&gt; In such a case, I feel that the platform vendor should modify the firmware to define EFI_MEMORY_SP.
&gt; 
&gt; In the past, I actually encountered another issue between our platform firmware and a Linux driver:
&gt; https://lore.kernel.org/linux-cxl/OS9PR01MB12421AEA8B27BF942CD0F18B19057A@OS9PR01MB12421.jpnprd01.prod.outlook.com/
&gt; In that case, I asked our firmware team to modify the firmware, and the issue was resolved.
&gt; 
&gt; Therefore, I would like to confirm why case 1) must be handled.
&gt; Have any actual machines already been released with such firmware?
&gt; Otherwise, is this just to prepare for a platform whose firmware cannot be fixed on the firmware side?

Maybe I&#x27;m misunderstanding Tomasz&#x27;s Case 1), because this is not
a work-around for a firmware issue.

The CXL driver always tries to create DAX regions out of RAM regions.
That happens if the CXL region is BIOS defined &#x27;auto&#x27; region or a
region requested via userspace. That is irregardless of Soft Reserved
existence. Soft-Reserved is not a requirement for CXL or DAX region
creation.

That piece broke in an earlier rev of this patchset [1] where the calls
to devm_cxl_add_dax_region(cxlr) started returning EPROBE_DEFER.

I intended to point out to Smita, that behavior is restored in v6.

--Alison

[1] https://lore.kernel.org/linux-cxl/aXMWzC8zf3bqIHJ0@aschofie-mobl2.lan/


&gt; 
&gt; Thanks,
&gt; ---
&gt; Yasunori Goto
&gt; 
&gt; 
</pre>
</details>
<div class="review-comment-signals">Signals: questioning the patch&#x27;s logic, restoring previous behavior</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Koralahalli Smita</span>
<a class="date-chip" href="../2026-02-13_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer pointed out a typo in the patch description, specifically correcting DAX_HMEM to &#x27;m&#x27;.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">
On 2/9/2026 10:44 PM, Smita Koralahalli wrote:
&gt; This series aims to address long-standing conflicts between HMEM and
&gt; CXL when handling Soft Reserved memory ranges.
&gt; 
&gt; Reworked from Dan&#x27;s patch:
&gt; https://git.kernel.org/pub/scm/linux/kernel/git/cxl/cxl.git/patch/?id=ab70c6227ee6165a562c215d9dcb4a1c55620d5d
&gt; 
&gt; Previous work:
&gt; https://lore.kernel.org/all/20250715180407.47426-1-Smita.KoralahalliChannabasappa@amd.com/
&gt; 
&gt; Link to v5:
&gt; https://lore.kernel.org/all/20260122045543.218194-1-Smita.KoralahalliChannabasappa@amd.com
&gt; 
&gt; The series is based on branch &quot;for-7.0/cxl-init&quot; and base-commit is
&gt; base-commit: bc62f5b308cbdedf29132fe96e9d591e526527e1
&gt; 

[snip]..

&gt; [5] When CXL_BUS = m (with CXL_ACPI, CXL_PCI, CXL_PORT, CXL_MEM = m),
&gt; DAX_CXL = m and DAX_HMEM = y the results are as expected. To validate the

Typo here, this is DAX_HMEM = m. Rest all looks good.

Thanks
Smita.


&gt; REGISTER path, I forced REGISTER even in cases where SR completely
&gt; overlaps the CXL region as I did not have access to a system where the
&gt; CXL region range is smaller than the SR range.
&gt; 
&gt; 850000000-284fffffff : Soft Reserved
&gt;    850000000-284fffffff : CXL Window 0
&gt;      850000000-280fffffff : region0
&gt;        850000000-284fffffff : dax6.0
&gt;          850000000-284fffffff : System RAM (kmem)
&gt; 
&gt; &quot;path&quot;:&quot;\/platform\/hmem.6&quot;,
&gt; &quot;id&quot;:6,
&gt; &quot;size&quot;:&quot;128.00 GiB (137.44 GB)&quot;,
&gt; &quot;align&quot;:2097152
&gt; 
&gt; [   30.897665] devm_cxl_add_dax_region: cxl_region region0: region0:
&gt; register dax_region0
&gt; [   30.921015] hmem: hmem_platform probe started.
&gt; [   31.017946] hmem_platform hmem_platform.0: Soft Reserved not fully
&gt; contained in CXL; using HMEM
&gt; [   31.056310] alloc_dev_dax_range:  dax6.0: alloc range[0]:
&gt; 0x0000000850000000:0x000000284fffffff
&gt; [   34.781516] cxl-dax: cxl_dax_region_init()
&gt; [   34.781522] cxl-dax: registering driver.
&gt; [   34.781523] cxl-dax: dax_hmem work flushed.
&gt; [   34.781549] alloc_dax_region: cxl_dax_region dax_region0: dax_region
&gt; resource conflict for [mem 0x850000000-0x284fffffff]
&gt; [   34.781552] cxl_bus_probe: cxl_dax_region dax_region0: probe: -12
&gt; [   34.781554] cxl_dax_region dax_region0: probe with driver cxl_dax_region
&gt; failed with error -12
&gt; 
[snip]


</pre>
</details>
<div class="review-comment-signals">Signals: typo correction</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Gregory Price</span>
<a class="date-chip" href="../2026-02-13_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="inline-review-badge">Inline Review</span>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Gregory Price raised concerns about a potential deadlock in the error path of the patch, specifically when walk_hmem_resources() encounters a CXL-intersecting range and then a non-CXL Soft Reserved range fails to register.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">On Tue, Feb 10, 2026 at 06:44:52AM +0000, Smita Koralahalli wrote:
&gt; This series aims to address long-standing conflicts between HMEM and
&gt; CXL when handling Soft Reserved memory ranges.
&gt; 
&gt; Reworked from Dan&#x27;s patch:
&gt; https://git.kernel.org/pub/scm/linux/kernel/git/cxl/cxl.git/patch/?id=ab70c6227ee6165a562c215d9dcb4a1c55620d5d
&gt;

Link is broken: bad commit reference


---

On Tue, Feb 10, 2026 at 06:45:00AM +0000, Smita Koralahalli wrote:

This is a review generated by kreview-0811365ff2
Reference: https://github.com/masoncl/review-prompts/

This is not an automated email, I thought this looked valid, the rest of
the text here is auto-generated.

~Gregory

---

[...]

&gt; +static void process_defer_work(void *data)
&gt; +{
&gt; +	struct platform_device *pdev = data;
&gt; +	int rc;
&gt; +
&gt; +	/* relies on cxl_acpi and cxl_pci having had a chance to load */
&gt; +	wait_for_device_probe();

[...]

&gt; +static void kill_defer_work(void *data)
&gt; +{
&gt; +	struct platform_device *pdev = data;
&gt; +
&gt; +	dax_hmem_flush_work();
&gt; +	dax_hmem_unregister_work(process_defer_work, pdev);
&gt; +}
&gt; +
&gt;  static int dax_hmem_platform_probe(struct platform_device *pdev)
&gt;  {
&gt; +	int rc;
&gt; +
&gt; +	rc = dax_hmem_register_work(process_defer_work, pdev);
&gt; +	if (rc)
&gt; +		return rc;
&gt; +
&gt; +	rc = devm_add_action_or_reset(&amp;pdev-&gt;dev, kill_defer_work, pdev);
&gt; +	if (rc)
&gt; +		return rc;
&gt; +
&gt;  	return walk_hmem_resources(&amp;pdev-&gt;dev, hmem_register_device);
&gt;  }

Is there a potential deadlock in the error path here? If
walk_hmem_resources() encounters a CXL-intersecting range first
(calling dax_hmem_queue_work(), which schedules process_defer_work
on system_long_wq), and then a subsequent non-CXL Soft Reserved
range fails to register, the probe returns an error. The devres
cleanup then calls kill_defer_work -&gt; dax_hmem_flush_work() -&gt;
flush_work(&amp;dax_hmem_work).

Meanwhile, process_defer_work calls wait_for_device_probe(), which
waits for probe_count to reach zero. Since devres_release_all runs
inside really_probe before driver_probe_device decrements
probe_count, this looks like a circular wait:

  driver_probe_device
    atomic_inc(&amp;probe_count)
    __driver_probe_device
      really_probe
        dax_hmem_platform_probe
          walk_hmem_resources -&gt; hmem_register_device
            CXL range: dax_hmem_queue_work()
            non-CXL range: fails
          returns error
        devres_release_all
          kill_defer_work
            dax_hmem_flush_work
              flush_work(&amp;dax_hmem_work)  &lt;-- waits for process_defer_work
                process_defer_work
                  wait_for_device_probe() &lt;-- waits for probe_count == 0
    atomic_dec(&amp;probe_count)              &lt;-- never reached

The trigger requires both CXL-intersecting and non-CXL Soft Reserved
ranges with the non-CXL registration failing, so the window is narrow,
but the deadlock would be permanent if hit.

Would it be safer to cancel the work instead of flushing it in the
error path, or to avoid queuing deferred work during the initial
walk?
</pre>
</details>
<div class="review-comment-signals">Signals: potential deadlock, requested changes</div>
</div>
<div class="thread-children">
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Koralahalli Smita</span>
<a class="date-chip" href="../2026-02-13_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="inline-review-badge">Inline Review</span>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Smita Koralahalli raised concerns about a potential deadlock in the patch, but agrees that avoiding queuing during the initial walk is the right approach.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">On 2/13/2026 6:47 AM, Gregory Price wrote:
&gt; On Tue, Feb 10, 2026 at 06:45:00AM +0000, Smita Koralahalli wrote:
&gt; 
&gt; This is a review generated by kreview-0811365ff2
&gt; Reference: https://github.com/masoncl/review-prompts/
&gt; 
&gt; This is not an automated email, I thought this looked valid, the rest of
&gt; the text here is auto-generated.
&gt; 
&gt; ~Gregory
&gt; 
&gt; ---
&gt; 
&gt; [...]
&gt; 
&gt;&gt; +static void process_defer_work(void *data)
&gt;&gt; +{
&gt;&gt; +	struct platform_device *pdev = data;
&gt;&gt; +	int rc;
&gt;&gt; +
&gt;&gt; +	/* relies on cxl_acpi and cxl_pci having had a chance to load */
&gt;&gt; +	wait_for_device_probe();
&gt; 
&gt; [...]
&gt; 
&gt;&gt; +static void kill_defer_work(void *data)
&gt;&gt; +{
&gt;&gt; +	struct platform_device *pdev = data;
&gt;&gt; +
&gt;&gt; +	dax_hmem_flush_work();
&gt;&gt; +	dax_hmem_unregister_work(process_defer_work, pdev);
&gt;&gt; +}
&gt;&gt; +
&gt;&gt;   static int dax_hmem_platform_probe(struct platform_device *pdev)
&gt;&gt;   {
&gt;&gt; +	int rc;
&gt;&gt; +
&gt;&gt; +	rc = dax_hmem_register_work(process_defer_work, pdev);
&gt;&gt; +	if (rc)
&gt;&gt; +		return rc;
&gt;&gt; +
&gt;&gt; +	rc = devm_add_action_or_reset(&amp;pdev-&gt;dev, kill_defer_work, pdev);
&gt;&gt; +	if (rc)
&gt;&gt; +		return rc;
&gt;&gt; +
&gt;&gt;   	return walk_hmem_resources(&amp;pdev-&gt;dev, hmem_register_device);
&gt;&gt;   }
&gt; 
&gt; Is there a potential deadlock in the error path here? If
&gt; walk_hmem_resources() encounters a CXL-intersecting range first
&gt; (calling dax_hmem_queue_work(), which schedules process_defer_work
&gt; on system_long_wq), and then a subsequent non-CXL Soft Reserved
&gt; range fails to register, the probe returns an error. The devres
&gt; cleanup then calls kill_defer_work -&gt; dax_hmem_flush_work() -&gt;
&gt; flush_work(&amp;dax_hmem_work).
&gt; 
&gt; Meanwhile, process_defer_work calls wait_for_device_probe(), which
&gt; waits for probe_count to reach zero. Since devres_release_all runs
&gt; inside really_probe before driver_probe_device decrements
&gt; probe_count, this looks like a circular wait:
&gt; 
&gt;    driver_probe_device
&gt;      atomic_inc(&amp;probe_count)
&gt;      __driver_probe_device
&gt;        really_probe
&gt;          dax_hmem_platform_probe
&gt;            walk_hmem_resources -&gt; hmem_register_device
&gt;              CXL range: dax_hmem_queue_work()
&gt;              non-CXL range: fails
&gt;            returns error
&gt;          devres_release_all
&gt;            kill_defer_work
&gt;              dax_hmem_flush_work
&gt;                flush_work(&amp;dax_hmem_work)  &lt;-- waits for process_defer_work
&gt;                  process_defer_work
&gt;                    wait_for_device_probe() &lt;-- waits for probe_count == 0
&gt;      atomic_dec(&amp;probe_count)              &lt;-- never reached
&gt; 
&gt; The trigger requires both CXL-intersecting and non-CXL Soft Reserved
&gt; ranges with the non-CXL registration failing, so the window is narrow,
&gt; but the deadlock would be permanent if hit.
&gt; 
&gt; Would it be safer to cancel the work instead of flushing it in the
&gt; error path, or to avoid queuing deferred work during the initial
&gt; walk?

Yes, you&#x27;re right, that&#x27;s a real deadlock. Thanks for pointing this out.

This might affect any wait on the work \u2014 flush_work, cancel_work_sync, 
all the same problem.

Just using dax_hmem_unregister_work (which only grabs the mutex and
NULLs pointers) avoids the deadlock but opens a use-after-free: the 
worker may have already copied fn/data and be mid-execution of 
process_defer_work(pdev) while devres tears down the pdev underneath it.

Your suggestion of avoiding queuing during the initial walk is the right 
approach I think. Set a flag when hmem_register_device defers a 
CXL-intersecting range, queue the work after walk_hmem_resources returns 
successfully. Something like:

static int dax_hmem_platform_probe(struct platform_device *pdev)
{
	..
	..
- 	return walk_hmem_resources(&amp;pdev-&gt;dev, hmem_register_device);
+	rc = walk_hmem_resources(&amp;pdev-&gt;dev, hmem_register_device);
+	if (rc)
+		return rc;

+	if (defer) //defer is set under DAX_CXL_MODE_DEFER
+		dax_hmem_queue_work();
}

I think this works but there might be subtleties I&#x27;m missing. What do 
you think?

Thanks
Smita
</pre>
</details>
<div class="review-comment-signals">Signals: potential deadlock, use-after-free</div>
</div>
</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Dave Jiang</span>
<a class="date-chip" href="../2026-02-13_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Dave Jiang suggested improvements for patch series, specifically asking about using typical work_struct pattern and taking a reference on pdev when queuing work.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">

On 2/9/26 11:44 PM, Smita Koralahalli wrote:
&gt; From: Dan Williams &lt;dan.j.williams@intel.com&gt;
&gt; 
&gt; Move hmem/ earlier in the dax Makefile so that hmem_init() runs before
&gt; dax_cxl.
&gt; 
&gt; In addition, defer registration of the dax_cxl driver to a workqueue
&gt; instead of using module_cxl_driver(). This ensures that dax_hmem has
&gt; an opportunity to initialize and register its deferred callback and make
&gt; ownership decisions before dax_cxl begins probing and claiming Soft
&gt; Reserved ranges.
&gt; 
&gt; Mark the dax_cxl driver as PROBE_PREFER_ASYNCHRONOUS so its probe runs
&gt; out of line from other synchronous probing avoiding ordering
&gt; dependencies while coordinating ownership decisions with dax_hmem.
&gt; 
&gt; Signed-off-by: Dan Williams &lt;dan.j.williams@intel.com&gt;
&gt; Signed-off-by: Smita Koralahalli &lt;Smita.KoralahalliChannabasappa@amd.com&gt;

Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;

&gt; ---
&gt;  drivers/dax/Makefile |  3 +--
&gt;  drivers/dax/cxl.c    | 27 ++++++++++++++++++++++++++-
&gt;  2 files changed, 27 insertions(+), 3 deletions(-)
&gt; 
&gt; diff --git a/drivers/dax/Makefile b/drivers/dax/Makefile
&gt; index 5ed5c39857c8..70e996bf1526 100644
&gt; --- a/drivers/dax/Makefile
&gt; +++ b/drivers/dax/Makefile
&gt; @@ -1,4 +1,5 @@
&gt;  # SPDX-License-Identifier: GPL-2.0
&gt; +obj-y += hmem/
&gt;  obj-$(CONFIG_DAX) += dax.o
&gt;  obj-$(CONFIG_DEV_DAX) += device_dax.o
&gt;  obj-$(CONFIG_DEV_DAX_KMEM) += kmem.o
&gt; @@ -10,5 +11,3 @@ dax-y += bus.o
&gt;  device_dax-y := device.o
&gt;  dax_pmem-y := pmem.o
&gt;  dax_cxl-y := cxl.o
&gt; -
&gt; -obj-y += hmem/
&gt; diff --git a/drivers/dax/cxl.c b/drivers/dax/cxl.c
&gt; index 13cd94d32ff7..a2136adfa186 100644
&gt; --- a/drivers/dax/cxl.c
&gt; +++ b/drivers/dax/cxl.c
&gt; @@ -38,10 +38,35 @@ static struct cxl_driver cxl_dax_region_driver = {
&gt;  	.id = CXL_DEVICE_DAX_REGION,
&gt;  	.drv = {
&gt;  		.suppress_bind_attrs = true,
&gt; +		.probe_type = PROBE_PREFER_ASYNCHRONOUS,
&gt;  	},
&gt;  };
&gt;  
&gt; -module_cxl_driver(cxl_dax_region_driver);
&gt; +static void cxl_dax_region_driver_register(struct work_struct *work)
&gt; +{
&gt; +	cxl_driver_register(&amp;cxl_dax_region_driver);
&gt; +}
&gt; +
&gt; +static DECLARE_WORK(cxl_dax_region_driver_work, cxl_dax_region_driver_register);
&gt; +
&gt; +static int __init cxl_dax_region_init(void)
&gt; +{
&gt; +	/*
&gt; +	 * Need to resolve a race with dax_hmem wanting to drive regions
&gt; +	 * instead of CXL
&gt; +	 */
&gt; +	queue_work(system_long_wq, &amp;cxl_dax_region_driver_work);
&gt; +	return 0;
&gt; +}
&gt; +module_init(cxl_dax_region_init);
&gt; +
&gt; +static void __exit cxl_dax_region_exit(void)
&gt; +{
&gt; +	flush_work(&amp;cxl_dax_region_driver_work);
&gt; +	cxl_driver_unregister(&amp;cxl_dax_region_driver);
&gt; +}
&gt; +module_exit(cxl_dax_region_exit);
&gt; +
&gt;  MODULE_ALIAS_CXL(CXL_DEVICE_DAX_REGION);
&gt;  MODULE_DESCRIPTION(&quot;CXL DAX: direct access to CXL regions&quot;);
&gt;  MODULE_LICENSE(&quot;GPL&quot;);



---



On 2/9/26 11:44 PM, Smita Koralahalli wrote:
&gt; Introduce a global &quot;DAX Regions&quot; resource root and register each
&gt; dax_region-&gt;res under it via request_resource(). Release the resource on
&gt; dax_region teardown.
&gt; 
&gt; By enforcing a single global namespace for dax_region allocations, this
&gt; ensures only one of dax_hmem or dax_cxl can successfully register a
&gt; dax_region for a given range.
&gt; 
&gt; Co-developed-by: Dan Williams &lt;dan.j.williams@intel.com&gt;
&gt; Signed-off-by: Dan Williams &lt;dan.j.williams@intel.com&gt;
&gt; Signed-off-by: Smita Koralahalli &lt;Smita.KoralahalliChannabasappa@amd.com&gt;

Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;

&gt; ---
&gt;  drivers/dax/bus.c | 23 ++++++++++++++++++++---
&gt;  1 file changed, 20 insertions(+), 3 deletions(-)
&gt; 
&gt; diff --git a/drivers/dax/bus.c b/drivers/dax/bus.c
&gt; index fde29e0ad68b..5f387feb95f0 100644
&gt; --- a/drivers/dax/bus.c
&gt; +++ b/drivers/dax/bus.c
&gt; @@ -10,6 +10,7 @@
&gt;  #include &quot;dax-private.h&quot;
&gt;  #include &quot;bus.h&quot;
&gt;  
&gt; +static struct resource dax_regions = DEFINE_RES_MEM_NAMED(0, -1, &quot;DAX Regions&quot;);
&gt;  static DEFINE_MUTEX(dax_bus_lock);
&gt;  
&gt;  /*
&gt; @@ -625,6 +626,8 @@ static void dax_region_unregister(void *region)
&gt;  {
&gt;  	struct dax_region *dax_region = region;
&gt;  
&gt; +	scoped_guard(rwsem_write, &amp;dax_region_rwsem)
&gt; +		release_resource(&amp;dax_region-&gt;res);
&gt;  	sysfs_remove_groups(&amp;dax_region-&gt;dev-&gt;kobj,
&gt;  			dax_region_attribute_groups);
&gt;  	dax_region_put(dax_region);
&gt; @@ -635,6 +638,7 @@ struct dax_region *alloc_dax_region(struct device *parent, int region_id,
&gt;  		unsigned long flags)
&gt;  {
&gt;  	struct dax_region *dax_region;
&gt; +	int rc;
&gt;  
&gt;  	/*
&gt;  	 * The DAX core assumes that it can store its private data in
&gt; @@ -667,14 +671,27 @@ struct dax_region *alloc_dax_region(struct device *parent, int region_id,
&gt;  		.flags = IORESOURCE_MEM | flags,
&gt;  	};
&gt;  
&gt; -	if (sysfs_create_groups(&amp;parent-&gt;kobj, dax_region_attribute_groups)) {
&gt; -		kfree(dax_region);
&gt; -		return NULL;
&gt; +	scoped_guard(rwsem_write, &amp;dax_region_rwsem)
&gt; +		rc = request_resource(&amp;dax_regions, &amp;dax_region-&gt;res);
&gt; +	if (rc) {
&gt; +		dev_dbg(parent, &quot;dax_region resource conflict for %pR\n&quot;,
&gt; +			&amp;dax_region-&gt;res);
&gt; +		goto err_res;
&gt;  	}
&gt;  
&gt; +	if (sysfs_create_groups(&amp;parent-&gt;kobj, dax_region_attribute_groups))
&gt; +		goto err_sysfs;
&gt; +
&gt;  	if (devm_add_action_or_reset(parent, dax_region_unregister, dax_region))
&gt;  		return NULL;
&gt;  	return dax_region;
&gt; +
&gt; +err_sysfs:
&gt; +	scoped_guard(rwsem_write, &amp;dax_region_rwsem)
&gt; +		release_resource(&amp;dax_region-&gt;res);
&gt; +err_res:
&gt; +	kfree(dax_region);
&gt; +	return NULL;
&gt;  }
&gt;  EXPORT_SYMBOL_GPL(alloc_dax_region);
&gt;  



---



On 2/9/26 11:44 PM, Smita Koralahalli wrote:
&gt; Add helpers to register, queue and flush the deferred work.
&gt; 
&gt; These helpers allow dax_hmem to execute ownership resolution outside the
&gt; probe context before dax_cxl binds.
&gt; 
&gt; Signed-off-by: Smita Koralahalli &lt;Smita.KoralahalliChannabasappa@amd.com&gt;
&gt; ---
&gt;  drivers/dax/bus.c | 58 +++++++++++++++++++++++++++++++++++++++++++++++
&gt;  drivers/dax/bus.h |  7 ++++++
&gt;  2 files changed, 65 insertions(+)
&gt; 
&gt; diff --git a/drivers/dax/bus.c b/drivers/dax/bus.c
&gt; index 5f387feb95f0..92b88952ede1 100644
&gt; --- a/drivers/dax/bus.c
&gt; +++ b/drivers/dax/bus.c
&gt; @@ -25,6 +25,64 @@ DECLARE_RWSEM(dax_region_rwsem);
&gt;   */
&gt;  DECLARE_RWSEM(dax_dev_rwsem);
&gt;  
&gt; +static DEFINE_MUTEX(dax_hmem_lock);
&gt; +static dax_hmem_deferred_fn hmem_deferred_fn;
&gt; +static void *dax_hmem_data;
&gt; +
&gt; +static void hmem_deferred_work(struct work_struct *work)
&gt; +{
&gt; +	dax_hmem_deferred_fn fn;
&gt; +	void *data;
&gt; +
&gt; +	scoped_guard(mutex, &amp;dax_hmem_lock) {
&gt; +		fn = hmem_deferred_fn;
&gt; +		data = dax_hmem_data;
&gt; +	}
&gt; +
&gt; +	if (fn)
&gt; +		fn(data);
&gt; +}

Instead of having a global lock and dealing with all the global variables, why not just do this with the typical work_struct usage pattern and allocate a work item when queuing work?

DJ

&gt; +
&gt; +static DECLARE_WORK(dax_hmem_work, hmem_deferred_work);
&gt; +
&gt; +int dax_hmem_register_work(dax_hmem_deferred_fn fn, void *data)
&gt; +{
&gt; +	guard(mutex)(&amp;dax_hmem_lock);
&gt; +
&gt; +	if (hmem_deferred_fn)
&gt; +		return -EINVAL;
&gt; +
&gt; +	hmem_deferred_fn = fn;
&gt; +	dax_hmem_data = data;
&gt; +	return 0;
&gt; +}
&gt; +EXPORT_SYMBOL_GPL(dax_hmem_register_work);
&gt; +
&gt; +int dax_hmem_unregister_work(dax_hmem_deferred_fn fn, void *data)
&gt; +{
&gt; +	guard(mutex)(&amp;dax_hmem_lock);
&gt; +
&gt; +	if (hmem_deferred_fn != fn || dax_hmem_data != data)
&gt; +		return -EINVAL;
&gt; +
&gt; +	hmem_deferred_fn = NULL;
&gt; +	dax_hmem_data = NULL;
&gt; +	return 0;
&gt; +}
&gt; +EXPORT_SYMBOL_GPL(dax_hmem_unregister_work);
&gt; +
&gt; +void dax_hmem_queue_work(void)
&gt; +{
&gt; +	queue_work(system_long_wq, &amp;dax_hmem_work);
&gt; +}
&gt; +EXPORT_SYMBOL_GPL(dax_hmem_queue_work);
&gt; +
&gt; +void dax_hmem_flush_work(void)
&gt; +{
&gt; +	flush_work(&amp;dax_hmem_work);
&gt; +}
&gt; +EXPORT_SYMBOL_GPL(dax_hmem_flush_work);
&gt; +
&gt;  #define DAX_NAME_LEN 30
&gt;  struct dax_id {
&gt;  	struct list_head list;
&gt; diff --git a/drivers/dax/bus.h b/drivers/dax/bus.h
&gt; index cbbf64443098..b58a88e8089c 100644
&gt; --- a/drivers/dax/bus.h
&gt; +++ b/drivers/dax/bus.h
&gt; @@ -41,6 +41,13 @@ struct dax_device_driver {
&gt;  	void (*remove)(struct dev_dax *dev);
&gt;  };
&gt;  
&gt; +typedef void (*dax_hmem_deferred_fn)(void *data);
&gt; +
&gt; +int dax_hmem_register_work(dax_hmem_deferred_fn fn, void *data);
&gt; +int dax_hmem_unregister_work(dax_hmem_deferred_fn fn, void *data);
&gt; +void dax_hmem_queue_work(void);
&gt; +void dax_hmem_flush_work(void);
&gt; +
&gt;  int __dax_driver_register(struct dax_device_driver *dax_drv,
&gt;  		struct module *module, const char *mod_name);
&gt;  #define dax_driver_register(driver) \



---



On 2/9/26 11:45 PM, Smita Koralahalli wrote:
&gt; The current probe time ownership check for Soft Reserved memory based
&gt; solely on CXL window intersection is insufficient. dax_hmem probing is not
&gt; always guaranteed to run after CXL enumeration and region assembly, which
&gt; can lead to incorrect ownership decisions before the CXL stack has
&gt; finished publishing windows and assembling committed regions.
&gt; 
&gt; Introduce deferred ownership handling for Soft Reserved ranges that
&gt; intersect CXL windows. When such a range is encountered during dax_hmem
&gt; probe, schedule deferred work and wait for the CXL stack to complete
&gt; enumeration and region assembly before deciding ownership.
&gt; 
&gt; Evaluate ownership of Soft Reserved ranges based on CXL region
&gt; containment.
&gt; 
&gt;    - If all Soft Reserved ranges are fully contained within committed CXL
&gt;      regions, DROP handling Soft Reserved ranges from dax_hmem and allow
&gt;      dax_cxl to bind.
&gt; 
&gt;    - If any Soft Reserved range is not fully claimed by committed CXL
&gt;      region, REGISTER the Soft Reserved ranges with dax_hmem.
&gt; 
&gt; Use dax_cxl_mode to coordinate ownership decisions for Soft Reserved
&gt; ranges. Once, ownership resolution is complete, flush the deferred work
&gt; from dax_cxl before allowing dax_cxl to bind.
&gt; 
&gt; This enforces a strict ownership. Either CXL fully claims the Soft
&gt; reserved ranges or it relinquishes it entirely.
&gt; 
&gt; Co-developed-by: Dan Williams &lt;dan.j.williams@intel.com&gt;
&gt; Signed-off-by: Dan Williams &lt;dan.j.williams@intel.com&gt;
&gt; Signed-off-by: Smita Koralahalli &lt;Smita.KoralahalliChannabasappa@amd.com&gt;
&gt; ---
&gt;  drivers/dax/bus.c       |  3 ++
&gt;  drivers/dax/bus.h       | 19 ++++++++++
&gt;  drivers/dax/cxl.c       |  1 +
&gt;  drivers/dax/hmem/hmem.c | 78 +++++++++++++++++++++++++++++++++++++++--
&gt;  4 files changed, 99 insertions(+), 2 deletions(-)
&gt; 
&gt; diff --git a/drivers/dax/bus.c b/drivers/dax/bus.c
&gt; index 92b88952ede1..81985bcc70f9 100644
&gt; --- a/drivers/dax/bus.c
&gt; +++ b/drivers/dax/bus.c
&gt; @@ -25,6 +25,9 @@ DECLARE_RWSEM(dax_region_rwsem);
&gt;   */
&gt;  DECLARE_RWSEM(dax_dev_rwsem);
&gt;  
&gt; +enum dax_cxl_mode dax_cxl_mode = DAX_CXL_MODE_DEFER;
&gt; +EXPORT_SYMBOL_NS_GPL(dax_cxl_mode, &quot;CXL&quot;);
&gt; +
&gt;  static DEFINE_MUTEX(dax_hmem_lock);
&gt;  static dax_hmem_deferred_fn hmem_deferred_fn;
&gt;  static void *dax_hmem_data;
&gt; diff --git a/drivers/dax/bus.h b/drivers/dax/bus.h
&gt; index b58a88e8089c..82616ff52fd1 100644
&gt; --- a/drivers/dax/bus.h
&gt; +++ b/drivers/dax/bus.h
&gt; @@ -41,6 +41,25 @@ struct dax_device_driver {
&gt;  	void (*remove)(struct dev_dax *dev);
&gt;  };
&gt;  
&gt; +/*
&gt; + * enum dax_cxl_mode - State machine to determine ownership for CXL
&gt; + * tagged Soft Reserved memory ranges.
&gt; + * @DAX_CXL_MODE_DEFER: Ownership resolution pending. Set while waiting
&gt; + * for CXL enumeration and region assembly to complete.
&gt; + * @DAX_CXL_MODE_REGISTER: CXL regions do not fully cover Soft Reserved
&gt; + * ranges. Fall back to registering those ranges via dax_hmem.
&gt; + * @DAX_CXL_MODE_DROP: All Soft Reserved ranges intersecting CXL windows
&gt; + * are fully contained within committed CXL regions. Drop HMEM handling
&gt; + * and allow dax_cxl to bind.
&gt; + */
&gt; +enum dax_cxl_mode {
&gt; +	DAX_CXL_MODE_DEFER,
&gt; +	DAX_CXL_MODE_REGISTER,
&gt; +	DAX_CXL_MODE_DROP,
&gt; +};
&gt; +
&gt; +extern enum dax_cxl_mode dax_cxl_mode;
&gt; +
&gt;  typedef void (*dax_hmem_deferred_fn)(void *data);
&gt;  
&gt;  int dax_hmem_register_work(dax_hmem_deferred_fn fn, void *data);
&gt; diff --git a/drivers/dax/cxl.c b/drivers/dax/cxl.c
&gt; index a2136adfa186..3ab39b77843d 100644
&gt; --- a/drivers/dax/cxl.c
&gt; +++ b/drivers/dax/cxl.c
&gt; @@ -44,6 +44,7 @@ static struct cxl_driver cxl_dax_region_driver = {
&gt;  
&gt;  static void cxl_dax_region_driver_register(struct work_struct *work)
&gt;  {
&gt; +	dax_hmem_flush_work();
&gt;  	cxl_driver_register(&amp;cxl_dax_region_driver);
&gt;  }
&gt;  
&gt; diff --git a/drivers/dax/hmem/hmem.c b/drivers/dax/hmem/hmem.c
&gt; index 1e3424358490..85854e25254b 100644
&gt; --- a/drivers/dax/hmem/hmem.c
&gt; +++ b/drivers/dax/hmem/hmem.c
&gt; @@ -3,6 +3,7 @@
&gt;  #include &lt;linux/memregion.h&gt;
&gt;  #include &lt;linux/module.h&gt;
&gt;  #include &lt;linux/dax.h&gt;
&gt; +#include &lt;cxl/cxl.h&gt;
&gt;  #include &quot;../bus.h&quot;
&gt;  
&gt;  static bool region_idle;
&gt; @@ -69,8 +70,18 @@ static int hmem_register_device(struct device *host, int target_nid,
&gt;  	if (IS_ENABLED(CONFIG_DEV_DAX_CXL) &amp;&amp;
&gt;  	    region_intersects(res-&gt;start, resource_size(res), IORESOURCE_MEM,
&gt;  			      IORES_DESC_CXL) != REGION_DISJOINT) {
&gt; -		dev_dbg(host, &quot;deferring range to CXL: %pr\n&quot;, res);
&gt; -		return 0;
&gt; +		switch (dax_cxl_mode) {
&gt; +		case DAX_CXL_MODE_DEFER:
&gt; +			dev_dbg(host, &quot;deferring range to CXL: %pr\n&quot;, res);
&gt; +			dax_hmem_queue_work();
&gt; +			return 0;
&gt; +		case DAX_CXL_MODE_REGISTER:
&gt; +			dev_dbg(host, &quot;registering CXL range: %pr\n&quot;, res);
&gt; +			break;
&gt; +		case DAX_CXL_MODE_DROP:
&gt; +			dev_dbg(host, &quot;dropping CXL range: %pr\n&quot;, res);
&gt; +			return 0;
&gt; +		}
&gt;  	}
&gt;  
&gt;  	rc = region_intersects_soft_reserve(res-&gt;start, resource_size(res));
&gt; @@ -123,8 +134,70 @@ static int hmem_register_device(struct device *host, int target_nid,
&gt;  	return rc;
&gt;  }
&gt;  
&gt; +static int hmem_register_cxl_device(struct device *host, int target_nid,
&gt; +				    const struct resource *res)
&gt; +{
&gt; +	if (region_intersects(res-&gt;start, resource_size(res), IORESOURCE_MEM,
&gt; +			      IORES_DESC_CXL) != REGION_DISJOINT)
&gt; +		return hmem_register_device(host, target_nid, res);
&gt; +
&gt; +	return 0;
&gt; +}
&gt; +
&gt; +static int soft_reserve_has_cxl_match(struct device *host, int target_nid,
&gt; +				      const struct resource *res)
&gt; +{
&gt; +	if (region_intersects(res-&gt;start, resource_size(res), IORESOURCE_MEM,
&gt; +			      IORES_DESC_CXL) != REGION_DISJOINT) {
&gt; +		if (!cxl_region_contains_soft_reserve((struct resource *)res))
&gt; +			return 1;
&gt; +	}
&gt; +
&gt; +	return 0;
&gt; +}
&gt; +
&gt; +static void process_defer_work(void *data)
&gt; +{
&gt; +	struct platform_device *pdev = data;
&gt; +	int rc;
&gt; +
&gt; +	/* relies on cxl_acpi and cxl_pci having had a chance to load */
&gt; +	wait_for_device_probe();
&gt; +
&gt; +	rc = walk_hmem_resources(&amp;pdev-&gt;dev, soft_reserve_has_cxl_match);
&gt; +
&gt; +	if (!rc) {
&gt; +		dax_cxl_mode = DAX_CXL_MODE_DROP;
&gt; +		dev_dbg(&amp;pdev-&gt;dev, &quot;All Soft Reserved ranges claimed by CXL\n&quot;);
&gt; +	} else {
&gt; +		dax_cxl_mode = DAX_CXL_MODE_REGISTER;
&gt; +		dev_warn(&amp;pdev-&gt;dev,
&gt; +			 &quot;Soft Reserved not fully contained in CXL; using HMEM\n&quot;);
&gt; +	}
&gt; +
&gt; +	walk_hmem_resources(&amp;pdev-&gt;dev, hmem_register_cxl_device);
&gt; +}
&gt; +
&gt; +static void kill_defer_work(void *data)
&gt; +{
&gt; +	struct platform_device *pdev = data;
&gt; +
&gt; +	dax_hmem_flush_work();
&gt; +	dax_hmem_unregister_work(process_defer_work, pdev);
&gt; +}
&gt; +
&gt;  static int dax_hmem_platform_probe(struct platform_device *pdev)
&gt;  {
&gt; +	int rc;
&gt; +
&gt; +	rc = dax_hmem_register_work(process_defer_work, pdev);

Do we need to take a reference on pdev when we queue the work?

DJ

&gt; +	if (rc)
&gt; +		return rc;
&gt; +
&gt; +	rc = devm_add_action_or_reset(&amp;pdev-&gt;dev, kill_defer_work, pdev);
&gt; +	if (rc)
&gt; +		return rc;
&gt; +
&gt;  	return walk_hmem_resources(&amp;pdev-&gt;dev, hmem_register_device);
&gt;  }
&gt;  
&gt; @@ -174,3 +247,4 @@ MODULE_ALIAS(&quot;platform:hmem_platform*&quot;);
&gt;  MODULE_DESCRIPTION(&quot;HMEM DAX: direct access to &#x27;specific purpose&#x27; memory&quot;);
&gt;  MODULE_LICENSE(&quot;GPL v2&quot;);
&gt;  MODULE_AUTHOR(&quot;Intel Corporation&quot;);
&gt; +MODULE_IMPORT_NS(&quot;CXL&quot;);

</pre>
</details>
<div class="review-comment-signals">Signals: requested changes, suggested alternative approach</div>
</div>
<div class="thread-children">
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Koralahalli Smita</span>
<a class="date-chip" href="../2026-02-13_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="inline-review-badge">Inline Review</span>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The reviewer Smita Koralahalli raised concerns about the implementation of deferred work for dax_hmem and dax_cxl coordination, suggesting a statically allocated struct instead of kmalloc + container_of pattern to avoid allocating new independent work items. She also questioned the necessity of a mutex.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Hi Dave,

On 2/18/2026 9:52 AM, Dave Jiang wrote:
&gt; 
&gt; 
&gt; On 2/9/26 11:44 PM, Smita Koralahalli wrote:
&gt;&gt; Add helpers to register, queue and flush the deferred work.
&gt;&gt;
&gt;&gt; These helpers allow dax_hmem to execute ownership resolution outside the
&gt;&gt; probe context before dax_cxl binds.
&gt;&gt;
&gt;&gt; Signed-off-by: Smita Koralahalli &lt;Smita.KoralahalliChannabasappa@amd.com&gt;
&gt;&gt; ---
&gt;&gt;   drivers/dax/bus.c | 58 +++++++++++++++++++++++++++++++++++++++++++++++
&gt;&gt;   drivers/dax/bus.h |  7 ++++++
&gt;&gt;   2 files changed, 65 insertions(+)
&gt;&gt;
&gt;&gt; diff --git a/drivers/dax/bus.c b/drivers/dax/bus.c
&gt;&gt; index 5f387feb95f0..92b88952ede1 100644
&gt;&gt; --- a/drivers/dax/bus.c
&gt;&gt; +++ b/drivers/dax/bus.c
&gt;&gt; @@ -25,6 +25,64 @@ DECLARE_RWSEM(dax_region_rwsem);
&gt;&gt;    */
&gt;&gt;   DECLARE_RWSEM(dax_dev_rwsem);
&gt;&gt;   
&gt;&gt; +static DEFINE_MUTEX(dax_hmem_lock);
&gt;&gt; +static dax_hmem_deferred_fn hmem_deferred_fn;
&gt;&gt; +static void *dax_hmem_data;
&gt;&gt; +
&gt;&gt; +static void hmem_deferred_work(struct work_struct *work)
&gt;&gt; +{
&gt;&gt; +	dax_hmem_deferred_fn fn;
&gt;&gt; +	void *data;
&gt;&gt; +
&gt;&gt; +	scoped_guard(mutex, &amp;dax_hmem_lock) {
&gt;&gt; +		fn = hmem_deferred_fn;
&gt;&gt; +		data = dax_hmem_data;
&gt;&gt; +	}
&gt;&gt; +
&gt;&gt; +	if (fn)
&gt;&gt; +		fn(data);
&gt;&gt; +}
&gt; 
&gt; Instead of having a global lock and dealing with all the global variables, why not just do this with the typical work_struct usage pattern and allocate a work item when queuing work?
&gt; 
&gt; DJ

Thanks for the feedback.

Just to clarify, are you hinting towards a statically allocated struct
with an embedded work_struct, something like below? Rather than the 
typical kmalloc + container_of pattern?

+struct dax_hmem_deferred_ctx {
+	struct work_struct work;
+	dax_hmem_deferred_fn fn;
+	void *data;
+};

+static struct dax_hmem_deferred_ctx dax_hmem_ctx;

+int dax_hmem_register_work(dax_hmem_deferred_fn fn, void *data)
+{
+	if (dax_hmem_ctx.fn)
+		return -EINVAL;

+	INIT_WORK(&amp;dax_hmem_ctx.work, hmem_deferred_work);
..

My understanding is that Dan wanted this to remain a singleton deferred 
work item queued once and flushed from dax_cxl. I think with kmalloc + 
container_of approach, every call would allocate and queue a new 
independent work item..

Regarding the mutex: looking at it again, it may not be necessary I 
think. If we can rely on the call ordering (register_work() before 
queue_work()), and if flush_work() in kill_defer_work() ensures the work 
has fully completed before unregister_work() NULLs the pointers, then 
the static struct above would be sufficient without additional locking. 
If I&#x27;m missing a scenario or race here, please correct me.

Thanks,
Smita

&gt; 
&gt;&gt; +
&gt;&gt; +static DECLARE_WORK(dax_hmem_work, hmem_deferred_work);
&gt;&gt; +
&gt;&gt; +int dax_hmem_register_work(dax_hmem_deferred_fn fn, void *data)
&gt;&gt; +{
&gt;&gt; +	guard(mutex)(&amp;dax_hmem_lock);
&gt;&gt; +
&gt;&gt; +	if (hmem_deferred_fn)
&gt;&gt; +		return -EINVAL;
&gt;&gt; +
&gt;&gt; +	hmem_deferred_fn = fn;
&gt;&gt; +	dax_hmem_data = data;
&gt;&gt; +	return 0;
&gt;&gt; +}
&gt;&gt; +EXPORT_SYMBOL_GPL(dax_hmem_register_work);
&gt;&gt; +
&gt;&gt; +int dax_hmem_unregister_work(dax_hmem_deferred_fn fn, void *data)
&gt;&gt; +{
&gt;&gt; +	guard(mutex)(&amp;dax_hmem_lock);
&gt;&gt; +
&gt;&gt; +	if (hmem_deferred_fn != fn || dax_hmem_data != data)
&gt;&gt; +		return -EINVAL;
&gt;&gt; +
&gt;&gt; +	hmem_deferred_fn = NULL;
&gt;&gt; +	dax_hmem_data = NULL;
&gt;&gt; +	return 0;
&gt;&gt; +}
&gt;&gt; +EXPORT_SYMBOL_GPL(dax_hmem_unregister_work);
&gt;&gt; +
&gt;&gt; +void dax_hmem_queue_work(void)
&gt;&gt; +{
&gt;&gt; +	queue_work(system_long_wq, &amp;dax_hmem_work);
&gt;&gt; +}
&gt;&gt; +EXPORT_SYMBOL_GPL(dax_hmem_queue_work);
&gt;&gt; +
&gt;&gt; +void dax_hmem_flush_work(void)
&gt;&gt; +{
&gt;&gt; +	flush_work(&amp;dax_hmem_work);
&gt;&gt; +}
&gt;&gt; +EXPORT_SYMBOL_GPL(dax_hmem_flush_work);
&gt;&gt; +
&gt;&gt;   #define DAX_NAME_LEN 30
&gt;&gt;   struct dax_id {
&gt;&gt;   	struct list_head list;
&gt;&gt; diff --git a/drivers/dax/bus.h b/drivers/dax/bus.h
&gt;&gt; index cbbf64443098..b58a88e8089c 100644
&gt;&gt; --- a/drivers/dax/bus.h
&gt;&gt; +++ b/drivers/dax/bus.h
&gt;&gt; @@ -41,6 +41,13 @@ struct dax_device_driver {
&gt;&gt;   	void (*remove)(struct dev_dax *dev);
&gt;&gt;   };
&gt;&gt;   
&gt;&gt; +typedef void (*dax_hmem_deferred_fn)(void *data);
&gt;&gt; +
&gt;&gt; +int dax_hmem_register_work(dax_hmem_deferred_fn fn, void *data);
&gt;&gt; +int dax_hmem_unregister_work(dax_hmem_deferred_fn fn, void *data);
&gt;&gt; +void dax_hmem_queue_work(void);
&gt;&gt; +void dax_hmem_flush_work(void);
&gt;&gt; +
&gt;&gt;   int __dax_driver_register(struct dax_device_driver *dax_drv,
&gt;&gt;   		struct module *module, const char *mod_name);
&gt;&gt;   #define dax_driver_register(driver) \
&gt; 

</pre>
</details>
<div class="review-comment-signals">Signals: requested changes, technical concerns</div>
</div>
</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Tomasz Wolski</span>
<a class="date-chip" href="../2026-02-13_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="review-tag-badge">Tested-by</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The reviewer, Tomasz Wolski, tested the patch on QEMU and physical setups and asked a question about &#x27;Soft Reserve&#x27; parent entries in iomem, wondering if their absence on his physical setup is okay.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Tested on QEMU and physical setups. 

I have one question about &quot;Soft Reserve&quot; parent entries in iomem.
On QEMU I see parent &quot;Soft Reserved&quot;:

a90000000-b4fffffff : Soft Reserved
  a90000000-b4fffffff : CXL Window 0
    a90000000-b4fffffff : dax1.0
      a90000000-b4fffffff : System RAM (kmem)

While on my physical setup this is missing - not sure if this is okay?

BIOS-e820: [mem 0x0000002070000000-0x000000a06fffffff] soft reserved

2070000000-606fffffff : CXL Window 0
  2070000000-606fffffff : region0
    2070000000-606fffffff : dax0.0
      2070000000-606fffffff : System RAM (kmem)
6070000000-a06fffffff : CXL Window 1
  6070000000-a06fffffff : region1
    6070000000-a06fffffff : dax1.0
      6070000000-a06fffffff : System RAM (kmem)

Tested-by: Tomasz Wolski &lt;tomasz.wolski@fujitsu.com&gt;
</pre>
</details>
<div class="review-comment-signals">Signals: question</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Alejandro Palau</span>
<a class="date-chip" href="../2026-02-13_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The reviewer raised concerns about the patch&#x27;s decision to gate Soft Reserved deferral on DEV_DAX_CXL configuration, questioning why it&#x27;s an all-or-nothing approach and suggesting that the reason for this decision should be explained in the commit message or code comments.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">
On 2/10/26 06:45, Smita Koralahalli wrote:
&gt; The current probe time ownership check for Soft Reserved memory based
&gt; solely on CXL window intersection is insufficient. dax_hmem probing is not
&gt; always guaranteed to run after CXL enumeration and region assembly, which
&gt; can lead to incorrect ownership decisions before the CXL stack has
&gt; finished publishing windows and assembling committed regions.
&gt;
&gt; Introduce deferred ownership handling for Soft Reserved ranges that
&gt; intersect CXL windows. When such a range is encountered during dax_hmem
&gt; probe, schedule deferred work and wait for the CXL stack to complete
&gt; enumeration and region assembly before deciding ownership.
&gt;
&gt; Evaluate ownership of Soft Reserved ranges based on CXL region
&gt; containment.
&gt;
&gt;     - If all Soft Reserved ranges are fully contained within committed CXL
&gt;       regions, DROP handling Soft Reserved ranges from dax_hmem and allow
&gt;       dax_cxl to bind.
&gt;
&gt;     - If any Soft Reserved range is not fully claimed by committed CXL
&gt;       region, REGISTER the Soft Reserved ranges with dax_hmem.
&gt;
&gt; Use dax_cxl_mode to coordinate ownership decisions for Soft Reserved
&gt; ranges. Once, ownership resolution is complete, flush the deferred work
&gt; from dax_cxl before allowing dax_cxl to bind.
&gt;
&gt; This enforces a strict ownership. Either CXL fully claims the Soft
&gt; reserved ranges or it relinquishes it entirely.


As I said before, I do not understand why this an all or none decision. 
If I understood this right, we are not trusting on how the platform is 
dealing with CXL configuration leading to some soft reserved ranges not 
having a cxl region. If we do not trust it, why to give such a memory to 
the kernel through hmem?


IMO, it is important to state here the reason for this decision. If I 
understood this wrongly, I guess it is even more important to explain 
the reason behind the decision in the commit and maybe as a comment in 
the code as well. I could not understand it, but at least there would be 
an explanation.


Moreover, as I also commented previously, with Type2 devices, it is 
almost certain the modules containing the related drivers will not be 
probed at this point, or if not fully certain, it is a potential 
possibility. That implies not all the soft reserved regions could have 
linked cxl regions ... leading to given all those soft reserved ranges 
to hmem. I know the &quot;approved&quot; solution is Type2 should go without soft 
reserved memory, but some Type2 devices/drivers could be happy enough 
with dax. If we do not want to deal with this problem now, at least 
there should be some indication of this problem.


&gt;
&gt; Co-developed-by: Dan Williams &lt;dan.j.williams@intel.com&gt;
&gt; Signed-off-by: Dan Williams &lt;dan.j.williams@intel.com&gt;
&gt; Signed-off-by: Smita Koralahalli &lt;Smita.KoralahalliChannabasappa@amd.com&gt;
&gt; ---
&gt;   drivers/dax/bus.c       |  3 ++
&gt;   drivers/dax/bus.h       | 19 ++++++++++
&gt;   drivers/dax/cxl.c       |  1 +
&gt;   drivers/dax/hmem/hmem.c | 78 +++++++++++++++++++++++++++++++++++++++--
&gt;   4 files changed, 99 insertions(+), 2 deletions(-)
&gt;
&gt; diff --git a/drivers/dax/bus.c b/drivers/dax/bus.c
&gt; index 92b88952ede1..81985bcc70f9 100644
&gt; --- a/drivers/dax/bus.c
&gt; +++ b/drivers/dax/bus.c
&gt; @@ -25,6 +25,9 @@ DECLARE_RWSEM(dax_region_rwsem);
&gt;    */
&gt;   DECLARE_RWSEM(dax_dev_rwsem);
&gt;   
&gt; +enum dax_cxl_mode dax_cxl_mode = DAX_CXL_MODE_DEFER;
&gt; +EXPORT_SYMBOL_NS_GPL(dax_cxl_mode, &quot;CXL&quot;);
&gt; +
&gt;   static DEFINE_MUTEX(dax_hmem_lock);
&gt;   static dax_hmem_deferred_fn hmem_deferred_fn;
&gt;   static void *dax_hmem_data;
&gt; diff --git a/drivers/dax/bus.h b/drivers/dax/bus.h
&gt; index b58a88e8089c..82616ff52fd1 100644
&gt; --- a/drivers/dax/bus.h
&gt; +++ b/drivers/dax/bus.h
&gt; @@ -41,6 +41,25 @@ struct dax_device_driver {
&gt;   	void (*remove)(struct dev_dax *dev);
&gt;   };
&gt;   
&gt; +/*
&gt; + * enum dax_cxl_mode - State machine to determine ownership for CXL
&gt; + * tagged Soft Reserved memory ranges.
&gt; + * @DAX_CXL_MODE_DEFER: Ownership resolution pending. Set while waiting
&gt; + * for CXL enumeration and region assembly to complete.
&gt; + * @DAX_CXL_MODE_REGISTER: CXL regions do not fully cover Soft Reserved
&gt; + * ranges. Fall back to registering those ranges via dax_hmem.
&gt; + * @DAX_CXL_MODE_DROP: All Soft Reserved ranges intersecting CXL windows
&gt; + * are fully contained within committed CXL regions. Drop HMEM handling
&gt; + * and allow dax_cxl to bind.
&gt; + */
&gt; +enum dax_cxl_mode {
&gt; +	DAX_CXL_MODE_DEFER,
&gt; +	DAX_CXL_MODE_REGISTER,
&gt; +	DAX_CXL_MODE_DROP,
&gt; +};
&gt; +
&gt; +extern enum dax_cxl_mode dax_cxl_mode;
&gt; +
&gt;   typedef void (*dax_hmem_deferred_fn)(void *data);
&gt;   
&gt;   int dax_hmem_register_work(dax_hmem_deferred_fn fn, void *data);
&gt; diff --git a/drivers/dax/cxl.c b/drivers/dax/cxl.c
&gt; index a2136adfa186..3ab39b77843d 100644
&gt; --- a/drivers/dax/cxl.c
&gt; +++ b/drivers/dax/cxl.c
&gt; @@ -44,6 +44,7 @@ static struct cxl_driver cxl_dax_region_driver = {
&gt;   
&gt;   static void cxl_dax_region_driver_register(struct work_struct *work)
&gt;   {
&gt; +	dax_hmem_flush_work();
&gt;   	cxl_driver_register(&amp;cxl_dax_region_driver);
&gt;   }
&gt;   
&gt; diff --git a/drivers/dax/hmem/hmem.c b/drivers/dax/hmem/hmem.c
&gt; index 1e3424358490..85854e25254b 100644
&gt; --- a/drivers/dax/hmem/hmem.c
&gt; +++ b/drivers/dax/hmem/hmem.c
&gt; @@ -3,6 +3,7 @@
&gt;   #include &lt;linux/memregion.h&gt;
&gt;   #include &lt;linux/module.h&gt;
&gt;   #include &lt;linux/dax.h&gt;
&gt; +#include &lt;cxl/cxl.h&gt;
&gt;   #include &quot;../bus.h&quot;
&gt;   
&gt;   static bool region_idle;
&gt; @@ -69,8 +70,18 @@ static int hmem_register_device(struct device *host, int target_nid,
&gt;   	if (IS_ENABLED(CONFIG_DEV_DAX_CXL) &amp;&amp;
&gt;   	    region_intersects(res-&gt;start, resource_size(res), IORESOURCE_MEM,
&gt;   			      IORES_DESC_CXL) != REGION_DISJOINT) {
&gt; -		dev_dbg(host, &quot;deferring range to CXL: %pr\n&quot;, res);
&gt; -		return 0;
&gt; +		switch (dax_cxl_mode) {
&gt; +		case DAX_CXL_MODE_DEFER:
&gt; +			dev_dbg(host, &quot;deferring range to CXL: %pr\n&quot;, res);
&gt; +			dax_hmem_queue_work();
&gt; +			return 0;
&gt; +		case DAX_CXL_MODE_REGISTER:
&gt; +			dev_dbg(host, &quot;registering CXL range: %pr\n&quot;, res);
&gt; +			break;
&gt; +		case DAX_CXL_MODE_DROP:
&gt; +			dev_dbg(host, &quot;dropping CXL range: %pr\n&quot;, res);
&gt; +			return 0;
&gt; +		}
&gt;   	}
&gt;   
&gt;   	rc = region_intersects_soft_reserve(res-&gt;start, resource_size(res));
&gt; @@ -123,8 +134,70 @@ static int hmem_register_device(struct device *host, int target_nid,
&gt;   	return rc;
&gt;   }
&gt;   
&gt; +static int hmem_register_cxl_device(struct device *host, int target_nid,
&gt; +				    const struct resource *res)
&gt; +{
&gt; +	if (region_intersects(res-&gt;start, resource_size(res), IORESOURCE_MEM,
&gt; +			      IORES_DESC_CXL) != REGION_DISJOINT)
&gt; +		return hmem_register_device(host, target_nid, res);
&gt; +
&gt; +	return 0;
&gt; +}
&gt; +
&gt; +static int soft_reserve_has_cxl_match(struct device *host, int target_nid,
&gt; +				      const struct resource *res)
&gt; +{
&gt; +	if (region_intersects(res-&gt;start, resource_size(res), IORESOURCE_MEM,
&gt; +			      IORES_DESC_CXL) != REGION_DISJOINT) {
&gt; +		if (!cxl_region_contains_soft_reserve((struct resource *)res))
&gt; +			return 1;
&gt; +	}
&gt; +
&gt; +	return 0;
&gt; +}
&gt; +
&gt; +static void process_defer_work(void *data)
&gt; +{
&gt; +	struct platform_device *pdev = data;
&gt; +	int rc;
&gt; +
&gt; +	/* relies on cxl_acpi and cxl_pci having had a chance to load */
&gt; +	wait_for_device_probe();
&gt; +
&gt; +	rc = walk_hmem_resources(&amp;pdev-&gt;dev, soft_reserve_has_cxl_match);
&gt; +
&gt; +	if (!rc) {
&gt; +		dax_cxl_mode = DAX_CXL_MODE_DROP;
&gt; +		dev_dbg(&amp;pdev-&gt;dev, &quot;All Soft Reserved ranges claimed by CXL\n&quot;);
&gt; +	} else {
&gt; +		dax_cxl_mode = DAX_CXL_MODE_REGISTER;
&gt; +		dev_warn(&amp;pdev-&gt;dev,
&gt; +			 &quot;Soft Reserved not fully contained in CXL; using HMEM\n&quot;);
&gt; +	}
&gt; +
&gt; +	walk_hmem_resources(&amp;pdev-&gt;dev, hmem_register_cxl_device);
&gt; +}
&gt; +
&gt; +static void kill_defer_work(void *data)
&gt; +{
&gt; +	struct platform_device *pdev = data;
&gt; +
&gt; +	dax_hmem_flush_work();
&gt; +	dax_hmem_unregister_work(process_defer_work, pdev);
&gt; +}
&gt; +
&gt;   static int dax_hmem_platform_probe(struct platform_device *pdev)
&gt;   {
&gt; +	int rc;
&gt; +
&gt; +	rc = dax_hmem_register_work(process_defer_work, pdev);
&gt; +	if (rc)
&gt; +		return rc;
&gt; +
&gt; +	rc = devm_add_action_or_reset(&amp;pdev-&gt;dev, kill_defer_work, pdev);
&gt; +	if (rc)
&gt; +		return rc;
&gt; +
&gt;   	return walk_hmem_resources(&amp;pdev-&gt;dev, hmem_register_device);
&gt;   }
&gt;   
&gt; @@ -174,3 +247,4 @@ MODULE_ALIAS(&quot;platform:hmem_platform*&quot;);
&gt;   MODULE_DESCRIPTION(&quot;HMEM DAX: direct access to &#x27;specific purpose&#x27; memory&quot;);
&gt;   MODULE_LICENSE(&quot;GPL v2&quot;);
&gt;   MODULE_AUTHOR(&quot;Intel Corporation&quot;);
&gt; +MODULE_IMPORT_NS(&quot;CXL&quot;);

</pre>
</details>
<div class="review-comment-signals">Signals: requested changes, clarification needed</div>
</div>
</div>
</div>
</div>
</div>

    <footer>LKML Daily Activity Tracker</footer>
    <script>
    // When arriving via a date anchor (e.g. #2026-02-15 from a daily report),
    // scroll the anchor into view after a brief delay so layout is complete.
    (function () {
        var hash = window.location.hash;
        if (!hash) return;
        var target = document.getElementById(hash.slice(1));
        if (!target) return;
        setTimeout(function () {
            target.scrollIntoView({behavior: 'smooth', block: 'start'});
        }, 80);
    })();
    </script>
</body>
</html>