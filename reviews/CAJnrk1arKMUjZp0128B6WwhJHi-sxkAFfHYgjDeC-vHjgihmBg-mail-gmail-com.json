{
  "thread_id": "CAJnrk1arKMUjZp0128B6WwhJHi-sxkAFfHYgjDeC=vHjgihmBg@mail.gmail.com",
  "subject": "Re: [PATCH v2 0/9] io_uring: add kernel-managed buffer rings",
  "url": "https://lore.kernel.org/all/CAJnrk1arKMUjZp0128B6WwhJHi-sxkAFfHYgjDeC=vHjgihmBg@mail.gmail.com/",
  "dates": {
    "2026-02-18": {
      "report_file": "2026-02-18_ollama_llama3.1-8b.html",
      "developer": "Joanne Koong",
      "reviews": [
        {
          "author": "syzbot ci",
          "summary": "The reviewer reported a general protection fault in io_remove_buffers_legacy, indicating a null pointer dereference in the list_del function. The issue was triggered by syzkaller testing and is likely related to incorrect handling of buffer ring lifecycles.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "general protection fault",
            "null-ptr-deref"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "syzbot ci has tested the following series\n\n[v2] io_uring: add kernel-managed buffer rings\nhttps://lore.kernel.org/all/20260218025207.1425553-1-joannelkoong@gmail.com\n* [PATCH v2 1/9] io_uring/memmap: chunk allocations in io_region_allocate_pages()\n* [PATCH v2 2/9] io_uring/kbuf: add support for kernel-managed buffer rings\n* [PATCH v2 3/9] io_uring/kbuf: support kernel-managed buffer rings in buffer selection\n* [PATCH v2 4/9] io_uring/kbuf: add buffer ring pinning/unpinning\n* [PATCH v2 5/9] io_uring/kbuf: return buffer id in buffer selection\n* [PATCH v2 6/9] io_uring/kbuf: add recycling for kernel managed buffer rings\n* [PATCH v2 7/9] io_uring/kbuf: add io_uring_is_kmbuf_ring()\n* [PATCH v2 8/9] io_uring/kbuf: export io_ring_buffer_select()\n* [PATCH v2 9/9] io_uring/cmd: set selected buffer index in __io_uring_cmd_done()\n\nand found the following issue:\ngeneral protection fault in io_remove_buffers_legacy\n\nFull report is available here:\nhttps://ci.syzbot.org/series/ddeaf464-c69b-4166-b0cf-53c9d51e4820\n\n***\n\ngeneral protection fault in io_remove_buffers_legacy\n\ntree:      torvalds\nURL:       https://kernel.googlesource.com/pub/scm/linux/kernel/git/torvalds/linux\nbase:      2961f841b025fb234860bac26dfb7fa7cb0fb122\narch:      amd64\ncompiler:  Debian clang version 21.1.8 (++20251221033036+2078da43e25a-1~exp1~20251221153213.50), Debian LLD 21.1.8\nconfig:    https://ci.syzbot.org/builds/ab5ad5aa-2757-4d66-a2c5-391a8417535d/config\nC repro:   https://ci.syzbot.org/findings/061747e2-36f1-499b-ac34-38cefffbce63/c_repro\nsyz repro: https://ci.syzbot.org/findings/061747e2-36f1-499b-ac34-38cefffbce63/syz_repro\n\nOops: general protection fault, probably for non-canonical address 0xdffffc0000000001: 0000 [#1] SMP KASAN PTI\nKASAN: null-ptr-deref in range [0x0000000000000008-0x000000000000000f]\nCPU: 1 UID: 0 PID: 5967 Comm: syz.0.17 Not tainted syzkaller #0 PREEMPT(full) \nHardware name: QEMU Standard PC (Q35 + ICH9, 2009), BIOS 1.16.2-debian-1.16.2-1 04/01/2014\nRIP: 0010:__list_del_entry_valid_or_report+0x25/0x190 lib/list_debug.c:49\nCode: 90 90 90 90 90 f3 0f 1e fa 41 57 41 56 41 55 41 54 53 48 89 fb 49 bd 00 00 00 00 00 fc ff df 48 83 c7 08 48 89 f8 48 c1 e8 03 <42> 80 3c 28 00 74 05 e8 df 8c 77 fd 4c 8b 7b 08 48 89 d8 48 c1 e8\nRSP: 0018:ffffc900040a7b68 EFLAGS: 00010202\nRAX: 0000000000000001 RBX: 0000000000000000 RCX: 1ffff11035ee2732\nRDX: 1ffff11035ee2730 RSI: 00000000ffffffff RDI: 0000000000000008\nRBP: dffffc0000000000 R08: ffff8881af7139b7 R09: 0000000000000000\nR10: ffff8881af7139a0 R11: ffffed1035ee2737 R12: ffff8881af713980\nR13: dffffc0000000000 R14: 00000000ffffffff R15: 0000000000000000\nFS:  0000555560587500(0000) GS:ffff8882a9466000(0000) knlGS:0000000000000000\nCS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\nCR2: 0000200000001000 CR3: 0000000175cd2000 CR4: 00000000000006f0\nCall Trace:\n <TASK>\n __list_del_entry_valid include/linux/list.h:132 [inline]\n __list_del_entry include/linux/list.h:223 [inline]\n list_del include/linux/list.h:237 [inline]\n io_remove_buffers_legacy+0x139/0x310 io_uring/kbuf.c:533\n io_put_bl+0x62/0x120 io_uring/kbuf.c:548\n io_register_pbuf_ring+0x6c0/0x7d0 io_uring/kbuf.c:855\n __io_uring_register io_uring/register.c:838 [inline]\n __do_sys_io_uring_register io_uring/register.c:1024 [inline]\n __se_sys_io_uring_register+0xc3e/0x19a0 io_uring/register.c:1001\n do_syscall_x64 arch/x86/entry/syscall_64.c:63 [inline]\n do_syscall_64+0x14d/0xf80 arch/x86/entry/syscall_64.c:94\n entry_SYSCALL_64_after_hwframe+0x77/0x7f\nRIP: 0033:0x7f056859bf79\nCode: ff c3 66 2e 0f 1f 84 00 00 00 00 00 0f 1f 44 00 00 48 89 f8 48 89 f7 48 89 d6 48 89 ca 4d 89 c2 4d 89 c8 4c 8b 4c 24 08 0f 05 <48> 3d 01 f0 ff ff 73 01 c3 48 c7 c1 e8 ff ff ff f7 d8 64 89 01 48\nRSP: 002b:00007fffd8dcfaf8 EFLAGS: 00000246 ORIG_RAX: 00000000000001ab\nRAX: ffffffffffffffda RBX: 00007f0568815fa0 RCX: 00007f056859bf79\nRDX: 0000200000000040 RSI: 0000000000000016 RDI: 0000000000000004\nRBP: 00007f05686327e0 R08: 0000000000000000 R09: 0000000000000000\nR10: 0000000000000001 R11: 0000000000000246 R12: 0000000000000000\nR13: 00007f0568815fac R14: 00007f0568815fa0 R15: 00007f0568815fa0\n </TASK>\nModules linked in:\n---[ end trace 0000000000000000 ]---\nRIP: 0010:__list_del_entry_valid_or_report+0x25/0x190 lib/list_debug.c:49\nCode: 90 90 90 90 90 f3 0f 1e fa 41 57 41 56 41 55 41 54 53 48 89 fb 49 bd 00 00 00 00 00 fc ff df 48 83 c7 08 48 89 f8 48 c1 e8 03 <42> 80 3c 28 00 74 05 e8 df 8c 77 fd 4c 8b 7b 08 48 89 d8 48 c1 e8\nRSP: 0018:ffffc900040a7b68 EFLAGS: 00010202\nRAX: 0000000000000001 RBX: 0000000000000000 RCX: 1ffff11035ee2732\nRDX: 1ffff11035ee2730 RSI: 00000000ffffffff RDI: 0000000000000008\nRBP: dffffc0000000000 R08: ffff8881af7139b7 R09: 0000000000000000\nR10: ffff8881af7139a0 R11: ffffed1035ee2737 R12: ffff8881af713980\nR13: dffffc0000000000 R14: 00000000ffffffff R15: 0000000000000000\nFS:  0000555560587500(0000) GS:ffff8882a9466000(0000) knlGS:0000000000000000\nCS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\nCR2: 00007f25f1e17095 CR3: 0000000175cd2000 CR4: 00000000000006f0\n----------------\nCode disassembly (best guess):\n   0:\t90                   \tnop\n   1:\t90                   \tnop\n   2:\t90                   \tnop\n   3:\t90                   \tnop\n   4:\t90                   \tnop\n   5:\tf3 0f 1e fa          \tendbr64\n   9:\t41 57                \tpush   %r15\n   b:\t41 56                \tpush   %r14\n   d:\t41 55                \tpush   %r13\n   f:\t41 54                \tpush   %r12\n  11:\t53                   \tpush   %rbx\n  12:\t48 89 fb             \tmov    %rdi,%rbx\n  15:\t49 bd 00 00 00 00 00 \tmovabs $0xdffffc0000000000,%r13\n  1c:\tfc ff df\n  1f:\t48 83 c7 08          \tadd    $0x8,%rdi\n  23:\t48 89 f8             \tmov    %rdi,%rax\n  26:\t48 c1 e8 03          \tshr    $0x3,%rax\n* 2a:\t42 80 3c 28 00       \tcmpb   $0x0,(%rax,%r13,1) <-- trapping instruction\n  2f:\t74 05                \tje     0x36\n  31:\te8 df 8c 77 fd       \tcall   0xfd778d15\n  36:\t4c 8b 7b 08          \tmov    0x8(%rbx),%r15\n  3a:\t48 89 d8             \tmov    %rbx,%rax\n  3d:\t48                   \trex.W\n  3e:\tc1                   \t.byte 0xc1\n  3f:\te8                   \t.byte 0xe8\n\n\n***\n\nIf these findings have caused you to resend the series or submit a\nseparate fix, please add the following tag to your commit message:\n  Tested-by: syzbot@syzkaller.appspotmail.com\n\n---\nThis report is generated by a bot. It may contain errors.\nsyzbot ci engineers can be reached at syzkaller@googlegroups.com.",
          "reply_to": "Joanne Koong",
          "message_date": "2026-02-18"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "Author acknowledged that the patch needs further revision and promised to update v2 with another version",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "acknowledged need for further revision",
            "promised to update"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "I'm going to update v2 with another version, as per the conversation\nin this thread [1].\n\nThanks,\nJoanne\n\n[1] https://lore.kernel.org/linux-fsdevel/20260210002852.1394504-1-joannelkoong@gmail.com/T/#t",
          "reply_to": "",
          "message_date": "2026-02-18"
        }
      ],
      "analysis_source": "llm-per-reviewer"
    },
    "2026-02-17": {
      "report_file": "2026-02-18_ollama_llama3.1-8b.html",
      "developer": "Joanne Koong",
      "reviews": [
        {
          "author": "Joanne Koong (author)",
          "summary": "The author addressed a concern about inefficient memory allocation in io_region_allocate_pages() by reworking the function to allocate memory in 2MB chunks, attempting compound allocations for each chunk. The author acknowledged that this change is necessary to use kernel-managed ring buffers and will help with TLB performance. A fix is planned.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "acknowledged a fix is needed",
            "will help with TLB performance"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Currently, io_region_allocate_pages() tries a single compound allocation\nfor the entire region, and falls back to alloc_pages_bulk_node() if that\nfails.\n\nWhen allocating a large region, trying to do a single compound\nallocation may be unrealistic while allocating page by page may be\ninefficient and cause worse TLB performance.\n\nRework io_region_allocate_pages() to allocate memory in 2MB chunks,\nattempting a compound allocation for each chunk.\n\nReplace IO_REGION_F_SINGLE_REF with IO_REGION_F_COMPOUND_PAGES to\nreflect that the page array may contain tail pages from multiple\ncompound allocations.\n\nCurrently, alloc_pages_bulk_node() fails when the GFP_KERNEL_ACCOUNT gfp\nflag is set. This makes this commit a necessary change in order to use\nkernel-managed ring buffers (which will allocate regions of large\nsizes), at least until that issue is fixed.\n\nSigned-off-by: Joanne Koong <joannelkoong@gmail.com>\n---\n io_uring/memmap.c | 87 ++++++++++++++++++++++++++++++++++-------------\n 1 file changed, 64 insertions(+), 23 deletions(-)\n\ndiff --git a/io_uring/memmap.c b/io_uring/memmap.c\nindex 89f56609e50a..6e91960aa8fc 100644\n--- a/io_uring/memmap.c\n+++ b/io_uring/memmap.c\n@@ -15,6 +15,28 @@\n #include \"rsrc.h\"\n #include \"zcrx.h\"\n \n+static void release_compound_pages(struct page **pages, unsigned long nr_pages)\n+{\n+\tstruct page *page;\n+\tunsigned int nr, i = 0;\n+\n+\twhile (nr_pages) {\n+\t\tpage = pages[i];\n+\n+\t\tif (!page || WARN_ON_ONCE(page != compound_head(page)))\n+\t\t\treturn;\n+\n+\t\tnr = compound_nr(page);\n+\t\tput_page(page);\n+\n+\t\tif (nr >= nr_pages)\n+\t\t\treturn;\n+\n+\t\ti += nr;\n+\t\tnr_pages -= nr;\n+\t}\n+}\n+\n static bool io_mem_alloc_compound(struct page **pages, int nr_pages,\n \t\t\t\t  size_t size, gfp_t gfp)\n {\n@@ -84,22 +106,19 @@ enum {\n \tIO_REGION_F_VMAP\t\t\t= 1,\n \t/* memory is provided by user and pinned by the kernel */\n \tIO_REGION_F_USER_PROVIDED\t\t= 2,\n-\t/* only the first page in the array is ref'ed */\n-\tIO_REGION_F_SINGLE_REF\t\t\t= 4,\n+\t/* memory may contain tail pages from compound allocations */\n+\tIO_REGION_F_COMPOUND_PAGES\t\t= 4,\n };\n \n void io_free_region(struct user_struct *user, struct io_mapped_region *mr)\n {\n \tif (mr->pages) {\n-\t\tlong nr_refs = mr->nr_pages;\n-\n-\t\tif (mr->flags & IO_REGION_F_SINGLE_REF)\n-\t\t\tnr_refs = 1;\n-\n \t\tif (mr->flags & IO_REGION_F_USER_PROVIDED)\n-\t\t\tunpin_user_pages(mr->pages, nr_refs);\n+\t\t\tunpin_user_pages(mr->pages, mr->nr_pages);\n+\t\telse if (mr->flags & IO_REGION_F_COMPOUND_PAGES)\n+\t\t\trelease_compound_pages(mr->pages, mr->nr_pages);\n \t\telse\n-\t\t\trelease_pages(mr->pages, nr_refs);\n+\t\t\trelease_pages(mr->pages, mr->nr_pages);\n \n \t\tkvfree(mr->pages);\n \t}\n@@ -154,28 +173,50 @@ static int io_region_allocate_pages(struct io_mapped_region *mr,\n \t\t\t\t    unsigned long mmap_offset)\n {\n \tgfp_t gfp = GFP_KERNEL_ACCOUNT | __GFP_ZERO | __GFP_NOWARN;\n-\tsize_t size = io_region_size(mr);\n \tunsigned long nr_allocated;\n-\tstruct page **pages;\n+\tstruct page **pages, **cur_pages;\n+\tunsigned chunk_size, chunk_nr_pages;\n+\tunsigned int pages_left;\n \n \tpages = kvmalloc_array(mr->nr_pages, sizeof(*pages), gfp);\n \tif (!pages)\n \t\treturn -ENOMEM;\n \n-\tif (io_mem_alloc_compound(pages, mr->nr_pages, size, gfp)) {\n-\t\tmr->flags |= IO_REGION_F_SINGLE_REF;\n-\t\tgoto done;\n-\t}\n+\tchunk_size = SZ_2M;\n+\tchunk_nr_pages = chunk_size >> PAGE_SHIFT;\n+\tpages_left = mr->nr_pages;\n+\tcur_pages = pages;\n+\n+\twhile (pages_left) {\n+\t\tunsigned int nr_pages = min(pages_left,\n+\t\t\t\t\t    chunk_nr_pages);\n+\n+\t\tif (io_mem_alloc_compound(cur_pages, nr_pages,\n+\t\t\t\t\t  nr_pages << PAGE_SHIFT, gfp)) {\n+\t\t\tmr->flags |= IO_REGION_F_COMPOUND_PAGES;\n+\t\t\tcur_pages += nr_pages;\n+\t\t\tpages_left -= nr_pages;\n+\t\t\tcontinue;\n+\t\t}\n \n-\tnr_allocated = alloc_pages_bulk_node(gfp, NUMA_NO_NODE,\n-\t\t\t\t\t     mr->nr_pages, pages);\n-\tif (nr_allocated != mr->nr_pages) {\n-\t\tif (nr_allocated)\n-\t\t\trelease_pages(pages, nr_allocated);\n-\t\tkvfree(pages);\n-\t\treturn -ENOMEM;\n+\t\tnr_allocated = alloc_pages_bulk_node(gfp, NUMA_NO_NODE,\n+\t\t\t\t\t\t     nr_pages, cur_pages);\n+\t\tif (nr_allocated != nr_pages) {\n+\t\t\tunsigned int total =\n+\t\t\t\t(cur_pages - pages) + nr_allocated;\n+\n+\t\t\tif (mr->flags & IO_REGION_F_COMPOUND_PAGES)\n+\t\t\t\trelease_compound_pages(pages, total);\n+\t\t\telse\n+\t\t\t\trelease_pages(pages, total);\n+\t\t\tkvfree(pages);\n+\t\t\treturn -ENOMEM;\n+\t\t}\n+\n+\t\tcur_pages += nr_pages;\n+\t\tpages_left -= nr_pages;\n \t}\n-done:\n+\n \treg->mmap_offset = mmap_offset;\n \tmr->pages = pages;\n \treturn 0;\n-- \n2.47.3",
          "reply_to": "",
          "message_date": "2026-02-17"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "The author addressed a concern about the kernel-managed buffer ring interface, specifically the handling of memory allocation and virtual mappings for the buffers. The author explained that when the caller sets the IOU_PBUF_RING_KERNEL_MANAGED flag, the kernel allocates the memory for the ring and its buffers, and the application must set the buffer size through reg->buf_size. The buffers are recycled by the kernel. When the caller makes a subsequent mmap call, the virtual mapping returned is a contiguous mapping of the buffers. The author did not promise to restructure the code in response to this feedback.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Add support for kernel-managed buffer rings, which allow the kernel to\nallocate and manage the backing buffers for a buffer ring, rather than\nrequiring the application to provide and manage them.\n\nInternally, the IOBL_KERNEL_MANAGED flag marks buffer lists as\nkernel-managed for appropriate handling in the I/O path.\n\nAt the uapi level, kernel-managed buffer rings are created through the\npbuf interface with the IOU_PBUF_RING_KERNEL_MANAGED flag set. The\nio_uring_buf_reg struct is modified to allow taking in a buf_size\ninstead of a ring_addr. To create a kernel-managed buffer ring, the\ncaller must set the IOU_PBUF_RING_MMAP flag as well to indicate that the\nkernel will allocate the memory for the ring. When the caller mmaps the\nring, they will get back a virtual mapping to the buffer memory.\n\nSigned-off-by: Joanne Koong <joannelkoong@gmail.com>\n---\n include/uapi/linux/io_uring.h | 14 +++++-\n io_uring/kbuf.c               | 95 +++++++++++++++++++++++++++++------\n io_uring/kbuf.h               |  6 ++-\n 3 files changed, 97 insertions(+), 18 deletions(-)\n\ndiff --git a/include/uapi/linux/io_uring.h b/include/uapi/linux/io_uring.h\nindex 6750c383a2ab..278b56a87745 100644\n--- a/include/uapi/linux/io_uring.h\n+++ b/include/uapi/linux/io_uring.h\n@@ -885,15 +885,27 @@ struct io_uring_buf_ring {\n  *\t\t\tuse of it will consume only as much as it needs. This\n  *\t\t\trequires that both the kernel and application keep\n  *\t\t\ttrack of where the current read/recv index is at.\n+ * IOU_PBUF_RING_KERNEL_MANAGED: If set, kernel allocates the memory for the\n+ *\t\t\tring and its buffers. The application must set the\n+ *\t\t\tbuffer size through reg->buf_size. The buffers are\n+ *\t\t\trecycled by the kernel. IOU_PBUF_RING_MMAP must be set\n+ *\t\t\tas well. When the caller makes a subsequent mmap call,\n+ *\t\t\tthe virtual mapping returned is a contiguous mapping of\n+ *\t\t\tthe buffers. IOU_PBUF_RING_INC is not yet supported.\n  */\n enum io_uring_register_pbuf_ring_flags {\n \tIOU_PBUF_RING_MMAP\t= 1,\n \tIOU_PBUF_RING_INC\t= 2,\n+\tIOU_PBUF_RING_KERNEL_MANAGED = 4,\n };\n \n /* argument for IORING_(UN)REGISTER_PBUF_RING */\n struct io_uring_buf_reg {\n-\t__u64\tring_addr;\n+\tunion {\n+\t\t__u64\tring_addr;\n+\t\t/* used if reg->flags & IOU_PBUF_RING_KERNEL_MANAGED */\n+\t\t__u32   buf_size;\n+\t};\n \t__u32\tring_entries;\n \t__u16\tbgid;\n \t__u16\tflags;\ndiff --git a/io_uring/kbuf.c b/io_uring/kbuf.c\nindex 67d4fe576473..816200e91b1f 100644\n--- a/io_uring/kbuf.c\n+++ b/io_uring/kbuf.c\n@@ -427,10 +427,13 @@ static int io_remove_buffers_legacy(struct io_ring_ctx *ctx,\n \n static void io_put_bl(struct io_ring_ctx *ctx, struct io_buffer_list *bl)\n {\n-\tif (bl->flags & IOBL_BUF_RING)\n+\tif (bl->flags & IOBL_BUF_RING) {\n \t\tio_free_region(ctx->user, &bl->region);\n-\telse\n+\t\tif (bl->flags & IOBL_KERNEL_MANAGED)\n+\t\t\tkfree(bl->buf_ring);\n+\t} else {\n \t\tio_remove_buffers_legacy(ctx, bl, -1U);\n+\t}\n \n \tkfree(bl);\n }\n@@ -596,6 +599,51 @@ int io_manage_buffers_legacy(struct io_kiocb *req, unsigned int issue_flags)\n \treturn IOU_COMPLETE;\n }\n \n+static int io_setup_kmbuf_ring(struct io_ring_ctx *ctx,\n+\t\t\t       struct io_buffer_list *bl,\n+\t\t\t       const struct io_uring_buf_reg *reg)\n+{\n+\tstruct io_uring_region_desc rd;\n+\tstruct io_uring_buf_ring *ring;\n+\tunsigned long ring_size;\n+\tvoid *buf_region;\n+\tunsigned int i;\n+\tint ret;\n+\n+\t/* allocate pages for the ring structure */\n+\tring_size = flex_array_size(ring, bufs, reg->ring_entries);\n+\tring = kzalloc(ring_size, GFP_KERNEL_ACCOUNT);\n+\tif (!ring)\n+\t\treturn -ENOMEM;\n+\n+\tmemset(&rd, 0, sizeof(rd));\n+\trd.size = (u64)reg->buf_size * reg->ring_entries;\n+\n+\tret = io_create_region(ctx, &bl->region, &rd, 0);\n+\tif (ret) {\n+\t\tkfree(ring);\n+\t\treturn ret;\n+\t}\n+\n+\t/* initialize ring buf entries to point to the buffers */\n+\tbuf_region = io_region_get_ptr(&bl->region);\n+\tfor (i = 0; i < reg->ring_entries; i++) {\n+\t\tstruct io_uring_buf *buf = &ring->bufs[i];\n+\n+\t\tbuf->addr = (u64)(uintptr_t)buf_region;\n+\t\tbuf->len = reg->buf_size;\n+\t\tbuf->bid = i;\n+\n+\t\tbuf_region += reg->buf_size;\n+\t}\n+\tring->tail = reg->ring_entries;\n+\n+\tbl->buf_ring = ring;\n+\tbl->flags |= IOBL_KERNEL_MANAGED;\n+\n+\treturn 0;\n+}\n+\n int io_register_pbuf_ring(struct io_ring_ctx *ctx, void __user *arg)\n {\n \tstruct io_uring_buf_reg reg;\n@@ -612,7 +660,8 @@ int io_register_pbuf_ring(struct io_ring_ctx *ctx, void __user *arg)\n \t\treturn -EFAULT;\n \tif (!mem_is_zero(reg.resv, sizeof(reg.resv)))\n \t\treturn -EINVAL;\n-\tif (reg.flags & ~(IOU_PBUF_RING_MMAP | IOU_PBUF_RING_INC))\n+\tif (reg.flags & ~(IOU_PBUF_RING_MMAP | IOU_PBUF_RING_INC |\n+\t\t\t  IOU_PBUF_RING_KERNEL_MANAGED))\n \t\treturn -EINVAL;\n \tif (!is_power_of_2(reg.ring_entries))\n \t\treturn -EINVAL;\n@@ -620,6 +669,15 @@ int io_register_pbuf_ring(struct io_ring_ctx *ctx, void __user *arg)\n \tif (reg.ring_entries >= 65536)\n \t\treturn -EINVAL;\n \n+\tif (reg.flags & IOU_PBUF_RING_KERNEL_MANAGED) {\n+\t\tif (!(reg.flags & IOU_PBUF_RING_MMAP))\n+\t\t\treturn -EINVAL;\n+\t\tif (reg.flags & IOU_PBUF_RING_INC)\n+\t\t\treturn -EINVAL;\n+\t\tif (!reg.buf_size || !PAGE_ALIGNED(reg.buf_size))\n+\t\t\treturn -EINVAL;\n+\t}\n+\n \tbl = io_buffer_get_list(ctx, reg.bgid);\n \tif (bl) {\n \t\t/* if mapped buffer ring OR classic exists, don't allow */\n@@ -634,17 +692,26 @@ int io_register_pbuf_ring(struct io_ring_ctx *ctx, void __user *arg)\n \n \tmmap_offset = (unsigned long)reg.bgid << IORING_OFF_PBUF_SHIFT;\n \tring_size = flex_array_size(br, bufs, reg.ring_entries);\n-\n \tmemset(&rd, 0, sizeof(rd));\n-\trd.size = PAGE_ALIGN(ring_size);\n-\tif (!(reg.flags & IOU_PBUF_RING_MMAP)) {\n-\t\trd.user_addr = reg.ring_addr;\n-\t\trd.flags |= IORING_MEM_REGION_TYPE_USER;\n+\n+\tif (reg.flags & IOU_PBUF_RING_KERNEL_MANAGED) {\n+\t\tret = io_setup_kmbuf_ring(ctx, bl, &reg);\n+\t\tif (ret) {\n+\t\t\tkfree(bl);\n+\t\t\treturn ret;\n+\t\t}\n+\t} else {\n+\t\trd.size = PAGE_ALIGN(ring_size);\n+\t\tif (!(reg.flags & IOU_PBUF_RING_MMAP)) {\n+\t\t\trd.user_addr = reg.ring_addr;\n+\t\t\trd.flags |= IORING_MEM_REGION_TYPE_USER;\n+\t\t}\n+\t\tret = io_create_region(ctx, &bl->region, &rd, mmap_offset);\n+\t\tif (ret)\n+\t\t\tgoto fail;\n+\t\tbl->buf_ring = io_region_get_ptr(&bl->region);\n \t}\n-\tret = io_create_region(ctx, &bl->region, &rd, mmap_offset);\n-\tif (ret)\n-\t\tgoto fail;\n-\tbr = io_region_get_ptr(&bl->region);\n+\tbr = bl->buf_ring;\n \n #ifdef SHM_COLOUR\n \t/*\n@@ -666,15 +733,13 @@ int io_register_pbuf_ring(struct io_ring_ctx *ctx, void __user *arg)\n \tbl->nr_entries = reg.ring_entries;\n \tbl->mask = reg.ring_entries - 1;\n \tbl->flags |= IOBL_BUF_RING;\n-\tbl->buf_ring = br;\n \tif (reg.flags & IOU_PBUF_RING_INC)\n \t\tbl->flags |= IOBL_INC;\n \tret = io_buffer_add_list(ctx, bl, reg.bgid);\n \tif (!ret)\n \t\treturn 0;\n fail:\n-\tio_free_region(ctx->user, &bl->region);\n-\tkfree(bl);\n+\tio_put_bl(ctx, bl);\n \treturn ret;\n }\n \ndiff --git a/io_uring/kbuf.h b/io_uring/kbuf.h\nindex bf15e26520d3..38dd5fe6716e 100644\n--- a/io_uring/kbuf.h\n+++ b/io_uring/kbuf.h\n@@ -7,9 +7,11 @@\n \n enum {\n \t/* ring mapped provided buffers */\n-\tIOBL_BUF_RING\t= 1,\n+\tIOBL_BUF_RING\t\t= 1,\n \t/* buffers are consumed incrementally rather than always fully */\n-\tIOBL_INC\t= 2,\n+\tIOBL_INC\t\t= 2,\n+\t/* buffers are kernel managed */\n+\tIOBL_KERNEL_MANAGED\t= 4,\n };\n \n struct io_buffer_list {\n-- \n2.47.3",
          "reply_to": "",
          "message_date": "2026-02-17"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "The author addressed a concern about distinguishing between kernel-managed buffer addresses and negative values when error checking, by modifying the io_br_sel struct to separate address and value fields for kernel-managed buffers. The selected kernel-managed buffer will be auto-committed.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "acknowledged a fix is needed",
            "planned a restructuring"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Allow kernel-managed buffers to be selected. This requires modifying the\nio_br_sel struct to separate the fields for address and val, since a\nkernel address cannot be distinguished from a negative val when error\nchecking.\n\nAuto-commit any selected kernel-managed buffer.\n\nSigned-off-by: Joanne Koong <joannelkoong@gmail.com>\n---\n include/linux/io_uring_types.h |  8 ++++----\n io_uring/kbuf.c                | 16 ++++++++++++----\n 2 files changed, 16 insertions(+), 8 deletions(-)\n\ndiff --git a/include/linux/io_uring_types.h b/include/linux/io_uring_types.h\nindex 3e4a82a6f817..36cc2e0346d9 100644\n--- a/include/linux/io_uring_types.h\n+++ b/include/linux/io_uring_types.h\n@@ -93,13 +93,13 @@ struct io_mapped_region {\n  */\n struct io_br_sel {\n \tstruct io_buffer_list *buf_list;\n-\t/*\n-\t * Some selection parts return the user address, others return an error.\n-\t */\n \tunion {\n+\t\t/* for classic/ring provided buffers */\n \t\tvoid __user *addr;\n-\t\tssize_t val;\n+\t\t/* for kernel-managed buffers */\n+\t\tvoid *kaddr;\n \t};\n+\tssize_t val;\n };\n \n \ndiff --git a/io_uring/kbuf.c b/io_uring/kbuf.c\nindex 816200e91b1f..efcc6540f948 100644\n--- a/io_uring/kbuf.c\n+++ b/io_uring/kbuf.c\n@@ -155,7 +155,8 @@ static int io_provided_buffers_select(struct io_kiocb *req, size_t *len,\n \treturn 1;\n }\n \n-static bool io_should_commit(struct io_kiocb *req, unsigned int issue_flags)\n+static bool io_should_commit(struct io_kiocb *req, struct io_buffer_list *bl,\n+\t\t\t     unsigned int issue_flags)\n {\n \t/*\n \t* If we came in unlocked, we have no choice but to consume the\n@@ -170,7 +171,11 @@ static bool io_should_commit(struct io_kiocb *req, unsigned int issue_flags)\n \tif (issue_flags & IO_URING_F_UNLOCKED)\n \t\treturn true;\n \n-\t/* uring_cmd commits kbuf upfront, no need to auto-commit */\n+\t/* kernel-managed buffers are auto-committed */\n+\tif (bl->flags & IOBL_KERNEL_MANAGED)\n+\t\treturn true;\n+\n+\t/* multishot uring_cmd commits kbuf upfront, no need to auto-commit */\n \tif (!io_file_can_poll(req) && req->opcode != IORING_OP_URING_CMD)\n \t\treturn true;\n \treturn false;\n@@ -200,9 +205,12 @@ static struct io_br_sel io_ring_buffer_select(struct io_kiocb *req, size_t *len,\n \treq->flags |= REQ_F_BUFFER_RING | REQ_F_BUFFERS_COMMIT;\n \treq->buf_index = READ_ONCE(buf->bid);\n \tsel.buf_list = bl;\n-\tsel.addr = u64_to_user_ptr(READ_ONCE(buf->addr));\n+\tif (bl->flags & IOBL_KERNEL_MANAGED)\n+\t\tsel.kaddr = (void *)(uintptr_t)READ_ONCE(buf->addr);\n+\telse\n+\t\tsel.addr = u64_to_user_ptr(READ_ONCE(buf->addr));\n \n-\tif (io_should_commit(req, issue_flags)) {\n+\tif (io_should_commit(req, bl, issue_flags)) {\n \t\tio_kbuf_commit(req, sel.buf_list, *len, 1);\n \t\tsel.buf_list = NULL;\n \t}\n-- \n2.47.3",
          "reply_to": "",
          "message_date": "2026-02-17"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "The author addressed a concern about userspace unregistering a buffer ring while it is pinned by the kernel, and provided a mechanism for kernel subsystems to safely access buffer ring contents. The author added APIs to pin and unpin buffer rings, preventing userspace from unregistering a buffer ring while it is pinned. This change is necessary for fuse to pin the buffer ring because fuse may need to select a buffer in atomic contexts.",
          "sentiment": "positive",
          "sentiment_signals": [
            "added mechanism",
            "necessary for fuse"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Add kernel APIs to pin and unpin buffer rings, preventing userspace from\nunregistering a buffer ring while it is pinned by the kernel.\n\nThis provides a mechanism for kernel subsystems to safely access buffer\nring contents while ensuring the buffer ring remains valid. A pinned\nbuffer ring cannot be unregistered until explicitly unpinned. On the\nuserspace side, trying to unregister a pinned buffer will return -EBUSY.\n\nThis is a preparatory change for upcoming fuse usage of kernel-managed\nbuffer rings. It is necessary for fuse to pin the buffer ring because\nfuse may need to select a buffer in atomic contexts, which it can only\ndo so by using the underlying buffer list pointer.\n\nSigned-off-by: Joanne Koong <joannelkoong@gmail.com>\n---\n include/linux/io_uring/cmd.h | 17 +++++++++++\n io_uring/kbuf.c              | 55 ++++++++++++++++++++++++++++++++++++\n io_uring/kbuf.h              |  5 ++++\n 3 files changed, 77 insertions(+)\n\ndiff --git a/include/linux/io_uring/cmd.h b/include/linux/io_uring/cmd.h\nindex 375fd048c4cb..bd681d8ab1d4 100644\n--- a/include/linux/io_uring/cmd.h\n+++ b/include/linux/io_uring/cmd.h\n@@ -84,6 +84,10 @@ struct io_br_sel io_uring_cmd_buffer_select(struct io_uring_cmd *ioucmd,\n bool io_uring_mshot_cmd_post_cqe(struct io_uring_cmd *ioucmd,\n \t\t\t\t struct io_br_sel *sel, unsigned int issue_flags);\n \n+int io_uring_buf_ring_pin(struct io_uring_cmd *cmd, unsigned buf_group,\n+\t\t\t  unsigned issue_flags, struct io_buffer_list **out_bl);\n+int io_uring_buf_ring_unpin(struct io_uring_cmd *cmd, unsigned buf_group,\n+\t\t\t    unsigned issue_flags);\n #else\n static inline int\n io_uring_cmd_import_fixed(u64 ubuf, unsigned long len, int rw,\n@@ -126,6 +130,19 @@ static inline bool io_uring_mshot_cmd_post_cqe(struct io_uring_cmd *ioucmd,\n {\n \treturn true;\n }\n+static inline int io_uring_buf_ring_pin(struct io_uring_cmd *cmd,\n+\t\t\t\t\tunsigned buf_group,\n+\t\t\t\t\tunsigned issue_flags,\n+\t\t\t\t\tstruct io_buffer_list **bl)\n+{\n+\treturn -EOPNOTSUPP;\n+}\n+static inline int io_uring_buf_ring_unpin(struct io_uring_cmd *cmd,\n+\t\t\t\t\t  unsigned buf_group,\n+\t\t\t\t\t  unsigned issue_flags)\n+{\n+\treturn -EOPNOTSUPP;\n+}\n #endif\n \n static inline struct io_uring_cmd *io_uring_cmd_from_tw(struct io_tw_req tw_req)\ndiff --git a/io_uring/kbuf.c b/io_uring/kbuf.c\nindex efcc6540f948..1d86ad7803fd 100644\n--- a/io_uring/kbuf.c\n+++ b/io_uring/kbuf.c\n@@ -9,6 +9,7 @@\n #include <linux/poll.h>\n #include <linux/vmalloc.h>\n #include <linux/io_uring.h>\n+#include <linux/io_uring/cmd.h>\n \n #include <uapi/linux/io_uring.h>\n \n@@ -237,6 +238,58 @@ struct io_br_sel io_buffer_select(struct io_kiocb *req, size_t *len,\n \treturn sel;\n }\n \n+int io_uring_buf_ring_pin(struct io_uring_cmd *cmd, unsigned buf_group,\n+\t\t\t  unsigned issue_flags, struct io_buffer_list **out_bl)\n+{\n+\tstruct io_ring_ctx *ctx = cmd_to_io_kiocb(cmd)->ctx;\n+\tstruct io_buffer_list *bl;\n+\tint ret = -EINVAL;\n+\n+\tio_ring_submit_lock(ctx, issue_flags);\n+\n+\tbl = io_buffer_get_list(ctx, buf_group);\n+\tif (!bl || !(bl->flags & IOBL_BUF_RING))\n+\t\tgoto err;\n+\n+\tif (unlikely(bl->flags & IOBL_PINNED)) {\n+\t\tret = -EALREADY;\n+\t\tgoto err;\n+\t}\n+\n+\tbl->flags |= IOBL_PINNED;\n+\tret = 0;\n+\t*out_bl = bl;\n+err:\n+\tio_ring_submit_unlock(ctx, issue_flags);\n+\treturn ret;\n+}\n+EXPORT_SYMBOL_GPL(io_uring_buf_ring_pin);\n+\n+int io_uring_buf_ring_unpin(struct io_uring_cmd *cmd, unsigned buf_group,\n+\t\t       unsigned issue_flags)\n+{\n+\tstruct io_ring_ctx *ctx = cmd_to_io_kiocb(cmd)->ctx;\n+\tstruct io_buffer_list *bl;\n+\tunsigned int required_flags;\n+\tint ret = -EINVAL;\n+\n+\tio_ring_submit_lock(ctx, issue_flags);\n+\n+\tbl = io_buffer_get_list(ctx, buf_group);\n+\tif (!bl)\n+\t\tgoto err;\n+\n+\trequired_flags = IOBL_BUF_RING | IOBL_PINNED;\n+\tif ((bl->flags & required_flags) == required_flags) {\n+\t\tbl->flags &= ~IOBL_PINNED;\n+\t\tret = 0;\n+\t}\n+err:\n+\tio_ring_submit_unlock(ctx, issue_flags);\n+\treturn ret;\n+}\n+EXPORT_SYMBOL_GPL(io_uring_buf_ring_unpin);\n+\n /* cap it at a reasonable 256, will be one page even for 4K */\n #define PEEK_MAX_IMPORT\t\t256\n \n@@ -768,6 +821,8 @@ int io_unregister_pbuf_ring(struct io_ring_ctx *ctx, void __user *arg)\n \t\treturn -ENOENT;\n \tif (!(bl->flags & IOBL_BUF_RING))\n \t\treturn -EINVAL;\n+\tif (bl->flags & IOBL_PINNED)\n+\t\treturn -EBUSY;\n \n \tscoped_guard(mutex, &ctx->mmap_lock)\n \t\txa_erase(&ctx->io_bl_xa, bl->bgid);\ndiff --git a/io_uring/kbuf.h b/io_uring/kbuf.h\nindex 38dd5fe6716e..006e8a73a117 100644\n--- a/io_uring/kbuf.h\n+++ b/io_uring/kbuf.h\n@@ -12,6 +12,11 @@ enum {\n \tIOBL_INC\t\t= 2,\n \t/* buffers are kernel managed */\n \tIOBL_KERNEL_MANAGED\t= 4,\n+\t/*\n+\t * buffer ring is pinned and cannot be unregistered by userspace until\n+\t * it has been unpinned\n+\t */\n+\tIOBL_PINNED\t\t= 8,\n };\n \n struct io_buffer_list {\n-- \n2.47.3",
          "reply_to": "",
          "message_date": "2026-02-17"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "The author addressed a concern about returning the id of the selected buffer in io_buffer_select() for kernel-managed buffer rings, agreeing to modify the function to return the buffer id.",
          "sentiment": "positive",
          "sentiment_signals": [
            "agreed to modify the function"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Return the id of the selected buffer in io_buffer_select(). This is\nneeded for kernel-managed buffer rings to later recycle the selected\nbuffer.\n\nSigned-off-by: Joanne Koong <joannelkoong@gmail.com>\n---\n include/linux/io_uring/cmd.h   | 2 +-\n include/linux/io_uring_types.h | 2 ++\n io_uring/kbuf.c                | 7 +++++--\n 3 files changed, 8 insertions(+), 3 deletions(-)\n\ndiff --git a/include/linux/io_uring/cmd.h b/include/linux/io_uring/cmd.h\nindex bd681d8ab1d4..31f47cce99f5 100644\n--- a/include/linux/io_uring/cmd.h\n+++ b/include/linux/io_uring/cmd.h\n@@ -71,7 +71,7 @@ void io_uring_cmd_issue_blocking(struct io_uring_cmd *ioucmd);\n \n /*\n  * Select a buffer from the provided buffer group for multishot uring_cmd.\n- * Returns the selected buffer address and size.\n+ * Returns the selected buffer address, size, and id.\n  */\n struct io_br_sel io_uring_cmd_buffer_select(struct io_uring_cmd *ioucmd,\n \t\t\t\t\t    unsigned buf_group, size_t *len,\ndiff --git a/include/linux/io_uring_types.h b/include/linux/io_uring_types.h\nindex 36cc2e0346d9..5a56bb341337 100644\n--- a/include/linux/io_uring_types.h\n+++ b/include/linux/io_uring_types.h\n@@ -100,6 +100,8 @@ struct io_br_sel {\n \t\tvoid *kaddr;\n \t};\n \tssize_t val;\n+\t/* id of the selected buffer */\n+\tunsigned buf_id;\n };\n \n \ndiff --git a/io_uring/kbuf.c b/io_uring/kbuf.c\nindex 1d86ad7803fd..d20221f1b9b2 100644\n--- a/io_uring/kbuf.c\n+++ b/io_uring/kbuf.c\n@@ -206,6 +206,7 @@ static struct io_br_sel io_ring_buffer_select(struct io_kiocb *req, size_t *len,\n \treq->flags |= REQ_F_BUFFER_RING | REQ_F_BUFFERS_COMMIT;\n \treq->buf_index = READ_ONCE(buf->bid);\n \tsel.buf_list = bl;\n+\tsel.buf_id = req->buf_index;\n \tif (bl->flags & IOBL_KERNEL_MANAGED)\n \t\tsel.kaddr = (void *)(uintptr_t)READ_ONCE(buf->addr);\n \telse\n@@ -229,10 +230,12 @@ struct io_br_sel io_buffer_select(struct io_kiocb *req, size_t *len,\n \n \tbl = io_buffer_get_list(ctx, buf_group);\n \tif (likely(bl)) {\n-\t\tif (bl->flags & IOBL_BUF_RING)\n+\t\tif (bl->flags & IOBL_BUF_RING) {\n \t\t\tsel = io_ring_buffer_select(req, len, bl, issue_flags);\n-\t\telse\n+\t\t} else {\n \t\t\tsel.addr = io_provided_buffer_select(req, len, bl);\n+\t\t\tsel.buf_id = req->buf_index;\n+\t\t}\n \t}\n \tio_ring_submit_unlock(req->ctx, issue_flags);\n \treturn sel;\n-- \n2.47.3",
          "reply_to": "",
          "message_date": "2026-02-17"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "The author addressed a concern about buffer recycling by adding an interface for buffers to be recycled back into a kernel-managed buffer ring, which will be implemented in the io_uring/kbuf.c file.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "acknowledged fix needed"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Add an interface for buffers to be recycled back into a kernel-managed\nbuffer ring.\n\nSigned-off-by: Joanne Koong <joannelkoong@gmail.com>\n---\n include/linux/io_uring/cmd.h | 11 +++++++++\n io_uring/kbuf.c              | 48 ++++++++++++++++++++++++++++++++++++\n 2 files changed, 59 insertions(+)\n\ndiff --git a/include/linux/io_uring/cmd.h b/include/linux/io_uring/cmd.h\nindex 31f47cce99f5..5cebcd6d50e6 100644\n--- a/include/linux/io_uring/cmd.h\n+++ b/include/linux/io_uring/cmd.h\n@@ -88,6 +88,10 @@ int io_uring_buf_ring_pin(struct io_uring_cmd *cmd, unsigned buf_group,\n \t\t\t  unsigned issue_flags, struct io_buffer_list **out_bl);\n int io_uring_buf_ring_unpin(struct io_uring_cmd *cmd, unsigned buf_group,\n \t\t\t    unsigned issue_flags);\n+\n+int io_uring_kmbuf_recycle(struct io_uring_cmd *cmd, unsigned int buf_group,\n+\t\t\t   u64 addr, unsigned int len, unsigned int bid,\n+\t\t\t   unsigned int issue_flags);\n #else\n static inline int\n io_uring_cmd_import_fixed(u64 ubuf, unsigned long len, int rw,\n@@ -143,6 +147,13 @@ static inline int io_uring_buf_ring_unpin(struct io_uring_cmd *cmd,\n {\n \treturn -EOPNOTSUPP;\n }\n+static inline int io_uring_kmbuf_recycle(struct io_uring_cmd *cmd,\n+\t\t\t\t\t unsigned int buf_group, u64 addr,\n+\t\t\t\t\t unsigned int len, unsigned int bid,\n+\t\t\t\t\t unsigned int issue_flags)\n+{\n+\treturn -EOPNOTSUPP;\n+}\n #endif\n \n static inline struct io_uring_cmd *io_uring_cmd_from_tw(struct io_tw_req tw_req)\ndiff --git a/io_uring/kbuf.c b/io_uring/kbuf.c\nindex d20221f1b9b2..6e4dd1e003f4 100644\n--- a/io_uring/kbuf.c\n+++ b/io_uring/kbuf.c\n@@ -102,6 +102,54 @@ void io_kbuf_drop_legacy(struct io_kiocb *req)\n \treq->kbuf = NULL;\n }\n \n+int io_uring_kmbuf_recycle(struct io_uring_cmd *cmd, unsigned int buf_group,\n+\t\t\t   u64 addr, unsigned int len, unsigned int bid,\n+\t\t\t   unsigned int issue_flags)\n+{\n+\tstruct io_kiocb *req = cmd_to_io_kiocb(cmd);\n+\tstruct io_ring_ctx *ctx = req->ctx;\n+\tstruct io_uring_buf_ring *br;\n+\tstruct io_uring_buf *buf;\n+\tstruct io_buffer_list *bl;\n+\tunsigned int required_flags;\n+\tint ret = -EINVAL;\n+\n+\tif (WARN_ON_ONCE(req->flags & REQ_F_BUFFERS_COMMIT))\n+\t\treturn ret;\n+\n+\tio_ring_submit_lock(ctx, issue_flags);\n+\n+\tbl = io_buffer_get_list(ctx, buf_group);\n+\n+\tif (!bl)\n+\t\tgoto err;\n+\n+\trequired_flags = IOBL_BUF_RING | IOBL_KERNEL_MANAGED;\n+\tif (WARN_ON_ONCE((bl->flags & required_flags) != required_flags))\n+\t\tgoto err;\n+\n+\tbr = bl->buf_ring;\n+\n+\tif (WARN_ON_ONCE((__u16)(br->tail - bl->head) >= bl->nr_entries))\n+\t\tgoto err;\n+\n+\tbuf = &br->bufs[(br->tail) & bl->mask];\n+\n+\tbuf->addr = addr;\n+\tbuf->len = len;\n+\tbuf->bid = bid;\n+\n+\treq->flags &= ~REQ_F_BUFFER_RING;\n+\n+\tbr->tail++;\n+\tret = 0;\n+\n+err:\n+\tio_ring_submit_unlock(ctx, issue_flags);\n+\treturn ret;\n+}\n+EXPORT_SYMBOL_GPL(io_uring_kmbuf_recycle);\n+\n bool io_kbuf_recycle_legacy(struct io_kiocb *req, unsigned issue_flags)\n {\n \tstruct io_ring_ctx *ctx = req->ctx;\n-- \n2.47.3",
          "reply_to": "",
          "message_date": "2026-02-17"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "The author addressed a concern about the io_uring_is_kmbuf_ring() function, which returns true if there is a kernel-managed buffer ring at the specified buffer group. The author explained that this function is preparatory for upcoming fuse kernel-managed buffer support and needs to ensure the buffer ring registered by the server is a kernel-managed buffer ring.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "preparatory"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "io_uring_is_kmbuf_ring() returns true if there is a kernel-managed\nbuffer ring at the specified buffer group.\n\nThis is a preparatory patch for upcoming fuse kernel-managed buffer\nsupport, which needs to ensure the buffer ring registered by the server\nis a kernel-managed buffer ring.\n\nSigned-off-by: Joanne Koong <joannelkoong@gmail.com>\n---\n include/linux/io_uring/cmd.h |  9 +++++++++\n io_uring/kbuf.c              | 20 ++++++++++++++++++++\n 2 files changed, 29 insertions(+)\n\ndiff --git a/include/linux/io_uring/cmd.h b/include/linux/io_uring/cmd.h\nindex 5cebcd6d50e6..dce6a0ce8538 100644\n--- a/include/linux/io_uring/cmd.h\n+++ b/include/linux/io_uring/cmd.h\n@@ -92,6 +92,9 @@ int io_uring_buf_ring_unpin(struct io_uring_cmd *cmd, unsigned buf_group,\n int io_uring_kmbuf_recycle(struct io_uring_cmd *cmd, unsigned int buf_group,\n \t\t\t   u64 addr, unsigned int len, unsigned int bid,\n \t\t\t   unsigned int issue_flags);\n+\n+bool io_uring_is_kmbuf_ring(struct io_uring_cmd *cmd, unsigned int buf_group,\n+\t\t\t    unsigned int issue_flags);\n #else\n static inline int\n io_uring_cmd_import_fixed(u64 ubuf, unsigned long len, int rw,\n@@ -154,6 +157,12 @@ static inline int io_uring_kmbuf_recycle(struct io_uring_cmd *cmd,\n {\n \treturn -EOPNOTSUPP;\n }\n+static inline bool io_uring_is_kmbuf_ring(struct io_uring_cmd *cmd,\n+\t\t\t\t\t  unsigned int buf_group,\n+\t\t\t\t\t  unsigned int issue_flags)\n+{\n+\treturn false;\n+}\n #endif\n \n static inline struct io_uring_cmd *io_uring_cmd_from_tw(struct io_tw_req tw_req)\ndiff --git a/io_uring/kbuf.c b/io_uring/kbuf.c\nindex 6e4dd1e003f4..bd10c830cd30 100644\n--- a/io_uring/kbuf.c\n+++ b/io_uring/kbuf.c\n@@ -917,3 +917,23 @@ struct io_mapped_region *io_pbuf_get_region(struct io_ring_ctx *ctx,\n \t\treturn NULL;\n \treturn &bl->region;\n }\n+\n+bool io_uring_is_kmbuf_ring(struct io_uring_cmd *cmd, unsigned int buf_group,\n+\t\t\t    unsigned int issue_flags)\n+{\n+\tstruct io_ring_ctx *ctx = cmd_to_io_kiocb(cmd)->ctx;\n+\tstruct io_buffer_list *bl;\n+\tbool is_kmbuf_ring = false;\n+\n+\tio_ring_submit_lock(ctx, issue_flags);\n+\n+\tbl = io_buffer_get_list(ctx, buf_group);\n+\tif (likely(bl) && (bl->flags & IOBL_KERNEL_MANAGED)) {\n+\t\tWARN_ON_ONCE(!(bl->flags & IOBL_BUF_RING));\n+\t\tis_kmbuf_ring = true;\n+\t}\n+\n+\tio_ring_submit_unlock(ctx, issue_flags);\n+\treturn is_kmbuf_ring;\n+}\n+EXPORT_SYMBOL_GPL(io_uring_is_kmbuf_ring);\n-- \n2.47.3",
          "reply_to": "",
          "message_date": "2026-02-17"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "The author addressed a concern about the io_uring mutex being held in atomic contexts when selecting a buffer from a kernel-managed bufring, and agreed to export io_ring_buffer_select() as a preparatory patch for fuse io-uring.",
          "sentiment": "positive",
          "sentiment_signals": [
            "acknowledged fix needed",
            "agreed to restructure"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Export io_ring_buffer_select() so that it may be used by callers who\npass in a pinned bufring without needing to grab the io_uring mutex.\n\nThis is a preparatory patch that will be needed by fuse io-uring, which\nwill need to select a buffer from a kernel-managed bufring while the\nuring mutex may already be held by in-progress commits, and may need to\nselect a buffer in atomic contexts.\n\nSigned-off-by: Joanne Koong <joannelkoong@gmail.com>\n---\n include/linux/io_uring/cmd.h | 14 ++++++++++++++\n io_uring/kbuf.c              |  7 ++++---\n 2 files changed, 18 insertions(+), 3 deletions(-)\n\ndiff --git a/include/linux/io_uring/cmd.h b/include/linux/io_uring/cmd.h\nindex dce6a0ce8538..ac8925fa81f6 100644\n--- a/include/linux/io_uring/cmd.h\n+++ b/include/linux/io_uring/cmd.h\n@@ -95,6 +95,10 @@ int io_uring_kmbuf_recycle(struct io_uring_cmd *cmd, unsigned int buf_group,\n \n bool io_uring_is_kmbuf_ring(struct io_uring_cmd *cmd, unsigned int buf_group,\n \t\t\t    unsigned int issue_flags);\n+\n+struct io_br_sel io_ring_buffer_select(struct io_kiocb *req, size_t *len,\n+\t\t\t\t       struct io_buffer_list *bl,\n+\t\t\t\t       unsigned int issue_flags);\n #else\n static inline int\n io_uring_cmd_import_fixed(u64 ubuf, unsigned long len, int rw,\n@@ -163,6 +167,16 @@ static inline bool io_uring_is_kmbuf_ring(struct io_uring_cmd *cmd,\n {\n \treturn false;\n }\n+static inline struct io_br_sel io_ring_buffer_select(struct io_kiocb *req,\n+\t\t\t\t\t\t     size_t *len,\n+\t\t\t\t\t\t     struct io_buffer_list *bl,\n+\t\t\t\t\t\t     unsigned int issue_flags)\n+{\n+\tstruct io_br_sel sel = {\n+\t\t.val = -EOPNOTSUPP,\n+\t};\n+\treturn sel;\n+}\n #endif\n \n static inline struct io_uring_cmd *io_uring_cmd_from_tw(struct io_tw_req tw_req)\ndiff --git a/io_uring/kbuf.c b/io_uring/kbuf.c\nindex bd10c830cd30..fcc64e4a6a29 100644\n--- a/io_uring/kbuf.c\n+++ b/io_uring/kbuf.c\n@@ -230,9 +230,9 @@ static bool io_should_commit(struct io_kiocb *req, struct io_buffer_list *bl,\n \treturn false;\n }\n \n-static struct io_br_sel io_ring_buffer_select(struct io_kiocb *req, size_t *len,\n-\t\t\t\t\t      struct io_buffer_list *bl,\n-\t\t\t\t\t      unsigned int issue_flags)\n+struct io_br_sel io_ring_buffer_select(struct io_kiocb *req, size_t *len,\n+\t\t\t\t       struct io_buffer_list *bl,\n+\t\t\t\t       unsigned int issue_flags)\n {\n \tstruct io_uring_buf_ring *br = bl->buf_ring;\n \t__u16 tail, head = bl->head;\n@@ -266,6 +266,7 @@ static struct io_br_sel io_ring_buffer_select(struct io_kiocb *req, size_t *len,\n \t}\n \treturn sel;\n }\n+EXPORT_SYMBOL_GPL(io_ring_buffer_select);\n \n struct io_br_sel io_buffer_select(struct io_kiocb *req, size_t *len,\n \t\t\t\t  unsigned buf_group, unsigned int issue_flags)\n-- \n2.47.3",
          "reply_to": "",
          "message_date": "2026-02-17"
        },
        {
          "author": "Joanne Koong (author)",
          "summary": "The author addressed a concern about indicating which buffer was selected in the completion queue entry, and responded by adding a flag (IORING_CQE_F_BUFFER) to indicate this, along with encoding the buffer index if a buffer was selected.",
          "sentiment": "positive",
          "sentiment_signals": [
            "acknowledged the need for change",
            "provided a clear solution"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "When uring_cmd operations select a buffer, the completion queue entry\nshould indicate which buffer was selected.\n\nSet IORING_CQE_F_BUFFER on the completed entry and encode the buffer\nindex if a buffer was selected.\n\nThis change is needed in order to relay to userspace which selected\nbuffer contains the data.\n\nSigned-off-by: Joanne Koong <joannelkoong@gmail.com>\n---\n io_uring/uring_cmd.c | 6 +++++-\n 1 file changed, 5 insertions(+), 1 deletion(-)\n\ndiff --git a/io_uring/uring_cmd.c b/io_uring/uring_cmd.c\nindex ee7b49f47cb5..6d38df1a812d 100644\n--- a/io_uring/uring_cmd.c\n+++ b/io_uring/uring_cmd.c\n@@ -151,6 +151,7 @@ void __io_uring_cmd_done(struct io_uring_cmd *ioucmd, s32 ret, u64 res2,\n \t\t       unsigned issue_flags, bool is_cqe32)\n {\n \tstruct io_kiocb *req = cmd_to_io_kiocb(ioucmd);\n+\tu32 cflags = 0;\n \n \tif (WARN_ON_ONCE(req->flags & REQ_F_APOLL_MULTISHOT))\n \t\treturn;\n@@ -160,7 +161,10 @@ void __io_uring_cmd_done(struct io_uring_cmd *ioucmd, s32 ret, u64 res2,\n \tif (ret < 0)\n \t\treq_set_fail(req);\n \n-\tio_req_set_res(req, ret, 0);\n+\tif (req->flags & (REQ_F_BUFFER_SELECTED | REQ_F_BUFFER_RING))\n+\t\tcflags |= IORING_CQE_F_BUFFER |\n+\t\t\t(req->buf_index << IORING_CQE_BUFFER_SHIFT);\n+\tio_req_set_res(req, ret, cflags);\n \tif (is_cqe32) {\n \t\tif (req->ctx->flags & IORING_SETUP_CQE_MIXED)\n \t\t\treq->cqe.flags |= IORING_CQE_F_32;\n-- \n2.47.3",
          "reply_to": "",
          "message_date": "2026-02-17"
        }
      ],
      "analysis_source": "llm-per-reviewer"
    }
  }
}