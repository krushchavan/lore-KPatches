<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Review Comments: Re: [LSF/MM/BPF TOPIC] VFS idmappings support in NFS</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
                         "Helvetica Neue", Arial, sans-serif;
            background: #f5f5f5;
            color: #333;
            line-height: 1.6;
            padding: 20px;
            max-width: 900px;
            margin: 0 auto;
        }
        .home-link { margin-bottom: 12px; display: block; }
        .home-link a { color: #0366d6; text-decoration: none; font-size: 0.9em; }
        .home-link a:hover { text-decoration: underline; }

        h1 { font-size: 1.3em; margin-bottom: 2px; color: #1a1a1a; line-height: 1.3; }

        .lore-link { font-size: 0.85em; margin: 4px 0 6px; display: block; }
        .lore-link a { color: #0366d6; text-decoration: none; }
        .lore-link a:hover { text-decoration: underline; }

        .date-range {
            font-size: 0.8em;
            color: #888;
            margin-bottom: 16px;
        }
        .date-range a { color: #0366d6; text-decoration: none; }
        .date-range a:hover { text-decoration: underline; }

        /* thread-node scroll margin so the card isn't clipped at the top */
        .thread-node { scroll-margin-top: 8px; }

        /* ── Patch summary ──────────────────────────────────────────── */
        .patch-summary-block {
            background: #fff;
            border-radius: 8px;
            padding: 12px 16px;
            margin-bottom: 20px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.08);
            border-left: 3px solid #4a90d9;
        }
        .patch-summary-label {
            font-size: 0.72em;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 0.06em;
            color: #4a90d9;
            margin-bottom: 4px;
        }
        .patch-summary-text {
            font-size: 0.88em;
            color: #444;
            line-height: 1.55;
        }

        /* ── Thread tree ────────────────────────────────────────────── */
        .thread-tree {
            display: flex;
            flex-direction: column;
            gap: 6px;
        }

        /* Depth indentation via left border */
        .thread-node { position: relative; }
        .thread-children {
            margin-left: 20px;
            padding-left: 12px;
            border-left: 2px solid #e0e0e0;
            margin-top: 6px;
            display: flex;
            flex-direction: column;
            gap: 6px;
        }

        /* ── Review comment card ────────────────────────────────────── */
        .review-comment {
            background: #fff;
            border-radius: 6px;
            padding: 10px 14px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.08);
            font-size: 0.88em;
        }
        .review-comment-header {
            display: flex;
            flex-wrap: wrap;
            align-items: center;
            gap: 6px;
            margin-bottom: 5px;
        }
        .review-author {
            font-weight: 700;
            color: #1a1a1a;
            font-size: 0.95em;
        }

        /* Date chip — links back to the daily report */
        .date-chip {
            font-size: 0.75em;
            color: #777;
            background: #f0f0f0;
            border-radius: 10px;
            padding: 1px 7px;
            text-decoration: none;
            white-space: nowrap;
        }
        a.date-chip:hover { background: #e0e8f5; color: #0366d6; }

        .badge {
            display: inline-block;
            padding: 1px 8px;
            border-radius: 10px;
            font-size: 0.75em;
            font-weight: 600;
        }
        .inline-review-badge {
            display: inline-block;
            padding: 0 6px;
            border-radius: 8px;
            font-size: 0.78em;
            font-weight: 500;
            background: #e3f2fd;
            color: #1565c0;
        }
        .review-tag-badge {
            display: inline-block;
            padding: 0 6px;
            border-radius: 8px;
            font-size: 0.78em;
            font-weight: 500;
            background: #e8f5e9;
            color: #2e7d32;
        }
        .analysis-source-badge {
            display: inline-block;
            padding: 1px 7px;
            border-radius: 10px;
            font-size: 0.72em;
            font-weight: 600;
            border: 1px solid rgba(0,0,0,0.1);
        }

        .review-comment-text {
            color: #444;
            line-height: 1.55;
            margin-bottom: 4px;
        }
        .review-comment-signals {
            margin-top: 3px;
            font-size: 0.85em;
            color: #aaa;
            font-style: italic;
        }

        /* ── Collapsible raw body ───────────────────────────────────── */
        .raw-body-toggle {
            margin-top: 5px;
            font-size: 0.85em;
        }
        .raw-body-toggle summary {
            cursor: pointer;
            color: #888;
            padding: 2px 0;
            font-weight: 500;
            font-size: 0.9em;
            list-style: none;
        }
        .raw-body-toggle summary::-webkit-details-marker { display: none; }
        .raw-body-toggle summary::before { content: "▶ "; font-size: 0.7em; }
        .raw-body-toggle[open] summary::before { content: "▼ "; }
        .raw-body-toggle summary:hover { color: #555; }
        .raw-body-text {
            white-space: pre-wrap;
            font-size: 0.95em;
            background: #f8f8f8;
            padding: 8px 10px;
            border-radius: 4px;
            max-height: 360px;
            overflow-y: auto;
            margin-top: 4px;
            line-height: 1.5;
            color: #444;
            border: 1px solid #e8e8e8;
        }

        .no-reviews {
            color: #aaa;
            font-size: 0.85em;
            font-style: italic;
            padding: 8px 0;
        }

        footer {
            text-align: center;
            color: #bbb;
            font-size: 0.78em;
            margin-top: 36px;
            padding: 16px;
        }
    </style>
</head>
<body>
    <div class="home-link"><a href="../">&larr; Back to reports</a></div>
    <h1>Re: [LSF/MM/BPF TOPIC] VFS idmappings support in NFS</h1>
    <div class="lore-link"><a href="https://lore.kernel.org/all/a0eab8f07873e38fa4c5d958de6b75761d690874.camel@kernel.org/" target="_blank">View on lore.kernel.org &rarr;</a></div>
    <div class="date-range">Active on: <a href="#2026-02-18">2026-02-18</a></div>
    
    <div class="thread-tree">
<div class="thread-node depth-0" id="2026-02-18">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Jeff Layton</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-18">2026-02-18</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Jeff Layton requested clarification and understanding of the use-case for VFS idmappings in NFS, specifically how they would be used to remap uid/gid values in a real environment.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">On Wed, 2026-02-18 at 13:44 +0100, Alexander Mikhalitsyn wrote:
&gt; Dear friends,
&gt; 
&gt; I would like to propose &quot;VFS idmappings support in NFS&quot; as a topic for discussion at the LSF/MM/BPF Summit.
&gt; 
&gt; Previously, I worked on VFS idmap support for FUSE/virtiofs [2] and cephfs [1] with support/guidance
&gt; from Christian.
&gt; 
&gt; This experience with Cephfs &amp; FUSE has shown that VFS idmap semantics, while being very elegant and
&gt; intuitive for local filesystems, can be quite challenging to combine with network/network-like (e.g. FUSE)
&gt; FSes. In case of Cephfs we had to modify its protocol (!) (see [2]) as a part of our agreement with
&gt; ceph folks about the right way to support idmaps.
&gt; 
&gt; One obstacle here was that cephfs has some features that are not very Linux-wayish, I would say.
&gt; In particular, system administrator can configure path-based UID/GID restrictions on a *server*-side (Ceph MDS).
&gt; Basically, you can say &quot;I expect UID 1000 and GID 2000 for all files under /stuff directory&quot;.
&gt; The problem here is that these UID/GIDs are taken from a syscall-caller&#x27;s creds (not from (struct file *)-&gt;f_cred)
&gt; which makes cephfs FDs not very transferable through unix sockets. [3]
&gt; 
&gt; These path-based UID/GID restrictions mean that server expects client to send UID/GID with every single request,
&gt; not only for those OPs where UID/GID needs to be written to the disk (mknod, mkdir, symlink, etc).
&gt; VFS idmaps API is designed to prevent filesystems developers from making a mistakes when supporting FS_ALLOW_IDMAP.
&gt; For example, (struct mnt_idmap *) is not passed to every single i_op, but instead to only those where it can be
&gt; used legitimately. Particularly, readlink/listxattr or rmdir are not expected to use idmapping information anyhow.
&gt; 
&gt; We&#x27;ve seen very similar challenges with FUSE. Not a long time ago on Linux Containers project forum, there
&gt; was a discussion about mergerfs (a popular FUSE-based filesystem) &amp; VFS idmaps [5]. And I see that this problem
&gt; of &quot;caller UID/GID are needed everywhere&quot; still blocks VFS idmaps adoption in some usecases.
&gt; Antonio Musumeci (mergerfs maintainer) claimed that in many cases filesystems behind mergerfs may not be fully
&gt; POSIX and basically, when mergerfs does IO on the underlying FSes it needs to do UID/GID switch to caller&#x27;s UID/GID
&gt; (taken from FUSE request header).
&gt; 
&gt; We don&#x27;t expect NFS to be any simpler :-) I would say that supporting NFS is a final boss. It would be great
&gt; to have a deep technical discussion with VFS/FSes maintainers and developers about all these challenges and
&gt; make some conclusions and identify a right direction/approach to these problems. From my side, I&#x27;m going
&gt; to get more familiar with high-level part of NFS (or even make PoC if time permits), identify challenges,
&gt; summarize everything and prepare some slides to navigate/plan discussion.
&gt; 
&gt; [1] cephfs https://lore.kernel.org/linux-fsdevel/20230807132626.182101-1-aleksandr.mikhalitsyn@canonical.com
&gt; [2] cephfs protocol changes https://github.com/ceph/ceph/pull/52575
&gt; [3] cephfs &amp; f_cred https://lore.kernel.org/lkml/CAEivzxeZ6fDgYMnjk21qXYz13tHqZa8rP-cZ2jdxkY0eX+dOjw@mail.gmail.com/
&gt; [4] fuse/virtiofs https://lore.kernel.org/linux-fsdevel/20240903151626.264609-1-aleksandr.mikhalitsyn@canonical.com/
&gt; [5]
&gt; mergerfshttps://discuss.linuxcontainers.org/t/is-it-the-case-that-you-cannot-use-shift-true-for-disk-devices-where-the-source-is-a-mergerfs-mount-is-there-a-workaround/25336/11?u=amikhalitsyn
&gt; 
&gt; Kind regards,
&gt; Alexander Mikhalitsyn @ futurfusion.io


IIUC, people mostly use vfs-layer idmappings because they want to remap
the uid/gid values of files that get stored on the backing store (disk,
ceph MDS, or whatever).

I&#x27;ve never used idmappings myself much in practice. Could you lay out
an example of how you would use them with NFS in a real environment so
I understand the problem better? I&#x27;d start by assuming a simple setup
with AUTH_SYS and no NFSv4 idmapping involved, since that case should
be fairly straightforward.

Mixing in AUTH_GSS and real idmapping will be where things get harder,
so let&#x27;s not worry about those cases for now.
-- 
Jeff Layton &lt;jlayton@kernel.org&gt;


---

On Wed, 2026-02-18 at 09:37 -0500, Trond Myklebust wrote:
&gt; On Wed, 2026-02-18 at 08:49 -0500, Jeff Layton wrote:
&gt; &gt; On Wed, 2026-02-18 at 13:44 +0100, Alexander Mikhalitsyn wrote:
&gt; &gt; &gt; Dear friends,
&gt; &gt; &gt; 
&gt; &gt; &gt; I would like to propose &quot;VFS idmappings support in NFS&quot; as a topic
&gt; &gt; &gt; for discussion at the LSF/MM/BPF Summit.
&gt; &gt; &gt; 
&gt; &gt; &gt; Previously, I worked on VFS idmap support for FUSE/virtiofs [2] and
&gt; &gt; &gt; cephfs [1] with support/guidance
&gt; &gt; &gt; from Christian.
&gt; &gt; &gt; 
&gt; &gt; &gt; This experience with Cephfs &amp; FUSE has shown that VFS idmap
&gt; &gt; &gt; semantics, while being very elegant and
&gt; &gt; &gt; intuitive for local filesystems, can be quite challenging to
&gt; &gt; &gt; combine with network/network-like (e.g. FUSE)
&gt; &gt; &gt; FSes. In case of Cephfs we had to modify its protocol (!) (see [2])
&gt; &gt; &gt; as a part of our agreement with
&gt; &gt; &gt; ceph folks about the right way to support idmaps.
&gt; &gt; &gt; 
&gt; &gt; &gt; One obstacle here was that cephfs has some features that are not
&gt; &gt; &gt; very Linux-wayish, I would say.
&gt; &gt; &gt; In particular, system administrator can configure path-based
&gt; &gt; &gt; UID/GID restrictions on a *server*-side (Ceph MDS).
&gt; &gt; &gt; Basically, you can say &quot;I expect UID 1000 and GID 2000 for all
&gt; &gt; &gt; files under /stuff directory&quot;.
&gt; &gt; &gt; The problem here is that these UID/GIDs are taken from a syscall-
&gt; &gt; &gt; caller&#x27;s creds (not from (struct file *)-&gt;f_cred)
&gt; &gt; &gt; which makes cephfs FDs not very transferable through unix sockets.
&gt; &gt; &gt; [3]
&gt; &gt; &gt; 
&gt; &gt; &gt; These path-based UID/GID restrictions mean that server expects
&gt; &gt; &gt; client to send UID/GID with every single request,
&gt; &gt; &gt; not only for those OPs where UID/GID needs to be written to the
&gt; &gt; &gt; disk (mknod, mkdir, symlink, etc).
&gt; &gt; &gt; VFS idmaps API is designed to prevent filesystems developers from
&gt; &gt; &gt; making a mistakes when supporting FS_ALLOW_IDMAP.
&gt; &gt; &gt; For example, (struct mnt_idmap *) is not passed to every single
&gt; &gt; &gt; i_op, but instead to only those where it can be
&gt; &gt; &gt; used legitimately. Particularly, readlink/listxattr or rmdir are
&gt; &gt; &gt; not expected to use idmapping information anyhow.
&gt; &gt; &gt; 
&gt; &gt; &gt; We&#x27;ve seen very similar challenges with FUSE. Not a long time ago
&gt; &gt; &gt; on Linux Containers project forum, there
&gt; &gt; &gt; was a discussion about mergerfs (a popular FUSE-based filesystem) &amp;
&gt; &gt; &gt; VFS idmaps [5]. And I see that this problem
&gt; &gt; &gt; of &quot;caller UID/GID are needed everywhere&quot; still blocks VFS idmaps
&gt; &gt; &gt; adoption in some usecases.
&gt; &gt; &gt; Antonio Musumeci (mergerfs maintainer) claimed that in many cases
&gt; &gt; &gt; filesystems behind mergerfs may not be fully
&gt; &gt; &gt; POSIX and basically, when mergerfs does IO on the underlying FSes
&gt; &gt; &gt; it needs to do UID/GID switch to caller&#x27;s UID/GID
&gt; &gt; &gt; (taken from FUSE request header).
&gt; &gt; &gt; 
&gt; &gt; &gt; We don&#x27;t expect NFS to be any simpler :-) I would say that
&gt; &gt; &gt; supporting NFS is a final boss. It would be great
&gt; &gt; &gt; to have a deep technical discussion with VFS/FSes maintainers and
&gt; &gt; &gt; developers about all these challenges and
&gt; &gt; &gt; make some conclusions and identify a right direction/approach to
&gt; &gt; &gt; these problems. From my side, I&#x27;m going
&gt; &gt; &gt; to get more familiar with high-level part of NFS (or even make PoC
&gt; &gt; &gt; if time permits), identify challenges,
&gt; &gt; &gt; summarize everything and prepare some slides to navigate/plan
&gt; &gt; &gt; discussion.
&gt; &gt; &gt; 
&gt; &gt; &gt; [1] cephfs
&gt; &gt; &gt; https://lore.kernel.org/linux-fsdevel/20230807132626.182101-1-aleksandr.mikhalitsyn@canonical.com
&gt; &gt; &gt; [2] cephfs protocol changes https://github.com/ceph/ceph/pull/52575
&gt; &gt; &gt; [3] cephfs &amp; f_cred
&gt; &gt; &gt; https://lore.kernel.org/lkml/CAEivzxeZ6fDgYMnjk21qXYz13tHqZa8rP-cZ2jdxkY0eX+dOjw@mail.gmail.com/
&gt; &gt; &gt; [4] fuse/virtiofs
&gt; &gt; &gt; https://lore.kernel.org/linux-fsdevel/20240903151626.264609-1-aleksandr.mikhalitsyn@canonical.com/
&gt; &gt; &gt; [5]
&gt; &gt; &gt; mergerfs
&gt; &gt; &gt; https://discuss.linuxcontainers.org/t/is-it-the-case-that-you-
&gt; &gt; &gt; cannot-use-shift-true-for-disk-devices-where-the-source-is-a-
&gt; &gt; &gt; mergerfs-mount-is-there-a-workaround/25336/11?u=amikhalitsyn
&gt; &gt; &gt; 
&gt; &gt; &gt; Kind regards,
&gt; &gt; &gt; Alexander Mikhalitsyn @ futurfusion.io
&gt; &gt; 
&gt; &gt; 
&gt; &gt; IIUC, people mostly use vfs-layer idmappings because they want to
&gt; &gt; remap
&gt; &gt; the uid/gid values of files that get stored on the backing store
&gt; &gt; (disk,
&gt; &gt; ceph MDS, or whatever).
&gt; &gt; 
&gt; &gt; I&#x27;ve never used idmappings myself much in practice. Could you lay out
&gt; &gt; an example of how you would use them with NFS in a real environment
&gt; &gt; so
&gt; &gt; I understand the problem better? I&#x27;d start by assuming a simple setup
&gt; &gt; with AUTH_SYS and no NFSv4 idmapping involved, since that case should
&gt; &gt; be fairly straightforward.
&gt; &gt; 
&gt; &gt; Mixing in AUTH_GSS and real idmapping will be where things get
&gt; &gt; harder,
&gt; &gt; so let&#x27;s not worry about those cases for now.
&gt; 
&gt; I think you do need to worry about those cases. As the NFS and RPC
&gt; protocols stand today, strong authentication will defeat any client
&gt; side idmapping scheme, because the server can&#x27;t know what uids or gids
&gt; the client is using on its end; it just knows about the account that
&gt; was used to authenticate.
&gt; 

Oh, we absolutely need to worry about them, but this is a difficult
topic to get our arms around. We can potentially have several layers
that are doing idmapping, so I want to understand a simple use-case
first. Once that&#x27;s clear I plan to start throwing in monkey wrenches.

&gt; I think if you do want to implement something generic, you&#x27;re going to
&gt; have to consider how the client and server can exchange (and store) the
&gt; information needed to allow the client to perform the mapping of file
&gt; owners/group owners on its end. The client would presumably also need
&gt; to be in charge of enforcing permissions for such mappings.
&gt; It would be a very different security model than the one used by NFS
&gt; today, and almost certainly require protocol extensions.

That may be, but I still don&#x27;t fully understand the use-case here.
Maybe they&#x27;d be content with just shifting UIDs at a higher level
without changing the protocol? Without understanding how they intend to
use this, it&#x27;s hard to know what&#x27;s needed.

-- 
Jeff Layton &lt;jlayton@kernel.org&gt;


---

On Wed, 2026-02-18 at 15:36 +0100, Alexander Mikhalitsyn wrote:
&gt; Am Mi., 18. Feb. 2026 um 14:49 Uhr schrieb Jeff Layton &lt;jlayton@kernel.org&gt;:
&gt; &gt; 
&gt; &gt; On Wed, 2026-02-18 at 13:44 +0100, Alexander Mikhalitsyn wrote:
&gt; &gt; &gt; Dear friends,
&gt; &gt; &gt; 
&gt; &gt; &gt; I would like to propose &quot;VFS idmappings support in NFS&quot; as a topic for discussion at the LSF/MM/BPF Summit.
&gt; &gt; &gt; 
&gt; &gt; &gt; Previously, I worked on VFS idmap support for FUSE/virtiofs [2] and cephfs [1] with support/guidance
&gt; &gt; &gt; from Christian.
&gt; &gt; &gt; 
&gt; &gt; &gt; This experience with Cephfs &amp; FUSE has shown that VFS idmap semantics, while being very elegant and
&gt; &gt; &gt; intuitive for local filesystems, can be quite challenging to combine with network/network-like (e.g. FUSE)
&gt; &gt; &gt; FSes. In case of Cephfs we had to modify its protocol (!) (see [2]) as a part of our agreement with
&gt; &gt; &gt; ceph folks about the right way to support idmaps.
&gt; &gt; &gt; 
&gt; &gt; &gt; One obstacle here was that cephfs has some features that are not very Linux-wayish, I would say.
&gt; &gt; &gt; In particular, system administrator can configure path-based UID/GID restrictions on a *server*-side (Ceph MDS).
&gt; &gt; &gt; Basically, you can say &quot;I expect UID 1000 and GID 2000 for all files under /stuff directory&quot;.
&gt; &gt; &gt; The problem here is that these UID/GIDs are taken from a syscall-caller&#x27;s creds (not from (struct file *)-&gt;f_cred)
&gt; &gt; &gt; which makes cephfs FDs not very transferable through unix sockets. [3]
&gt; &gt; &gt; 
&gt; &gt; &gt; These path-based UID/GID restrictions mean that server expects client to send UID/GID with every single request,
&gt; &gt; &gt; not only for those OPs where UID/GID needs to be written to the disk (mknod, mkdir, symlink, etc).
&gt; &gt; &gt; VFS idmaps API is designed to prevent filesystems developers from making a mistakes when supporting FS_ALLOW_IDMAP.
&gt; &gt; &gt; For example, (struct mnt_idmap *) is not passed to every single i_op, but instead to only those where it can be
&gt; &gt; &gt; used legitimately. Particularly, readlink/listxattr or rmdir are not expected to use idmapping information anyhow.
&gt; &gt; &gt; 
&gt; &gt; &gt; We&#x27;ve seen very similar challenges with FUSE. Not a long time ago on Linux Containers project forum, there
&gt; &gt; &gt; was a discussion about mergerfs (a popular FUSE-based filesystem) &amp; VFS idmaps [5]. And I see that this problem
&gt; &gt; &gt; of &quot;caller UID/GID are needed everywhere&quot; still blocks VFS idmaps adoption in some usecases.
&gt; &gt; &gt; Antonio Musumeci (mergerfs maintainer) claimed that in many cases filesystems behind mergerfs may not be fully
&gt; &gt; &gt; POSIX and basically, when mergerfs does IO on the underlying FSes it needs to do UID/GID switch to caller&#x27;s UID/GID
&gt; &gt; &gt; (taken from FUSE request header).
&gt; &gt; &gt; 
&gt; &gt; &gt; We don&#x27;t expect NFS to be any simpler :-) I would say that supporting NFS is a final boss. It would be great
&gt; &gt; &gt; to have a deep technical discussion with VFS/FSes maintainers and developers about all these challenges and
&gt; &gt; &gt; make some conclusions and identify a right direction/approach to these problems. From my side, I&#x27;m going
&gt; &gt; &gt; to get more familiar with high-level part of NFS (or even make PoC if time permits), identify challenges,
&gt; &gt; &gt; summarize everything and prepare some slides to navigate/plan discussion.
&gt; &gt; &gt; 
&gt; &gt; &gt; [1] cephfs https://lore.kernel.org/linux-fsdevel/20230807132626.182101-1-aleksandr.mikhalitsyn@canonical.com
&gt; &gt; &gt; [2] cephfs protocol changes https://github.com/ceph/ceph/pull/52575
&gt; &gt; &gt; [3] cephfs &amp; f_cred https://lore.kernel.org/lkml/CAEivzxeZ6fDgYMnjk21qXYz13tHqZa8rP-cZ2jdxkY0eX+dOjw@mail.gmail.com/
&gt; &gt; &gt; [4] fuse/virtiofs https://lore.kernel.org/linux-fsdevel/20240903151626.264609-1-aleksandr.mikhalitsyn@canonical.com/
&gt; &gt; &gt; [5]
&gt; &gt; &gt; mergerfshttps://discuss.linuxcontainers.org/t/is-it-the-case-that-you-cannot-use-shift-true-for-disk-devices-where-the-source-is-a-mergerfs-mount-is-there-a-workaround/25336/11?u=amikhalitsyn
&gt; &gt; &gt; 
&gt; &gt; &gt; Kind regards,
&gt; &gt; &gt; Alexander Mikhalitsyn @ futurfusion.io
&gt; &gt; 
&gt; 
&gt; Hi Jeff,
&gt; 
&gt; thanks for such a fast reply! ;)
&gt; 
&gt; &gt; 
&gt; &gt; IIUC, people mostly use vfs-layer idmappings because they want to remap
&gt; &gt; the uid/gid values of files that get stored on the backing store (disk,
&gt; &gt; ceph MDS, or whatever).
&gt; 
&gt; yes, precisely.
&gt; 
&gt; &gt; 
&gt; &gt; I&#x27;ve never used idmappings myself much in practice. Could you lay out
&gt; &gt; an example of how you would use them with NFS in a real environment so
&gt; &gt; I understand the problem better? I&#x27;d start by assuming a simple setup
&gt; &gt; with AUTH_SYS and no NFSv4 idmapping involved, since that case should
&gt; &gt; be fairly straightforward.
&gt; 
&gt; For me, from the point of LXC/Incus project, idmapped mounts are used as
&gt; a way to &quot;delegate&quot; filesystems (or subtrees) to the containers:
&gt; 1. We, of course, assume that container enables user namespaces and
&gt; user can&#x27;t mount a filesystem
&gt; inside because it has no FS_USERNS_MOUNT flag set (like in case of Cephfs, NFS,
&gt; CIFS and many others).
&gt; 2. At the same time host&#x27;s system administrator wants to avoid
&gt; remapping between container&#x27;s user ns and
&gt; sb-&gt;s_user_ns (which is init_user_ns for those filesystems). [
&gt; motivation here is that in many
&gt; cases you may want to have the same subtree to be shared with other
&gt; containers and even host users too and
&gt; you want UIDs to be &quot;compatible&quot;, i.e UID 1000 in one container and
&gt; UID 1000 in another container should
&gt; land as UID 1000 on the filesystem&#x27;s inode ]
&gt; 
&gt; For this usecase, when we bind-mount filesystem to container, we apply
&gt; VFS idmap equal to container&#x27;s
&gt; user namespace. This makes a behavior I described.
&gt; 

Ok: so you have a process running in a userns as UID 2000 and you want
to use vfs layer idmapping so that when you create a file as that user
that it ends up being owned by UID 1000. Is that basically correct?

Typically, the RPC credentials used in an OPEN or CREATE call is what
determines its ownership (at least until a SETATTR comes in). With
AUTH_SYS, the credential is just a uid and set of gids.

So in this case, it sounds like you would need just do that conversion
(maybe at the RPC client layer?) when issuing an RPC. You don&#x27;t really
need a protocol extension for that case.

As Trond points out though, AUTH_GSS and NFSv4 idmapping will make this
more complex. Once you&#x27;re using kerberos credentials for
authentication, you don&#x27;t have much control over what the UIDs and GIDs
will be on newly-created files, but is that really a problem? As long
as all of the clients have a consistent view, I wouldn&#x27;t think so.

&gt; But this is just one use case. I&#x27;m pretty sure there are some more
&gt; around here :)
&gt; I know that folks from Preferred Networks (preferred.jp) are also
&gt; interested in VFS idmap support in NFS,
&gt; probably they can share some ideas/use cases too.
&gt; 
&gt; 

Yes, we don&#x27;t want to focus too much on a single use-case, but I find
it helpful to focus on a single simple problem first.
-- 
Jeff Layton &lt;jlayton@kernel.org&gt;
</pre>
</details>
<div class="review-comment-signals">Signals: requested clarification, wanted to understand the problem better</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Alexander Mikhalitsyn (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-18">2026-02-18</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The reviewer discussed the challenges of implementing VFS idmappings support in NFS, citing similar issues with FUSE and Cephfs. They proposed a high-level approach to avoid modifying the NFS protocol and suggested starting with a simple case before tackling more complex scenarios.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Am Mi., 18. Feb. 2026 um 14:49 Uhr schrieb Jeff Layton &lt;jlayton@kernel.org&gt;:
&gt;
&gt; On Wed, 2026-02-18 at 13:44 +0100, Alexander Mikhalitsyn wrote:
&gt; &gt; Dear friends,
&gt; &gt;
&gt; &gt; I would like to propose &quot;VFS idmappings support in NFS&quot; as a topic for discussion at the LSF/MM/BPF Summit.
&gt; &gt;
&gt; &gt; Previously, I worked on VFS idmap support for FUSE/virtiofs [2] and cephfs [1] with support/guidance
&gt; &gt; from Christian.
&gt; &gt;
&gt; &gt; This experience with Cephfs &amp; FUSE has shown that VFS idmap semantics, while being very elegant and
&gt; &gt; intuitive for local filesystems, can be quite challenging to combine with network/network-like (e.g. FUSE)
&gt; &gt; FSes. In case of Cephfs we had to modify its protocol (!) (see [2]) as a part of our agreement with
&gt; &gt; ceph folks about the right way to support idmaps.
&gt; &gt;
&gt; &gt; One obstacle here was that cephfs has some features that are not very Linux-wayish, I would say.
&gt; &gt; In particular, system administrator can configure path-based UID/GID restrictions on a *server*-side (Ceph MDS).
&gt; &gt; Basically, you can say &quot;I expect UID 1000 and GID 2000 for all files under /stuff directory&quot;.
&gt; &gt; The problem here is that these UID/GIDs are taken from a syscall-caller&#x27;s creds (not from (struct file *)-&gt;f_cred)
&gt; &gt; which makes cephfs FDs not very transferable through unix sockets. [3]
&gt; &gt;
&gt; &gt; These path-based UID/GID restrictions mean that server expects client to send UID/GID with every single request,
&gt; &gt; not only for those OPs where UID/GID needs to be written to the disk (mknod, mkdir, symlink, etc).
&gt; &gt; VFS idmaps API is designed to prevent filesystems developers from making a mistakes when supporting FS_ALLOW_IDMAP.
&gt; &gt; For example, (struct mnt_idmap *) is not passed to every single i_op, but instead to only those where it can be
&gt; &gt; used legitimately. Particularly, readlink/listxattr or rmdir are not expected to use idmapping information anyhow.
&gt; &gt;
&gt; &gt; We&#x27;ve seen very similar challenges with FUSE. Not a long time ago on Linux Containers project forum, there
&gt; &gt; was a discussion about mergerfs (a popular FUSE-based filesystem) &amp; VFS idmaps [5]. And I see that this problem
&gt; &gt; of &quot;caller UID/GID are needed everywhere&quot; still blocks VFS idmaps adoption in some usecases.
&gt; &gt; Antonio Musumeci (mergerfs maintainer) claimed that in many cases filesystems behind mergerfs may not be fully
&gt; &gt; POSIX and basically, when mergerfs does IO on the underlying FSes it needs to do UID/GID switch to caller&#x27;s UID/GID
&gt; &gt; (taken from FUSE request header).
&gt; &gt;
&gt; &gt; We don&#x27;t expect NFS to be any simpler :-) I would say that supporting NFS is a final boss. It would be great
&gt; &gt; to have a deep technical discussion with VFS/FSes maintainers and developers about all these challenges and
&gt; &gt; make some conclusions and identify a right direction/approach to these problems. From my side, I&#x27;m going
&gt; &gt; to get more familiar with high-level part of NFS (or even make PoC if time permits), identify challenges,
&gt; &gt; summarize everything and prepare some slides to navigate/plan discussion.
&gt; &gt;
&gt; &gt; [1] cephfs https://lore.kernel.org/linux-fsdevel/20230807132626.182101-1-aleksandr.mikhalitsyn@canonical.com
&gt; &gt; [2] cephfs protocol changes https://github.com/ceph/ceph/pull/52575
&gt; &gt; [3] cephfs &amp; f_cred https://lore.kernel.org/lkml/CAEivzxeZ6fDgYMnjk21qXYz13tHqZa8rP-cZ2jdxkY0eX+dOjw@mail.gmail.com/
&gt; &gt; [4] fuse/virtiofs https://lore.kernel.org/linux-fsdevel/20240903151626.264609-1-aleksandr.mikhalitsyn@canonical.com/
&gt; &gt; [5]
&gt; &gt; mergerfshttps://discuss.linuxcontainers.org/t/is-it-the-case-that-you-cannot-use-shift-true-for-disk-devices-where-the-source-is-a-mergerfs-mount-is-there-a-workaround/25336/11?u=amikhalitsyn
&gt; &gt;
&gt; &gt; Kind regards,
&gt; &gt; Alexander Mikhalitsyn @ futurfusion.io
&gt;

Hi Jeff,

thanks for such a fast reply! ;)

&gt;
&gt; IIUC, people mostly use vfs-layer idmappings because they want to remap
&gt; the uid/gid values of files that get stored on the backing store (disk,
&gt; ceph MDS, or whatever).

yes, precisely.

&gt;
&gt; I&#x27;ve never used idmappings myself much in practice. Could you lay out
&gt; an example of how you would use them with NFS in a real environment so
&gt; I understand the problem better? I&#x27;d start by assuming a simple setup
&gt; with AUTH_SYS and no NFSv4 idmapping involved, since that case should
&gt; be fairly straightforward.

For me, from the point of LXC/Incus project, idmapped mounts are used as
a way to &quot;delegate&quot; filesystems (or subtrees) to the containers:
1. We, of course, assume that container enables user namespaces and
user can&#x27;t mount a filesystem
inside because it has no FS_USERNS_MOUNT flag set (like in case of Cephfs, NFS,
CIFS and many others).
2. At the same time host&#x27;s system administrator wants to avoid
remapping between container&#x27;s user ns and
sb-&gt;s_user_ns (which is init_user_ns for those filesystems). [
motivation here is that in many
cases you may want to have the same subtree to be shared with other
containers and even host users too and
you want UIDs to be &quot;compatible&quot;, i.e UID 1000 in one container and
UID 1000 in another container should
land as UID 1000 on the filesystem&#x27;s inode ]

For this usecase, when we bind-mount filesystem to container, we apply
VFS idmap equal to container&#x27;s
user namespace. This makes a behavior I described.

But this is just one use case. I&#x27;m pretty sure there are some more
around here :)
I know that folks from Preferred Networks (preferred.jp) are also
interested in VFS idmap support in NFS,
probably they can share some ideas/use cases too.

&gt;
&gt; Mixing in AUTH_GSS and real idmapping will be where things get harder,
&gt; so let&#x27;s not worry about those cases for now.
&gt; --
&gt; Jeff Layton &lt;jlayton@kernel.org&gt;

Kind regards,
Alex


---

Am Mi., 18. Feb. 2026 um 16:08 Uhr schrieb Jeff Layton &lt;jlayton@kernel.org&gt;:
&gt;
&gt; On Wed, 2026-02-18 at 09:37 -0500, Trond Myklebust wrote:
&gt; &gt; On Wed, 2026-02-18 at 08:49 -0500, Jeff Layton wrote:
&gt; &gt; &gt; On Wed, 2026-02-18 at 13:44 +0100, Alexander Mikhalitsyn wrote:
&gt; &gt; &gt; &gt; Dear friends,
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; I would like to propose &quot;VFS idmappings support in NFS&quot; as a topic
&gt; &gt; &gt; &gt; for discussion at the LSF/MM/BPF Summit.
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; Previously, I worked on VFS idmap support for FUSE/virtiofs [2] and
&gt; &gt; &gt; &gt; cephfs [1] with support/guidance
&gt; &gt; &gt; &gt; from Christian.
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; This experience with Cephfs &amp; FUSE has shown that VFS idmap
&gt; &gt; &gt; &gt; semantics, while being very elegant and
&gt; &gt; &gt; &gt; intuitive for local filesystems, can be quite challenging to
&gt; &gt; &gt; &gt; combine with network/network-like (e.g. FUSE)
&gt; &gt; &gt; &gt; FSes. In case of Cephfs we had to modify its protocol (!) (see [2])
&gt; &gt; &gt; &gt; as a part of our agreement with
&gt; &gt; &gt; &gt; ceph folks about the right way to support idmaps.
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; One obstacle here was that cephfs has some features that are not
&gt; &gt; &gt; &gt; very Linux-wayish, I would say.
&gt; &gt; &gt; &gt; In particular, system administrator can configure path-based
&gt; &gt; &gt; &gt; UID/GID restrictions on a *server*-side (Ceph MDS).
&gt; &gt; &gt; &gt; Basically, you can say &quot;I expect UID 1000 and GID 2000 for all
&gt; &gt; &gt; &gt; files under /stuff directory&quot;.
&gt; &gt; &gt; &gt; The problem here is that these UID/GIDs are taken from a syscall-
&gt; &gt; &gt; &gt; caller&#x27;s creds (not from (struct file *)-&gt;f_cred)
&gt; &gt; &gt; &gt; which makes cephfs FDs not very transferable through unix sockets.
&gt; &gt; &gt; &gt; [3]
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; These path-based UID/GID restrictions mean that server expects
&gt; &gt; &gt; &gt; client to send UID/GID with every single request,
&gt; &gt; &gt; &gt; not only for those OPs where UID/GID needs to be written to the
&gt; &gt; &gt; &gt; disk (mknod, mkdir, symlink, etc).
&gt; &gt; &gt; &gt; VFS idmaps API is designed to prevent filesystems developers from
&gt; &gt; &gt; &gt; making a mistakes when supporting FS_ALLOW_IDMAP.
&gt; &gt; &gt; &gt; For example, (struct mnt_idmap *) is not passed to every single
&gt; &gt; &gt; &gt; i_op, but instead to only those where it can be
&gt; &gt; &gt; &gt; used legitimately. Particularly, readlink/listxattr or rmdir are
&gt; &gt; &gt; &gt; not expected to use idmapping information anyhow.
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; We&#x27;ve seen very similar challenges with FUSE. Not a long time ago
&gt; &gt; &gt; &gt; on Linux Containers project forum, there
&gt; &gt; &gt; &gt; was a discussion about mergerfs (a popular FUSE-based filesystem) &amp;
&gt; &gt; &gt; &gt; VFS idmaps [5]. And I see that this problem
&gt; &gt; &gt; &gt; of &quot;caller UID/GID are needed everywhere&quot; still blocks VFS idmaps
&gt; &gt; &gt; &gt; adoption in some usecases.
&gt; &gt; &gt; &gt; Antonio Musumeci (mergerfs maintainer) claimed that in many cases
&gt; &gt; &gt; &gt; filesystems behind mergerfs may not be fully
&gt; &gt; &gt; &gt; POSIX and basically, when mergerfs does IO on the underlying FSes
&gt; &gt; &gt; &gt; it needs to do UID/GID switch to caller&#x27;s UID/GID
&gt; &gt; &gt; &gt; (taken from FUSE request header).
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; We don&#x27;t expect NFS to be any simpler :-) I would say that
&gt; &gt; &gt; &gt; supporting NFS is a final boss. It would be great
&gt; &gt; &gt; &gt; to have a deep technical discussion with VFS/FSes maintainers and
&gt; &gt; &gt; &gt; developers about all these challenges and
&gt; &gt; &gt; &gt; make some conclusions and identify a right direction/approach to
&gt; &gt; &gt; &gt; these problems. From my side, I&#x27;m going
&gt; &gt; &gt; &gt; to get more familiar with high-level part of NFS (or even make PoC
&gt; &gt; &gt; &gt; if time permits), identify challenges,
&gt; &gt; &gt; &gt; summarize everything and prepare some slides to navigate/plan
&gt; &gt; &gt; &gt; discussion.
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; [1] cephfs
&gt; &gt; &gt; &gt; https://lore.kernel.org/linux-fsdevel/20230807132626.182101-1-aleksandr.mikhalitsyn@canonical.com
&gt; &gt; &gt; &gt; [2] cephfs protocol changes https://github.com/ceph/ceph/pull/52575
&gt; &gt; &gt; &gt; [3] cephfs &amp; f_cred
&gt; &gt; &gt; &gt; https://lore.kernel.org/lkml/CAEivzxeZ6fDgYMnjk21qXYz13tHqZa8rP-cZ2jdxkY0eX+dOjw@mail.gmail.com/
&gt; &gt; &gt; &gt; [4] fuse/virtiofs
&gt; &gt; &gt; &gt; https://lore.kernel.org/linux-fsdevel/20240903151626.264609-1-aleksandr.mikhalitsyn@canonical.com/
&gt; &gt; &gt; &gt; [5]
&gt; &gt; &gt; &gt; mergerfs
&gt; &gt; &gt; &gt; https://discuss.linuxcontainers.org/t/is-it-the-case-that-you-
&gt; &gt; &gt; &gt; cannot-use-shift-true-for-disk-devices-where-the-source-is-a-
&gt; &gt; &gt; &gt; mergerfs-mount-is-there-a-workaround/25336/11?u=amikhalitsyn
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; Kind regards,
&gt; &gt; &gt; &gt; Alexander Mikhalitsyn @ futurfusion.io
&gt; &gt; &gt;
&gt; &gt; &gt;
&gt; &gt; &gt; IIUC, people mostly use vfs-layer idmappings because they want to
&gt; &gt; &gt; remap
&gt; &gt; &gt; the uid/gid values of files that get stored on the backing store
&gt; &gt; &gt; (disk,
&gt; &gt; &gt; ceph MDS, or whatever).
&gt; &gt; &gt;
&gt; &gt; &gt; I&#x27;ve never used idmappings myself much in practice. Could you lay out
&gt; &gt; &gt; an example of how you would use them with NFS in a real environment
&gt; &gt; &gt; so
&gt; &gt; &gt; I understand the problem better? I&#x27;d start by assuming a simple setup
&gt; &gt; &gt; with AUTH_SYS and no NFSv4 idmapping involved, since that case should
&gt; &gt; &gt; be fairly straightforward.
&gt; &gt; &gt;
&gt; &gt; &gt; Mixing in AUTH_GSS and real idmapping will be where things get
&gt; &gt; &gt; harder,
&gt; &gt; &gt; so let&#x27;s not worry about those cases for now.
&gt; &gt;
&gt; &gt; I think you do need to worry about those cases. As the NFS and RPC
&gt; &gt; protocols stand today, strong authentication will defeat any client
&gt; &gt; side idmapping scheme, because the server can&#x27;t know what uids or gids
&gt; &gt; the client is using on its end; it just knows about the account that
&gt; &gt; was used to authenticate.
&gt; &gt;
&gt;
&gt; Oh, we absolutely need to worry about them, but this is a difficult
&gt; topic to get our arms around. We can potentially have several layers
&gt; that are doing idmapping, so I want to understand a simple use-case
&gt; first. Once that&#x27;s clear I plan to start throwing in monkey wrenches.
&gt;
&gt; &gt; I think if you do want to implement something generic, you&#x27;re going to
&gt; &gt; have to consider how the client and server can exchange (and store) the
&gt; &gt; information needed to allow the client to perform the mapping of file
&gt; &gt; owners/group owners on its end. The client would presumably also need
&gt; &gt; to be in charge of enforcing permissions for such mappings.
&gt; &gt; It would be a very different security model than the one used by NFS
&gt; &gt; today, and almost certainly require protocol extensions.
&gt;
&gt; That may be, but I still don&#x27;t fully understand the use-case here.

Please, let me know if my earlier reply doesn&#x27;t clarify LXC/Incus use case.
I can prepare a more detailed explanation with command line/configuration
examples with pleasure.

&gt; Maybe they&#x27;d be content with just shifting UIDs at a higher level
&gt; without changing the protocol? Without understanding how they intend to
&gt; use this, it&#x27;s hard to know what&#x27;s needed.

If you ask me, I have no problem or I would say more, I look positively
on the way &quot;keep it high level &amp; don&#x27;t touch NFS protocol&quot; ;-)
But I remember a very tight discussion (good context [1]) about Cephfs and
this way wasn&#x27;t considered as acceptable back then (and we had to make
a protocol extension).
We can always go iteratively, and first version can be simple and then on-demand
we can support more tricky cases if this is acceptable for you guys.
You set the rules. ;-)

[1] https://lore.kernel.org/lkml/f3864ed6-8c97-8a7a-f268-dab29eb2fb21@redhat.com/

Kind regards,
Alex

&gt;
&gt; --
&gt; Jeff Layton &lt;jlayton@kernel.org&gt;


---

Am Mi., 18. Feb. 2026 um 17:01 Uhr schrieb Jeff Layton &lt;jlayton@kernel.org&gt;:
&gt;
&gt; On Wed, 2026-02-18 at 15:36 +0100, Alexander Mikhalitsyn wrote:
&gt; &gt; Am Mi., 18. Feb. 2026 um 14:49 Uhr schrieb Jeff Layton &lt;jlayton@kernel.org&gt;:
&gt; &gt; &gt;
&gt; &gt; &gt; On Wed, 2026-02-18 at 13:44 +0100, Alexander Mikhalitsyn wrote:
&gt; &gt; &gt; &gt; Dear friends,
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; I would like to propose &quot;VFS idmappings support in NFS&quot; as a topic for discussion at the LSF/MM/BPF Summit.
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; Previously, I worked on VFS idmap support for FUSE/virtiofs [2] and cephfs [1] with support/guidance
&gt; &gt; &gt; &gt; from Christian.
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; This experience with Cephfs &amp; FUSE has shown that VFS idmap semantics, while being very elegant and
&gt; &gt; &gt; &gt; intuitive for local filesystems, can be quite challenging to combine with network/network-like (e.g. FUSE)
&gt; &gt; &gt; &gt; FSes. In case of Cephfs we had to modify its protocol (!) (see [2]) as a part of our agreement with
&gt; &gt; &gt; &gt; ceph folks about the right way to support idmaps.
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; One obstacle here was that cephfs has some features that are not very Linux-wayish, I would say.
&gt; &gt; &gt; &gt; In particular, system administrator can configure path-based UID/GID restrictions on a *server*-side (Ceph MDS).
&gt; &gt; &gt; &gt; Basically, you can say &quot;I expect UID 1000 and GID 2000 for all files under /stuff directory&quot;.
&gt; &gt; &gt; &gt; The problem here is that these UID/GIDs are taken from a syscall-caller&#x27;s creds (not from (struct file *)-&gt;f_cred)
&gt; &gt; &gt; &gt; which makes cephfs FDs not very transferable through unix sockets. [3]
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; These path-based UID/GID restrictions mean that server expects client to send UID/GID with every single request,
&gt; &gt; &gt; &gt; not only for those OPs where UID/GID needs to be written to the disk (mknod, mkdir, symlink, etc).
&gt; &gt; &gt; &gt; VFS idmaps API is designed to prevent filesystems developers from making a mistakes when supporting FS_ALLOW_IDMAP.
&gt; &gt; &gt; &gt; For example, (struct mnt_idmap *) is not passed to every single i_op, but instead to only those where it can be
&gt; &gt; &gt; &gt; used legitimately. Particularly, readlink/listxattr or rmdir are not expected to use idmapping information anyhow.
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; We&#x27;ve seen very similar challenges with FUSE. Not a long time ago on Linux Containers project forum, there
&gt; &gt; &gt; &gt; was a discussion about mergerfs (a popular FUSE-based filesystem) &amp; VFS idmaps [5]. And I see that this problem
&gt; &gt; &gt; &gt; of &quot;caller UID/GID are needed everywhere&quot; still blocks VFS idmaps adoption in some usecases.
&gt; &gt; &gt; &gt; Antonio Musumeci (mergerfs maintainer) claimed that in many cases filesystems behind mergerfs may not be fully
&gt; &gt; &gt; &gt; POSIX and basically, when mergerfs does IO on the underlying FSes it needs to do UID/GID switch to caller&#x27;s UID/GID
&gt; &gt; &gt; &gt; (taken from FUSE request header).
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; We don&#x27;t expect NFS to be any simpler :-) I would say that supporting NFS is a final boss. It would be great
&gt; &gt; &gt; &gt; to have a deep technical discussion with VFS/FSes maintainers and developers about all these challenges and
&gt; &gt; &gt; &gt; make some conclusions and identify a right direction/approach to these problems. From my side, I&#x27;m going
&gt; &gt; &gt; &gt; to get more familiar with high-level part of NFS (or even make PoC if time permits), identify challenges,
&gt; &gt; &gt; &gt; summarize everything and prepare some slides to navigate/plan discussion.
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; [1] cephfs https://lore.kernel.org/linux-fsdevel/20230807132626.182101-1-aleksandr.mikhalitsyn@canonical.com
&gt; &gt; &gt; &gt; [2] cephfs protocol changes https://github.com/ceph/ceph/pull/52575
&gt; &gt; &gt; &gt; [3] cephfs &amp; f_cred https://lore.kernel.org/lkml/CAEivzxeZ6fDgYMnjk21qXYz13tHqZa8rP-cZ2jdxkY0eX+dOjw@mail.gmail.com/
&gt; &gt; &gt; &gt; [4] fuse/virtiofs https://lore.kernel.org/linux-fsdevel/20240903151626.264609-1-aleksandr.mikhalitsyn@canonical.com/
&gt; &gt; &gt; &gt; [5]
&gt; &gt; &gt; &gt; mergerfshttps://discuss.linuxcontainers.org/t/is-it-the-case-that-you-cannot-use-shift-true-for-disk-devices-where-the-source-is-a-mergerfs-mount-is-there-a-workaround/25336/11?u=amikhalitsyn
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; Kind regards,
&gt; &gt; &gt; &gt; Alexander Mikhalitsyn @ futurfusion.io
&gt; &gt; &gt;
&gt; &gt;
&gt; &gt; Hi Jeff,
&gt; &gt;
&gt; &gt; thanks for such a fast reply! ;)
&gt; &gt;
&gt; &gt; &gt;
&gt; &gt; &gt; IIUC, people mostly use vfs-layer idmappings because they want to remap
&gt; &gt; &gt; the uid/gid values of files that get stored on the backing store (disk,
&gt; &gt; &gt; ceph MDS, or whatever).
&gt; &gt;
&gt; &gt; yes, precisely.
&gt; &gt;
&gt; &gt; &gt;
&gt; &gt; &gt; I&#x27;ve never used idmappings myself much in practice. Could you lay out
&gt; &gt; &gt; an example of how you would use them with NFS in a real environment so
&gt; &gt; &gt; I understand the problem better? I&#x27;d start by assuming a simple setup
&gt; &gt; &gt; with AUTH_SYS and no NFSv4 idmapping involved, since that case should
&gt; &gt; &gt; be fairly straightforward.
&gt; &gt;
&gt; &gt; For me, from the point of LXC/Incus project, idmapped mounts are used as
&gt; &gt; a way to &quot;delegate&quot; filesystems (or subtrees) to the containers:
&gt; &gt; 1. We, of course, assume that container enables user namespaces and
&gt; &gt; user can&#x27;t mount a filesystem
&gt; &gt; inside because it has no FS_USERNS_MOUNT flag set (like in case of Cephfs, NFS,
&gt; &gt; CIFS and many others).
&gt; &gt; 2. At the same time host&#x27;s system administrator wants to avoid
&gt; &gt; remapping between container&#x27;s user ns and
&gt; &gt; sb-&gt;s_user_ns (which is init_user_ns for those filesystems). [
&gt; &gt; motivation here is that in many
&gt; &gt; cases you may want to have the same subtree to be shared with other
&gt; &gt; containers and even host users too and
&gt; &gt; you want UIDs to be &quot;compatible&quot;, i.e UID 1000 in one container and
&gt; &gt; UID 1000 in another container should
&gt; &gt; land as UID 1000 on the filesystem&#x27;s inode ]
&gt; &gt;
&gt; &gt; For this usecase, when we bind-mount filesystem to container, we apply
&gt; &gt; VFS idmap equal to container&#x27;s
&gt; &gt; user namespace. This makes a behavior I described.
&gt; &gt;
&gt;
&gt; Ok: so you have a process running in a userns as UID 2000 and you want
&gt; to use vfs layer idmapping so that when you create a file as that user
&gt; that it ends up being owned by UID 1000. Is that basically correct?

In our case, we have a UID 1000 (inside user namespace), which mapped to
something like 10000 + 1000 (in the init_user_ns). And then we have
NFS mount (sb-&gt;s_user_ns = init_user_ns, ofc), so if user UID 1000
(inside the container)
creates a file, it will be 11000, right? But we do bind-mount of that
NFS mount+VFS idmap,
so that once file is created it has owner_uid = 1000. (This scenario
is covered by [1] and [2])

[1] https://docs.kernel.org/filesystems/idmappings.html#example-3
[2] https://docs.kernel.org/filesystems/idmappings.html#example-3-reconsidered

&gt;
&gt; Typically, the RPC credentials used in an OPEN or CREATE call is what
&gt; determines its ownership (at least until a SETATTR comes in). With
&gt; AUTH_SYS, the credential is just a uid and set of gids.
&gt;
&gt; So in this case, it sounds like you would need just do that conversion
&gt; (maybe at the RPC client layer?) when issuing an RPC. You don&#x27;t really
&gt; need a protocol extension for that case.
&gt;
&gt; As Trond points out though, AUTH_GSS and NFSv4 idmapping will make this
&gt; more complex. Once you&#x27;re using kerberos credentials for
&gt; authentication, you don&#x27;t have much control over what the UIDs and GIDs
&gt; will be on newly-created files, but is that really a problem? As long
&gt; as all of the clients have a consistent view, I wouldn&#x27;t think so.

I absolutely agree.

&gt;
&gt; &gt; But this is just one use case. I&#x27;m pretty sure there are some more
&gt; &gt; around here :)
&gt; &gt; I know that folks from Preferred Networks (preferred.jp) are also
&gt; &gt; interested in VFS idmap support in NFS,
&gt; &gt; probably they can share some ideas/use cases too.
&gt; &gt;
&gt; &gt;
&gt;
&gt; Yes, we don&#x27;t want to focus too much on a single use-case, but I find
&gt; it helpful to focus on a single simple problem first.

Yes, I could prepare RFC patches before LSF/MM/BPF for that simple case so
we have something to start with.

&gt; --
&gt; Jeff Layton &lt;jlayton@kernel.org&gt;
</pre>
</details>
<div class="review-comment-signals">Signals: NEEDS_WORK, POSITIVE</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Trond Myklebust</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-18">2026-02-18</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The reviewer raised concerns that a generic idmapping scheme for NFS would require protocol extensions and a different security model, where the client is in charge of enforcing permissions.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">On Wed, 2026-02-18 at 08:49 -0500, Jeff Layton wrote:
&gt; On Wed, 2026-02-18 at 13:44 +0100, Alexander Mikhalitsyn wrote:
&gt; &gt; Dear friends,
&gt; &gt; 
&gt; &gt; I would like to propose &quot;VFS idmappings support in NFS&quot; as a topic
&gt; &gt; for discussion at the LSF/MM/BPF Summit.
&gt; &gt; 
&gt; &gt; Previously, I worked on VFS idmap support for FUSE/virtiofs [2] and
&gt; &gt; cephfs [1] with support/guidance
&gt; &gt; from Christian.
&gt; &gt; 
&gt; &gt; This experience with Cephfs &amp; FUSE has shown that VFS idmap
&gt; &gt; semantics, while being very elegant and
&gt; &gt; intuitive for local filesystems, can be quite challenging to
&gt; &gt; combine with network/network-like (e.g. FUSE)
&gt; &gt; FSes. In case of Cephfs we had to modify its protocol (!) (see [2])
&gt; &gt; as a part of our agreement with
&gt; &gt; ceph folks about the right way to support idmaps.
&gt; &gt; 
&gt; &gt; One obstacle here was that cephfs has some features that are not
&gt; &gt; very Linux-wayish, I would say.
&gt; &gt; In particular, system administrator can configure path-based
&gt; &gt; UID/GID restrictions on a *server*-side (Ceph MDS).
&gt; &gt; Basically, you can say &quot;I expect UID 1000 and GID 2000 for all
&gt; &gt; files under /stuff directory&quot;.
&gt; &gt; The problem here is that these UID/GIDs are taken from a syscall-
&gt; &gt; caller&#x27;s creds (not from (struct file *)-&gt;f_cred)
&gt; &gt; which makes cephfs FDs not very transferable through unix sockets.
&gt; &gt; [3]
&gt; &gt; 
&gt; &gt; These path-based UID/GID restrictions mean that server expects
&gt; &gt; client to send UID/GID with every single request,
&gt; &gt; not only for those OPs where UID/GID needs to be written to the
&gt; &gt; disk (mknod, mkdir, symlink, etc).
&gt; &gt; VFS idmaps API is designed to prevent filesystems developers from
&gt; &gt; making a mistakes when supporting FS_ALLOW_IDMAP.
&gt; &gt; For example, (struct mnt_idmap *) is not passed to every single
&gt; &gt; i_op, but instead to only those where it can be
&gt; &gt; used legitimately. Particularly, readlink/listxattr or rmdir are
&gt; &gt; not expected to use idmapping information anyhow.
&gt; &gt; 
&gt; &gt; We&#x27;ve seen very similar challenges with FUSE. Not a long time ago
&gt; &gt; on Linux Containers project forum, there
&gt; &gt; was a discussion about mergerfs (a popular FUSE-based filesystem) &amp;
&gt; &gt; VFS idmaps [5]. And I see that this problem
&gt; &gt; of &quot;caller UID/GID are needed everywhere&quot; still blocks VFS idmaps
&gt; &gt; adoption in some usecases.
&gt; &gt; Antonio Musumeci (mergerfs maintainer) claimed that in many cases
&gt; &gt; filesystems behind mergerfs may not be fully
&gt; &gt; POSIX and basically, when mergerfs does IO on the underlying FSes
&gt; &gt; it needs to do UID/GID switch to caller&#x27;s UID/GID
&gt; &gt; (taken from FUSE request header).
&gt; &gt; 
&gt; &gt; We don&#x27;t expect NFS to be any simpler :-) I would say that
&gt; &gt; supporting NFS is a final boss. It would be great
&gt; &gt; to have a deep technical discussion with VFS/FSes maintainers and
&gt; &gt; developers about all these challenges and
&gt; &gt; make some conclusions and identify a right direction/approach to
&gt; &gt; these problems. From my side, I&#x27;m going
&gt; &gt; to get more familiar with high-level part of NFS (or even make PoC
&gt; &gt; if time permits), identify challenges,
&gt; &gt; summarize everything and prepare some slides to navigate/plan
&gt; &gt; discussion.
&gt; &gt; 
&gt; &gt; [1] cephfs
&gt; &gt; https://lore.kernel.org/linux-fsdevel/20230807132626.182101-1-aleksandr.mikhalitsyn@canonical.com
&gt; &gt; [2] cephfs protocol changes https://github.com/ceph/ceph/pull/52575
&gt; &gt; [3] cephfs &amp; f_cred
&gt; &gt; https://lore.kernel.org/lkml/CAEivzxeZ6fDgYMnjk21qXYz13tHqZa8rP-cZ2jdxkY0eX+dOjw@mail.gmail.com/
&gt; &gt; [4] fuse/virtiofs
&gt; &gt; https://lore.kernel.org/linux-fsdevel/20240903151626.264609-1-aleksandr.mikhalitsyn@canonical.com/
&gt; &gt; [5]
&gt; &gt; mergerfs
&gt; &gt; https://discuss.linuxcontainers.org/t/is-it-the-case-that-you-
&gt; &gt; cannot-use-shift-true-for-disk-devices-where-the-source-is-a-
&gt; &gt; mergerfs-mount-is-there-a-workaround/25336/11?u=amikhalitsyn
&gt; &gt; 
&gt; &gt; Kind regards,
&gt; &gt; Alexander Mikhalitsyn @ futurfusion.io
&gt; 
&gt; 
&gt; IIUC, people mostly use vfs-layer idmappings because they want to
&gt; remap
&gt; the uid/gid values of files that get stored on the backing store
&gt; (disk,
&gt; ceph MDS, or whatever).
&gt; 
&gt; I&#x27;ve never used idmappings myself much in practice. Could you lay out
&gt; an example of how you would use them with NFS in a real environment
&gt; so
&gt; I understand the problem better? I&#x27;d start by assuming a simple setup
&gt; with AUTH_SYS and no NFSv4 idmapping involved, since that case should
&gt; be fairly straightforward.
&gt; 
&gt; Mixing in AUTH_GSS and real idmapping will be where things get
&gt; harder,
&gt; so let&#x27;s not worry about those cases for now.

I think you do need to worry about those cases. As the NFS and RPC
protocols stand today, strong authentication will defeat any client
side idmapping scheme, because the server can&#x27;t know what uids or gids
the client is using on its end; it just knows about the account that
was used to authenticate.

I think if you do want to implement something generic, you&#x27;re going to
have to consider how the client and server can exchange (and store) the
information needed to allow the client to perform the mapping of file
owners/group owners on its end. The client would presumably also need
to be in charge of enforcing permissions for such mappings.
It would be a very different security model than the one used by NFS
today, and almost certainly require protocol extensions.

-- 
Trond Myklebust
Linux NFS client maintainer, Hammerspace
trondmy@kernel.org, trond.myklebust@hammerspace.com
</pre>
</details>
<div class="review-comment-signals">Signals: requested changes, protocol extensions</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">NeilBrown</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-18">2026-02-18</a>
<span class="inline-review-badge">Inline Review</span>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The reviewer raised concerns about the conversion of RPCs in NFSv3 and how idmapped NFS filesystems interact with client and server uids, suggesting that the kernel idmapping should not be used with NFSv4.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">On Thu, 19 Feb 2026, Jeff Layton wrote:
&gt; On Wed, 2026-02-18 at 15:36 +0100, Alexander Mikhalitsyn wrote:
&gt; &gt; Am Mi., 18. Feb. 2026 um 14:49 Uhr schrieb Jeff Layton &lt;jlayton@kernel.org&gt;:
&gt; &gt; &gt; 
&gt; &gt; &gt; On Wed, 2026-02-18 at 13:44 +0100, Alexander Mikhalitsyn wrote:
&gt; &gt; &gt; &gt; Dear friends,
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; I would like to propose &quot;VFS idmappings support in NFS&quot; as a topic for discussion at the LSF/MM/BPF Summit.
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; Previously, I worked on VFS idmap support for FUSE/virtiofs [2] and cephfs [1] with support/guidance
&gt; &gt; &gt; &gt; from Christian.
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; This experience with Cephfs &amp; FUSE has shown that VFS idmap semantics, while being very elegant and
&gt; &gt; &gt; &gt; intuitive for local filesystems, can be quite challenging to combine with network/network-like (e.g. FUSE)
&gt; &gt; &gt; &gt; FSes. In case of Cephfs we had to modify its protocol (!) (see [2]) as a part of our agreement with
&gt; &gt; &gt; &gt; ceph folks about the right way to support idmaps.
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; One obstacle here was that cephfs has some features that are not very Linux-wayish, I would say.
&gt; &gt; &gt; &gt; In particular, system administrator can configure path-based UID/GID restrictions on a *server*-side (Ceph MDS).
&gt; &gt; &gt; &gt; Basically, you can say &quot;I expect UID 1000 and GID 2000 for all files under /stuff directory&quot;.
&gt; &gt; &gt; &gt; The problem here is that these UID/GIDs are taken from a syscall-caller&#x27;s creds (not from (struct file *)-&gt;f_cred)
&gt; &gt; &gt; &gt; which makes cephfs FDs not very transferable through unix sockets. [3]
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; These path-based UID/GID restrictions mean that server expects client to send UID/GID with every single request,
&gt; &gt; &gt; &gt; not only for those OPs where UID/GID needs to be written to the disk (mknod, mkdir, symlink, etc).
&gt; &gt; &gt; &gt; VFS idmaps API is designed to prevent filesystems developers from making a mistakes when supporting FS_ALLOW_IDMAP.
&gt; &gt; &gt; &gt; For example, (struct mnt_idmap *) is not passed to every single i_op, but instead to only those where it can be
&gt; &gt; &gt; &gt; used legitimately. Particularly, readlink/listxattr or rmdir are not expected to use idmapping information anyhow.
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; We&#x27;ve seen very similar challenges with FUSE. Not a long time ago on Linux Containers project forum, there
&gt; &gt; &gt; &gt; was a discussion about mergerfs (a popular FUSE-based filesystem) &amp; VFS idmaps [5]. And I see that this problem
&gt; &gt; &gt; &gt; of &quot;caller UID/GID are needed everywhere&quot; still blocks VFS idmaps adoption in some usecases.
&gt; &gt; &gt; &gt; Antonio Musumeci (mergerfs maintainer) claimed that in many cases filesystems behind mergerfs may not be fully
&gt; &gt; &gt; &gt; POSIX and basically, when mergerfs does IO on the underlying FSes it needs to do UID/GID switch to caller&#x27;s UID/GID
&gt; &gt; &gt; &gt; (taken from FUSE request header).
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; We don&#x27;t expect NFS to be any simpler :-) I would say that supporting NFS is a final boss. It would be great
&gt; &gt; &gt; &gt; to have a deep technical discussion with VFS/FSes maintainers and developers about all these challenges and
&gt; &gt; &gt; &gt; make some conclusions and identify a right direction/approach to these problems. From my side, I&#x27;m going
&gt; &gt; &gt; &gt; to get more familiar with high-level part of NFS (or even make PoC if time permits), identify challenges,
&gt; &gt; &gt; &gt; summarize everything and prepare some slides to navigate/plan discussion.
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; [1] cephfs https://lore.kernel.org/linux-fsdevel/20230807132626.182101-1-aleksandr.mikhalitsyn@canonical.com
&gt; &gt; &gt; &gt; [2] cephfs protocol changes https://github.com/ceph/ceph/pull/52575
&gt; &gt; &gt; &gt; [3] cephfs &amp; f_cred https://lore.kernel.org/lkml/CAEivzxeZ6fDgYMnjk21qXYz13tHqZa8rP-cZ2jdxkY0eX+dOjw@mail.gmail.com/
&gt; &gt; &gt; &gt; [4] fuse/virtiofs https://lore.kernel.org/linux-fsdevel/20240903151626.264609-1-aleksandr.mikhalitsyn@canonical.com/
&gt; &gt; &gt; &gt; [5]
&gt; &gt; &gt; &gt; mergerfshttps://discuss.linuxcontainers.org/t/is-it-the-case-that-you-cannot-use-shift-true-for-disk-devices-where-the-source-is-a-mergerfs-mount-is-there-a-workaround/25336/11?u=amikhalitsyn
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; Kind regards,
&gt; &gt; &gt; &gt; Alexander Mikhalitsyn @ futurfusion.io
&gt; &gt; &gt; 
&gt; &gt; 
&gt; &gt; Hi Jeff,
&gt; &gt; 
&gt; &gt; thanks for such a fast reply! ;)
&gt; &gt; 
&gt; &gt; &gt; 
&gt; &gt; &gt; IIUC, people mostly use vfs-layer idmappings because they want to remap
&gt; &gt; &gt; the uid/gid values of files that get stored on the backing store (disk,
&gt; &gt; &gt; ceph MDS, or whatever).
&gt; &gt; 
&gt; &gt; yes, precisely.
&gt; &gt; 
&gt; &gt; &gt; 
&gt; &gt; &gt; I&#x27;ve never used idmappings myself much in practice. Could you lay out
&gt; &gt; &gt; an example of how you would use them with NFS in a real environment so
&gt; &gt; &gt; I understand the problem better? I&#x27;d start by assuming a simple setup
&gt; &gt; &gt; with AUTH_SYS and no NFSv4 idmapping involved, since that case should
&gt; &gt; &gt; be fairly straightforward.
&gt; &gt; 
&gt; &gt; For me, from the point of LXC/Incus project, idmapped mounts are used as
&gt; &gt; a way to &quot;delegate&quot; filesystems (or subtrees) to the containers:
&gt; &gt; 1. We, of course, assume that container enables user namespaces and
&gt; &gt; user can&#x27;t mount a filesystem
&gt; &gt; inside because it has no FS_USERNS_MOUNT flag set (like in case of Cephfs, NFS,
&gt; &gt; CIFS and many others).
&gt; &gt; 2. At the same time host&#x27;s system administrator wants to avoid
&gt; &gt; remapping between container&#x27;s user ns and
&gt; &gt; sb-&gt;s_user_ns (which is init_user_ns for those filesystems). [
&gt; &gt; motivation here is that in many
&gt; &gt; cases you may want to have the same subtree to be shared with other
&gt; &gt; containers and even host users too and
&gt; &gt; you want UIDs to be &quot;compatible&quot;, i.e UID 1000 in one container and
&gt; &gt; UID 1000 in another container should
&gt; &gt; land as UID 1000 on the filesystem&#x27;s inode ]
&gt; &gt; 
&gt; &gt; For this usecase, when we bind-mount filesystem to container, we apply
&gt; &gt; VFS idmap equal to container&#x27;s
&gt; &gt; user namespace. This makes a behavior I described.
&gt; &gt; 
&gt; 
&gt; Ok: so you have a process running in a userns as UID 2000 and you want
&gt; to use vfs layer idmapping so that when you create a file as that user
&gt; that it ends up being owned by UID 1000. Is that basically correct?
&gt; 
&gt; Typically, the RPC credentials used in an OPEN or CREATE call is what
&gt; determines its ownership (at least until a SETATTR comes in). With
&gt; AUTH_SYS, the credential is just a uid and set of gids.
&gt; 
&gt; So in this case, it sounds like you would need just do that conversion
&gt; (maybe at the RPC client layer?) when issuing an RPC. You don&#x27;t really
&gt; need a protocol extension for that case.

You also need to consider the conversion when receiving an RPC.

If you use krb5 and NFSv3 then you really want the mapping between krb5
identity and uid to be the same on client and server, so then when an
application creates a file and the stats it, it sees that it owns it.

If I use a krb5 identity in an idmapped NFS filesystem I&#x27;ll want the
server to map the identity to the &quot;underlying&quot; uid (was would be stored
in a local filesystem) and then when the client gets a GETATTR reply,
the VFS maps back to the uid seen by the application.

With NFSv4 and the idmapper you wouldn&#x27;t need (or want) the kernel
idmapping to be used at all.  You would want the idmapper deamon to run
in the user-namespace and map from on-the-wire names to the appropriate
app-level uids.
This would mean that a given NFS mount would need to be an a given user
namespace.  Maybe that isn&#x27;t desired.

If it is important for a given NFS mount to be available in multiple
user namespaces, then the idmapper daemon would need to map to the
underlying uid, and the VFS mapping would map that up to the app-level
uid.

NeilBrown


&gt; 
&gt; As Trond points out though, AUTH_GSS and NFSv4 idmapping will make this
&gt; more complex. Once you&#x27;re using kerberos credentials for
&gt; authentication, you don&#x27;t have much control over what the UIDs and GIDs
&gt; will be on newly-created files, but is that really a problem? As long
&gt; as all of the clients have a consistent view, I wouldn&#x27;t think so.
&gt; 
&gt; &gt; But this is just one use case. I&#x27;m pretty sure there are some more
&gt; &gt; around here :)
&gt; &gt; I know that folks from Preferred Networks (preferred.jp) are also
&gt; &gt; interested in VFS idmap support in NFS,
&gt; &gt; probably they can share some ideas/use cases too.
&gt; &gt; 
&gt; &gt; 
&gt; 
&gt; Yes, we don&#x27;t want to focus too much on a single use-case, but I find
&gt; it helpful to focus on a single simple problem first.
&gt; -- 
&gt; Jeff Layton &lt;jlayton@kernel.org&gt;
&gt; 
&gt; 

</pre>
</details>
<div class="review-comment-signals">Signals: requested changes, technical concerns</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Kohei Sugihara</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-18">2026-02-18</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Kohei Sugihara expressed interest in supporting NFS for ID-mapping and shared a use case of running multi-tenant Kubernetes clusters where they need to share a single storage endpoint among multiple pods using ReadWriteMany (RWX) access mode. He outlined two possible models for handling UID/GID mapping between the client and server, with model (a) being simpler but potentially having security implications.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">On Thu, Feb 19, 2026 at 9:58 AM NeilBrown &lt;neilb@ownmail.net&gt; wrote:
&gt;
&gt; On Thu, 19 Feb 2026, Jeff Layton wrote:
&gt; &gt; On Wed, 2026-02-18 at 15:36 +0100, Alexander Mikhalitsyn wrote:
&gt; &gt; &gt; Am Mi., 18. Feb. 2026 um 14:49 Uhr schrieb Jeff Layton &lt;jlayton@kernel.org&gt;:
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; On Wed, 2026-02-18 at 13:44 +0100, Alexander Mikhalitsyn wrote:
&gt; &gt; &gt; &gt; &gt; Dear friends,
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt; I would like to propose &quot;VFS idmappings support in NFS&quot; as a topic for discussion at the LSF/MM/BPF Summit.
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt; Previously, I worked on VFS idmap support for FUSE/virtiofs [2] and cephfs [1] with support/guidance
&gt; &gt; &gt; &gt; &gt; from Christian.
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt; This experience with Cephfs &amp; FUSE has shown that VFS idmap semantics, while being very elegant and
&gt; &gt; &gt; &gt; &gt; intuitive for local filesystems, can be quite challenging to combine with network/network-like (e.g. FUSE)
&gt; &gt; &gt; &gt; &gt; FSes. In case of Cephfs we had to modify its protocol (!) (see [2]) as a part of our agreement with
&gt; &gt; &gt; &gt; &gt; ceph folks about the right way to support idmaps.
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt; One obstacle here was that cephfs has some features that are not very Linux-wayish, I would say.
&gt; &gt; &gt; &gt; &gt; In particular, system administrator can configure path-based UID/GID restrictions on a *server*-side (Ceph MDS).
&gt; &gt; &gt; &gt; &gt; Basically, you can say &quot;I expect UID 1000 and GID 2000 for all files under /stuff directory&quot;.
&gt; &gt; &gt; &gt; &gt; The problem here is that these UID/GIDs are taken from a syscall-caller&#x27;s creds (not from (struct file *)-&gt;f_cred)
&gt; &gt; &gt; &gt; &gt; which makes cephfs FDs not very transferable through unix sockets. [3]
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt; These path-based UID/GID restrictions mean that server expects client to send UID/GID with every single request,
&gt; &gt; &gt; &gt; &gt; not only for those OPs where UID/GID needs to be written to the disk (mknod, mkdir, symlink, etc).
&gt; &gt; &gt; &gt; &gt; VFS idmaps API is designed to prevent filesystems developers from making a mistakes when supporting FS_ALLOW_IDMAP.
&gt; &gt; &gt; &gt; &gt; For example, (struct mnt_idmap *) is not passed to every single i_op, but instead to only those where it can be
&gt; &gt; &gt; &gt; &gt; used legitimately. Particularly, readlink/listxattr or rmdir are not expected to use idmapping information anyhow.
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt; We&#x27;ve seen very similar challenges with FUSE. Not a long time ago on Linux Containers project forum, there
&gt; &gt; &gt; &gt; &gt; was a discussion about mergerfs (a popular FUSE-based filesystem) &amp; VFS idmaps [5]. And I see that this problem
&gt; &gt; &gt; &gt; &gt; of &quot;caller UID/GID are needed everywhere&quot; still blocks VFS idmaps adoption in some usecases.
&gt; &gt; &gt; &gt; &gt; Antonio Musumeci (mergerfs maintainer) claimed that in many cases filesystems behind mergerfs may not be fully
&gt; &gt; &gt; &gt; &gt; POSIX and basically, when mergerfs does IO on the underlying FSes it needs to do UID/GID switch to caller&#x27;s UID/GID
&gt; &gt; &gt; &gt; &gt; (taken from FUSE request header).
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt; We don&#x27;t expect NFS to be any simpler :-) I would say that supporting NFS is a final boss. It would be great
&gt; &gt; &gt; &gt; &gt; to have a deep technical discussion with VFS/FSes maintainers and developers about all these challenges and
&gt; &gt; &gt; &gt; &gt; make some conclusions and identify a right direction/approach to these problems. From my side, I&#x27;m going
&gt; &gt; &gt; &gt; &gt; to get more familiar with high-level part of NFS (or even make PoC if time permits), identify challenges,
&gt; &gt; &gt; &gt; &gt; summarize everything and prepare some slides to navigate/plan discussion.
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt; [1] cephfs https://lore.kernel.org/linux-fsdevel/20230807132626.182101-1-aleksandr.mikhalitsyn@canonical.com
&gt; &gt; &gt; &gt; &gt; [2] cephfs protocol changes https://github.com/ceph/ceph/pull/52575
&gt; &gt; &gt; &gt; &gt; [3] cephfs &amp; f_cred https://lore.kernel.org/lkml/CAEivzxeZ6fDgYMnjk21qXYz13tHqZa8rP-cZ2jdxkY0eX+dOjw@mail.gmail.com/
&gt; &gt; &gt; &gt; &gt; [4] fuse/virtiofs https://lore.kernel.org/linux-fsdevel/20240903151626.264609-1-aleksandr.mikhalitsyn@canonical.com/
&gt; &gt; &gt; &gt; &gt; [5]
&gt; &gt; &gt; &gt; &gt; mergerfshttps://discuss.linuxcontainers.org/t/is-it-the-case-that-you-cannot-use-shift-true-for-disk-devices-where-the-source-is-a-mergerfs-mount-is-there-a-workaround/25336/11?u=amikhalitsyn
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt; Kind regards,
&gt; &gt; &gt; &gt; &gt; Alexander Mikhalitsyn @ futurfusion.io
&gt; &gt; &gt; &gt;
&gt; &gt; &gt;
&gt; &gt; &gt; Hi Jeff,
&gt; &gt; &gt;
&gt; &gt; &gt; thanks for such a fast reply! ;)
&gt; &gt; &gt;
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; IIUC, people mostly use vfs-layer idmappings because they want to remap
&gt; &gt; &gt; &gt; the uid/gid values of files that get stored on the backing store (disk,
&gt; &gt; &gt; &gt; ceph MDS, or whatever).
&gt; &gt; &gt;
&gt; &gt; &gt; yes, precisely.
&gt; &gt; &gt;
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; I&#x27;ve never used idmappings myself much in practice. Could you lay out
&gt; &gt; &gt; &gt; an example of how you would use them with NFS in a real environment so
&gt; &gt; &gt; &gt; I understand the problem better? I&#x27;d start by assuming a simple setup
&gt; &gt; &gt; &gt; with AUTH_SYS and no NFSv4 idmapping involved, since that case should
&gt; &gt; &gt; &gt; be fairly straightforward.
&gt; &gt; &gt;
&gt; &gt; &gt; For me, from the point of LXC/Incus project, idmapped mounts are used as
&gt; &gt; &gt; a way to &quot;delegate&quot; filesystems (or subtrees) to the containers:
&gt; &gt; &gt; 1. We, of course, assume that container enables user namespaces and
&gt; &gt; &gt; user can&#x27;t mount a filesystem
&gt; &gt; &gt; inside because it has no FS_USERNS_MOUNT flag set (like in case of Cephfs, NFS,
&gt; &gt; &gt; CIFS and many others).
&gt; &gt; &gt; 2. At the same time host&#x27;s system administrator wants to avoid
&gt; &gt; &gt; remapping between container&#x27;s user ns and
&gt; &gt; &gt; sb-&gt;s_user_ns (which is init_user_ns for those filesystems). [
&gt; &gt; &gt; motivation here is that in many
&gt; &gt; &gt; cases you may want to have the same subtree to be shared with other
&gt; &gt; &gt; containers and even host users too and
&gt; &gt; &gt; you want UIDs to be &quot;compatible&quot;, i.e UID 1000 in one container and
&gt; &gt; &gt; UID 1000 in another container should
&gt; &gt; &gt; land as UID 1000 on the filesystem&#x27;s inode ]
&gt; &gt; &gt;
&gt; &gt; &gt; For this usecase, when we bind-mount filesystem to container, we apply
&gt; &gt; &gt; VFS idmap equal to container&#x27;s
&gt; &gt; &gt; user namespace. This makes a behavior I described.
&gt; &gt; &gt;
&gt; &gt;
&gt; &gt; Ok: so you have a process running in a userns as UID 2000 and you want
&gt; &gt; to use vfs layer idmapping so that when you create a file as that user
&gt; &gt; that it ends up being owned by UID 1000. Is that basically correct?
&gt; &gt;
&gt; &gt; Typically, the RPC credentials used in an OPEN or CREATE call is what
&gt; &gt; determines its ownership (at least until a SETATTR comes in). With
&gt; &gt; AUTH_SYS, the credential is just a uid and set of gids.
&gt; &gt;
&gt; &gt; So in this case, it sounds like you would need just do that conversion
&gt; &gt; (maybe at the RPC client layer?) when issuing an RPC. You don&#x27;t really
&gt; &gt; need a protocol extension for that case.
&gt;
&gt; You also need to consider the conversion when receiving an RPC.
&gt;
&gt; If you use krb5 and NFSv3 then you really want the mapping between krb5
&gt; identity and uid to be the same on client and server, so then when an
&gt; application creates a file and the stats it, it sees that it owns it.
&gt;
&gt; If I use a krb5 identity in an idmapped NFS filesystem I&#x27;ll want the
&gt; server to map the identity to the &quot;underlying&quot; uid (was would be stored
&gt; in a local filesystem) and then when the client gets a GETATTR reply,
&gt; the VFS maps back to the uid seen by the application.


Thank you Alex for the proposal and quick follow-ups. We&#x27;re really
interested in this feature and we&#x27;d like to share our use case.

&gt; &gt; &gt; But this is just one use case. I&#x27;m pretty sure there are some more
&gt; &gt; &gt; around here :)
&gt; &gt; &gt; I know that folks from Preferred Networks (preferred.jp) are also
&gt; &gt; &gt; interested in VFS idmap support in NFS,
&gt; &gt; &gt; probably they can share some ideas/use cases too.

Our use case is running multi-tenant Kubernetes clusters with
Kubernetes User Namespaces [1]. Basically we need to share a single
storage endpoint among multiple pods using ReadWriteMany (RWX) access
mode. Implementations that support both RWX and ID-mapped mount are
limited [2].

NFS is operationally common, so I am interested in supporting NFS for
ID-mapping, but NFS is complex due to its variety of mount options and
security features as Trond mentioned. We&#x27;d like to share our use case
and define the minimum goal. Our goal is here:

- 1: Mount the same NFS export as a persistent volume from multiple
Kubernetes Pods running on different compute nodes. Each tenant has
its own exports.
- 2: UID/GID in a container in the pod can be configurable to an
arbitrary value by runAsUser/runAsGroup (e.g. runAsUser/Group is set
to 1000).
- 3: We can access the export from the container as 1000:1000. At
minimum, ownership should be consistent from the container view (i.e.
stat shows 1000:1000 for files that the container creates). Today,
ID-mapped mount does not support NFS. The NFS client ends up using the
host-mapped uid/gid (e.g. container 1000 becomes host 11000), so the
container view becomes inconsistent across nodes.

There are (at least) two possible models here:
a) the NFS client sends 1000:1000 on the wire and the server stores
1000:1000 (so server-side ownership matches the container uid/gid), or
b) the server stores the host uid/gid (e.g. 11000:11000) and the
client/VFS maps it so that the container still sees 1000:1000.
My intuition is that (a) is simpler for a multi-node RWX setup, but it
may have security / policy implications depending on how the server
does authorization (especially with sec=sys). I think it’s worth
discussing what the safe and reasonable minimum should be.

In this case, UID/GID in the host node is not deterministic for the
process in the container due to user_namespaces(7), so we need to do
ID-mapping to unify UID/GID between container and file system. Also,
we likely need to consider both request and reply paths (e.g. GETATTR)
to keep the view consistent.

&gt; Mixing in AUTH_GSS and real idmapping will be where things get harder,
&gt; so let&#x27;s not worry about those cases for now.
I totally agree with Jeff. We can start a minimum PoC with AUTH_SYS.

&gt; With NFSv4 and the idmapper you wouldn&#x27;t need (or want) the kernel
&gt; idmapping to be used at all.  You would want the idmapper deamon to run
&gt; in the user-namespace and map from on-the-wire names to the appropriate
&gt; app-level uids.
&gt; This would mean that a given NFS mount would need to be an a given user
&gt; namespace.  Maybe that isn&#x27;t desired.
Neil, thank you for your comment. We initially expected it to be in
NFSv4. I totally agree with you and exactly our concern is how do we
make it consistent with idmapd(8). In the Kubernetes case, we cannot
pass CAP_SYS_ADMIN to allow pods to mount NFS directly, so mount will
be done on the host. As you mentioned, we think we can share a single
NFS export from multiple hosts and pods, so I think introducing
ID-mapping into the VFS layer (with referencing local id-mapping
table) is appropriate.

We can start by picking a small case. My concern was whether this
could violate NFS protocol or not, whether things can be done on the
client side or not, and this topic is suitable for dealing with this
as the VFS community. If things can be done on the client side, we can
cover existing NFS server implementations (e.g. OpenZFS, proprietary
appliances). I believe this can be applied to recent containerized
runtime environments, even this small working set.

Adding more context, Kubernetes and the container community actively
work on host isolation using the Linux user namespace feature.
Recently they experienced RCE vulnerabilities on container runtime but
it could be mitigated by host isolation using the user namespace
isolation [3]. Along with migrating the runtime environment to user
namespace, extending file system support will be worth discussing.

Kind regards,
Kohei

[1] https://kubernetes.io/docs/concepts/workloads/pods/user-namespaces/
[2] https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes
[3] https://lpc.events/event/19/contributions/2065/

</pre>
</details>
<div class="review-comment-signals">Signals: requested changes, discussed potential security implications</div>
</div>
</div>
</div>

    <footer>LKML Daily Activity Tracker</footer>
    <script>
    // When arriving via a date anchor (e.g. #2026-02-15 from a daily report),
    // scroll the anchor into view after a brief delay so layout is complete.
    (function () {
        var hash = window.location.hash;
        if (!hash) return;
        var target = document.getElementById(hash.slice(1));
        if (!target) return;
        setTimeout(function () {
            target.scrollIntoView({behavior: 'smooth', block: 'start'});
        }, 80);
    })();
    </script>
</body>
</html>