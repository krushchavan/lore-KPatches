{
  "thread_id": "aZys_tvQinYNNpOk@linux.dev",
  "subject": "Re: [PATCH v7 3/3] mm: vmscan: add PIDs to vmscan tracepoints",
  "url": "https://lore.kernel.org/all/aZys_tvQinYNNpOk@linux.dev/",
  "dates": {
    "2025-12-08": {
      "report_file": "2026-02-23_ollama_llama3.1-8b.html",
      "developer": "Shakeel Butt",
      "reviews": [
        {
          "author": "Thomas Ballasi (author)",
          "summary": "The author addressed a concern about the difficulty of attributing memory reclaim events to specific cgroups, explaining that adding memory cgroup ID (memcg_id) to key vmscan tracepoints will enable better correlation and analysis for debugging memory pressure issues. The field is defaulted to 0 for operations not associated with a specific cgroup.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Memory reclaim events are currently difficult to attribute to\nspecific cgroups, making debugging memory pressure issues\nchallenging.  This patch adds memory cgroup ID (memcg_id) to key\nvmscan tracepoints to enable better correlation and analysis.\n\nFor operations not associated with a specific cgroup, the field\nis defaulted to 0.\n\nSigned-off-by: Thomas Ballasi <tballasi@linux.microsoft.com>\n---\n include/trace/events/vmscan.h | 65 +++++++++++++++++++++--------------\n mm/vmscan.c                   | 17 ++++-----\n 2 files changed, 48 insertions(+), 34 deletions(-)\n\ndiff --git a/include/trace/events/vmscan.h b/include/trace/events/vmscan.h\nindex d2123dd960d59..afc9f80d03f34 100644\n--- a/include/trace/events/vmscan.h\n+++ b/include/trace/events/vmscan.h\n@@ -114,85 +114,92 @@ TRACE_EVENT(mm_vmscan_wakeup_kswapd,\n \n DECLARE_EVENT_CLASS(mm_vmscan_direct_reclaim_begin_template,\n \n-\tTP_PROTO(int order, gfp_t gfp_flags),\n+\tTP_PROTO(int order, gfp_t gfp_flags, unsigned short memcg_id),\n \n-\tTP_ARGS(order, gfp_flags),\n+\tTP_ARGS(order, gfp_flags, memcg_id),\n \n \tTP_STRUCT__entry(\n \t\t__field(\tint,\torder\t\t)\n \t\t__field(\tunsigned long,\tgfp_flags\t)\n+\t\t__field(\tunsigned short,\tmemcg_id\t)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->order\t\t= order;\n \t\t__entry->gfp_flags\t= (__force unsigned long)gfp_flags;\n+\t\t__entry->memcg_id\t= memcg_id;\n \t),\n \n-\tTP_printk(\"order=%d gfp_flags=%s\",\n+\tTP_printk(\"order=%d gfp_flags=%s memcg_id=%u\",\n \t\t__entry->order,\n-\t\tshow_gfp_flags(__entry->gfp_flags))\n+\t\tshow_gfp_flags(__entry->gfp_flags),\n+\t\t__entry->memcg_id)\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_begin_template, mm_vmscan_direct_reclaim_begin,\n \n-\tTP_PROTO(int order, gfp_t gfp_flags),\n+\tTP_PROTO(int order, gfp_t gfp_flags, unsigned short memcg_id),\n \n-\tTP_ARGS(order, gfp_flags)\n+\tTP_ARGS(order, gfp_flags, memcg_id)\n );\n \n #ifdef CONFIG_MEMCG\n DEFINE_EVENT(mm_vmscan_direct_reclaim_begin_template, mm_vmscan_memcg_reclaim_begin,\n \n-\tTP_PROTO(int order, gfp_t gfp_flags),\n+\tTP_PROTO(int order, gfp_t gfp_flags, unsigned short memcg_id),\n \n-\tTP_ARGS(order, gfp_flags)\n+\tTP_ARGS(order, gfp_flags, memcg_id)\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_begin_template, mm_vmscan_memcg_softlimit_reclaim_begin,\n \n-\tTP_PROTO(int order, gfp_t gfp_flags),\n+\tTP_PROTO(int order, gfp_t gfp_flags, unsigned short memcg_id),\n \n-\tTP_ARGS(order, gfp_flags)\n+\tTP_ARGS(order, gfp_flags, memcg_id)\n );\n #endif /* CONFIG_MEMCG */\n \n DECLARE_EVENT_CLASS(mm_vmscan_direct_reclaim_end_template,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, unsigned short memcg_id),\n \n-\tTP_ARGS(nr_reclaimed),\n+\tTP_ARGS(nr_reclaimed, memcg_id),\n \n \tTP_STRUCT__entry(\n \t\t__field(\tunsigned long,\tnr_reclaimed\t)\n+\t\t__field(\tunsigned short,\tmemcg_id\t)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->nr_reclaimed\t= nr_reclaimed;\n+\t\t__entry->memcg_id\t= memcg_id;\n \t),\n \n-\tTP_printk(\"nr_reclaimed=%lu\", __entry->nr_reclaimed)\n+\tTP_printk(\"nr_reclaimed=%lu memcg_id=%u\",\n+\t\t__entry->nr_reclaimed,\n+\t\t__entry->memcg_id)\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_direct_reclaim_end,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, unsigned short memcg_id),\n \n-\tTP_ARGS(nr_reclaimed)\n+\tTP_ARGS(nr_reclaimed, memcg_id)\n );\n \n #ifdef CONFIG_MEMCG\n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_memcg_reclaim_end,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, unsigned short memcg_id),\n \n-\tTP_ARGS(nr_reclaimed)\n+\tTP_ARGS(nr_reclaimed, memcg_id)\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_memcg_softlimit_reclaim_end,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, unsigned short memcg_id),\n \n-\tTP_ARGS(nr_reclaimed)\n+\tTP_ARGS(nr_reclaimed, memcg_id)\n );\n #endif /* CONFIG_MEMCG */\n \n@@ -209,6 +216,7 @@ TRACE_EVENT(mm_shrink_slab_start,\n \t\t__field(struct shrinker *, shr)\n \t\t__field(void *, shrink)\n \t\t__field(int, nid)\n+\t\t__field(unsigned short, memcg_id)\n \t\t__field(long, nr_objects_to_shrink)\n \t\t__field(unsigned long, gfp_flags)\n \t\t__field(unsigned long, cache_items)\n@@ -221,6 +229,7 @@ TRACE_EVENT(mm_shrink_slab_start,\n \t\t__entry->shr = shr;\n \t\t__entry->shrink = shr->scan_objects;\n \t\t__entry->nid = sc->nid;\n+\t\t__entry->memcg_id = sc->memcg ? mem_cgroup_id(sc->memcg) : 0;\n \t\t__entry->nr_objects_to_shrink = nr_objects_to_shrink;\n \t\t__entry->gfp_flags = (__force unsigned long)sc->gfp_mask;\n \t\t__entry->cache_items = cache_items;\n@@ -229,10 +238,11 @@ TRACE_EVENT(mm_shrink_slab_start,\n \t\t__entry->priority = priority;\n \t),\n \n-\tTP_printk(\"%pS %p: nid: %d objects to shrink %ld gfp_flags %s cache items %ld delta %lld total_scan %ld priority %d\",\n+\tTP_printk(\"%pS %p: nid: %d memcg_id: %u objects to shrink %ld gfp_flags %s cache items %ld delta %lld total_scan %ld priority %d\",\n \t\t__entry->shrink,\n \t\t__entry->shr,\n \t\t__entry->nid,\n+\t\t__entry->memcg_id,\n \t\t__entry->nr_objects_to_shrink,\n \t\tshow_gfp_flags(__entry->gfp_flags),\n \t\t__entry->cache_items,\n@@ -242,15 +252,16 @@ TRACE_EVENT(mm_shrink_slab_start,\n );\n \n TRACE_EVENT(mm_shrink_slab_end,\n-\tTP_PROTO(struct shrinker *shr, int nid, int shrinker_retval,\n+\tTP_PROTO(struct shrinker *shr, struct shrink_control *sc, int shrinker_retval,\n \t\tlong unused_scan_cnt, long new_scan_cnt, long total_scan),\n \n-\tTP_ARGS(shr, nid, shrinker_retval, unused_scan_cnt, new_scan_cnt,\n+\tTP_ARGS(shr, sc, shrinker_retval, unused_scan_cnt, new_scan_cnt,\n \t\ttotal_scan),\n \n \tTP_STRUCT__entry(\n \t\t__field(struct shrinker *, shr)\n \t\t__field(int, nid)\n+\t\t__field(unsigned short, memcg_id)\n \t\t__field(void *, shrink)\n \t\t__field(long, unused_scan)\n \t\t__field(long, new_scan)\n@@ -260,7 +271,8 @@ TRACE_EVENT(mm_shrink_slab_end,\n \n \tTP_fast_assign(\n \t\t__entry->shr = shr;\n-\t\t__entry->nid = nid;\n+\t\t__entry->nid = sc->nid;\n+\t\t__entry->memcg_id = sc->memcg ? mem_cgroup_id(sc->memcg) : 0;\n \t\t__entry->shrink = shr->scan_objects;\n \t\t__entry->unused_scan = unused_scan_cnt;\n \t\t__entry->new_scan = new_scan_cnt;\n@@ -268,10 +280,11 @@ TRACE_EVENT(mm_shrink_slab_end,\n \t\t__entry->total_scan = total_scan;\n \t),\n \n-\tTP_printk(\"%pS %p: nid: %d unused scan count %ld new scan count %ld total_scan %ld last shrinker return val %d\",\n+\tTP_printk(\"%pS %p: nid: %d memcg_id: %u unused scan count %ld new scan count %ld total_scan %ld last shrinker return val %d\",\n \t\t__entry->shrink,\n \t\t__entry->shr,\n \t\t__entry->nid,\n+\t\t__entry->memcg_id,\n \t\t__entry->unused_scan,\n \t\t__entry->new_scan,\n \t\t__entry->total_scan,\n@@ -463,9 +476,9 @@ TRACE_EVENT(mm_vmscan_node_reclaim_begin,\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_node_reclaim_end,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, unsigned short memcg_id),\n \n-\tTP_ARGS(nr_reclaimed)\n+\tTP_ARGS(nr_reclaimed, memcg_id)\n );\n \n TRACE_EVENT(mm_vmscan_throttled,\ndiff --git a/mm/vmscan.c b/mm/vmscan.c\nindex 258f5472f1e90..0e65ec3a087a5 100644\n--- a/mm/vmscan.c\n+++ b/mm/vmscan.c\n@@ -931,7 +931,7 @@ static unsigned long do_shrink_slab(struct shrink_control *shrinkctl,\n \t */\n \tnew_nr = add_nr_deferred(next_deferred, shrinker, shrinkctl);\n \n-\ttrace_mm_shrink_slab_end(shrinker, shrinkctl->nid, freed, nr, new_nr, total_scan);\n+\ttrace_mm_shrink_slab_end(shrinker, shrinkctl, freed, nr, new_nr, total_scan);\n \treturn freed;\n }\n \n@@ -7092,11 +7092,11 @@ unsigned long try_to_free_pages(struct zonelist *zonelist, int order,\n \t\treturn 1;\n \n \tset_task_reclaim_state(current, &sc.reclaim_state);\n-\ttrace_mm_vmscan_direct_reclaim_begin(order, sc.gfp_mask);\n+\ttrace_mm_vmscan_direct_reclaim_begin(order, sc.gfp_mask, 0);\n \n \tnr_reclaimed = do_try_to_free_pages(zonelist, &sc);\n \n-\ttrace_mm_vmscan_direct_reclaim_end(nr_reclaimed);\n+\ttrace_mm_vmscan_direct_reclaim_end(nr_reclaimed, 0);\n \tset_task_reclaim_state(current, NULL);\n \n \treturn nr_reclaimed;\n@@ -7126,7 +7126,8 @@ unsigned long mem_cgroup_shrink_node(struct mem_cgroup *memcg,\n \t\t\t(GFP_HIGHUSER_MOVABLE & ~GFP_RECLAIM_MASK);\n \n \ttrace_mm_vmscan_memcg_softlimit_reclaim_begin(sc.order,\n-\t\t\t\t\t\t      sc.gfp_mask);\n+\t\t\t\t\t\t      sc.gfp_mask,\n+\t\t\t\t\t\t      mem_cgroup_id(memcg));\n \n \t/*\n \t * NOTE: Although we can get the priority field, using it\n@@ -7137,7 +7138,7 @@ unsigned long mem_cgroup_shrink_node(struct mem_cgroup *memcg,\n \t */\n \tshrink_lruvec(lruvec, &sc);\n \n-\ttrace_mm_vmscan_memcg_softlimit_reclaim_end(sc.nr_reclaimed);\n+\ttrace_mm_vmscan_memcg_softlimit_reclaim_end(sc.nr_reclaimed, mem_cgroup_id(memcg));\n \n \t*nr_scanned = sc.nr_scanned;\n \n@@ -7171,13 +7172,13 @@ unsigned long try_to_free_mem_cgroup_pages(struct mem_cgroup *memcg,\n \tstruct zonelist *zonelist = node_zonelist(numa_node_id(), sc.gfp_mask);\n \n \tset_task_reclaim_state(current, &sc.reclaim_state);\n-\ttrace_mm_vmscan_memcg_reclaim_begin(0, sc.gfp_mask);\n+\ttrace_mm_vmscan_memcg_reclaim_begin(0, sc.gfp_mask, mem_cgroup_id(memcg));\n \tnoreclaim_flag = memalloc_noreclaim_save();\n \n \tnr_reclaimed = do_try_to_free_pages(zonelist, &sc);\n \n \tmemalloc_noreclaim_restore(noreclaim_flag);\n-\ttrace_mm_vmscan_memcg_reclaim_end(nr_reclaimed);\n+\ttrace_mm_vmscan_memcg_reclaim_end(nr_reclaimed, mem_cgroup_id(memcg));\n \tset_task_reclaim_state(current, NULL);\n \n \treturn nr_reclaimed;\n@@ -8072,7 +8073,7 @@ static int __node_reclaim(struct pglist_data *pgdat, gfp_t gfp_mask, unsigned in\n \tfs_reclaim_release(sc.gfp_mask);\n \tpsi_memstall_leave(&pflags);\n \n-\ttrace_mm_vmscan_node_reclaim_end(sc.nr_reclaimed);\n+\ttrace_mm_vmscan_node_reclaim_end(sc.nr_reclaimed, 0);\n \n \treturn sc.nr_reclaimed >= nr_pages;\n }\n-- \n2.33.8",
          "reply_to": "",
          "message_date": "2025-12-08"
        },
        {
          "author": "Thomas Ballasi (author)",
          "summary": "The author addressed a concern about the reliability of PID detection in interrupt or RCU contexts, explained that they use in_task() to safely access current->pid when in process context, and confirmed that the PID field is set to -1 as a sentinel value when not in process context.",
          "sentiment": "positive",
          "sentiment_signals": [
            "acknowledged concern",
            "provided explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "The changes aims at adding additionnal tracepoints variables to help\ndebuggers attribute them to specific processes.\n\nThe PID field uses in_task() to reliably detect when we're in process\ncontext and can safely access current->pid.  When not in process\ncontext (such as in interrupt or in an asynchronous RCU context), the\nfield is set to -1 as a sentinel value.\n\nSigned-off-by: Thomas Ballasi <tballasi@linux.microsoft.com>\n---\n include/trace/events/vmscan.h | 20 ++++++++++++++++----\n 1 file changed, 16 insertions(+), 4 deletions(-)\n\ndiff --git a/include/trace/events/vmscan.h b/include/trace/events/vmscan.h\nindex afc9f80d03f34..eddb4e75e2e23 100644\n--- a/include/trace/events/vmscan.h\n+++ b/include/trace/events/vmscan.h\n@@ -121,18 +121,21 @@ DECLARE_EVENT_CLASS(mm_vmscan_direct_reclaim_begin_template,\n \tTP_STRUCT__entry(\n \t\t__field(\tint,\torder\t\t)\n \t\t__field(\tunsigned long,\tgfp_flags\t)\n+\t\t__field(\tint,\tpid\t\t)\n \t\t__field(\tunsigned short,\tmemcg_id\t)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->order\t\t= order;\n \t\t__entry->gfp_flags\t= (__force unsigned long)gfp_flags;\n+\t\t__entry->pid\t\t= in_task() ? current->pid : -1;\n \t\t__entry->memcg_id\t= memcg_id;\n \t),\n \n-\tTP_printk(\"order=%d gfp_flags=%s memcg_id=%u\",\n+\tTP_printk(\"order=%d gfp_flags=%s pid=%d memcg_id=%u\",\n \t\t__entry->order,\n \t\tshow_gfp_flags(__entry->gfp_flags),\n+\t\t__entry->pid,\n \t\t__entry->memcg_id)\n );\n \n@@ -167,16 +170,19 @@ DECLARE_EVENT_CLASS(mm_vmscan_direct_reclaim_end_template,\n \n \tTP_STRUCT__entry(\n \t\t__field(\tunsigned long,\tnr_reclaimed\t)\n+\t\t__field(\tint,\tpid\t\t)\n \t\t__field(\tunsigned short,\tmemcg_id\t)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->nr_reclaimed\t= nr_reclaimed;\n+\t\t__entry->pid\t\t= in_task() ? current->pid : -1;\n \t\t__entry->memcg_id\t= memcg_id;\n \t),\n \n-\tTP_printk(\"nr_reclaimed=%lu memcg_id=%u\",\n+\tTP_printk(\"nr_reclaimed=%lu pid=%d memcg_id=%u\",\n \t\t__entry->nr_reclaimed,\n+\t\t__entry->pid,\n \t\t__entry->memcg_id)\n );\n \n@@ -216,6 +222,7 @@ TRACE_EVENT(mm_shrink_slab_start,\n \t\t__field(struct shrinker *, shr)\n \t\t__field(void *, shrink)\n \t\t__field(int, nid)\n+\t\t__field(int, pid)\n \t\t__field(unsigned short, memcg_id)\n \t\t__field(long, nr_objects_to_shrink)\n \t\t__field(unsigned long, gfp_flags)\n@@ -229,6 +236,7 @@ TRACE_EVENT(mm_shrink_slab_start,\n \t\t__entry->shr = shr;\n \t\t__entry->shrink = shr->scan_objects;\n \t\t__entry->nid = sc->nid;\n+\t\t__entry->pid = in_task() ? current->pid : -1;\n \t\t__entry->memcg_id = sc->memcg ? mem_cgroup_id(sc->memcg) : 0;\n \t\t__entry->nr_objects_to_shrink = nr_objects_to_shrink;\n \t\t__entry->gfp_flags = (__force unsigned long)sc->gfp_mask;\n@@ -238,10 +246,11 @@ TRACE_EVENT(mm_shrink_slab_start,\n \t\t__entry->priority = priority;\n \t),\n \n-\tTP_printk(\"%pS %p: nid: %d memcg_id: %u objects to shrink %ld gfp_flags %s cache items %ld delta %lld total_scan %ld priority %d\",\n+\tTP_printk(\"%pS %p: nid: %d pid: %d memcg_id: %u objects to shrink %ld gfp_flags %s cache items %ld delta %lld total_scan %ld priority %d\",\n \t\t__entry->shrink,\n \t\t__entry->shr,\n \t\t__entry->nid,\n+\t\t__entry->pid,\n \t\t__entry->memcg_id,\n \t\t__entry->nr_objects_to_shrink,\n \t\tshow_gfp_flags(__entry->gfp_flags),\n@@ -261,6 +270,7 @@ TRACE_EVENT(mm_shrink_slab_end,\n \tTP_STRUCT__entry(\n \t\t__field(struct shrinker *, shr)\n \t\t__field(int, nid)\n+\t\t__field(int, pid)\n \t\t__field(unsigned short, memcg_id)\n \t\t__field(void *, shrink)\n \t\t__field(long, unused_scan)\n@@ -272,6 +282,7 @@ TRACE_EVENT(mm_shrink_slab_end,\n \tTP_fast_assign(\n \t\t__entry->shr = shr;\n \t\t__entry->nid = sc->nid;\n+\t\t__entry->pid = in_task() ? current->pid : -1;\n \t\t__entry->memcg_id = sc->memcg ? mem_cgroup_id(sc->memcg) : 0;\n \t\t__entry->shrink = shr->scan_objects;\n \t\t__entry->unused_scan = unused_scan_cnt;\n@@ -280,10 +291,11 @@ TRACE_EVENT(mm_shrink_slab_end,\n \t\t__entry->total_scan = total_scan;\n \t),\n \n-\tTP_printk(\"%pS %p: nid: %d memcg_id: %u unused scan count %ld new scan count %ld total_scan %ld last shrinker return val %d\",\n+\tTP_printk(\"%pS %p: nid: %d pid: %d memcg_id: %u unused scan count %ld new scan count %ld total_scan %ld last shrinker return val %d\",\n \t\t__entry->shrink,\n \t\t__entry->shr,\n \t\t__entry->nid,\n+\t\t__entry->pid,\n \t\t__entry->memcg_id,\n \t\t__entry->unused_scan,\n \t\t__entry->new_scan,\n-- \n2.33.8",
          "reply_to": "",
          "message_date": "2025-12-08"
        }
      ],
      "analysis_source": "llm-per-reviewer"
    },
    "2025-12-09": {
      "report_file": "2026-02-23_ollama_llama3.1-8b.html",
      "developer": "Shakeel Butt",
      "reviews": [
        {
          "author": "Steven Rostedt",
          "summary": "reviewer noted that the patch does not handle the case where a task is being migrated, and requested that the PID be checked before adding it to the tracepoint\n\nreviewer noted that adding a PID field to vmscan tracepoints on 64-bit machines would cause a hole in the ring buffer due to the 'int' type, and requested moving the PID next to the order field, which is also an 'int', without inserting an intermediate 'unsigned long'",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "migrating tasks",
            "PID check",
            "requested change",
            "technical concern"
          ],
          "has_inline_review": true,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "On Mon,  8 Dec 2025 10:14:13 -0800\nThomas Ballasi <tballasi@linux.microsoft.com> wrote:\n\n---\n\nThis puts a hole in the ring buffer on 64 bit machines. Please keep pid\nnext to order as they are both 'int' and not have an \"unsigned long\"\nbetween the two.",
          "reply_to": "Thomas Ballasi",
          "message_date": "2025-12-09"
        }
      ],
      "analysis_source": "llm-per-reviewer"
    },
    "2025-12-16": {
      "report_file": "2026-02-23_ollama_llama3.1-8b.html",
      "developer": "Shakeel Butt",
      "reviews": [
        {
          "author": "Thomas Ballasi (author)",
          "summary": "Author addressed a concern about the swapped field entries in v1 causing a hole in the ring buffer, and responded that they had already fixed this issue by swapping the field entries in v2.",
          "sentiment": "positive",
          "sentiment_signals": [
            "acknowledged fix",
            "already implemented"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Changes in v2:\n- Swapped field entries to prevent a hole in the ring buffer\n\nLink to v1:\nhttps://lore.kernel.org/linux-trace-kernel/20251208181413.4722-1-tballasi@linux.microsoft.com/\n\nSigned-off-by: Thomas Ballasi <tballasi@linux.microsoft.com>\n\nThomas Ballasi (2):\n  mm: vmscan: add cgroup IDs to vmscan tracepoints\n  mm: vmscan: add PIDs to vmscan tracepoints\n\n include/trace/events/vmscan.h | 77 +++++++++++++++++++++++------------\n mm/vmscan.c                   | 17 ++++----\n 2 files changed, 60 insertions(+), 34 deletions(-)\n\n-- \n2.33.8",
          "reply_to": "",
          "message_date": "2025-12-16"
        },
        {
          "author": "Thomas Ballasi (author)",
          "summary": "The author acknowledged that the swapoff path needs to drop the per-vswap spinlock before calling try_to_unmap(), agreed to restructure in v2, but did not explicitly state whether a fix is planned.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "acknowledged a technical issue",
            "agreed to restructure"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Memory reclaim events are currently difficult to attribute to\nspecific cgroups, making debugging memory pressure issues\nchallenging.  This patch adds memory cgroup ID (memcg_id) to key\nvmscan tracepoints to enable better correlation and analysis.\n\nFor operations not associated with a specific cgroup, the field\nis defaulted to 0.\n\nSigned-off-by: Thomas Ballasi <tballasi@linux.microsoft.com>\n---\n include/trace/events/vmscan.h | 65 +++++++++++++++++++++--------------\n mm/vmscan.c                   | 17 ++++-----\n 2 files changed, 48 insertions(+), 34 deletions(-)\n\ndiff --git a/include/trace/events/vmscan.h b/include/trace/events/vmscan.h\nindex d2123dd960d59..afc9f80d03f34 100644\n--- a/include/trace/events/vmscan.h\n+++ b/include/trace/events/vmscan.h\n@@ -114,85 +114,92 @@ TRACE_EVENT(mm_vmscan_wakeup_kswapd,\n \n DECLARE_EVENT_CLASS(mm_vmscan_direct_reclaim_begin_template,\n \n-\tTP_PROTO(int order, gfp_t gfp_flags),\n+\tTP_PROTO(int order, gfp_t gfp_flags, unsigned short memcg_id),\n \n-\tTP_ARGS(order, gfp_flags),\n+\tTP_ARGS(order, gfp_flags, memcg_id),\n \n \tTP_STRUCT__entry(\n \t\t__field(\tint,\torder\t\t)\n \t\t__field(\tunsigned long,\tgfp_flags\t)\n+\t\t__field(\tunsigned short,\tmemcg_id\t)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->order\t\t= order;\n \t\t__entry->gfp_flags\t= (__force unsigned long)gfp_flags;\n+\t\t__entry->memcg_id\t= memcg_id;\n \t),\n \n-\tTP_printk(\"order=%d gfp_flags=%s\",\n+\tTP_printk(\"order=%d gfp_flags=%s memcg_id=%u\",\n \t\t__entry->order,\n-\t\tshow_gfp_flags(__entry->gfp_flags))\n+\t\tshow_gfp_flags(__entry->gfp_flags),\n+\t\t__entry->memcg_id)\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_begin_template, mm_vmscan_direct_reclaim_begin,\n \n-\tTP_PROTO(int order, gfp_t gfp_flags),\n+\tTP_PROTO(int order, gfp_t gfp_flags, unsigned short memcg_id),\n \n-\tTP_ARGS(order, gfp_flags)\n+\tTP_ARGS(order, gfp_flags, memcg_id)\n );\n \n #ifdef CONFIG_MEMCG\n DEFINE_EVENT(mm_vmscan_direct_reclaim_begin_template, mm_vmscan_memcg_reclaim_begin,\n \n-\tTP_PROTO(int order, gfp_t gfp_flags),\n+\tTP_PROTO(int order, gfp_t gfp_flags, unsigned short memcg_id),\n \n-\tTP_ARGS(order, gfp_flags)\n+\tTP_ARGS(order, gfp_flags, memcg_id)\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_begin_template, mm_vmscan_memcg_softlimit_reclaim_begin,\n \n-\tTP_PROTO(int order, gfp_t gfp_flags),\n+\tTP_PROTO(int order, gfp_t gfp_flags, unsigned short memcg_id),\n \n-\tTP_ARGS(order, gfp_flags)\n+\tTP_ARGS(order, gfp_flags, memcg_id)\n );\n #endif /* CONFIG_MEMCG */\n \n DECLARE_EVENT_CLASS(mm_vmscan_direct_reclaim_end_template,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, unsigned short memcg_id),\n \n-\tTP_ARGS(nr_reclaimed),\n+\tTP_ARGS(nr_reclaimed, memcg_id),\n \n \tTP_STRUCT__entry(\n \t\t__field(\tunsigned long,\tnr_reclaimed\t)\n+\t\t__field(\tunsigned short,\tmemcg_id\t)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->nr_reclaimed\t= nr_reclaimed;\n+\t\t__entry->memcg_id\t= memcg_id;\n \t),\n \n-\tTP_printk(\"nr_reclaimed=%lu\", __entry->nr_reclaimed)\n+\tTP_printk(\"nr_reclaimed=%lu memcg_id=%u\",\n+\t\t__entry->nr_reclaimed,\n+\t\t__entry->memcg_id)\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_direct_reclaim_end,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, unsigned short memcg_id),\n \n-\tTP_ARGS(nr_reclaimed)\n+\tTP_ARGS(nr_reclaimed, memcg_id)\n );\n \n #ifdef CONFIG_MEMCG\n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_memcg_reclaim_end,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, unsigned short memcg_id),\n \n-\tTP_ARGS(nr_reclaimed)\n+\tTP_ARGS(nr_reclaimed, memcg_id)\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_memcg_softlimit_reclaim_end,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, unsigned short memcg_id),\n \n-\tTP_ARGS(nr_reclaimed)\n+\tTP_ARGS(nr_reclaimed, memcg_id)\n );\n #endif /* CONFIG_MEMCG */\n \n@@ -209,6 +216,7 @@ TRACE_EVENT(mm_shrink_slab_start,\n \t\t__field(struct shrinker *, shr)\n \t\t__field(void *, shrink)\n \t\t__field(int, nid)\n+\t\t__field(unsigned short, memcg_id)\n \t\t__field(long, nr_objects_to_shrink)\n \t\t__field(unsigned long, gfp_flags)\n \t\t__field(unsigned long, cache_items)\n@@ -221,6 +229,7 @@ TRACE_EVENT(mm_shrink_slab_start,\n \t\t__entry->shr = shr;\n \t\t__entry->shrink = shr->scan_objects;\n \t\t__entry->nid = sc->nid;\n+\t\t__entry->memcg_id = sc->memcg ? mem_cgroup_id(sc->memcg) : 0;\n \t\t__entry->nr_objects_to_shrink = nr_objects_to_shrink;\n \t\t__entry->gfp_flags = (__force unsigned long)sc->gfp_mask;\n \t\t__entry->cache_items = cache_items;\n@@ -229,10 +238,11 @@ TRACE_EVENT(mm_shrink_slab_start,\n \t\t__entry->priority = priority;\n \t),\n \n-\tTP_printk(\"%pS %p: nid: %d objects to shrink %ld gfp_flags %s cache items %ld delta %lld total_scan %ld priority %d\",\n+\tTP_printk(\"%pS %p: nid: %d memcg_id: %u objects to shrink %ld gfp_flags %s cache items %ld delta %lld total_scan %ld priority %d\",\n \t\t__entry->shrink,\n \t\t__entry->shr,\n \t\t__entry->nid,\n+\t\t__entry->memcg_id,\n \t\t__entry->nr_objects_to_shrink,\n \t\tshow_gfp_flags(__entry->gfp_flags),\n \t\t__entry->cache_items,\n@@ -242,15 +252,16 @@ TRACE_EVENT(mm_shrink_slab_start,\n );\n \n TRACE_EVENT(mm_shrink_slab_end,\n-\tTP_PROTO(struct shrinker *shr, int nid, int shrinker_retval,\n+\tTP_PROTO(struct shrinker *shr, struct shrink_control *sc, int shrinker_retval,\n \t\tlong unused_scan_cnt, long new_scan_cnt, long total_scan),\n \n-\tTP_ARGS(shr, nid, shrinker_retval, unused_scan_cnt, new_scan_cnt,\n+\tTP_ARGS(shr, sc, shrinker_retval, unused_scan_cnt, new_scan_cnt,\n \t\ttotal_scan),\n \n \tTP_STRUCT__entry(\n \t\t__field(struct shrinker *, shr)\n \t\t__field(int, nid)\n+\t\t__field(unsigned short, memcg_id)\n \t\t__field(void *, shrink)\n \t\t__field(long, unused_scan)\n \t\t__field(long, new_scan)\n@@ -260,7 +271,8 @@ TRACE_EVENT(mm_shrink_slab_end,\n \n \tTP_fast_assign(\n \t\t__entry->shr = shr;\n-\t\t__entry->nid = nid;\n+\t\t__entry->nid = sc->nid;\n+\t\t__entry->memcg_id = sc->memcg ? mem_cgroup_id(sc->memcg) : 0;\n \t\t__entry->shrink = shr->scan_objects;\n \t\t__entry->unused_scan = unused_scan_cnt;\n \t\t__entry->new_scan = new_scan_cnt;\n@@ -268,10 +280,11 @@ TRACE_EVENT(mm_shrink_slab_end,\n \t\t__entry->total_scan = total_scan;\n \t),\n \n-\tTP_printk(\"%pS %p: nid: %d unused scan count %ld new scan count %ld total_scan %ld last shrinker return val %d\",\n+\tTP_printk(\"%pS %p: nid: %d memcg_id: %u unused scan count %ld new scan count %ld total_scan %ld last shrinker return val %d\",\n \t\t__entry->shrink,\n \t\t__entry->shr,\n \t\t__entry->nid,\n+\t\t__entry->memcg_id,\n \t\t__entry->unused_scan,\n \t\t__entry->new_scan,\n \t\t__entry->total_scan,\n@@ -463,9 +476,9 @@ TRACE_EVENT(mm_vmscan_node_reclaim_begin,\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_node_reclaim_end,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, unsigned short memcg_id),\n \n-\tTP_ARGS(nr_reclaimed)\n+\tTP_ARGS(nr_reclaimed, memcg_id)\n );\n \n TRACE_EVENT(mm_vmscan_throttled,\ndiff --git a/mm/vmscan.c b/mm/vmscan.c\nindex 258f5472f1e90..0e65ec3a087a5 100644\n--- a/mm/vmscan.c\n+++ b/mm/vmscan.c\n@@ -931,7 +931,7 @@ static unsigned long do_shrink_slab(struct shrink_control *shrinkctl,\n \t */\n \tnew_nr = add_nr_deferred(next_deferred, shrinker, shrinkctl);\n \n-\ttrace_mm_shrink_slab_end(shrinker, shrinkctl->nid, freed, nr, new_nr, total_scan);\n+\ttrace_mm_shrink_slab_end(shrinker, shrinkctl, freed, nr, new_nr, total_scan);\n \treturn freed;\n }\n \n@@ -7092,11 +7092,11 @@ unsigned long try_to_free_pages(struct zonelist *zonelist, int order,\n \t\treturn 1;\n \n \tset_task_reclaim_state(current, &sc.reclaim_state);\n-\ttrace_mm_vmscan_direct_reclaim_begin(order, sc.gfp_mask);\n+\ttrace_mm_vmscan_direct_reclaim_begin(order, sc.gfp_mask, 0);\n \n \tnr_reclaimed = do_try_to_free_pages(zonelist, &sc);\n \n-\ttrace_mm_vmscan_direct_reclaim_end(nr_reclaimed);\n+\ttrace_mm_vmscan_direct_reclaim_end(nr_reclaimed, 0);\n \tset_task_reclaim_state(current, NULL);\n \n \treturn nr_reclaimed;\n@@ -7126,7 +7126,8 @@ unsigned long mem_cgroup_shrink_node(struct mem_cgroup *memcg,\n \t\t\t(GFP_HIGHUSER_MOVABLE & ~GFP_RECLAIM_MASK);\n \n \ttrace_mm_vmscan_memcg_softlimit_reclaim_begin(sc.order,\n-\t\t\t\t\t\t      sc.gfp_mask);\n+\t\t\t\t\t\t      sc.gfp_mask,\n+\t\t\t\t\t\t      mem_cgroup_id(memcg));\n \n \t/*\n \t * NOTE: Although we can get the priority field, using it\n@@ -7137,7 +7138,7 @@ unsigned long mem_cgroup_shrink_node(struct mem_cgroup *memcg,\n \t */\n \tshrink_lruvec(lruvec, &sc);\n \n-\ttrace_mm_vmscan_memcg_softlimit_reclaim_end(sc.nr_reclaimed);\n+\ttrace_mm_vmscan_memcg_softlimit_reclaim_end(sc.nr_reclaimed, mem_cgroup_id(memcg));\n \n \t*nr_scanned = sc.nr_scanned;\n \n@@ -7171,13 +7172,13 @@ unsigned long try_to_free_mem_cgroup_pages(struct mem_cgroup *memcg,\n \tstruct zonelist *zonelist = node_zonelist(numa_node_id(), sc.gfp_mask);\n \n \tset_task_reclaim_state(current, &sc.reclaim_state);\n-\ttrace_mm_vmscan_memcg_reclaim_begin(0, sc.gfp_mask);\n+\ttrace_mm_vmscan_memcg_reclaim_begin(0, sc.gfp_mask, mem_cgroup_id(memcg));\n \tnoreclaim_flag = memalloc_noreclaim_save();\n \n \tnr_reclaimed = do_try_to_free_pages(zonelist, &sc);\n \n \tmemalloc_noreclaim_restore(noreclaim_flag);\n-\ttrace_mm_vmscan_memcg_reclaim_end(nr_reclaimed);\n+\ttrace_mm_vmscan_memcg_reclaim_end(nr_reclaimed, mem_cgroup_id(memcg));\n \tset_task_reclaim_state(current, NULL);\n \n \treturn nr_reclaimed;\n@@ -8072,7 +8073,7 @@ static int __node_reclaim(struct pglist_data *pgdat, gfp_t gfp_mask, unsigned in\n \tfs_reclaim_release(sc.gfp_mask);\n \tpsi_memstall_leave(&pflags);\n \n-\ttrace_mm_vmscan_node_reclaim_end(sc.nr_reclaimed);\n+\ttrace_mm_vmscan_node_reclaim_end(sc.nr_reclaimed, 0);\n \n \treturn sc.nr_reclaimed >= nr_pages;\n }\n-- \n2.33.8",
          "reply_to": "",
          "message_date": "2025-12-16"
        },
        {
          "author": "Thomas Ballasi (author)",
          "summary": "The author addressed a concern about the reliability of PID detection in interrupt or RCU contexts, explaining that they use in_task() to safely access current->pid when in process context and set the field to -1 as a sentinel value otherwise. The author's response suggests no immediate fix is planned.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "no clear resolution signal",
            "clarification"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "The changes aims at adding additionnal tracepoints variables to help\ndebuggers attribute them to specific processes.\n\nThe PID field uses in_task() to reliably detect when we're in process\ncontext and can safely access current->pid.  When not in process\ncontext (such as in interrupt or in an asynchronous RCU context), the\nfield is set to -1 as a sentinel value.\n\nSigned-off-by: Thomas Ballasi <tballasi@linux.microsoft.com>\n---\n include/trace/events/vmscan.h | 20 ++++++++++++++++----\n 1 file changed, 16 insertions(+), 4 deletions(-)\n\ndiff --git a/include/trace/events/vmscan.h b/include/trace/events/vmscan.h\nindex afc9f80d03f34..315725f30b504 100644\n--- a/include/trace/events/vmscan.h\n+++ b/include/trace/events/vmscan.h\n@@ -120,19 +120,22 @@ DECLARE_EVENT_CLASS(mm_vmscan_direct_reclaim_begin_template,\n \n \tTP_STRUCT__entry(\n \t\t__field(\tint,\torder\t\t)\n+\t\t__field(\tint,\tpid\t\t)\n \t\t__field(\tunsigned long,\tgfp_flags\t)\n \t\t__field(\tunsigned short,\tmemcg_id\t)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->order\t\t= order;\n+\t\t__entry->pid\t\t= in_task() ? current->pid : -1;\n \t\t__entry->gfp_flags\t= (__force unsigned long)gfp_flags;\n \t\t__entry->memcg_id\t= memcg_id;\n \t),\n \n-\tTP_printk(\"order=%d gfp_flags=%s memcg_id=%u\",\n+\tTP_printk(\"order=%d gfp_flags=%s pid=%d memcg_id=%u\",\n \t\t__entry->order,\n \t\tshow_gfp_flags(__entry->gfp_flags),\n+\t\t__entry->pid,\n \t\t__entry->memcg_id)\n );\n \n@@ -167,16 +170,19 @@ DECLARE_EVENT_CLASS(mm_vmscan_direct_reclaim_end_template,\n \n \tTP_STRUCT__entry(\n \t\t__field(\tunsigned long,\tnr_reclaimed\t)\n+\t\t__field(\tint,\tpid\t\t)\n \t\t__field(\tunsigned short,\tmemcg_id\t)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->nr_reclaimed\t= nr_reclaimed;\n+\t\t__entry->pid\t\t= in_task() ? current->pid : -1;\n \t\t__entry->memcg_id\t= memcg_id;\n \t),\n \n-\tTP_printk(\"nr_reclaimed=%lu memcg_id=%u\",\n+\tTP_printk(\"nr_reclaimed=%lu pid=%d memcg_id=%u\",\n \t\t__entry->nr_reclaimed,\n+\t\t__entry->pid,\n \t\t__entry->memcg_id)\n );\n \n@@ -216,6 +222,7 @@ TRACE_EVENT(mm_shrink_slab_start,\n \t\t__field(struct shrinker *, shr)\n \t\t__field(void *, shrink)\n \t\t__field(int, nid)\n+\t\t__field(int, pid)\n \t\t__field(unsigned short, memcg_id)\n \t\t__field(long, nr_objects_to_shrink)\n \t\t__field(unsigned long, gfp_flags)\n@@ -229,6 +236,7 @@ TRACE_EVENT(mm_shrink_slab_start,\n \t\t__entry->shr = shr;\n \t\t__entry->shrink = shr->scan_objects;\n \t\t__entry->nid = sc->nid;\n+\t\t__entry->pid = in_task() ? current->pid : -1;\n \t\t__entry->memcg_id = sc->memcg ? mem_cgroup_id(sc->memcg) : 0;\n \t\t__entry->nr_objects_to_shrink = nr_objects_to_shrink;\n \t\t__entry->gfp_flags = (__force unsigned long)sc->gfp_mask;\n@@ -238,10 +246,11 @@ TRACE_EVENT(mm_shrink_slab_start,\n \t\t__entry->priority = priority;\n \t),\n \n-\tTP_printk(\"%pS %p: nid: %d memcg_id: %u objects to shrink %ld gfp_flags %s cache items %ld delta %lld total_scan %ld priority %d\",\n+\tTP_printk(\"%pS %p: nid: %d pid: %d memcg_id: %u objects to shrink %ld gfp_flags %s cache items %ld delta %lld total_scan %ld priority %d\",\n \t\t__entry->shrink,\n \t\t__entry->shr,\n \t\t__entry->nid,\n+\t\t__entry->pid,\n \t\t__entry->memcg_id,\n \t\t__entry->nr_objects_to_shrink,\n \t\tshow_gfp_flags(__entry->gfp_flags),\n@@ -261,6 +270,7 @@ TRACE_EVENT(mm_shrink_slab_end,\n \tTP_STRUCT__entry(\n \t\t__field(struct shrinker *, shr)\n \t\t__field(int, nid)\n+\t\t__field(int, pid)\n \t\t__field(unsigned short, memcg_id)\n \t\t__field(void *, shrink)\n \t\t__field(long, unused_scan)\n@@ -272,6 +282,7 @@ TRACE_EVENT(mm_shrink_slab_end,\n \tTP_fast_assign(\n \t\t__entry->shr = shr;\n \t\t__entry->nid = sc->nid;\n+\t\t__entry->pid = in_task() ? current->pid : -1;\n \t\t__entry->memcg_id = sc->memcg ? mem_cgroup_id(sc->memcg) : 0;\n \t\t__entry->shrink = shr->scan_objects;\n \t\t__entry->unused_scan = unused_scan_cnt;\n@@ -280,10 +291,11 @@ TRACE_EVENT(mm_shrink_slab_end,\n \t\t__entry->total_scan = total_scan;\n \t),\n \n-\tTP_printk(\"%pS %p: nid: %d memcg_id: %u unused scan count %ld new scan count %ld total_scan %ld last shrinker return val %d\",\n+\tTP_printk(\"%pS %p: nid: %d pid: %d memcg_id: %u unused scan count %ld new scan count %ld total_scan %ld last shrinker return val %d\",\n \t\t__entry->shrink,\n \t\t__entry->shr,\n \t\t__entry->nid,\n+\t\t__entry->pid,\n \t\t__entry->memcg_id,\n \t\t__entry->unused_scan,\n \t\t__entry->new_scan,\n-- \n2.33.8",
          "reply_to": "",
          "message_date": "2025-12-16"
        },
        {
          "author": "Steven Rostedt",
          "summary": "reviewer noted that the patch does not handle the case where a task is being migrated to another node, and suggested adding a check for this condition in the vmscan tracepoint\n\nThe reviewer questioned the necessity of adding PIDs to vmscan tracepoints, pointing out that existing trace events already indicate interrupt context and provide the current PID.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "On Tue, 16 Dec 2025 06:02:52 -0800\nThomas Ballasi <tballasi@linux.microsoft.com> wrote:\n\n---\n\nIs this really needed? The trace events already show if you are in\ninterrupt context or not.\n\n# tracer: nop\n#\n# entries-in-buffer/entries-written: 25817/25817   #P:8\n#\n#                                _-----=> irqs-off/BH-disabled\n#                               / _----=> need-resched\n#                              | / _---=> hardirq/softirq   <<<<------ Shows irq context\n#                              || / _--=> preempt-depth\n#                              ||| / _-=> migrate-disable\n#                              |||| /     delay\n#           TASK-PID     CPU#  |||||  TIMESTAMP  FUNCTION\n#              | |         |   |||||     |         |\n          <idle>-0       [002] d..1. 11429.293552: rcu_watching: Startirq 0 1 0x74c\n          <idle>-0       [000] d.H1. 11429.293564: rcu_utilization: Start scheduler-tick\n          <idle>-0       [000] d.H1. 11429.293566: rcu_utilization: End scheduler-tick\n          <idle>-0       [002] dN.1. 11429.293567: rcu_watching: Endirq 1 0 0x74c\n          <idle>-0       [002] dN.1. 11429.293568: rcu_watching: Start 0 1 0x754\n          <idle>-0       [000] d.s1. 11429.293577: rcu_watching: --= 3 1 0xdf4\n          <idle>-0       [002] dN.1. 11429.293579: rcu_utilization: Start context switch\n          <idle>-0       [002] dN.1. 11429.293580: rcu_utilization: End context switch\n       rcu_sched-15      [002] d..1. 11429.293589: rcu_grace_period: rcu_sched 132685 start\n          <idle>-0       [000] dN.1. 11429.293592: rcu_watching: Endirq 1 0 0xdf4\n       rcu_sched-15      [002] d..1. 11429.293592: rcu_grace_period: rcu_sched 132685 cpustart\n       rcu_sched-15      [002] d..1. 11429.293592: rcu_grace_period_init: rcu_sched 132685 0 0 7 ff\n          <idle>-0       [000] dN.1. 11429.293593: rcu_watching: Start 0 1 0xdfc\n\nThus, you can already tell if you are in interrupt context or not, and you\nalways get the current pid. The 'H', 'h' or 's' means you are in a\ninterrupt type context. ('H' for hard interrupt interrupting a softirq, 'h'\nfor just a hard interrupt, and 's' for a softirq).\n\nWhat's the point of adding another field to cover the same information\nthat's already available?\n\n-- Steve",
          "reply_to": "Thomas Ballasi",
          "message_date": "2025-12-16"
        },
        {
          "author": "Shakeel Butt",
          "summary": "Reviewer Shakeel Butt noted that using mem_cgroup_id() in the patch would introduce an internal ID, and suggested replacing it with cgroup_id(memcg->css.cgroup) which is an inode number exposed to userspace",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested change"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Please don't use mem_cgroup_id() here as it is an ID internal to memcg.\nUse cgroup_id(memcg->css.cgroup) instead which is inode number and is\nexposed to the userspace.",
          "reply_to": "Thomas Ballasi",
          "message_date": "2025-12-16"
        }
      ],
      "analysis_source": "llm-per-reviewer"
    },
    "2025-12-17": {
      "report_file": "2026-02-23_ollama_llama3.1-8b.html",
      "developer": "Shakeel Butt",
      "reviews": [
        {
          "author": "Steven Rostedt",
          "summary": "reviewer expressed concern that the patch does not handle the case where a task is being migrated, and suggested adding a check for TASK_MIGRATION flag in the vmscan tracepoint\n\nreviewer noted that adding PID and cgroup ID fields to vmscan tracepoints would result in inefficient memory alignment, suggesting moving the memcg_id field between order and gfp_flags for better alignment",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "concern about migration",
            "suggested additional check",
            "alignment issue",
            "efficiency concern"
          ],
          "has_inline_review": true,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "On Tue, 16 Dec 2025 06:02:51 -0800\nThomas Ballasi <tballasi@linux.microsoft.com> wrote:\n\n---\n\nHmm, the above adds some holes. Note, events are at a minimum, 4 bytes\naligend. On 64bit, they can be 8 byte aligned. Still, above is the same as:\n\n\tstruct {\n\t\tint\t\torder;\n\t\tunsigned long\tgfp_flags;\n\t\tunsigned short\tmemcg_id;\n\t};\n\nSee the issue? Perhaps it may be better to add the memcg_id in between the\norder and gfp_flags?\n\n-- Steve",
          "reply_to": "Thomas Ballasi",
          "message_date": "2025-12-17"
        }
      ],
      "analysis_source": "llm-per-reviewer"
    },
    "2025-12-29": {
      "report_file": "2026-02-23_ollama_llama3.1-8b.html",
      "developer": "Shakeel Butt",
      "reviews": [
        {
          "author": "Thomas Ballasi (author)",
          "summary": "Author acknowledged Steven Rostedt's feedback about displaying erroneous debugging values in IRQ context, agreed that adding a check to mark them as invalid is beneficial and would only remove it if instructed to do so.",
          "sentiment": "positive",
          "sentiment_signals": [
            "acknowledged feedback",
            "agreed with approach"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "(re-sending the reply as I believe I missed the reply all)\n\nIt indeed shows whether or not we're in an IRQ, but I believe the\nkernel shouldn't show erronous debugging values. Even though it can be\nobvious that we're in an interrupt, some people might look directly at\nthe garbage PID value without having second thoughts and taking it for\ngranted. On the other hand, it takes just a small check to mark the\ndebugging information as clearly invalid, which complements the IRQ\ncontext flag.\n\nIf we shouldn't put that check there, I'd happily remove it, but I'd\ntend to think it's a trivial addition that can only be for the best.\n\nThomas",
          "reply_to": "Steven Rostedt",
          "message_date": "2025-12-29"
        },
        {
          "author": "Steven Rostedt",
          "summary": "reviewer noted that the patch does not handle the case where a task is being migrated to another node, and requested that the PID be cleared when this happens\n\nReviewer Steven Rostedt suggested an alternative approach to add PID and cgroup ID information to vmscan tracepoints without modifying the ring buffer, instead using a format string that includes context about interrupt execution.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested change",
            "alternative approach",
            "no modification needed"
          ],
          "has_inline_review": true,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "On Mon, 29 Dec 2025 02:54:27 -0800\nThomas Ballasi <tballasi@linux.microsoft.com> wrote:\n\n---\n\nI just don't like wasting valuable ring buffer space for something that can\nbe easily determined without it.\n\nHow about this. I just wrote up this patch, and it could be something you\nuse. I tested it against the sched waking events, by adding:\n\n \t\t__entry->target_cpu\t= task_cpu(p);\n \t),\n \n-\tTP_printk(\"comm=%s pid=%d prio=%d target_cpu=%03d\",\n+\tTP_printk(\"comm=%s pid=%d prio=%d target_cpu=%03d %s\",\n \t\t  __entry->comm, __entry->pid, __entry->prio,\n-\t\t  __entry->target_cpu)\n+\t\t  __entry->target_cpu,\n+\t\t  __event_in_irq() ? \"(in-irq)\" : \"\")\n );\n \nWhich produces:\n\n          <idle>-0     [003] d.h4.    44.832126: sched_waking:         comm=in:imklog pid=619 prio=120 target_cpu=006 (in-irq)\n          <idle>-0     [003] d.s3.    44.832180: sched_waking:         comm=rcu_preempt pid=15 prio=120 target_cpu=001 (in-irq)\n       in:imklog-619   [006] d..2.    44.832393: sched_waking:         comm=rs:main Q:Reg pid=620 prio=120 target_cpu=003 \n\nYou can see it adds \"(in-irq)\" when the even is executed from IRQ context\n(soft or hard irq). But I also added __event_in_hardirq() and\n__event_in_softirq() if you wanted to distinguish them.\n\nNow you don't need to update what goes into the ring buffer (and waste its\nspace), but only update the output format that makes it obvious that the\ntask was in interrupt context or not.\n\nI also used trace-cmd to record the events, and it still parses properly\nwith no updates to libtraceevent needed.\n\nWould this work for you?\n\nBelow is the patch that allows for this:\n\n-- Steve\n\n\ndiff --git a/include/trace/stages/stage3_trace_output.h b/include/trace/stages/stage3_trace_output.h\nindex 1e7b0bef95f5..53a23988a3b8 100644\n--- a/include/trace/stages/stage3_trace_output.h\n+++ b/include/trace/stages/stage3_trace_output.h\n@@ -150,3 +150,11 @@\n \n #undef __get_buf\n #define __get_buf(len)\t\ttrace_seq_acquire(p, (len))\n+\n+#undef __event_in_hardirq\n+#undef __event_in_softirq\n+#undef __event_in_irq\n+\n+#define __event_in_hardirq()\t(__entry->ent.flags & TRACE_FLAG_HARDIRQ)\n+#define __event_in_softirq()\t(__entry->ent.flags & TRACE_FLAG_SOFTIRQ)\n+#define __event_in_irq()\t(__entry->ent.flags & (TRACE_FLAG_HARDIRQ | TRACE_FLAG_SOFTIRQ))\ndiff --git a/include/trace/stages/stage7_class_define.h b/include/trace/stages/stage7_class_define.h\nindex fcd564a590f4..47008897a795 100644\n--- a/include/trace/stages/stage7_class_define.h\n+++ b/include/trace/stages/stage7_class_define.h\n@@ -26,6 +26,25 @@\n #undef __print_hex_dump\n #undef __get_buf\n \n+#undef __event_in_hardirq\n+#undef __event_in_softirq\n+#undef __event_in_irq\n+\n+/*\n+ * The TRACE_FLAG_* are enums. Instead of using TRACE_DEFINE_ENUM(),\n+ * use their hardcoded values. These values are parsed by user space\n+ * tooling elsewhere so they will never change.\n+ *\n+ * See \"enum trace_flag_type\" in linux/trace_events.h:\n+ *   TRACE_FLAG_HARDIRQ\n+ *   TRACE_FLAG_SOFTIRQ\n+ */\n+\n+/* This is what is displayed in the format files */\n+#define __event_in_hardirq()\t(REC->common_flags & 0x8)\n+#define __event_in_softirq()\t(REC->common_flags & 0x10)\n+#define __event_in_irq()\t(REC->common_flags & 0x18)\n+\n /*\n  * The below is not executed in the kernel. It is only what is\n  * displayed in the print format for userspace to parse.",
          "reply_to": "Thomas Ballasi",
          "message_date": "2025-12-29"
        },
        {
          "author": "Steven Rostedt",
          "summary": "reviewer pointed out that the patch does not handle the case where a task is being migrated to another cgroup, and suggested adding a check for this condition\n\nreviewer suggested using a previously posted patch instead of the current one, providing a link to it",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "task migration",
            "cgroup change",
            "no clear technical issue raised"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "On Mon, 29 Dec 2025 13:29:42 -0500\nSteven Rostedt <rostedt@goodmis.org> wrote:\n\n---\n\nIf this would work for you. Feel free to take the patch I posted and use that:\n\n   https://lore.kernel.org/all/20251229163515.3d1b0bba@gandalf.local.home/\n\n-- Steve",
          "reply_to": "",
          "message_date": "2025-12-29"
        }
      ],
      "analysis_source": "llm-per-reviewer"
    },
    "2026-01-05": {
      "report_file": "2026-02-23_ollama_llama3.1-8b.html",
      "developer": "Shakeel Butt",
      "reviews": [
        {
          "author": "Thomas Ballasi (author)",
          "summary": "Author addressed a concern about the swapoff path needing to drop the per-vswap spinlock before calling try_to_unmap(), agreed to restructure in v2.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "acknowledged fix needed",
            "agreed to restructure"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Changes in v3:\n- Swapped multiple field entries to prevent a hole in the ring buffer\n- Replaced in_task() with __event_in_irq\n- Replaced mem_cgroup_id(memcg) with cgroup_id(memcg->css.cgroup)\n- Rebased the tree to latest 6.18\n\nLink to v2:\nhttps://lore.kernel.org/linux-trace-kernel/20251216140252.11864-1-tballasi@linux.microsoft.com/\n\nSigned-off-by: Thomas Ballasi <tballasi@linux.microsoft.com>\n\nThomas Ballasi (2):\n  mm: vmscan: add cgroup IDs to vmscan tracepoints\n  mm: vmscan: add PIDs to vmscan tracepoints\n\n include/trace/events/vmscan.h | 100 ++++++++++++++++++++++------------\n mm/shrinker.c                 |   2 +-\n mm/vmscan.c                   |  17 +++---\n 3 files changed, 74 insertions(+), 45 deletions(-)\n\n-- \n2.33.8",
          "reply_to": "",
          "message_date": "2026-01-05"
        },
        {
          "author": "Thomas Ballasi (author)",
          "summary": "The author addressed a concern about the default value of the memory cgroup ID (memcg_id) being set to 0 for operations not associated with a specific cgroup, explaining that this is intentional and allows for better correlation and analysis. The author did not indicate any plans to change this behavior.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "no clear resolution signal",
            "author provided explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Memory reclaim events are currently difficult to attribute to\nspecific cgroups, making debugging memory pressure issues\nchallenging.  This patch adds memory cgroup ID (memcg_id) to key\nvmscan tracepoints to enable better correlation and analysis.\n\nFor operations not associated with a specific cgroup, the field\nis defaulted to 0.\n\nSigned-off-by: Thomas Ballasi <tballasi@linux.microsoft.com>\n---\n include/trace/events/vmscan.h | 79 ++++++++++++++++++++---------------\n mm/shrinker.c                 |  2 +-\n mm/vmscan.c                   | 17 ++++----\n 3 files changed, 56 insertions(+), 42 deletions(-)\n\ndiff --git a/include/trace/events/vmscan.h b/include/trace/events/vmscan.h\nindex 490958fa10dee..93a9a9ba9405d 100644\n--- a/include/trace/events/vmscan.h\n+++ b/include/trace/events/vmscan.h\n@@ -114,85 +114,92 @@ TRACE_EVENT(mm_vmscan_wakeup_kswapd,\n \n DECLARE_EVENT_CLASS(mm_vmscan_direct_reclaim_begin_template,\n \n-\tTP_PROTO(int order, gfp_t gfp_flags),\n+\tTP_PROTO(gfp_t gfp_flags, int order, unsigned short memcg_id),\n \n-\tTP_ARGS(order, gfp_flags),\n+\tTP_ARGS(gfp_flags, order, memcg_id),\n \n \tTP_STRUCT__entry(\n-\t\t__field(\tint,\torder\t\t)\n \t\t__field(\tunsigned long,\tgfp_flags\t)\n+\t\t__field(\tint,\torder\t\t)\n+\t\t__field(\tunsigned short,\tmemcg_id\t)\n \t),\n \n \tTP_fast_assign(\n-\t\t__entry->order\t\t= order;\n \t\t__entry->gfp_flags\t= (__force unsigned long)gfp_flags;\n+\t\t__entry->order\t\t= order;\n+\t\t__entry->memcg_id\t= memcg_id;\n \t),\n \n-\tTP_printk(\"order=%d gfp_flags=%s\",\n+\tTP_printk(\"order=%d gfp_flags=%s memcg_id=%u\",\n \t\t__entry->order,\n-\t\tshow_gfp_flags(__entry->gfp_flags))\n+\t\tshow_gfp_flags(__entry->gfp_flags),\n+\t\t__entry->memcg_id)\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_begin_template, mm_vmscan_direct_reclaim_begin,\n \n-\tTP_PROTO(int order, gfp_t gfp_flags),\n+\tTP_PROTO(gfp_t gfp_flags, int order, unsigned short memcg_id),\n \n-\tTP_ARGS(order, gfp_flags)\n+\tTP_ARGS(gfp_flags, order, memcg_id)\n );\n \n #ifdef CONFIG_MEMCG\n DEFINE_EVENT(mm_vmscan_direct_reclaim_begin_template, mm_vmscan_memcg_reclaim_begin,\n \n-\tTP_PROTO(int order, gfp_t gfp_flags),\n+\tTP_PROTO(gfp_t gfp_flags, int order, unsigned short memcg_id),\n \n-\tTP_ARGS(order, gfp_flags)\n+\tTP_ARGS(gfp_flags, order, memcg_id)\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_begin_template, mm_vmscan_memcg_softlimit_reclaim_begin,\n \n-\tTP_PROTO(int order, gfp_t gfp_flags),\n+\tTP_PROTO(gfp_t gfp_flags, int order, unsigned short memcg_id),\n \n-\tTP_ARGS(order, gfp_flags)\n+\tTP_ARGS(gfp_flags, order, memcg_id)\n );\n #endif /* CONFIG_MEMCG */\n \n DECLARE_EVENT_CLASS(mm_vmscan_direct_reclaim_end_template,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, unsigned short memcg_id),\n \n-\tTP_ARGS(nr_reclaimed),\n+\tTP_ARGS(nr_reclaimed, memcg_id),\n \n \tTP_STRUCT__entry(\n \t\t__field(\tunsigned long,\tnr_reclaimed\t)\n+\t\t__field(\tunsigned short,\tmemcg_id\t)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->nr_reclaimed\t= nr_reclaimed;\n+\t\t__entry->memcg_id\t= memcg_id;\n \t),\n \n-\tTP_printk(\"nr_reclaimed=%lu\", __entry->nr_reclaimed)\n+\tTP_printk(\"nr_reclaimed=%lu memcg_id=%u\",\n+\t\t__entry->nr_reclaimed,\n+\t\t__entry->memcg_id)\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_direct_reclaim_end,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, unsigned short memcg_id),\n \n-\tTP_ARGS(nr_reclaimed)\n+\tTP_ARGS(nr_reclaimed, memcg_id)\n );\n \n #ifdef CONFIG_MEMCG\n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_memcg_reclaim_end,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, unsigned short memcg_id),\n \n-\tTP_ARGS(nr_reclaimed)\n+\tTP_ARGS(nr_reclaimed, memcg_id)\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_memcg_softlimit_reclaim_end,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, unsigned short memcg_id),\n \n-\tTP_ARGS(nr_reclaimed)\n+\tTP_ARGS(nr_reclaimed, memcg_id)\n );\n #endif /* CONFIG_MEMCG */\n \n@@ -208,31 +215,34 @@ TRACE_EVENT(mm_shrink_slab_start,\n \tTP_STRUCT__entry(\n \t\t__field(struct shrinker *, shr)\n \t\t__field(void *, shrink)\n-\t\t__field(int, nid)\n \t\t__field(long, nr_objects_to_shrink)\n \t\t__field(unsigned long, gfp_flags)\n \t\t__field(unsigned long, cache_items)\n \t\t__field(unsigned long long, delta)\n \t\t__field(unsigned long, total_scan)\n \t\t__field(int, priority)\n+\t\t__field(int, nid)\n+\t\t__field(unsigned short, memcg_id)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->shr = shr;\n \t\t__entry->shrink = shr->scan_objects;\n-\t\t__entry->nid = sc->nid;\n \t\t__entry->nr_objects_to_shrink = nr_objects_to_shrink;\n \t\t__entry->gfp_flags = (__force unsigned long)sc->gfp_mask;\n \t\t__entry->cache_items = cache_items;\n \t\t__entry->delta = delta;\n \t\t__entry->total_scan = total_scan;\n \t\t__entry->priority = priority;\n+\t\t__entry->nid = sc->nid;\n+\t\t__entry->memcg_id = sc->memcg ? cgroup_id(sc->memcg->css.cgroup) : 0;\n \t),\n \n-\tTP_printk(\"%pS %p: nid: %d objects to shrink %ld gfp_flags %s cache items %ld delta %lld total_scan %ld priority %d\",\n+\tTP_printk(\"%pS %p: nid: %d memcg_id: %u objects to shrink %ld gfp_flags %s cache items %ld delta %lld total_scan %ld priority %d\",\n \t\t__entry->shrink,\n \t\t__entry->shr,\n \t\t__entry->nid,\n+\t\t__entry->memcg_id,\n \t\t__entry->nr_objects_to_shrink,\n \t\tshow_gfp_flags(__entry->gfp_flags),\n \t\t__entry->cache_items,\n@@ -242,36 +252,39 @@ TRACE_EVENT(mm_shrink_slab_start,\n );\n \n TRACE_EVENT(mm_shrink_slab_end,\n-\tTP_PROTO(struct shrinker *shr, int nid, int shrinker_retval,\n+\tTP_PROTO(struct shrinker *shr, struct shrink_control *sc, int shrinker_retval,\n \t\tlong unused_scan_cnt, long new_scan_cnt, long total_scan),\n \n-\tTP_ARGS(shr, nid, shrinker_retval, unused_scan_cnt, new_scan_cnt,\n+\tTP_ARGS(shr, sc, shrinker_retval, unused_scan_cnt, new_scan_cnt,\n \t\ttotal_scan),\n \n \tTP_STRUCT__entry(\n \t\t__field(struct shrinker *, shr)\n-\t\t__field(int, nid)\n \t\t__field(void *, shrink)\n \t\t__field(long, unused_scan)\n \t\t__field(long, new_scan)\n-\t\t__field(int, retval)\n \t\t__field(long, total_scan)\n+\t\t__field(int, nid)\n+\t\t__field(int, retval)\n+\t\t__field(unsigned short, memcg_id)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->shr = shr;\n-\t\t__entry->nid = nid;\n \t\t__entry->shrink = shr->scan_objects;\n \t\t__entry->unused_scan = unused_scan_cnt;\n \t\t__entry->new_scan = new_scan_cnt;\n-\t\t__entry->retval = shrinker_retval;\n \t\t__entry->total_scan = total_scan;\n+\t\t__entry->nid = sc->nid;\n+\t\t__entry->retval = shrinker_retval;\n+\t\t__entry->memcg_id = cgroup_id(sc->memcg->css.cgroup);\n \t),\n \n-\tTP_printk(\"%pS %p: nid: %d unused scan count %ld new scan count %ld total_scan %ld last shrinker return val %d\",\n+\tTP_printk(\"%pS %p: nid: %d memcg_id: %u unused scan count %ld new scan count %ld total_scan %ld last shrinker return val %d\",\n \t\t__entry->shrink,\n \t\t__entry->shr,\n \t\t__entry->nid,\n+\t\t__entry->memcg_id,\n \t\t__entry->unused_scan,\n \t\t__entry->new_scan,\n \t\t__entry->total_scan,\n@@ -504,9 +517,9 @@ TRACE_EVENT(mm_vmscan_node_reclaim_begin,\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_node_reclaim_end,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, unsigned short memcg_id),\n \n-\tTP_ARGS(nr_reclaimed)\n+\tTP_ARGS(nr_reclaimed, memcg_id)\n );\n \n TRACE_EVENT(mm_vmscan_throttled,\ndiff --git a/mm/shrinker.c b/mm/shrinker.c\nindex 4a93fd433689a..e3b894c20bec8 100644\n--- a/mm/shrinker.c\n+++ b/mm/shrinker.c\n@@ -461,7 +461,7 @@ static unsigned long do_shrink_slab(struct shrink_control *shrinkctl,\n \t */\n \tnew_nr = add_nr_deferred(next_deferred, shrinker, shrinkctl);\n \n-\ttrace_mm_shrink_slab_end(shrinker, shrinkctl->nid, freed, nr, new_nr, total_scan);\n+\ttrace_mm_shrink_slab_end(shrinker, shrinkctl, freed, nr, new_nr, total_scan);\n \treturn freed;\n }\n \ndiff --git a/mm/vmscan.c b/mm/vmscan.c\nindex b2fc8b626d3df..3ac9f45461795 100644\n--- a/mm/vmscan.c\n+++ b/mm/vmscan.c\n@@ -6642,11 +6642,11 @@ unsigned long try_to_free_pages(struct zonelist *zonelist, int order,\n \t\treturn 1;\n \n \tset_task_reclaim_state(current, &sc.reclaim_state);\n-\ttrace_mm_vmscan_direct_reclaim_begin(order, sc.gfp_mask);\n+\ttrace_mm_vmscan_direct_reclaim_begin(sc.gfp_mask, order, 0);\n \n \tnr_reclaimed = do_try_to_free_pages(zonelist, &sc);\n \n-\ttrace_mm_vmscan_direct_reclaim_end(nr_reclaimed);\n+\ttrace_mm_vmscan_direct_reclaim_end(nr_reclaimed, 0);\n \tset_task_reclaim_state(current, NULL);\n \n \treturn nr_reclaimed;\n@@ -6675,8 +6675,9 @@ unsigned long mem_cgroup_shrink_node(struct mem_cgroup *memcg,\n \tsc.gfp_mask = (gfp_mask & GFP_RECLAIM_MASK) |\n \t\t\t(GFP_HIGHUSER_MOVABLE & ~GFP_RECLAIM_MASK);\n \n-\ttrace_mm_vmscan_memcg_softlimit_reclaim_begin(sc.order,\n-\t\t\t\t\t\t      sc.gfp_mask);\n+\ttrace_mm_vmscan_memcg_softlimit_reclaim_begin(sc.gfp_mask,\n+\t\t\t\t\t\t      sc.order,\n+\t\t\t\t\t\t      cgroup_id(memcg->css.cgroup));\n \n \t/*\n \t * NOTE: Although we can get the priority field, using it\n@@ -6687,7 +6688,7 @@ unsigned long mem_cgroup_shrink_node(struct mem_cgroup *memcg,\n \t */\n \tshrink_lruvec(lruvec, &sc);\n \n-\ttrace_mm_vmscan_memcg_softlimit_reclaim_end(sc.nr_reclaimed);\n+\ttrace_mm_vmscan_memcg_softlimit_reclaim_end(sc.nr_reclaimed, cgroup_id(memcg->css.cgroup));\n \n \t*nr_scanned = sc.nr_scanned;\n \n@@ -6723,13 +6724,13 @@ unsigned long try_to_free_mem_cgroup_pages(struct mem_cgroup *memcg,\n \tstruct zonelist *zonelist = node_zonelist(numa_node_id(), sc.gfp_mask);\n \n \tset_task_reclaim_state(current, &sc.reclaim_state);\n-\ttrace_mm_vmscan_memcg_reclaim_begin(0, sc.gfp_mask);\n+\ttrace_mm_vmscan_memcg_reclaim_begin(sc.gfp_mask, 0, cgroup_id(memcg->css.cgroup));\n \tnoreclaim_flag = memalloc_noreclaim_save();\n \n \tnr_reclaimed = do_try_to_free_pages(zonelist, &sc);\n \n \tmemalloc_noreclaim_restore(noreclaim_flag);\n-\ttrace_mm_vmscan_memcg_reclaim_end(nr_reclaimed);\n+\ttrace_mm_vmscan_memcg_reclaim_end(nr_reclaimed, cgroup_id(memcg->css.cgroup));\n \tset_task_reclaim_state(current, NULL);\n \n \treturn nr_reclaimed;\n@@ -7675,7 +7676,7 @@ static unsigned long __node_reclaim(struct pglist_data *pgdat, gfp_t gfp_mask,\n \tdelayacct_freepages_end();\n \tpsi_memstall_leave(&pflags);\n \n-\ttrace_mm_vmscan_node_reclaim_end(sc->nr_reclaimed);\n+\ttrace_mm_vmscan_node_reclaim_end(sc->nr_reclaimed, 0);\n \n \treturn sc->nr_reclaimed;\n }\n-- \n2.33.8",
          "reply_to": "",
          "message_date": "2026-01-05"
        },
        {
          "author": "Thomas Ballasi (author)",
          "summary": "The author addressed a concern about the reliability of PID detection in interrupt and RCU contexts, explaining that the PID field is set to -1 as a sentinel value when not in process context, and using in_task() to safely access current->pid when in process context. The author confirmed that this approach is correct.",
          "sentiment": "positive",
          "sentiment_signals": [
            "acknowledged concern",
            "explained reasoning"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "The changes aims at adding additionnal tracepoints variables to help\ndebuggers attribute them to specific processes.\n\nThe PID field uses in_task() to reliably detect when we're in process\ncontext and can safely access current->pid.  When not in process\ncontext (such as in interrupt or in an asynchronous RCU context), the\nfield is set to -1 as a sentinel value.\n\nSigned-off-by: Thomas Ballasi <tballasi@linux.microsoft.com>\n---\n include/trace/events/vmscan.h | 33 ++++++++++++++++++++++++---------\n 1 file changed, 24 insertions(+), 9 deletions(-)\n\ndiff --git a/include/trace/events/vmscan.h b/include/trace/events/vmscan.h\nindex 93a9a9ba9405d..d438abfa03ebb 100644\n--- a/include/trace/events/vmscan.h\n+++ b/include/trace/events/vmscan.h\n@@ -121,19 +121,23 @@ DECLARE_EVENT_CLASS(mm_vmscan_direct_reclaim_begin_template,\n \tTP_STRUCT__entry(\n \t\t__field(\tunsigned long,\tgfp_flags\t)\n \t\t__field(\tint,\torder\t\t)\n+\t\t__field(\tint,\tpid\t\t)\n \t\t__field(\tunsigned short,\tmemcg_id\t)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->gfp_flags\t= (__force unsigned long)gfp_flags;\n \t\t__entry->order\t\t= order;\n+\t\t__entry->pid\t\t= current->pid;\n \t\t__entry->memcg_id\t= memcg_id;\n \t),\n \n-\tTP_printk(\"order=%d gfp_flags=%s memcg_id=%u\",\n+\tTP_printk(\"order=%d gfp_flags=%s pid=%d memcg_id=%u %s\",\n \t\t__entry->order,\n \t\tshow_gfp_flags(__entry->gfp_flags),\n-\t\t__entry->memcg_id)\n+\t\t__entry->pid,\n+\t\t__entry->memcg_id,\n++\t\t__event_in_irq() ? \"(in-irq)\" : \"\")\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_begin_template, mm_vmscan_direct_reclaim_begin,\n@@ -167,17 +171,21 @@ DECLARE_EVENT_CLASS(mm_vmscan_direct_reclaim_end_template,\n \n \tTP_STRUCT__entry(\n \t\t__field(\tunsigned long,\tnr_reclaimed\t)\n+\t\t__field(\tint,\tpid\t\t)\n \t\t__field(\tunsigned short,\tmemcg_id\t)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->nr_reclaimed\t= nr_reclaimed;\n+\t\t__entry->pid\t\t= current->pid;\n \t\t__entry->memcg_id\t= memcg_id;\n \t),\n \n-\tTP_printk(\"nr_reclaimed=%lu memcg_id=%u\",\n+\tTP_printk(\"nr_reclaimed=%lu pid=%d memcg_id=%u %s\",\n \t\t__entry->nr_reclaimed,\n-\t\t__entry->memcg_id)\n+\t\t__entry->pid,\n+\t\t__entry->memcg_id,\n+\t\t__event_in_irq() ? \"(in-irq)\" : \"\")\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_direct_reclaim_end,\n@@ -222,6 +230,7 @@ TRACE_EVENT(mm_shrink_slab_start,\n \t\t__field(unsigned long, total_scan)\n \t\t__field(int, priority)\n \t\t__field(int, nid)\n+\t\t__field(int, pid)\n \t\t__field(unsigned short, memcg_id)\n \t),\n \n@@ -235,20 +244,23 @@ TRACE_EVENT(mm_shrink_slab_start,\n \t\t__entry->total_scan = total_scan;\n \t\t__entry->priority = priority;\n \t\t__entry->nid = sc->nid;\n+\t\t__entry->pid = current->pid;\n \t\t__entry->memcg_id = sc->memcg ? cgroup_id(sc->memcg->css.cgroup) : 0;\n \t),\n \n-\tTP_printk(\"%pS %p: nid: %d memcg_id: %u objects to shrink %ld gfp_flags %s cache items %ld delta %lld total_scan %ld priority %d\",\n+\tTP_printk(\"%pS %p: nid: %d pid: %d memcg_id: %u objects to shrink %ld gfp_flags %s cache items %ld delta %lld total_scan %ld priority %d %s\",\n \t\t__entry->shrink,\n \t\t__entry->shr,\n \t\t__entry->nid,\n+\t\t__entry->pid,\n \t\t__entry->memcg_id,\n \t\t__entry->nr_objects_to_shrink,\n \t\tshow_gfp_flags(__entry->gfp_flags),\n \t\t__entry->cache_items,\n \t\t__entry->delta,\n \t\t__entry->total_scan,\n-\t\t__entry->priority)\n+\t\t__entry->priority,\n++\t\t__event_in_irq() ? \"(in-irq)\" : \"\")\n );\n \n TRACE_EVENT(mm_shrink_slab_end,\n@@ -266,29 +278,32 @@ TRACE_EVENT(mm_shrink_slab_end,\n \t\t__field(long, total_scan)\n \t\t__field(int, nid)\n \t\t__field(int, retval)\n+\t\t__field(int, pid)\n \t\t__field(unsigned short, memcg_id)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->shr = shr;\n-\t\t__entry->shrink = shr->scan_objects;\n \t\t__entry->unused_scan = unused_scan_cnt;\n \t\t__entry->new_scan = new_scan_cnt;\n \t\t__entry->total_scan = total_scan;\n \t\t__entry->nid = sc->nid;\n \t\t__entry->retval = shrinker_retval;\n+\t\t__entry->pid = current->pid;\n \t\t__entry->memcg_id = cgroup_id(sc->memcg->css.cgroup);\n \t),\n \n-\tTP_printk(\"%pS %p: nid: %d memcg_id: %u unused scan count %ld new scan count %ld total_scan %ld last shrinker return val %d\",\n+\tTP_printk(\"%pS %p: nid: %d pid: %d memcg_id: %u unused scan count %ld new scan count %ld total_scan %ld last shrinker return val %d %s\",\n \t\t__entry->shrink,\n \t\t__entry->shr,\n \t\t__entry->nid,\n+\t\t__entry->pid,\n \t\t__entry->memcg_id,\n \t\t__entry->unused_scan,\n \t\t__entry->new_scan,\n \t\t__entry->total_scan,\n-\t\t__entry->retval)\n+\t\t__entry->retval,\n++\t\t__event_in_irq() ? \"(in-irq)\" : \"\")\n );\n \n TRACE_EVENT(mm_vmscan_lru_isolate,\n-- \n2.33.8",
          "reply_to": "",
          "message_date": "2026-01-05"
        },
        {
          "author": "Shakeel Butt",
          "summary": "Reviewer noted that memcg_id is a u64 but was being used as an unsigned short, and suggested passing the memcg pointer to the tracepoint instead of using cgroup_id() directly.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "type mismatch",
            "preference for alternative approach"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Couple of comments:\n\n1. memcg_id is u64 but the patch is using 'unsigned short'.\n2. I would prefer memcg pointer be passed in tracepoint and then in\ntrace header file cgroup_id() be used similar to other users in\ninclude/trace/events/ folder.\n\nOrthogonally I am cleaning up memcg id usage and after that cleanup,\nmem_cgroup_id() would be preferred way to get the ID. No need to do\nanything now as I will cleanup this usage later as well.",
          "reply_to": "Thomas Ballasi",
          "message_date": "2026-01-05"
        },
        {
          "author": "Andrew Morton",
          "summary": "The reviewer, Andrew Morton, reported a compilation error due to an implicit function declaration of '__event_in_irq' in the 'trace_raw_output_mm_vmscan_direct_reclaim_begin_template' function. The issue arises from the macro 'TP_printk' expanding to include the function call without declaring it first.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "compilation error",
            "implicit function declaration"
          ],
          "has_inline_review": true,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "x86_64 allmodconfig;\n\n\nIn file included from ./include/trace/define_trace.h:132,\n                 from ./include/trace/events/vmscan.h:569,\n                 from mm/vmscan.c:73:\n./include/trace/events/vmscan.h: In function 'trace_raw_output_mm_vmscan_direct_reclaim_begin_template':\n./include/trace/events/vmscan.h:140:17: error: implicit declaration of function '__event_in_irq' [-Wimplicit-function-declaration]\n  140 | +               __event_in_irq() ? \"(in-irq)\" : \"\")\n      |                 ^~~~~~~~~~~~~~\n./include/trace/trace_events.h:219:34: note: in definition of macro 'DECLARE_EVENT_CLASS'\n  219 |         trace_event_printf(iter, print);                                \\\n      |                                  ^~~~~\n./include/trace/events/vmscan.h:135:9: note: in expansion of macro 'TP_printk'\n  135 |         TP_printk(\"order=%d gfp_flags=%s pid=%d memcg_id=%u %s\",\n      |         ^~~~~~~~~\nmake[3]: *** [scripts/Makefile.build:287: mm/vmscan.o] Error 1\nmake[2]: *** [scripts/Makefile.build:556: mm] Error 2\nmake[1]: *** [/usr/src/25/Makefile:2054: .] Error 2\nmake: *** [Makefile:248: __sub-make] Error 2",
          "reply_to": "Thomas Ballasi",
          "message_date": "2026-01-05"
        },
        {
          "author": "Steven Rostedt",
          "summary": "reviewer noted that the patch does not handle the case where a task is being migrated, and requested that the PID be added to the tracepoint only after the migration has completed\n\nreviewer expressed confusion about why his previous patch was not included in the series and requested clarification",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "migration",
            "task",
            "confusion",
            "request for clarification"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "On Mon, 5 Jan 2026 18:06:40 -0800\nAndrew Morton <akpm@linux-foundation.org> wrote:\n\n---\n\nThis is dependent on my patch:\n\n  https://lore.kernel.org/all/20251229163515.3d1b0bba@gandalf.local.home/\n\nWhere I said you can take this patch. But I don't see it as part of the\nseries.\n\n  https://lore.kernel.org/all/20251229163634.5aad205d@gandalf.local.home/\n\n-- Steve",
          "reply_to": "Andrew Morton",
          "message_date": "2026-01-05"
        }
      ],
      "analysis_source": "llm-per-reviewer"
    },
    "2026-01-07": {
      "report_file": "2026-02-23_ollama_llama3.1-8b.html",
      "developer": "Shakeel Butt",
      "reviews": [
        {
          "author": "Harry Yoo",
          "summary": "The reviewer, Harry Yoo, pointed out that the patch breaks CONFIG_MEMCG=n builds due to an invalid use of undefined type 'struct mem_cgroup' in various functions within include/trace/events/vmscan.h.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "build failure",
            "undefined type"
          ],
          "has_inline_review": true,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Hi Thomas, this is breaking CONFIG_MEMCG=n builds.\n\nIn file included from ./include/trace/define_trace.h:132,\n                 from ./include/trace/events/vmscan.h:569,\n                 from mm/vmscan.c:73:\n./include/trace/events/vmscan.h: In function \\u2018do_trace_event_raw_event_mm_shrink_slab_start\\u2019:\n./include/trace/events/vmscan.h:248:68: error: invalid use of undefined type \\u2018struct mem_cgroup\\u2019\n  248 |                 __entry->memcg_id = sc->memcg ? cgroup_id(sc->memcg->css.cgroup) : 0;\n      |                                                                    ^~\n./include/trace/trace_events.h:427:11: note: in definition of macro \\u2018__DECLARE_EVENT_CLASS\\u2019\n  427 |         { assign; }                                                     \\\n      |           ^~~~~~\n./include/trace/trace_events.h:435:23: note: in expansion of macro \\u2018PARAMS\\u2019\n  435 |                       PARAMS(assign), PARAMS(print))                    \\\n      |                       ^~~~~~\n./include/trace/trace_events.h:40:9: note: in expansion of macro \\u2018DECLARE_EVENT_CLASS\\u2019\n   40 |         DECLARE_EVENT_CLASS(name,                              \\\n      |         ^~~~~~~~~~~~~~~~~~~\n./include/trace/trace_events.h:44:30: note: in expansion of macro \\u2018PARAMS\\u2019\n   44 |                              PARAMS(assign),                   \\\n      |                              ^~~~~~\n./include/trace/events/vmscan.h:214:1: note: in expansion of macro \\u2018TRACE_EVENT\\u2019\n  214 | TRACE_EVENT(mm_shrink_slab_start,\n      | ^~~~~~~~~~~\n./include/trace/events/vmscan.h:237:9: note: in expansion of macro \\u2018TP_fast_assign\\u2019\n  237 |         TP_fast_assign(\n      |         ^~~~~~~~~~~~~~\n./include/trace/events/vmscan.h: In function \\u2018do_trace_event_raw_event_mm_shrink_slab_end\\u2019:\n./include/trace/events/vmscan.h:293:56: error: invalid use of undefined type \\u2018struct mem_cgroup\\u2019\n  293 |                 __entry->memcg_id = cgroup_id(sc->memcg->css.cgroup);\n      |                                                        ^~\n./include/trace/trace_events.h:427:11: note: in definition of macro \\u2018__DECLARE_EVENT_CLASS\\u2019\n  427 |         { assign; }                                                     \\\n      |           ^~~~~~\n./include/trace/trace_events.h:435:23: note: in expansion of macro \\u2018PARAMS\\u2019\n  435 |                       PARAMS(assign), PARAMS(print))                    \\\n      |                       ^~~~~~\n./include/trace/trace_events.h:40:9: note: in expansion of macro \\u2018DECLARE_EVENT_CLASS\\u2019\n   40 |         DECLARE_EVENT_CLASS(name,                              \\\n      |         ^~~~~~~~~~~~~~~~~~~\n./include/trace/trace_events.h:44:30: note: in expansion of macro \\u2018PARAMS\\u2019\n   44 |                              PARAMS(assign),                   \\\n      |                              ^~~~~~\n./include/trace/events/vmscan.h:266:1: note: in expansion of macro \\u2018TRACE_EVENT\\u2019\n  266 | TRACE_EVENT(mm_shrink_slab_end,\n      | ^~~~~~~~~~~\n./include/trace/events/vmscan.h:285:9: note: in expansion of macro \\u2018TP_fast_assign\\u2019\n  285 |         TP_fast_assign(\n      |         ^~~~~~~~~~~~~~\nIn file included from ./include/trace/define_trace.h:133:\n./include/trace/events/vmscan.h: In function \\u2018do_perf_trace_mm_shrink_slab_start\\u2019:\n./include/trace/events/vmscan.h:248:68: error: invalid use of undefined type \\u2018struct mem_cgroup\\u2019\n  248 |                 __entry->memcg_id = sc->memcg ? cgroup_id(sc->memcg->css.cgroup) : 0;\n      |                                                                    ^~\n./include/trace/perf.h:51:11: note: in definition of macro \\u2018__DECLARE_EVENT_CLASS\\u2019\n   51 |         { assign; }                                                     \\\n      |           ^~~~~~\n./include/trace/perf.h:67:23: note: in expansion of macro \\u2018PARAMS\\u2019\n   67 |                       PARAMS(assign), PARAMS(print))                    \\\n      |                       ^~~~~~\n./include/trace/trace_events.h:40:9: note: in expansion of macro \\u2018DECLARE_EVENT_CLASS\\u2019\n   40 |         DECLARE_EVENT_CLASS(name,                              \\\n      |         ^~~~~~~~~~~~~~~~~~~\n./include/trace/trace_events.h:44:30: note: in expansion of macro \\u2018PARAMS\\u2019\n   44 |                              PARAMS(assign),                   \\\n      |                              ^~~~~~\n./include/trace/events/vmscan.h:214:1: note: in expansion of macro \\u2018TRACE_EVENT\\u2019\n  214 | TRACE_EVENT(mm_shrink_slab_start,\n      | ^~~~~~~~~~~\n./include/trace/events/vmscan.h:237:9: note: in expansion of macro \\u2018TP_fast_assign\\u2019\n  237 |         TP_fast_assign(\n      |         ^~~~~~~~~~~~~~\n./include/trace/events/vmscan.h: In function \\u2018do_perf_trace_mm_shrink_slab_end\\u2019:\n./include/trace/events/vmscan.h:293:56: error: invalid use of undefined type \\u2018struct mem_cgroup\\u2019\n  293 |                 __entry->memcg_id = cgroup_id(sc->memcg->css.cgroup);\n      |                                                        ^~\n./include/trace/perf.h:51:11: note: in definition of macro \\u2018__DECLARE_EVENT_CLASS\\u2019\n   51 |         { assign; }                                                     \\\n      |           ^~~~~~\n./include/trace/perf.h:67:23: note: in expansion of macro \\u2018PARAMS\\u2019\n   67 |                       PARAMS(assign), PARAMS(print))                    \\\n      |                       ^~~~~~\n./include/trace/trace_events.h:40:9: note: in expansion of macro \\u2018DECLARE_EVENT_CLASS\\u2019\n   40 |         DECLARE_EVENT_CLASS(name,                              \\\n      |         ^~~~~~~~~~~~~~~~~~~\n./include/trace/trace_events.h:44:30: note: in expansion of macro \\u2018PARAMS\\u2019\n   44 |                              PARAMS(assign),                   \\\n      |                              ^~~~~~\n./include/trace/events/vmscan.h:266:1: note: in expansion of macro \\u2018TRACE_EVENT\\u2019\n  266 | TRACE_EVENT(mm_shrink_slab_end,\n      | ^~~~~~~~~~~\n./include/trace/events/vmscan.h:285:9: note: in expansion of macro \\u2018TP_fast_assign\\u2019\n  285 |         TP_fast_assign(\n      |         ^~~~~~~~~~~~~~\n  CC      arch/x86/mm/extable.o\nmake[3]: *** [scripts/Makefile.build:287: mm/vmscan.o] Error 1\nmake[2]: *** [scripts/Makefile.build:556: mm] Error 2\nmake[2]: *** Waiting for unfinished jobs....\n\n-- \nCheers,\nHarry / Hyeonggon",
          "reply_to": "Thomas Ballasi",
          "message_date": "2026-01-07"
        },
        {
          "author": "Shakeel Butt",
          "summary": "reviewer pointed out that the patch does not handle the case where a task is being migrated to another node, and suggested adding a check for this scenario\n\nReviewer Shakeel Butt requested that the patch use mem_cgroup_id() instead of cgroup_id(memcg->css.cgroup) to improve accuracy and consistency in tracing cgroup IDs.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes",
            "requested change"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "On Mon, Jan 05, 2026 at 02:46:39PM -0800, Shakeel Butt wrote:\n[...]\n\n---\n\nThe series has been landed in mm-new. Please use mem_cgroup_id() instead\nof cgroup_id(memcg->css.cgroup).",
          "reply_to": "",
          "message_date": "2026-01-07"
        },
        {
          "author": "Shakeel Butt",
          "summary": "Reviewer pointed out that the patch can directly use mem_cgroup_id() after their own series landed in mm-new, eliminating the need for a CONFIG option",
          "sentiment": "neutral",
          "sentiment_signals": [
            "no specific technical concern or suggestion"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Oh sorry, I meant my series [1] landed in mm-new and with that Thomas\ncan directly use mem_cgroup_id() without worrying about CONFIG_MEMCG=n.\n\n[1] https://lkml.kernel.org/r/20251225232116.294540-1-shakeel.butt@linux.dev",
          "reply_to": "Andrew Morton",
          "message_date": "2026-01-07"
        }
      ],
      "analysis_source": "llm-per-reviewer"
    },
    "2026-01-15": {
      "report_file": "2026-02-23_ollama_llama3.1-8b.html",
      "developer": "Shakeel Butt",
      "reviews": [
        {
          "author": "Thomas Ballasi (author)",
          "summary": "Author addressed a concern about the type of memcg_id instances in vmscan tracepoints by changing them from unsigned short to u64, and updated struct entries accordingly.",
          "sentiment": "positive",
          "sentiment_signals": [
            "acknowledged feedback",
            "made changes"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Changes in v4:\n- added Steven's patch for __even_in_*irq() calls\n- moved back to mem_cgroup_id() following Shakeel's changes\n- passed cgroup ID through trace calls for slab_* tracepoints\n  instead of in vmscan.h directly\n- changed memcg_id instances types from unsigned short to u64 and\n  updated struct entries accordingly\n\nLink to v3:\nhttps://lore.kernel.org/linux-trace-kernel/20260105160423.23708-1-tballasi@linux.microsoft.com/\n\nSigned-off-by: Thomas Ballasi <tballasi@linux.microsoft.com>\n\nSteven Rostedt (1):\n  tracing: Add __event_in_*irq() helpers\n\nThomas Ballasi (2):\n  mm: vmscan: add cgroup IDs to vmscan tracepoints\n  mm: vmscan: add PIDs to vmscan tracepoints\n\n include/trace/events/vmscan.h              | 104 +++++++++++++--------\n include/trace/stages/stage3_trace_output.h |   8 ++\n include/trace/stages/stage7_class_define.h |  19 ++++\n mm/shrinker.c                              |   6 +-\n mm/vmscan.c                                |  17 ++--\n 5 files changed, 106 insertions(+), 48 deletions(-)\n\n-- \n2.33.8",
          "reply_to": "",
          "message_date": "2026-01-15"
        },
        {
          "author": "Thomas Ballasi (author)",
          "summary": "The author is addressing a concern about tracepoint flags and how they are used to indicate interrupt or softirq context. The author agrees that the information should be stored in the event structure itself, not just in the flags portion of the event header, but notes that this would require changes to existing code and suggests using helper macros instead.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "From: Steven Rostedt <rostedt@goodmis.org>\n\nSome trace events want to expose in their output if they were triggered in\nan interrupt or softirq context. Instead of recording this in the event\nstructure itself, as this information is stored in the flags portion of\nthe event header, add helper macros that can be used in the print format:\n\n  TP_printk(\"val=%d %s\", __entry->val, __entry_in_irq() ? \"(in-irq)\" : \"\")\n\nThis will output \"(in-irq)\" for the event in the trace data if the event\nwas triggered in hard or soft interrupt context.\n\nLink: https://lore.kernel.org/all/20251229132942.31a2b583@gandalf.local.home/\n\nSigned-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>\n---\n include/trace/stages/stage3_trace_output.h |  8 ++++++++\n include/trace/stages/stage7_class_define.h | 19 +++++++++++++++++++\n 2 files changed, 27 insertions(+)\n\ndiff --git a/include/trace/stages/stage3_trace_output.h b/include/trace/stages/stage3_trace_output.h\nindex 1e7b0bef95f52..53a23988a3b8a 100644\n--- a/include/trace/stages/stage3_trace_output.h\n+++ b/include/trace/stages/stage3_trace_output.h\n@@ -150,3 +150,11 @@\n \n #undef __get_buf\n #define __get_buf(len)\t\ttrace_seq_acquire(p, (len))\n+\n+#undef __event_in_hardirq\n+#undef __event_in_softirq\n+#undef __event_in_irq\n+\n+#define __event_in_hardirq()\t(__entry->ent.flags & TRACE_FLAG_HARDIRQ)\n+#define __event_in_softirq()\t(__entry->ent.flags & TRACE_FLAG_SOFTIRQ)\n+#define __event_in_irq()\t(__entry->ent.flags & (TRACE_FLAG_HARDIRQ | TRACE_FLAG_SOFTIRQ))\ndiff --git a/include/trace/stages/stage7_class_define.h b/include/trace/stages/stage7_class_define.h\nindex fcd564a590f43..47008897a7956 100644\n--- a/include/trace/stages/stage7_class_define.h\n+++ b/include/trace/stages/stage7_class_define.h\n@@ -26,6 +26,25 @@\n #undef __print_hex_dump\n #undef __get_buf\n \n+#undef __event_in_hardirq\n+#undef __event_in_softirq\n+#undef __event_in_irq\n+\n+/*\n+ * The TRACE_FLAG_* are enums. Instead of using TRACE_DEFINE_ENUM(),\n+ * use their hardcoded values. These values are parsed by user space\n+ * tooling elsewhere so they will never change.\n+ *\n+ * See \"enum trace_flag_type\" in linux/trace_events.h:\n+ *   TRACE_FLAG_HARDIRQ\n+ *   TRACE_FLAG_SOFTIRQ\n+ */\n+\n+/* This is what is displayed in the format files */\n+#define __event_in_hardirq()\t(REC->common_flags & 0x8)\n+#define __event_in_softirq()\t(REC->common_flags & 0x10)\n+#define __event_in_irq()\t(REC->common_flags & 0x18)\n+\n /*\n  * The below is not executed in the kernel. It is only what is\n  * displayed in the print format for userspace to parse.\n-- \n2.33.8",
          "reply_to": "",
          "message_date": "2026-01-15"
        },
        {
          "author": "Thomas Ballasi (author)",
          "summary": "The author addressed a concern about the default value of the memory cgroup ID (memcg_id) in tracepoints, explaining that it is defaulted to 0 for operations not associated with a specific cgroup.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Memory reclaim events are currently difficult to attribute to\nspecific cgroups, making debugging memory pressure issues\nchallenging.  This patch adds memory cgroup ID (memcg_id) to key\nvmscan tracepoints to enable better correlation and analysis.\n\nFor operations not associated with a specific cgroup, the field\nis defaulted to 0.\n\nSigned-off-by: Thomas Ballasi <tballasi@linux.microsoft.com>\n---\n include/trace/events/vmscan.h | 83 ++++++++++++++++++++---------------\n mm/shrinker.c                 |  6 ++-\n mm/vmscan.c                   | 17 +++----\n 3 files changed, 61 insertions(+), 45 deletions(-)\n\ndiff --git a/include/trace/events/vmscan.h b/include/trace/events/vmscan.h\nindex 490958fa10dee..20160e79eb0d7 100644\n--- a/include/trace/events/vmscan.h\n+++ b/include/trace/events/vmscan.h\n@@ -114,85 +114,92 @@ TRACE_EVENT(mm_vmscan_wakeup_kswapd,\n \n DECLARE_EVENT_CLASS(mm_vmscan_direct_reclaim_begin_template,\n \n-\tTP_PROTO(int order, gfp_t gfp_flags),\n+\tTP_PROTO(gfp_t gfp_flags, int order, u64 memcg_id),\n \n-\tTP_ARGS(order, gfp_flags),\n+\tTP_ARGS(gfp_flags, order, memcg_id),\n \n \tTP_STRUCT__entry(\n-\t\t__field(\tint,\torder\t\t)\n \t\t__field(\tunsigned long,\tgfp_flags\t)\n+\t\t__field(\tu64,\tmemcg_id\t)\n+\t\t__field(\tint,\torder\t\t)\n \t),\n \n \tTP_fast_assign(\n-\t\t__entry->order\t\t= order;\n \t\t__entry->gfp_flags\t= (__force unsigned long)gfp_flags;\n+\t\t__entry->order\t\t= order;\n+\t\t__entry->memcg_id\t= memcg_id;\n \t),\n \n-\tTP_printk(\"order=%d gfp_flags=%s\",\n+\tTP_printk(\"order=%d gfp_flags=%s memcg_id=%llu\",\n \t\t__entry->order,\n-\t\tshow_gfp_flags(__entry->gfp_flags))\n+\t\tshow_gfp_flags(__entry->gfp_flags),\n+\t\t__entry->memcg_id)\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_begin_template, mm_vmscan_direct_reclaim_begin,\n \n-\tTP_PROTO(int order, gfp_t gfp_flags),\n+\tTP_PROTO(gfp_t gfp_flags, int order, u64 memcg_id),\n \n-\tTP_ARGS(order, gfp_flags)\n+\tTP_ARGS(gfp_flags, order, memcg_id)\n );\n \n #ifdef CONFIG_MEMCG\n DEFINE_EVENT(mm_vmscan_direct_reclaim_begin_template, mm_vmscan_memcg_reclaim_begin,\n \n-\tTP_PROTO(int order, gfp_t gfp_flags),\n+\tTP_PROTO(gfp_t gfp_flags, int order, u64 memcg_id),\n \n-\tTP_ARGS(order, gfp_flags)\n+\tTP_ARGS(gfp_flags, order, memcg_id)\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_begin_template, mm_vmscan_memcg_softlimit_reclaim_begin,\n \n-\tTP_PROTO(int order, gfp_t gfp_flags),\n+\tTP_PROTO(gfp_t gfp_flags, int order, u64 memcg_id),\n \n-\tTP_ARGS(order, gfp_flags)\n+\tTP_ARGS(gfp_flags, order, memcg_id)\n );\n #endif /* CONFIG_MEMCG */\n \n DECLARE_EVENT_CLASS(mm_vmscan_direct_reclaim_end_template,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, u64 memcg_id),\n \n-\tTP_ARGS(nr_reclaimed),\n+\tTP_ARGS(nr_reclaimed, memcg_id),\n \n \tTP_STRUCT__entry(\n \t\t__field(\tunsigned long,\tnr_reclaimed\t)\n+\t\t__field(\tu64,\tmemcg_id\t)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->nr_reclaimed\t= nr_reclaimed;\n+\t\t__entry->memcg_id\t= memcg_id;\n \t),\n \n-\tTP_printk(\"nr_reclaimed=%lu\", __entry->nr_reclaimed)\n+\tTP_printk(\"nr_reclaimed=%lu memcg_id=%llu\",\n+\t\t__entry->nr_reclaimed,\n+\t\t__entry->memcg_id)\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_direct_reclaim_end,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, u64 memcg_id),\n \n-\tTP_ARGS(nr_reclaimed)\n+\tTP_ARGS(nr_reclaimed, memcg_id)\n );\n \n #ifdef CONFIG_MEMCG\n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_memcg_reclaim_end,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, u64 memcg_id),\n \n-\tTP_ARGS(nr_reclaimed)\n+\tTP_ARGS(nr_reclaimed, memcg_id)\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_memcg_softlimit_reclaim_end,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, u64 memcg_id),\n \n-\tTP_ARGS(nr_reclaimed)\n+\tTP_ARGS(nr_reclaimed, memcg_id)\n );\n #endif /* CONFIG_MEMCG */\n \n@@ -200,39 +207,42 @@ TRACE_EVENT(mm_shrink_slab_start,\n \tTP_PROTO(struct shrinker *shr, struct shrink_control *sc,\n \t\tlong nr_objects_to_shrink, unsigned long cache_items,\n \t\tunsigned long long delta, unsigned long total_scan,\n-\t\tint priority),\n+\t\tint priority, u64 memcg_id),\n \n \tTP_ARGS(shr, sc, nr_objects_to_shrink, cache_items, delta, total_scan,\n-\t\tpriority),\n+\t\tpriority, memcg_id),\n \n \tTP_STRUCT__entry(\n \t\t__field(struct shrinker *, shr)\n \t\t__field(void *, shrink)\n-\t\t__field(int, nid)\n \t\t__field(long, nr_objects_to_shrink)\n \t\t__field(unsigned long, gfp_flags)\n \t\t__field(unsigned long, cache_items)\n \t\t__field(unsigned long long, delta)\n \t\t__field(unsigned long, total_scan)\n \t\t__field(int, priority)\n+\t\t__field(int, nid)\n+\t\t__field(u64, memcg_id)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->shr = shr;\n \t\t__entry->shrink = shr->scan_objects;\n-\t\t__entry->nid = sc->nid;\n \t\t__entry->nr_objects_to_shrink = nr_objects_to_shrink;\n \t\t__entry->gfp_flags = (__force unsigned long)sc->gfp_mask;\n \t\t__entry->cache_items = cache_items;\n \t\t__entry->delta = delta;\n \t\t__entry->total_scan = total_scan;\n \t\t__entry->priority = priority;\n+\t\t__entry->nid = sc->nid;\n+\t\t__entry->memcg_id = memcg_id;\n \t),\n \n-\tTP_printk(\"%pS %p: nid: %d objects to shrink %ld gfp_flags %s cache items %ld delta %lld total_scan %ld priority %d\",\n+\tTP_printk(\"%pS %p: nid: %d memcg_id: %llu objects to shrink %ld gfp_flags %s cache items %ld delta %lld total_scan %ld priority %d\",\n \t\t__entry->shrink,\n \t\t__entry->shr,\n \t\t__entry->nid,\n+\t\t__entry->memcg_id,\n \t\t__entry->nr_objects_to_shrink,\n \t\tshow_gfp_flags(__entry->gfp_flags),\n \t\t__entry->cache_items,\n@@ -243,35 +253,38 @@ TRACE_EVENT(mm_shrink_slab_start,\n \n TRACE_EVENT(mm_shrink_slab_end,\n \tTP_PROTO(struct shrinker *shr, int nid, int shrinker_retval,\n-\t\tlong unused_scan_cnt, long new_scan_cnt, long total_scan),\n+\t\tlong unused_scan_cnt, long new_scan_cnt, long total_scan, u64 memcg_id),\n \n \tTP_ARGS(shr, nid, shrinker_retval, unused_scan_cnt, new_scan_cnt,\n-\t\ttotal_scan),\n+\t\ttotal_scan, memcg_id),\n \n \tTP_STRUCT__entry(\n \t\t__field(struct shrinker *, shr)\n-\t\t__field(int, nid)\n \t\t__field(void *, shrink)\n \t\t__field(long, unused_scan)\n \t\t__field(long, new_scan)\n-\t\t__field(int, retval)\n \t\t__field(long, total_scan)\n+\t\t__field(int, nid)\n+\t\t__field(int, retval)\n+\t\t__field(u64, memcg_id)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->shr = shr;\n-\t\t__entry->nid = nid;\n \t\t__entry->shrink = shr->scan_objects;\n \t\t__entry->unused_scan = unused_scan_cnt;\n \t\t__entry->new_scan = new_scan_cnt;\n-\t\t__entry->retval = shrinker_retval;\n \t\t__entry->total_scan = total_scan;\n+\t\t__entry->nid = nid;\n+\t\t__entry->retval = shrinker_retval;\n+\t\t__entry->memcg_id = memcg_id;\n \t),\n \n-\tTP_printk(\"%pS %p: nid: %d unused scan count %ld new scan count %ld total_scan %ld last shrinker return val %d\",\n+\tTP_printk(\"%pS %p: nid: %d memcg_id: %llu unused scan count %ld new scan count %ld total_scan %ld last shrinker return val %d\",\n \t\t__entry->shrink,\n \t\t__entry->shr,\n \t\t__entry->nid,\n+\t\t__entry->memcg_id,\n \t\t__entry->unused_scan,\n \t\t__entry->new_scan,\n \t\t__entry->total_scan,\n@@ -504,9 +517,9 @@ TRACE_EVENT(mm_vmscan_node_reclaim_begin,\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_node_reclaim_end,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, u64 memcg_id),\n \n-\tTP_ARGS(nr_reclaimed)\n+\tTP_ARGS(nr_reclaimed, memcg_id)\n );\n \n TRACE_EVENT(mm_vmscan_throttled,\ndiff --git a/mm/shrinker.c b/mm/shrinker.c\nindex 4a93fd433689a..ccfbe3fb3b378 100644\n--- a/mm/shrinker.c\n+++ b/mm/shrinker.c\n@@ -410,7 +410,8 @@ static unsigned long do_shrink_slab(struct shrink_control *shrinkctl,\n \ttotal_scan = min(total_scan, (2 * freeable));\n \n \ttrace_mm_shrink_slab_start(shrinker, shrinkctl, nr,\n-\t\t\t\t   freeable, delta, total_scan, priority);\n+\t\t\t\t   freeable, delta, total_scan, priority,\n+\t\t\t\t   mem_cgroup_id(shrinkctl->memcg));\n \n \t/*\n \t * Normally, we should not scan less than batch_size objects in one\n@@ -461,7 +462,8 @@ static unsigned long do_shrink_slab(struct shrink_control *shrinkctl,\n \t */\n \tnew_nr = add_nr_deferred(next_deferred, shrinker, shrinkctl);\n \n-\ttrace_mm_shrink_slab_end(shrinker, shrinkctl->nid, freed, nr, new_nr, total_scan);\n+\ttrace_mm_shrink_slab_end(shrinker, shrinkctl->nid, freed, nr, new_nr, total_scan,\n+\t\t\t\t mem_cgroup_id(shrinkctl->memcg));\n \treturn freed;\n }\n \ndiff --git a/mm/vmscan.c b/mm/vmscan.c\nindex b2fc8b626d3df..9a3cd975a9f30 100644\n--- a/mm/vmscan.c\n+++ b/mm/vmscan.c\n@@ -6642,11 +6642,11 @@ unsigned long try_to_free_pages(struct zonelist *zonelist, int order,\n \t\treturn 1;\n \n \tset_task_reclaim_state(current, &sc.reclaim_state);\n-\ttrace_mm_vmscan_direct_reclaim_begin(order, sc.gfp_mask);\n+\ttrace_mm_vmscan_direct_reclaim_begin(sc.gfp_mask, order, 0);\n \n \tnr_reclaimed = do_try_to_free_pages(zonelist, &sc);\n \n-\ttrace_mm_vmscan_direct_reclaim_end(nr_reclaimed);\n+\ttrace_mm_vmscan_direct_reclaim_end(nr_reclaimed, 0);\n \tset_task_reclaim_state(current, NULL);\n \n \treturn nr_reclaimed;\n@@ -6675,8 +6675,9 @@ unsigned long mem_cgroup_shrink_node(struct mem_cgroup *memcg,\n \tsc.gfp_mask = (gfp_mask & GFP_RECLAIM_MASK) |\n \t\t\t(GFP_HIGHUSER_MOVABLE & ~GFP_RECLAIM_MASK);\n \n-\ttrace_mm_vmscan_memcg_softlimit_reclaim_begin(sc.order,\n-\t\t\t\t\t\t      sc.gfp_mask);\n+\ttrace_mm_vmscan_memcg_softlimit_reclaim_begin(sc.gfp_mask,\n+\t\t\t\t\t\t      sc.order,\n+\t\t\t\t\t\t      mem_cgroup_id(memcg));\n \n \t/*\n \t * NOTE: Although we can get the priority field, using it\n@@ -6687,7 +6688,7 @@ unsigned long mem_cgroup_shrink_node(struct mem_cgroup *memcg,\n \t */\n \tshrink_lruvec(lruvec, &sc);\n \n-\ttrace_mm_vmscan_memcg_softlimit_reclaim_end(sc.nr_reclaimed);\n+\ttrace_mm_vmscan_memcg_softlimit_reclaim_end(sc.nr_reclaimed, mem_cgroup_id(memcg));\n \n \t*nr_scanned = sc.nr_scanned;\n \n@@ -6723,13 +6724,13 @@ unsigned long try_to_free_mem_cgroup_pages(struct mem_cgroup *memcg,\n \tstruct zonelist *zonelist = node_zonelist(numa_node_id(), sc.gfp_mask);\n \n \tset_task_reclaim_state(current, &sc.reclaim_state);\n-\ttrace_mm_vmscan_memcg_reclaim_begin(0, sc.gfp_mask);\n+\ttrace_mm_vmscan_memcg_reclaim_begin(sc.gfp_mask, 0, mem_cgroup_id(memcg));\n \tnoreclaim_flag = memalloc_noreclaim_save();\n \n \tnr_reclaimed = do_try_to_free_pages(zonelist, &sc);\n \n \tmemalloc_noreclaim_restore(noreclaim_flag);\n-\ttrace_mm_vmscan_memcg_reclaim_end(nr_reclaimed);\n+\ttrace_mm_vmscan_memcg_reclaim_end(nr_reclaimed, mem_cgroup_id(memcg));\n \tset_task_reclaim_state(current, NULL);\n \n \treturn nr_reclaimed;\n@@ -7675,7 +7676,7 @@ static unsigned long __node_reclaim(struct pglist_data *pgdat, gfp_t gfp_mask,\n \tdelayacct_freepages_end();\n \tpsi_memstall_leave(&pflags);\n \n-\ttrace_mm_vmscan_node_reclaim_end(sc->nr_reclaimed);\n+\ttrace_mm_vmscan_node_reclaim_end(sc->nr_reclaimed, 0);\n \n \treturn sc->nr_reclaimed;\n }\n-- \n2.33.8",
          "reply_to": "",
          "message_date": "2026-01-15"
        },
        {
          "author": "Thomas Ballasi (author)",
          "summary": "The author is addressing a concern about the reliability of PID detection in interrupt or RCU contexts, explaining that they use in_task() to safely access current->pid when in process context and set it to -1 as a sentinel value otherwise.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "The changes aims at adding additionnal tracepoints variables to help\ndebuggers attribute them to specific processes.\n\nThe PID field uses in_task() to reliably detect when we're in process\ncontext and can safely access current->pid.  When not in process\ncontext (such as in interrupt or in an asynchronous RCU context), the\nfield is set to -1 as a sentinel value.\n\nSigned-off-by: Thomas Ballasi <tballasi@linux.microsoft.com>\n---\n include/trace/events/vmscan.h | 35 +++++++++++++++++++++++++----------\n 1 file changed, 25 insertions(+), 10 deletions(-)\n\ndiff --git a/include/trace/events/vmscan.h b/include/trace/events/vmscan.h\nindex 20160e79eb0d7..288589e3364b0 100644\n--- a/include/trace/events/vmscan.h\n+++ b/include/trace/events/vmscan.h\n@@ -122,18 +122,22 @@ DECLARE_EVENT_CLASS(mm_vmscan_direct_reclaim_begin_template,\n \t\t__field(\tunsigned long,\tgfp_flags\t)\n \t\t__field(\tu64,\tmemcg_id\t)\n \t\t__field(\tint,\torder\t\t)\n+\t\t__field(\tint,\tpid\t\t)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->gfp_flags\t= (__force unsigned long)gfp_flags;\n \t\t__entry->order\t\t= order;\n+\t\t__entry->pid\t\t= current->pid;\n \t\t__entry->memcg_id\t= memcg_id;\n \t),\n \n-\tTP_printk(\"order=%d gfp_flags=%s memcg_id=%llu\",\n+\tTP_printk(\"order=%d gfp_flags=%s pid=%d memcg_id=%llu %s\",\n \t\t__entry->order,\n \t\tshow_gfp_flags(__entry->gfp_flags),\n-\t\t__entry->memcg_id)\n+\t\t__entry->pid,\n+\t\t__entry->memcg_id,\n++\t\t__event_in_irq() ? \"(in-irq)\" : \"\")\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_begin_template, mm_vmscan_direct_reclaim_begin,\n@@ -168,16 +172,20 @@ DECLARE_EVENT_CLASS(mm_vmscan_direct_reclaim_end_template,\n \tTP_STRUCT__entry(\n \t\t__field(\tunsigned long,\tnr_reclaimed\t)\n \t\t__field(\tu64,\tmemcg_id\t)\n+\t\t__field(\tint,\tpid\t\t)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->nr_reclaimed\t= nr_reclaimed;\n \t\t__entry->memcg_id\t= memcg_id;\n+\t\t__entry->pid\t\t= current->pid;\n \t),\n \n-\tTP_printk(\"nr_reclaimed=%lu memcg_id=%llu\",\n+\tTP_printk(\"nr_reclaimed=%lu pid=%d memcg_id=%llu %s\",\n \t\t__entry->nr_reclaimed,\n-\t\t__entry->memcg_id)\n+\t\t__entry->pid,\n+\t\t__entry->memcg_id,\n+\t\t__event_in_irq() ? \"(in-irq)\" : \"\")\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_direct_reclaim_end,\n@@ -220,9 +228,10 @@ TRACE_EVENT(mm_shrink_slab_start,\n \t\t__field(unsigned long, cache_items)\n \t\t__field(unsigned long long, delta)\n \t\t__field(unsigned long, total_scan)\n+\t\t__field(u64, memcg_id)\n \t\t__field(int, priority)\n \t\t__field(int, nid)\n-\t\t__field(u64, memcg_id)\n+\t\t__field(int, pid)\n \t),\n \n \tTP_fast_assign(\n@@ -236,19 +245,22 @@ TRACE_EVENT(mm_shrink_slab_start,\n \t\t__entry->priority = priority;\n \t\t__entry->nid = sc->nid;\n \t\t__entry->memcg_id = memcg_id;\n+\t\t__entry->pid = current->pid;\n \t),\n \n-\tTP_printk(\"%pS %p: nid: %d memcg_id: %llu objects to shrink %ld gfp_flags %s cache items %ld delta %lld total_scan %ld priority %d\",\n+\tTP_printk(\"%pS %p: nid: %d pid: %d memcg_id: %llu objects to shrink %ld gfp_flags %s cache items %ld delta %lld total_scan %ld priority %d %s\",\n \t\t__entry->shrink,\n \t\t__entry->shr,\n \t\t__entry->nid,\n+\t\t__entry->pid,\n \t\t__entry->memcg_id,\n \t\t__entry->nr_objects_to_shrink,\n \t\tshow_gfp_flags(__entry->gfp_flags),\n \t\t__entry->cache_items,\n \t\t__entry->delta,\n \t\t__entry->total_scan,\n-\t\t__entry->priority)\n+\t\t__entry->priority,\n++\t\t__event_in_irq() ? \"(in-irq)\" : \"\")\n );\n \n TRACE_EVENT(mm_shrink_slab_end,\n@@ -266,29 +278,32 @@ TRACE_EVENT(mm_shrink_slab_end,\n \t\t__field(long, total_scan)\n \t\t__field(int, nid)\n \t\t__field(int, retval)\n+\t\t__field(int, pid)\n \t\t__field(u64, memcg_id)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->shr = shr;\n-\t\t__entry->shrink = shr->scan_objects;\n \t\t__entry->unused_scan = unused_scan_cnt;\n \t\t__entry->new_scan = new_scan_cnt;\n \t\t__entry->total_scan = total_scan;\n \t\t__entry->nid = nid;\n \t\t__entry->retval = shrinker_retval;\n+\t\t__entry->pid = current->pid;\n \t\t__entry->memcg_id = memcg_id;\n \t),\n \n-\tTP_printk(\"%pS %p: nid: %d memcg_id: %llu unused scan count %ld new scan count %ld total_scan %ld last shrinker return val %d\",\n+\tTP_printk(\"%pS %p: nid: %d pid: %d memcg_id: %llu unused scan count %ld new scan count %ld total_scan %ld last shrinker return val %d %s\",\n \t\t__entry->shrink,\n \t\t__entry->shr,\n \t\t__entry->nid,\n+\t\t__entry->pid,\n \t\t__entry->memcg_id,\n \t\t__entry->unused_scan,\n \t\t__entry->new_scan,\n \t\t__entry->total_scan,\n-\t\t__entry->retval)\n+\t\t__entry->retval,\n++\t\t__event_in_irq() ? \"(in-irq)\" : \"\")\n );\n \n TRACE_EVENT(mm_vmscan_lru_isolate,\n-- \n2.33.8",
          "reply_to": "",
          "message_date": "2026-01-15"
        }
      ],
      "analysis_source": "llm-per-reviewer"
    },
    "2026-01-22": {
      "report_file": "2026-02-23_ollama_llama3.1-8b.html",
      "developer": "Shakeel Butt",
      "reviews": [
        {
          "author": "Thomas Ballasi (author)",
          "summary": "Author acknowledged a concern about extra '+' characters at (in-irq) warnings and confirmed that the issue was fixed in v5.",
          "sentiment": "positive",
          "sentiment_signals": [
            "acknowledged",
            "confirmed"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Changes in v5:\n- Fixed a small quirk that added extra +'s at (in-irq) warnings\n\nLink to v4:\nhttps://lore.kernel.org/linux-trace-kernel/20260115123809.2257-1-tballasi@linux.microsoft.com/\n\nSigned-off-by: Thomas Ballasi <tballasi@linux.microsoft.com>\n\nSteven Rostedt (1):\n  tracing: Add __event_in_*irq() helpers\n\nThomas Ballasi (2):\n  mm: vmscan: add cgroup IDs to vmscan tracepoints\n  mm: vmscan: add PIDs to vmscan tracepoints\n\n include/trace/events/vmscan.h              | 104 +++++++++++++--------\n include/trace/stages/stage3_trace_output.h |   8 ++\n include/trace/stages/stage7_class_define.h |  19 ++++\n mm/shrinker.c                              |   6 +-\n mm/vmscan.c                                |  17 ++--\n 5 files changed, 106 insertions(+), 48 deletions(-)\n\n-- \n2.33.8",
          "reply_to": "",
          "message_date": "2026-01-22"
        },
        {
          "author": "Thomas Ballasi (author)",
          "summary": "The author addressed a concern about tracepoint flags, explained that instead of recording this information directly in the event structure, helper macros can be used to print the context (interrupt or softirq) using the flags portion of the event header.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "From: Steven Rostedt <rostedt@goodmis.org>\n\nSome trace events want to expose in their output if they were triggered in\nan interrupt or softirq context. Instead of recording this in the event\nstructure itself, as this information is stored in the flags portion of\nthe event header, add helper macros that can be used in the print format:\n\n  TP_printk(\"val=%d %s\", __entry->val, __entry_in_irq() ? \"(in-irq)\" : \"\")\n\nThis will output \"(in-irq)\" for the event in the trace data if the event\nwas triggered in hard or soft interrupt context.\n\nLink: https://lore.kernel.org/all/20251229132942.31a2b583@gandalf.local.home/\n\nSigned-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>\n---\n include/trace/stages/stage3_trace_output.h |  8 ++++++++\n include/trace/stages/stage7_class_define.h | 19 +++++++++++++++++++\n 2 files changed, 27 insertions(+)\n\ndiff --git a/include/trace/stages/stage3_trace_output.h b/include/trace/stages/stage3_trace_output.h\nindex 1e7b0bef95f52..53a23988a3b8a 100644\n--- a/include/trace/stages/stage3_trace_output.h\n+++ b/include/trace/stages/stage3_trace_output.h\n@@ -150,3 +150,11 @@\n \n #undef __get_buf\n #define __get_buf(len)\t\ttrace_seq_acquire(p, (len))\n+\n+#undef __event_in_hardirq\n+#undef __event_in_softirq\n+#undef __event_in_irq\n+\n+#define __event_in_hardirq()\t(__entry->ent.flags & TRACE_FLAG_HARDIRQ)\n+#define __event_in_softirq()\t(__entry->ent.flags & TRACE_FLAG_SOFTIRQ)\n+#define __event_in_irq()\t(__entry->ent.flags & (TRACE_FLAG_HARDIRQ | TRACE_FLAG_SOFTIRQ))\ndiff --git a/include/trace/stages/stage7_class_define.h b/include/trace/stages/stage7_class_define.h\nindex fcd564a590f43..47008897a7956 100644\n--- a/include/trace/stages/stage7_class_define.h\n+++ b/include/trace/stages/stage7_class_define.h\n@@ -26,6 +26,25 @@\n #undef __print_hex_dump\n #undef __get_buf\n \n+#undef __event_in_hardirq\n+#undef __event_in_softirq\n+#undef __event_in_irq\n+\n+/*\n+ * The TRACE_FLAG_* are enums. Instead of using TRACE_DEFINE_ENUM(),\n+ * use their hardcoded values. These values are parsed by user space\n+ * tooling elsewhere so they will never change.\n+ *\n+ * See \"enum trace_flag_type\" in linux/trace_events.h:\n+ *   TRACE_FLAG_HARDIRQ\n+ *   TRACE_FLAG_SOFTIRQ\n+ */\n+\n+/* This is what is displayed in the format files */\n+#define __event_in_hardirq()\t(REC->common_flags & 0x8)\n+#define __event_in_softirq()\t(REC->common_flags & 0x10)\n+#define __event_in_irq()\t(REC->common_flags & 0x18)\n+\n /*\n  * The below is not executed in the kernel. It is only what is\n  * displayed in the print format for userspace to parse.\n-- \n2.33.8",
          "reply_to": "",
          "message_date": "2026-01-22"
        },
        {
          "author": "Thomas Ballasi (author)",
          "summary": "The author addressed a concern about the difficulty of attributing memory reclaim events to specific cgroups, explaining that adding memory cgroup ID (memcg_id) to key vmscan tracepoints will enable better correlation and analysis. The field is defaulted to 0 for operations not associated with a specific cgroup.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Memory reclaim events are currently difficult to attribute to\nspecific cgroups, making debugging memory pressure issues\nchallenging.  This patch adds memory cgroup ID (memcg_id) to key\nvmscan tracepoints to enable better correlation and analysis.\n\nFor operations not associated with a specific cgroup, the field\nis defaulted to 0.\n\nSigned-off-by: Thomas Ballasi <tballasi@linux.microsoft.com>\n---\n include/trace/events/vmscan.h | 83 ++++++++++++++++++++---------------\n mm/shrinker.c                 |  6 ++-\n mm/vmscan.c                   | 17 +++----\n 3 files changed, 61 insertions(+), 45 deletions(-)\n\ndiff --git a/include/trace/events/vmscan.h b/include/trace/events/vmscan.h\nindex 490958fa10dee..20160e79eb0d7 100644\n--- a/include/trace/events/vmscan.h\n+++ b/include/trace/events/vmscan.h\n@@ -114,85 +114,92 @@ TRACE_EVENT(mm_vmscan_wakeup_kswapd,\n \n DECLARE_EVENT_CLASS(mm_vmscan_direct_reclaim_begin_template,\n \n-\tTP_PROTO(int order, gfp_t gfp_flags),\n+\tTP_PROTO(gfp_t gfp_flags, int order, u64 memcg_id),\n \n-\tTP_ARGS(order, gfp_flags),\n+\tTP_ARGS(gfp_flags, order, memcg_id),\n \n \tTP_STRUCT__entry(\n-\t\t__field(\tint,\torder\t\t)\n \t\t__field(\tunsigned long,\tgfp_flags\t)\n+\t\t__field(\tu64,\tmemcg_id\t)\n+\t\t__field(\tint,\torder\t\t)\n \t),\n \n \tTP_fast_assign(\n-\t\t__entry->order\t\t= order;\n \t\t__entry->gfp_flags\t= (__force unsigned long)gfp_flags;\n+\t\t__entry->order\t\t= order;\n+\t\t__entry->memcg_id\t= memcg_id;\n \t),\n \n-\tTP_printk(\"order=%d gfp_flags=%s\",\n+\tTP_printk(\"order=%d gfp_flags=%s memcg_id=%llu\",\n \t\t__entry->order,\n-\t\tshow_gfp_flags(__entry->gfp_flags))\n+\t\tshow_gfp_flags(__entry->gfp_flags),\n+\t\t__entry->memcg_id)\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_begin_template, mm_vmscan_direct_reclaim_begin,\n \n-\tTP_PROTO(int order, gfp_t gfp_flags),\n+\tTP_PROTO(gfp_t gfp_flags, int order, u64 memcg_id),\n \n-\tTP_ARGS(order, gfp_flags)\n+\tTP_ARGS(gfp_flags, order, memcg_id)\n );\n \n #ifdef CONFIG_MEMCG\n DEFINE_EVENT(mm_vmscan_direct_reclaim_begin_template, mm_vmscan_memcg_reclaim_begin,\n \n-\tTP_PROTO(int order, gfp_t gfp_flags),\n+\tTP_PROTO(gfp_t gfp_flags, int order, u64 memcg_id),\n \n-\tTP_ARGS(order, gfp_flags)\n+\tTP_ARGS(gfp_flags, order, memcg_id)\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_begin_template, mm_vmscan_memcg_softlimit_reclaim_begin,\n \n-\tTP_PROTO(int order, gfp_t gfp_flags),\n+\tTP_PROTO(gfp_t gfp_flags, int order, u64 memcg_id),\n \n-\tTP_ARGS(order, gfp_flags)\n+\tTP_ARGS(gfp_flags, order, memcg_id)\n );\n #endif /* CONFIG_MEMCG */\n \n DECLARE_EVENT_CLASS(mm_vmscan_direct_reclaim_end_template,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, u64 memcg_id),\n \n-\tTP_ARGS(nr_reclaimed),\n+\tTP_ARGS(nr_reclaimed, memcg_id),\n \n \tTP_STRUCT__entry(\n \t\t__field(\tunsigned long,\tnr_reclaimed\t)\n+\t\t__field(\tu64,\tmemcg_id\t)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->nr_reclaimed\t= nr_reclaimed;\n+\t\t__entry->memcg_id\t= memcg_id;\n \t),\n \n-\tTP_printk(\"nr_reclaimed=%lu\", __entry->nr_reclaimed)\n+\tTP_printk(\"nr_reclaimed=%lu memcg_id=%llu\",\n+\t\t__entry->nr_reclaimed,\n+\t\t__entry->memcg_id)\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_direct_reclaim_end,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, u64 memcg_id),\n \n-\tTP_ARGS(nr_reclaimed)\n+\tTP_ARGS(nr_reclaimed, memcg_id)\n );\n \n #ifdef CONFIG_MEMCG\n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_memcg_reclaim_end,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, u64 memcg_id),\n \n-\tTP_ARGS(nr_reclaimed)\n+\tTP_ARGS(nr_reclaimed, memcg_id)\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_memcg_softlimit_reclaim_end,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, u64 memcg_id),\n \n-\tTP_ARGS(nr_reclaimed)\n+\tTP_ARGS(nr_reclaimed, memcg_id)\n );\n #endif /* CONFIG_MEMCG */\n \n@@ -200,39 +207,42 @@ TRACE_EVENT(mm_shrink_slab_start,\n \tTP_PROTO(struct shrinker *shr, struct shrink_control *sc,\n \t\tlong nr_objects_to_shrink, unsigned long cache_items,\n \t\tunsigned long long delta, unsigned long total_scan,\n-\t\tint priority),\n+\t\tint priority, u64 memcg_id),\n \n \tTP_ARGS(shr, sc, nr_objects_to_shrink, cache_items, delta, total_scan,\n-\t\tpriority),\n+\t\tpriority, memcg_id),\n \n \tTP_STRUCT__entry(\n \t\t__field(struct shrinker *, shr)\n \t\t__field(void *, shrink)\n-\t\t__field(int, nid)\n \t\t__field(long, nr_objects_to_shrink)\n \t\t__field(unsigned long, gfp_flags)\n \t\t__field(unsigned long, cache_items)\n \t\t__field(unsigned long long, delta)\n \t\t__field(unsigned long, total_scan)\n \t\t__field(int, priority)\n+\t\t__field(int, nid)\n+\t\t__field(u64, memcg_id)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->shr = shr;\n \t\t__entry->shrink = shr->scan_objects;\n-\t\t__entry->nid = sc->nid;\n \t\t__entry->nr_objects_to_shrink = nr_objects_to_shrink;\n \t\t__entry->gfp_flags = (__force unsigned long)sc->gfp_mask;\n \t\t__entry->cache_items = cache_items;\n \t\t__entry->delta = delta;\n \t\t__entry->total_scan = total_scan;\n \t\t__entry->priority = priority;\n+\t\t__entry->nid = sc->nid;\n+\t\t__entry->memcg_id = memcg_id;\n \t),\n \n-\tTP_printk(\"%pS %p: nid: %d objects to shrink %ld gfp_flags %s cache items %ld delta %lld total_scan %ld priority %d\",\n+\tTP_printk(\"%pS %p: nid: %d memcg_id: %llu objects to shrink %ld gfp_flags %s cache items %ld delta %lld total_scan %ld priority %d\",\n \t\t__entry->shrink,\n \t\t__entry->shr,\n \t\t__entry->nid,\n+\t\t__entry->memcg_id,\n \t\t__entry->nr_objects_to_shrink,\n \t\tshow_gfp_flags(__entry->gfp_flags),\n \t\t__entry->cache_items,\n@@ -243,35 +253,38 @@ TRACE_EVENT(mm_shrink_slab_start,\n \n TRACE_EVENT(mm_shrink_slab_end,\n \tTP_PROTO(struct shrinker *shr, int nid, int shrinker_retval,\n-\t\tlong unused_scan_cnt, long new_scan_cnt, long total_scan),\n+\t\tlong unused_scan_cnt, long new_scan_cnt, long total_scan, u64 memcg_id),\n \n \tTP_ARGS(shr, nid, shrinker_retval, unused_scan_cnt, new_scan_cnt,\n-\t\ttotal_scan),\n+\t\ttotal_scan, memcg_id),\n \n \tTP_STRUCT__entry(\n \t\t__field(struct shrinker *, shr)\n-\t\t__field(int, nid)\n \t\t__field(void *, shrink)\n \t\t__field(long, unused_scan)\n \t\t__field(long, new_scan)\n-\t\t__field(int, retval)\n \t\t__field(long, total_scan)\n+\t\t__field(int, nid)\n+\t\t__field(int, retval)\n+\t\t__field(u64, memcg_id)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->shr = shr;\n-\t\t__entry->nid = nid;\n \t\t__entry->shrink = shr->scan_objects;\n \t\t__entry->unused_scan = unused_scan_cnt;\n \t\t__entry->new_scan = new_scan_cnt;\n-\t\t__entry->retval = shrinker_retval;\n \t\t__entry->total_scan = total_scan;\n+\t\t__entry->nid = nid;\n+\t\t__entry->retval = shrinker_retval;\n+\t\t__entry->memcg_id = memcg_id;\n \t),\n \n-\tTP_printk(\"%pS %p: nid: %d unused scan count %ld new scan count %ld total_scan %ld last shrinker return val %d\",\n+\tTP_printk(\"%pS %p: nid: %d memcg_id: %llu unused scan count %ld new scan count %ld total_scan %ld last shrinker return val %d\",\n \t\t__entry->shrink,\n \t\t__entry->shr,\n \t\t__entry->nid,\n+\t\t__entry->memcg_id,\n \t\t__entry->unused_scan,\n \t\t__entry->new_scan,\n \t\t__entry->total_scan,\n@@ -504,9 +517,9 @@ TRACE_EVENT(mm_vmscan_node_reclaim_begin,\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_node_reclaim_end,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, u64 memcg_id),\n \n-\tTP_ARGS(nr_reclaimed)\n+\tTP_ARGS(nr_reclaimed, memcg_id)\n );\n \n TRACE_EVENT(mm_vmscan_throttled,\ndiff --git a/mm/shrinker.c b/mm/shrinker.c\nindex 4a93fd433689a..ccfbe3fb3b378 100644\n--- a/mm/shrinker.c\n+++ b/mm/shrinker.c\n@@ -410,7 +410,8 @@ static unsigned long do_shrink_slab(struct shrink_control *shrinkctl,\n \ttotal_scan = min(total_scan, (2 * freeable));\n \n \ttrace_mm_shrink_slab_start(shrinker, shrinkctl, nr,\n-\t\t\t\t   freeable, delta, total_scan, priority);\n+\t\t\t\t   freeable, delta, total_scan, priority,\n+\t\t\t\t   mem_cgroup_id(shrinkctl->memcg));\n \n \t/*\n \t * Normally, we should not scan less than batch_size objects in one\n@@ -461,7 +462,8 @@ static unsigned long do_shrink_slab(struct shrink_control *shrinkctl,\n \t */\n \tnew_nr = add_nr_deferred(next_deferred, shrinker, shrinkctl);\n \n-\ttrace_mm_shrink_slab_end(shrinker, shrinkctl->nid, freed, nr, new_nr, total_scan);\n+\ttrace_mm_shrink_slab_end(shrinker, shrinkctl->nid, freed, nr, new_nr, total_scan,\n+\t\t\t\t mem_cgroup_id(shrinkctl->memcg));\n \treturn freed;\n }\n \ndiff --git a/mm/vmscan.c b/mm/vmscan.c\nindex b2fc8b626d3df..9a3cd975a9f30 100644\n--- a/mm/vmscan.c\n+++ b/mm/vmscan.c\n@@ -6642,11 +6642,11 @@ unsigned long try_to_free_pages(struct zonelist *zonelist, int order,\n \t\treturn 1;\n \n \tset_task_reclaim_state(current, &sc.reclaim_state);\n-\ttrace_mm_vmscan_direct_reclaim_begin(order, sc.gfp_mask);\n+\ttrace_mm_vmscan_direct_reclaim_begin(sc.gfp_mask, order, 0);\n \n \tnr_reclaimed = do_try_to_free_pages(zonelist, &sc);\n \n-\ttrace_mm_vmscan_direct_reclaim_end(nr_reclaimed);\n+\ttrace_mm_vmscan_direct_reclaim_end(nr_reclaimed, 0);\n \tset_task_reclaim_state(current, NULL);\n \n \treturn nr_reclaimed;\n@@ -6675,8 +6675,9 @@ unsigned long mem_cgroup_shrink_node(struct mem_cgroup *memcg,\n \tsc.gfp_mask = (gfp_mask & GFP_RECLAIM_MASK) |\n \t\t\t(GFP_HIGHUSER_MOVABLE & ~GFP_RECLAIM_MASK);\n \n-\ttrace_mm_vmscan_memcg_softlimit_reclaim_begin(sc.order,\n-\t\t\t\t\t\t      sc.gfp_mask);\n+\ttrace_mm_vmscan_memcg_softlimit_reclaim_begin(sc.gfp_mask,\n+\t\t\t\t\t\t      sc.order,\n+\t\t\t\t\t\t      mem_cgroup_id(memcg));\n \n \t/*\n \t * NOTE: Although we can get the priority field, using it\n@@ -6687,7 +6688,7 @@ unsigned long mem_cgroup_shrink_node(struct mem_cgroup *memcg,\n \t */\n \tshrink_lruvec(lruvec, &sc);\n \n-\ttrace_mm_vmscan_memcg_softlimit_reclaim_end(sc.nr_reclaimed);\n+\ttrace_mm_vmscan_memcg_softlimit_reclaim_end(sc.nr_reclaimed, mem_cgroup_id(memcg));\n \n \t*nr_scanned = sc.nr_scanned;\n \n@@ -6723,13 +6724,13 @@ unsigned long try_to_free_mem_cgroup_pages(struct mem_cgroup *memcg,\n \tstruct zonelist *zonelist = node_zonelist(numa_node_id(), sc.gfp_mask);\n \n \tset_task_reclaim_state(current, &sc.reclaim_state);\n-\ttrace_mm_vmscan_memcg_reclaim_begin(0, sc.gfp_mask);\n+\ttrace_mm_vmscan_memcg_reclaim_begin(sc.gfp_mask, 0, mem_cgroup_id(memcg));\n \tnoreclaim_flag = memalloc_noreclaim_save();\n \n \tnr_reclaimed = do_try_to_free_pages(zonelist, &sc);\n \n \tmemalloc_noreclaim_restore(noreclaim_flag);\n-\ttrace_mm_vmscan_memcg_reclaim_end(nr_reclaimed);\n+\ttrace_mm_vmscan_memcg_reclaim_end(nr_reclaimed, mem_cgroup_id(memcg));\n \tset_task_reclaim_state(current, NULL);\n \n \treturn nr_reclaimed;\n@@ -7675,7 +7676,7 @@ static unsigned long __node_reclaim(struct pglist_data *pgdat, gfp_t gfp_mask,\n \tdelayacct_freepages_end();\n \tpsi_memstall_leave(&pflags);\n \n-\ttrace_mm_vmscan_node_reclaim_end(sc->nr_reclaimed);\n+\ttrace_mm_vmscan_node_reclaim_end(sc->nr_reclaimed, 0);\n \n \treturn sc->nr_reclaimed;\n }\n-- \n2.33.8",
          "reply_to": "",
          "message_date": "2026-01-22"
        },
        {
          "author": "Thomas Ballasi (author)",
          "summary": "The author addressed a concern about the PID field being set to -1 in non-process contexts, explaining that it uses in_task() to reliably detect when in process context and safely access current->pid.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "The changes aims at adding additionnal tracepoints variables to help\ndebuggers attribute them to specific processes.\n\nThe PID field uses in_task() to reliably detect when we're in process\ncontext and can safely access current->pid.  When not in process\ncontext (such as in interrupt or in an asynchronous RCU context), the\nfield is set to -1 as a sentinel value.\n\nSigned-off-by: Thomas Ballasi <tballasi@linux.microsoft.com>\n---\n include/trace/events/vmscan.h | 35 +++++++++++++++++++++++++----------\n 1 file changed, 25 insertions(+), 10 deletions(-)\n\ndiff --git a/include/trace/events/vmscan.h b/include/trace/events/vmscan.h\nindex 20160e79eb0d7..c7f7621e48af5 100644\n--- a/include/trace/events/vmscan.h\n+++ b/include/trace/events/vmscan.h\n@@ -122,18 +122,22 @@ DECLARE_EVENT_CLASS(mm_vmscan_direct_reclaim_begin_template,\n \t\t__field(\tunsigned long,\tgfp_flags\t)\n \t\t__field(\tu64,\tmemcg_id\t)\n \t\t__field(\tint,\torder\t\t)\n+\t\t__field(\tint,\tpid\t\t)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->gfp_flags\t= (__force unsigned long)gfp_flags;\n \t\t__entry->order\t\t= order;\n+\t\t__entry->pid\t\t= current->pid;\n \t\t__entry->memcg_id\t= memcg_id;\n \t),\n \n-\tTP_printk(\"order=%d gfp_flags=%s memcg_id=%llu\",\n+\tTP_printk(\"order=%d gfp_flags=%s pid=%d memcg_id=%llu %s\",\n \t\t__entry->order,\n \t\tshow_gfp_flags(__entry->gfp_flags),\n-\t\t__entry->memcg_id)\n+\t\t__entry->pid,\n+\t\t__entry->memcg_id,\n+\t\t__event_in_irq() ? \"(in-irq)\" : \"\")\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_begin_template, mm_vmscan_direct_reclaim_begin,\n@@ -168,16 +172,20 @@ DECLARE_EVENT_CLASS(mm_vmscan_direct_reclaim_end_template,\n \tTP_STRUCT__entry(\n \t\t__field(\tunsigned long,\tnr_reclaimed\t)\n \t\t__field(\tu64,\tmemcg_id\t)\n+\t\t__field(\tint,\tpid\t\t)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->nr_reclaimed\t= nr_reclaimed;\n \t\t__entry->memcg_id\t= memcg_id;\n+\t\t__entry->pid\t\t= current->pid;\n \t),\n \n-\tTP_printk(\"nr_reclaimed=%lu memcg_id=%llu\",\n+\tTP_printk(\"nr_reclaimed=%lu pid=%d memcg_id=%llu %s\",\n \t\t__entry->nr_reclaimed,\n-\t\t__entry->memcg_id)\n+\t\t__entry->pid,\n+\t\t__entry->memcg_id,\n+\t\t__event_in_irq() ? \"(in-irq)\" : \"\")\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_direct_reclaim_end,\n@@ -220,9 +228,10 @@ TRACE_EVENT(mm_shrink_slab_start,\n \t\t__field(unsigned long, cache_items)\n \t\t__field(unsigned long long, delta)\n \t\t__field(unsigned long, total_scan)\n+\t\t__field(u64, memcg_id)\n \t\t__field(int, priority)\n \t\t__field(int, nid)\n-\t\t__field(u64, memcg_id)\n+\t\t__field(int, pid)\n \t),\n \n \tTP_fast_assign(\n@@ -236,19 +245,22 @@ TRACE_EVENT(mm_shrink_slab_start,\n \t\t__entry->priority = priority;\n \t\t__entry->nid = sc->nid;\n \t\t__entry->memcg_id = memcg_id;\n+\t\t__entry->pid = current->pid;\n \t),\n \n-\tTP_printk(\"%pS %p: nid: %d memcg_id: %llu objects to shrink %ld gfp_flags %s cache items %ld delta %lld total_scan %ld priority %d\",\n+\tTP_printk(\"%pS %p: nid: %d pid: %d memcg_id: %llu objects to shrink %ld gfp_flags %s cache items %ld delta %lld total_scan %ld priority %d %s\",\n \t\t__entry->shrink,\n \t\t__entry->shr,\n \t\t__entry->nid,\n+\t\t__entry->pid,\n \t\t__entry->memcg_id,\n \t\t__entry->nr_objects_to_shrink,\n \t\tshow_gfp_flags(__entry->gfp_flags),\n \t\t__entry->cache_items,\n \t\t__entry->delta,\n \t\t__entry->total_scan,\n-\t\t__entry->priority)\n+\t\t__entry->priority,\n+\t\t__event_in_irq() ? \"(in-irq)\" : \"\")\n );\n \n TRACE_EVENT(mm_shrink_slab_end,\n@@ -266,29 +278,32 @@ TRACE_EVENT(mm_shrink_slab_end,\n \t\t__field(long, total_scan)\n \t\t__field(int, nid)\n \t\t__field(int, retval)\n+\t\t__field(int, pid)\n \t\t__field(u64, memcg_id)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->shr = shr;\n-\t\t__entry->shrink = shr->scan_objects;\n \t\t__entry->unused_scan = unused_scan_cnt;\n \t\t__entry->new_scan = new_scan_cnt;\n \t\t__entry->total_scan = total_scan;\n \t\t__entry->nid = nid;\n \t\t__entry->retval = shrinker_retval;\n+\t\t__entry->pid = current->pid;\n \t\t__entry->memcg_id = memcg_id;\n \t),\n \n-\tTP_printk(\"%pS %p: nid: %d memcg_id: %llu unused scan count %ld new scan count %ld total_scan %ld last shrinker return val %d\",\n+\tTP_printk(\"%pS %p: nid: %d pid: %d memcg_id: %llu unused scan count %ld new scan count %ld total_scan %ld last shrinker return val %d %s\",\n \t\t__entry->shrink,\n \t\t__entry->shr,\n \t\t__entry->nid,\n+\t\t__entry->pid,\n \t\t__entry->memcg_id,\n \t\t__entry->unused_scan,\n \t\t__entry->new_scan,\n \t\t__entry->total_scan,\n-\t\t__entry->retval)\n+\t\t__entry->retval,\n+\t\t__event_in_irq() ? \"(in-irq)\" : \"\")\n );\n \n TRACE_EVENT(mm_vmscan_lru_isolate,\n-- \n2.33.8",
          "reply_to": "",
          "message_date": "2026-01-22"
        },
        {
          "author": "Andrew Morton",
          "summary": "Reviewer Andrew Morton requested that Thomas Ballasi cc relevant maintainers on vmscan changes, specifically mentioning the output of scripts/get_maintainer.pl, and noted that the first patch was missing a Signed-off-by: from the original author.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "cc-relevant-maintainers",
            "missing-signed-off-by"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Pleae cc the relevant maintainers on vmscan changes.  We have a\nveritable army of them:\n\nhp2:/usr/src/mm> scripts/get_maintainer.pl --no-rolestats --nogit -f mm/vmscan.c\nAndrew Morton <akpm@linux-foundation.org>\nAxel Rasmussen <axelrasmussen@google.com>\nYuanchu Xie <yuanchu@google.com>\nWei Xu <weixugc@google.com>\nJohannes Weiner <hannes@cmpxchg.org>\nDavid Hildenbrand <david@kernel.org>\nMichal Hocko <mhocko@kernel.org>\nQi Zheng <zhengqi.arch@bytedance.com>\nShakeel Butt <shakeel.butt@linux.dev>\nLorenzo Stoakes <lorenzo.stoakes@oracle.com>\n\nThe first patch should have your Signed-off-by:, as you were on the\ndelivery path.\n\nThe patchset looks sensible to me - I'll await reviewer input before\nproceeding.  Thanks.",
          "reply_to": "Thomas Ballasi",
          "message_date": "2026-01-22"
        }
      ],
      "analysis_source": "llm-per-reviewer"
    },
    "2026-01-27": {
      "report_file": "2026-02-23_ollama_llama3.1-8b.html",
      "developer": "Shakeel Butt",
      "reviews": [
        {
          "author": "Shakeel Butt",
          "summary": "Reviewer Shakeel Butt requested that the patch be modified to pass the memcg pointer to the tracepoints, allowing for the use of the mem_cgroup_id() function to obtain the cgroup ID.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested change"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Please pass memcg pointer to tracepoints and call mem_cgroup_id(memcg)\nhere.",
          "reply_to": "Thomas Ballasi",
          "message_date": "2026-01-27"
        }
      ],
      "analysis_source": "llm-per-reviewer"
    },
    "2026-02-13": {
      "report_file": "2026-02-23_ollama_llama3.1-8b.html",
      "developer": "Shakeel Butt",
      "reviews": [
        {
          "author": "Thomas Ballasi (author)",
          "summary": "Author acknowledged Steven's patch was used as a reference and explained that passing memcg pointers instead of IDs is the correct approach, confirming this change in v6.",
          "sentiment": "positive",
          "sentiment_signals": [
            "acknowledged prior work",
            "explained technical decision"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Changes in v6:\n- Updated Steven's patch with sign-off\n- Passed memcg pointers as arguments in tracepoints instead of memcg_id\n\nLink to v5:\nhttps://lore.kernel.org/linux-trace-kernel/20260122182510.2126-1-tballasi@linux.microsoft.com/\n\nSigned-off-by: Thomas Ballasi <tballasi@linux.microsoft.com>\n\nSteven Rostedt (1):\n  tracing: Add __event_in_*irq() helpers\n\nThomas Ballasi (2):\n  mm: vmscan: add cgroup IDs to vmscan tracepoints\n  mm: vmscan: add PIDs to vmscan tracepoints\n\n include/trace/events/vmscan.h              | 104 +++++++++++++--------\n include/trace/stages/stage3_trace_output.h |   8 ++\n include/trace/stages/stage7_class_define.h |  19 ++++\n mm/shrinker.c                              |   6 +-\n mm/vmscan.c                                |  17 ++--\n 5 files changed, 106 insertions(+), 48 deletions(-)\n\n-- \n2.33.8",
          "reply_to": "",
          "message_date": "2026-02-13"
        },
        {
          "author": "Thomas Ballasi (author)",
          "summary": "The author addressed a concern about trace events wanting to expose if they were triggered in interrupt or softirq context, and explained that helper macros can be used in the print format to achieve this.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "From: Steven Rostedt <rostedt@goodmis.org>\n\nSome trace events want to expose in their output if they were triggered in\nan interrupt or softirq context. Instead of recording this in the event\nstructure itself, as this information is stored in the flags portion of\nthe event header, add helper macros that can be used in the print format:\n\n  TP_printk(\"val=%d %s\", __entry->val, __entry_in_irq() ? \"(in-irq)\" : \"\")\n\nThis will output \"(in-irq)\" for the event in the trace data if the event\nwas triggered in hard or soft interrupt context.\n\nLink: https://lore.kernel.org/all/20251229132942.31a2b583@gandalf.local.home/\n\nSigned-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>\nSigned-off-by: Thomas Ballasi <tballasi@linux.microsoft.com>\n---\n include/trace/stages/stage3_trace_output.h |  8 ++++++++\n include/trace/stages/stage7_class_define.h | 19 +++++++++++++++++++\n 2 files changed, 27 insertions(+)\n\ndiff --git a/include/trace/stages/stage3_trace_output.h b/include/trace/stages/stage3_trace_output.h\nindex 1e7b0bef95f52..53a23988a3b8a 100644\n--- a/include/trace/stages/stage3_trace_output.h\n+++ b/include/trace/stages/stage3_trace_output.h\n@@ -150,3 +150,11 @@\n \n #undef __get_buf\n #define __get_buf(len)\t\ttrace_seq_acquire(p, (len))\n+\n+#undef __event_in_hardirq\n+#undef __event_in_softirq\n+#undef __event_in_irq\n+\n+#define __event_in_hardirq()\t(__entry->ent.flags & TRACE_FLAG_HARDIRQ)\n+#define __event_in_softirq()\t(__entry->ent.flags & TRACE_FLAG_SOFTIRQ)\n+#define __event_in_irq()\t(__entry->ent.flags & (TRACE_FLAG_HARDIRQ | TRACE_FLAG_SOFTIRQ))\ndiff --git a/include/trace/stages/stage7_class_define.h b/include/trace/stages/stage7_class_define.h\nindex fcd564a590f43..47008897a7956 100644\n--- a/include/trace/stages/stage7_class_define.h\n+++ b/include/trace/stages/stage7_class_define.h\n@@ -26,6 +26,25 @@\n #undef __print_hex_dump\n #undef __get_buf\n \n+#undef __event_in_hardirq\n+#undef __event_in_softirq\n+#undef __event_in_irq\n+\n+/*\n+ * The TRACE_FLAG_* are enums. Instead of using TRACE_DEFINE_ENUM(),\n+ * use their hardcoded values. These values are parsed by user space\n+ * tooling elsewhere so they will never change.\n+ *\n+ * See \"enum trace_flag_type\" in linux/trace_events.h:\n+ *   TRACE_FLAG_HARDIRQ\n+ *   TRACE_FLAG_SOFTIRQ\n+ */\n+\n+/* This is what is displayed in the format files */\n+#define __event_in_hardirq()\t(REC->common_flags & 0x8)\n+#define __event_in_softirq()\t(REC->common_flags & 0x10)\n+#define __event_in_irq()\t(REC->common_flags & 0x18)\n+\n /*\n  * The below is not executed in the kernel. It is only what is\n  * displayed in the print format for userspace to parse.\n-- \n2.33.8",
          "reply_to": "",
          "message_date": "2026-02-13"
        },
        {
          "author": "Thomas Ballasi (author)",
          "summary": "The author is addressing a concern about the patch adding memory cgroup ID (memcg_id) to key vmscan tracepoints, which was previously missing in some scenarios. The author explains that for operations not associated with a specific cgroup, the field is defaulted to 0.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Memory reclaim events are currently difficult to attribute to\nspecific cgroups, making debugging memory pressure issues\nchallenging.  This patch adds memory cgroup ID (memcg_id) to key\nvmscan tracepoints to enable better correlation and analysis.\n\nFor operations not associated with a specific cgroup, the field\nis defaulted to 0.\n\nSigned-off-by: Thomas Ballasi <tballasi@linux.microsoft.com>\n---\n include/trace/events/vmscan.h | 83 ++++++++++++++++++++---------------\n mm/shrinker.c                 |  6 ++-\n mm/vmscan.c                   | 17 +++----\n 3 files changed, 61 insertions(+), 45 deletions(-)\n\ndiff --git a/include/trace/events/vmscan.h b/include/trace/events/vmscan.h\nindex 490958fa10dee..1212f6a7c223e 100644\n--- a/include/trace/events/vmscan.h\n+++ b/include/trace/events/vmscan.h\n@@ -114,85 +114,92 @@ TRACE_EVENT(mm_vmscan_wakeup_kswapd,\n \n DECLARE_EVENT_CLASS(mm_vmscan_direct_reclaim_begin_template,\n \n-\tTP_PROTO(int order, gfp_t gfp_flags),\n+\tTP_PROTO(gfp_t gfp_flags, int order, struct mem_cgroup *memcg),\n \n-\tTP_ARGS(order, gfp_flags),\n+\tTP_ARGS(gfp_flags, order, memcg),\n \n \tTP_STRUCT__entry(\n-\t\t__field(\tint,\torder\t\t)\n \t\t__field(\tunsigned long,\tgfp_flags\t)\n+\t\t__field(\tu64,\tmemcg_id\t)\n+\t\t__field(\tint,\torder\t\t)\n \t),\n \n \tTP_fast_assign(\n-\t\t__entry->order\t\t= order;\n \t\t__entry->gfp_flags\t= (__force unsigned long)gfp_flags;\n+\t\t__entry->order\t\t= order;\n+\t\t__entry->memcg_id\t= mem_cgroup_id(memcg);\n \t),\n \n-\tTP_printk(\"order=%d gfp_flags=%s\",\n+\tTP_printk(\"order=%d gfp_flags=%s memcg_id=%llu\",\n \t\t__entry->order,\n-\t\tshow_gfp_flags(__entry->gfp_flags))\n+\t\tshow_gfp_flags(__entry->gfp_flags),\n+\t\t__entry->memcg_id)\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_begin_template, mm_vmscan_direct_reclaim_begin,\n \n-\tTP_PROTO(int order, gfp_t gfp_flags),\n+\tTP_PROTO(gfp_t gfp_flags, int order, struct mem_cgroup *memcg),\n \n-\tTP_ARGS(order, gfp_flags)\n+\tTP_ARGS(gfp_flags, order, memcg)\n );\n \n #ifdef CONFIG_MEMCG\n DEFINE_EVENT(mm_vmscan_direct_reclaim_begin_template, mm_vmscan_memcg_reclaim_begin,\n \n-\tTP_PROTO(int order, gfp_t gfp_flags),\n+\tTP_PROTO(gfp_t gfp_flags, int order, struct mem_cgroup *memcg),\n \n-\tTP_ARGS(order, gfp_flags)\n+\tTP_ARGS(gfp_flags, order, memcg)\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_begin_template, mm_vmscan_memcg_softlimit_reclaim_begin,\n \n-\tTP_PROTO(int order, gfp_t gfp_flags),\n+\tTP_PROTO(gfp_t gfp_flags, int order, struct mem_cgroup *memcg),\n \n-\tTP_ARGS(order, gfp_flags)\n+\tTP_ARGS(gfp_flags, order, memcg)\n );\n #endif /* CONFIG_MEMCG */\n \n DECLARE_EVENT_CLASS(mm_vmscan_direct_reclaim_end_template,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, struct mem_cgroup *memcg),\n \n-\tTP_ARGS(nr_reclaimed),\n+\tTP_ARGS(nr_reclaimed, memcg),\n \n \tTP_STRUCT__entry(\n \t\t__field(\tunsigned long,\tnr_reclaimed\t)\n+\t\t__field(\tu64,\tmemcg_id\t)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->nr_reclaimed\t= nr_reclaimed;\n+\t\t__entry->memcg_id\t= mem_cgroup_id(memcg);\n \t),\n \n-\tTP_printk(\"nr_reclaimed=%lu\", __entry->nr_reclaimed)\n+\tTP_printk(\"nr_reclaimed=%lu memcg_id=%llu\",\n+\t\t__entry->nr_reclaimed,\n+\t\t__entry->memcg_id)\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_direct_reclaim_end,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, struct mem_cgroup *memcg),\n \n-\tTP_ARGS(nr_reclaimed)\n+\tTP_ARGS(nr_reclaimed, memcg)\n );\n \n #ifdef CONFIG_MEMCG\n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_memcg_reclaim_end,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, struct mem_cgroup *memcg),\n \n-\tTP_ARGS(nr_reclaimed)\n+\tTP_ARGS(nr_reclaimed, memcg)\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_memcg_softlimit_reclaim_end,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, struct mem_cgroup *memcg),\n \n-\tTP_ARGS(nr_reclaimed)\n+\tTP_ARGS(nr_reclaimed, memcg)\n );\n #endif /* CONFIG_MEMCG */\n \n@@ -200,39 +207,42 @@ TRACE_EVENT(mm_shrink_slab_start,\n \tTP_PROTO(struct shrinker *shr, struct shrink_control *sc,\n \t\tlong nr_objects_to_shrink, unsigned long cache_items,\n \t\tunsigned long long delta, unsigned long total_scan,\n-\t\tint priority),\n+\t\tint priority, struct mem_cgroup *memcg),\n \n \tTP_ARGS(shr, sc, nr_objects_to_shrink, cache_items, delta, total_scan,\n-\t\tpriority),\n+\t\tpriority, memcg),\n \n \tTP_STRUCT__entry(\n \t\t__field(struct shrinker *, shr)\n \t\t__field(void *, shrink)\n-\t\t__field(int, nid)\n \t\t__field(long, nr_objects_to_shrink)\n \t\t__field(unsigned long, gfp_flags)\n \t\t__field(unsigned long, cache_items)\n \t\t__field(unsigned long long, delta)\n \t\t__field(unsigned long, total_scan)\n \t\t__field(int, priority)\n+\t\t__field(int, nid)\n+\t\t__field(u64, memcg_id)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->shr = shr;\n \t\t__entry->shrink = shr->scan_objects;\n-\t\t__entry->nid = sc->nid;\n \t\t__entry->nr_objects_to_shrink = nr_objects_to_shrink;\n \t\t__entry->gfp_flags = (__force unsigned long)sc->gfp_mask;\n \t\t__entry->cache_items = cache_items;\n \t\t__entry->delta = delta;\n \t\t__entry->total_scan = total_scan;\n \t\t__entry->priority = priority;\n+\t\t__entry->nid = sc->nid;\n+\t\t__entry->memcg_id = mem_cgroup_id(memcg);\n \t),\n \n-\tTP_printk(\"%pS %p: nid: %d objects to shrink %ld gfp_flags %s cache items %ld delta %lld total_scan %ld priority %d\",\n+\tTP_printk(\"%pS %p: nid: %d memcg_id: %llu objects to shrink %ld gfp_flags %s cache items %ld delta %lld total_scan %ld priority %d\",\n \t\t__entry->shrink,\n \t\t__entry->shr,\n \t\t__entry->nid,\n+\t\t__entry->memcg_id,\n \t\t__entry->nr_objects_to_shrink,\n \t\tshow_gfp_flags(__entry->gfp_flags),\n \t\t__entry->cache_items,\n@@ -243,35 +253,38 @@ TRACE_EVENT(mm_shrink_slab_start,\n \n TRACE_EVENT(mm_shrink_slab_end,\n \tTP_PROTO(struct shrinker *shr, int nid, int shrinker_retval,\n-\t\tlong unused_scan_cnt, long new_scan_cnt, long total_scan),\n+\t\tlong unused_scan_cnt, long new_scan_cnt, long total_scan, struct mem_cgroup *memcg),\n \n \tTP_ARGS(shr, nid, shrinker_retval, unused_scan_cnt, new_scan_cnt,\n-\t\ttotal_scan),\n+\t\ttotal_scan, memcg),\n \n \tTP_STRUCT__entry(\n \t\t__field(struct shrinker *, shr)\n-\t\t__field(int, nid)\n \t\t__field(void *, shrink)\n \t\t__field(long, unused_scan)\n \t\t__field(long, new_scan)\n-\t\t__field(int, retval)\n \t\t__field(long, total_scan)\n+\t\t__field(int, nid)\n+\t\t__field(int, retval)\n+\t\t__field(u64, memcg_id)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->shr = shr;\n-\t\t__entry->nid = nid;\n \t\t__entry->shrink = shr->scan_objects;\n \t\t__entry->unused_scan = unused_scan_cnt;\n \t\t__entry->new_scan = new_scan_cnt;\n-\t\t__entry->retval = shrinker_retval;\n \t\t__entry->total_scan = total_scan;\n+\t\t__entry->nid = nid;\n+\t\t__entry->retval = shrinker_retval;\n+\t\t__entry->memcg_id = mem_cgroup_id(memcg);\n \t),\n \n-\tTP_printk(\"%pS %p: nid: %d unused scan count %ld new scan count %ld total_scan %ld last shrinker return val %d\",\n+\tTP_printk(\"%pS %p: nid: %d memcg_id: %llu unused scan count %ld new scan count %ld total_scan %ld last shrinker return val %d\",\n \t\t__entry->shrink,\n \t\t__entry->shr,\n \t\t__entry->nid,\n+\t\t__entry->memcg_id,\n \t\t__entry->unused_scan,\n \t\t__entry->new_scan,\n \t\t__entry->total_scan,\n@@ -504,9 +517,9 @@ TRACE_EVENT(mm_vmscan_node_reclaim_begin,\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_node_reclaim_end,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, struct mem_cgroup *memcg),\n \n-\tTP_ARGS(nr_reclaimed)\n+\tTP_ARGS(nr_reclaimed, memcg)\n );\n \n TRACE_EVENT(mm_vmscan_throttled,\ndiff --git a/mm/shrinker.c b/mm/shrinker.c\nindex 4a93fd433689a..ddf784f996a59 100644\n--- a/mm/shrinker.c\n+++ b/mm/shrinker.c\n@@ -410,7 +410,8 @@ static unsigned long do_shrink_slab(struct shrink_control *shrinkctl,\n \ttotal_scan = min(total_scan, (2 * freeable));\n \n \ttrace_mm_shrink_slab_start(shrinker, shrinkctl, nr,\n-\t\t\t\t   freeable, delta, total_scan, priority);\n+\t\t\t\t   freeable, delta, total_scan, priority,\n+\t\t\t\t   shrinkctl->memcg);\n \n \t/*\n \t * Normally, we should not scan less than batch_size objects in one\n@@ -461,7 +462,8 @@ static unsigned long do_shrink_slab(struct shrink_control *shrinkctl,\n \t */\n \tnew_nr = add_nr_deferred(next_deferred, shrinker, shrinkctl);\n \n-\ttrace_mm_shrink_slab_end(shrinker, shrinkctl->nid, freed, nr, new_nr, total_scan);\n+\ttrace_mm_shrink_slab_end(shrinker, shrinkctl->nid, freed, nr, new_nr, total_scan,\n+\t\t\t\t shrinkctl->memcg);\n \treturn freed;\n }\n \ndiff --git a/mm/vmscan.c b/mm/vmscan.c\nindex 614ccf39fe3fa..9d512fb354fcd 100644\n--- a/mm/vmscan.c\n+++ b/mm/vmscan.c\n@@ -6603,11 +6603,11 @@ unsigned long try_to_free_pages(struct zonelist *zonelist, int order,\n \t\treturn 1;\n \n \tset_task_reclaim_state(current, &sc.reclaim_state);\n-\ttrace_mm_vmscan_direct_reclaim_begin(order, sc.gfp_mask);\n+\ttrace_mm_vmscan_direct_reclaim_begin(sc.gfp_mask, order, 0);\n \n \tnr_reclaimed = do_try_to_free_pages(zonelist, &sc);\n \n-\ttrace_mm_vmscan_direct_reclaim_end(nr_reclaimed);\n+\ttrace_mm_vmscan_direct_reclaim_end(nr_reclaimed, 0);\n \tset_task_reclaim_state(current, NULL);\n \n \treturn nr_reclaimed;\n@@ -6636,8 +6636,9 @@ unsigned long mem_cgroup_shrink_node(struct mem_cgroup *memcg,\n \tsc.gfp_mask = (gfp_mask & GFP_RECLAIM_MASK) |\n \t\t\t(GFP_HIGHUSER_MOVABLE & ~GFP_RECLAIM_MASK);\n \n-\ttrace_mm_vmscan_memcg_softlimit_reclaim_begin(sc.order,\n-\t\t\t\t\t\t      sc.gfp_mask);\n+\ttrace_mm_vmscan_memcg_softlimit_reclaim_begin(sc.gfp_mask,\n+\t\t\t\t\t\t      sc.order,\n+\t\t\t\t\t\t      memcg);\n \n \t/*\n \t * NOTE: Although we can get the priority field, using it\n@@ -6648,7 +6649,7 @@ unsigned long mem_cgroup_shrink_node(struct mem_cgroup *memcg,\n \t */\n \tshrink_lruvec(lruvec, &sc);\n \n-\ttrace_mm_vmscan_memcg_softlimit_reclaim_end(sc.nr_reclaimed);\n+\ttrace_mm_vmscan_memcg_softlimit_reclaim_end(sc.nr_reclaimed, memcg);\n \n \t*nr_scanned = sc.nr_scanned;\n \n@@ -6684,13 +6685,13 @@ unsigned long try_to_free_mem_cgroup_pages(struct mem_cgroup *memcg,\n \tstruct zonelist *zonelist = node_zonelist(numa_node_id(), sc.gfp_mask);\n \n \tset_task_reclaim_state(current, &sc.reclaim_state);\n-\ttrace_mm_vmscan_memcg_reclaim_begin(0, sc.gfp_mask);\n+\ttrace_mm_vmscan_memcg_reclaim_begin(sc.gfp_mask, 0, memcg);\n \tnoreclaim_flag = memalloc_noreclaim_save();\n \n \tnr_reclaimed = do_try_to_free_pages(zonelist, &sc);\n \n \tmemalloc_noreclaim_restore(noreclaim_flag);\n-\ttrace_mm_vmscan_memcg_reclaim_end(nr_reclaimed);\n+\ttrace_mm_vmscan_memcg_reclaim_end(nr_reclaimed, memcg);\n \tset_task_reclaim_state(current, NULL);\n \n \treturn nr_reclaimed;\n@@ -7642,7 +7643,7 @@ static unsigned long __node_reclaim(struct pglist_data *pgdat, gfp_t gfp_mask,\n \tdelayacct_freepages_end();\n \tpsi_memstall_leave(&pflags);\n \n-\ttrace_mm_vmscan_node_reclaim_end(sc->nr_reclaimed);\n+\ttrace_mm_vmscan_node_reclaim_end(sc->nr_reclaimed, 0);\n \n \treturn sc->nr_reclaimed;\n }\n-- \n2.33.8",
          "reply_to": "",
          "message_date": "2026-02-13"
        },
        {
          "author": "Thomas Ballasi (author)",
          "summary": "The author is addressing a concern about the reliability of PID detection in interrupt or RCU contexts, explaining that they use in_task() to safely access current->pid when in process context and set it to -1 as a sentinel value otherwise.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "The changes aims at adding additionnal tracepoints variables to help\ndebuggers attribute them to specific processes.\n\nThe PID field uses in_task() to reliably detect when we're in process\ncontext and can safely access current->pid.  When not in process\ncontext (such as in interrupt or in an asynchronous RCU context), the\nfield is set to -1 as a sentinel value.\n\nSigned-off-by: Thomas Ballasi <tballasi@linux.microsoft.com>\n---\n include/trace/events/vmscan.h | 35 +++++++++++++++++++++++++----------\n 1 file changed, 25 insertions(+), 10 deletions(-)\n\ndiff --git a/include/trace/events/vmscan.h b/include/trace/events/vmscan.h\nindex 1212f6a7c223e..a68b712ef757a 100644\n--- a/include/trace/events/vmscan.h\n+++ b/include/trace/events/vmscan.h\n@@ -122,18 +122,22 @@ DECLARE_EVENT_CLASS(mm_vmscan_direct_reclaim_begin_template,\n \t\t__field(\tunsigned long,\tgfp_flags\t)\n \t\t__field(\tu64,\tmemcg_id\t)\n \t\t__field(\tint,\torder\t\t)\n+\t\t__field(\tint,\tpid\t\t)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->gfp_flags\t= (__force unsigned long)gfp_flags;\n \t\t__entry->order\t\t= order;\n+\t\t__entry->pid\t\t= current->pid;\n \t\t__entry->memcg_id\t= mem_cgroup_id(memcg);\n \t),\n \n-\tTP_printk(\"order=%d gfp_flags=%s memcg_id=%llu\",\n+\tTP_printk(\"order=%d gfp_flags=%s pid=%d memcg_id=%llu %s\",\n \t\t__entry->order,\n \t\tshow_gfp_flags(__entry->gfp_flags),\n-\t\t__entry->memcg_id)\n+\t\t__entry->pid,\n+\t\t__entry->memcg_id,\n+\t\t__event_in_irq() ? \"(in-irq)\" : \"\")\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_begin_template, mm_vmscan_direct_reclaim_begin,\n@@ -168,16 +172,20 @@ DECLARE_EVENT_CLASS(mm_vmscan_direct_reclaim_end_template,\n \tTP_STRUCT__entry(\n \t\t__field(\tunsigned long,\tnr_reclaimed\t)\n \t\t__field(\tu64,\tmemcg_id\t)\n+\t\t__field(\tint,\tpid\t\t)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->nr_reclaimed\t= nr_reclaimed;\n \t\t__entry->memcg_id\t= mem_cgroup_id(memcg);\n+\t\t__entry->pid\t\t= current->pid;\n \t),\n \n-\tTP_printk(\"nr_reclaimed=%lu memcg_id=%llu\",\n+\tTP_printk(\"nr_reclaimed=%lu pid=%d memcg_id=%llu %s\",\n \t\t__entry->nr_reclaimed,\n-\t\t__entry->memcg_id)\n+\t\t__entry->pid,\n+\t\t__entry->memcg_id,\n+\t\t__event_in_irq() ? \"(in-irq)\" : \"\")\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_direct_reclaim_end,\n@@ -220,9 +228,10 @@ TRACE_EVENT(mm_shrink_slab_start,\n \t\t__field(unsigned long, cache_items)\n \t\t__field(unsigned long long, delta)\n \t\t__field(unsigned long, total_scan)\n+\t\t__field(u64, memcg_id)\n \t\t__field(int, priority)\n \t\t__field(int, nid)\n-\t\t__field(u64, memcg_id)\n+\t\t__field(int, pid)\n \t),\n \n \tTP_fast_assign(\n@@ -236,19 +245,22 @@ TRACE_EVENT(mm_shrink_slab_start,\n \t\t__entry->priority = priority;\n \t\t__entry->nid = sc->nid;\n \t\t__entry->memcg_id = mem_cgroup_id(memcg);\n+\t\t__entry->pid = current->pid;\n \t),\n \n-\tTP_printk(\"%pS %p: nid: %d memcg_id: %llu objects to shrink %ld gfp_flags %s cache items %ld delta %lld total_scan %ld priority %d\",\n+\tTP_printk(\"%pS %p: nid: %d pid: %d memcg_id: %llu objects to shrink %ld gfp_flags %s cache items %ld delta %lld total_scan %ld priority %d %s\",\n \t\t__entry->shrink,\n \t\t__entry->shr,\n \t\t__entry->nid,\n+\t\t__entry->pid,\n \t\t__entry->memcg_id,\n \t\t__entry->nr_objects_to_shrink,\n \t\tshow_gfp_flags(__entry->gfp_flags),\n \t\t__entry->cache_items,\n \t\t__entry->delta,\n \t\t__entry->total_scan,\n-\t\t__entry->priority)\n+\t\t__entry->priority,\n+\t\t__event_in_irq() ? \"(in-irq)\" : \"\")\n );\n \n TRACE_EVENT(mm_shrink_slab_end,\n@@ -266,29 +278,32 @@ TRACE_EVENT(mm_shrink_slab_end,\n \t\t__field(long, total_scan)\n \t\t__field(int, nid)\n \t\t__field(int, retval)\n+\t\t__field(int, pid)\n \t\t__field(u64, memcg_id)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->shr = shr;\n-\t\t__entry->shrink = shr->scan_objects;\n \t\t__entry->unused_scan = unused_scan_cnt;\n \t\t__entry->new_scan = new_scan_cnt;\n \t\t__entry->total_scan = total_scan;\n \t\t__entry->nid = nid;\n \t\t__entry->retval = shrinker_retval;\n+\t\t__entry->pid = current->pid;\n \t\t__entry->memcg_id = mem_cgroup_id(memcg);\n \t),\n \n-\tTP_printk(\"%pS %p: nid: %d memcg_id: %llu unused scan count %ld new scan count %ld total_scan %ld last shrinker return val %d\",\n+\tTP_printk(\"%pS %p: nid: %d pid: %d memcg_id: %llu unused scan count %ld new scan count %ld total_scan %ld last shrinker return val %d %s\",\n \t\t__entry->shrink,\n \t\t__entry->shr,\n \t\t__entry->nid,\n+\t\t__entry->pid,\n \t\t__entry->memcg_id,\n \t\t__entry->unused_scan,\n \t\t__entry->new_scan,\n \t\t__entry->total_scan,\n-\t\t__entry->retval)\n+\t\t__entry->retval,\n+\t\t__event_in_irq() ? \"(in-irq)\" : \"\")\n );\n \n TRACE_EVENT(mm_vmscan_lru_isolate,\n-- \n2.33.8",
          "reply_to": "",
          "message_date": "2026-02-13"
        }
      ],
      "analysis_source": "llm-per-reviewer"
    },
    "2026-02-16": {
      "report_file": "2026-02-23_ollama_llama3.1-8b.html",
      "developer": "Shakeel Butt",
      "reviews": [
        {
          "author": "Usama Arif",
          "summary": "Reviewer questioned the removal of __entry->shrink in the patch, wondering if it was an unintended change.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "unclear intention",
            "potential mistake"
          ],
          "has_inline_review": true,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "__entry->shrink is removed here, but still printed below. Was this an intended\nchange of this commit?",
          "reply_to": "Thomas Ballasi",
          "message_date": "2026-02-16"
        },
        {
          "author": "Steven Rostedt",
          "summary": "reviewer noted that the patch does not handle the case where a task is being migrated, and requested that the PID be updated to reflect the new location of the task\n\nreviewer made a lighthearted comment about the patch, not raising any technical concerns or suggestions",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "migrating tasks",
            "PID update"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "On Mon, 16 Feb 2026 08:13:21 -0800\nUsama Arif <usama.arif@linux.dev> wrote:\n\n---\n\nYeah. That's when you should have done \"cut-and-paste\" but instead just\ntyped it in by memory :-p\n\n-- Steve",
          "reply_to": "Usama Arif",
          "message_date": "2026-02-16"
        }
      ],
      "analysis_source": "llm-per-reviewer"
    },
    "2026-02-23": {
      "report_file": "2026-02-23_ollama_llama3.1-8b.html",
      "developer": "Shakeel Butt",
      "reviews": [
        {
          "author": "Thomas Ballasi (author)",
          "summary": "Author addressed a concern about the __entry_in_irq() macro being renamed to __event_in_irq(), confirming that the change was made in v6 and providing a link to the updated patch.",
          "sentiment": "positive",
          "sentiment_signals": [
            "acknowledged fix",
            "provided clarification"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Changes in v6:\n- Edited __entry_in_irq() to __event_in_irq() in corresponding commit\n  message\n- Restore an entry that was removed inadvertently\n\nLink to v6:\nhttps://lore.kernel.org/linux-trace-kernel/20260213181537.54350-1-tballasi@linux.microsoft.com/\n\nSigned-off-by: Thomas Ballasi <tballasi@linux.microsoft.com>\n\nSteven Rostedt (1):\n  tracing: Add __event_in_*irq() helpers\n\nThomas Ballasi (2):\n  mm: vmscan: add cgroup IDs to vmscan tracepoints\n  mm: vmscan: add PIDs to vmscan tracepoints\n\n include/trace/events/vmscan.h              | 103 +++++++++++++--------\n include/trace/stages/stage3_trace_output.h |   8 ++\n include/trace/stages/stage7_class_define.h |  19 ++++\n mm/shrinker.c                              |   6 +-\n mm/vmscan.c                                |  17 ++--\n 5 files changed, 106 insertions(+), 47 deletions(-)\n\n-- \n2.33.8",
          "reply_to": "",
          "message_date": "2026-02-23"
        },
        {
          "author": "Thomas Ballasi (author)",
          "summary": "The author is addressing a concern about tracepoint flags and interrupt context, explaining that instead of recording this information in the event structure itself, helper macros can be used to print the relevant information in the format string.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "From: Steven Rostedt <rostedt@goodmis.org>\n\nSome trace events want to expose in their output if they were triggered in\nan interrupt or softirq context. Instead of recording this in the event\nstructure itself, as this information is stored in the flags portion of\nthe event header, add helper macros that can be used in the print format:\n\n  TP_printk(\"val=%d %s\", __entry->val, __event_in_irq() ? \"(in-irq)\" : \"\")\n\nThis will output \"(in-irq)\" for the event in the trace data if the event\nwas triggered in hard or soft interrupt context.\n\nLink: https://lore.kernel.org/all/20251229132942.31a2b583@gandalf.local.home/\n\nSigned-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>\nSigned-off-by: Thomas Ballasi <tballasi@linux.microsoft.com>\n---\n include/trace/stages/stage3_trace_output.h |  8 ++++++++\n include/trace/stages/stage7_class_define.h | 19 +++++++++++++++++++\n 2 files changed, 27 insertions(+)\n\ndiff --git a/include/trace/stages/stage3_trace_output.h b/include/trace/stages/stage3_trace_output.h\nindex 1e7b0bef95f52..53a23988a3b8a 100644\n--- a/include/trace/stages/stage3_trace_output.h\n+++ b/include/trace/stages/stage3_trace_output.h\n@@ -150,3 +150,11 @@\n \n #undef __get_buf\n #define __get_buf(len)\t\ttrace_seq_acquire(p, (len))\n+\n+#undef __event_in_hardirq\n+#undef __event_in_softirq\n+#undef __event_in_irq\n+\n+#define __event_in_hardirq()\t(__entry->ent.flags & TRACE_FLAG_HARDIRQ)\n+#define __event_in_softirq()\t(__entry->ent.flags & TRACE_FLAG_SOFTIRQ)\n+#define __event_in_irq()\t(__entry->ent.flags & (TRACE_FLAG_HARDIRQ | TRACE_FLAG_SOFTIRQ))\ndiff --git a/include/trace/stages/stage7_class_define.h b/include/trace/stages/stage7_class_define.h\nindex fcd564a590f43..47008897a7956 100644\n--- a/include/trace/stages/stage7_class_define.h\n+++ b/include/trace/stages/stage7_class_define.h\n@@ -26,6 +26,25 @@\n #undef __print_hex_dump\n #undef __get_buf\n \n+#undef __event_in_hardirq\n+#undef __event_in_softirq\n+#undef __event_in_irq\n+\n+/*\n+ * The TRACE_FLAG_* are enums. Instead of using TRACE_DEFINE_ENUM(),\n+ * use their hardcoded values. These values are parsed by user space\n+ * tooling elsewhere so they will never change.\n+ *\n+ * See \"enum trace_flag_type\" in linux/trace_events.h:\n+ *   TRACE_FLAG_HARDIRQ\n+ *   TRACE_FLAG_SOFTIRQ\n+ */\n+\n+/* This is what is displayed in the format files */\n+#define __event_in_hardirq()\t(REC->common_flags & 0x8)\n+#define __event_in_softirq()\t(REC->common_flags & 0x10)\n+#define __event_in_irq()\t(REC->common_flags & 0x18)\n+\n /*\n  * The below is not executed in the kernel. It is only what is\n  * displayed in the print format for userspace to parse.\n-- \n2.33.8",
          "reply_to": "",
          "message_date": "2026-02-23"
        },
        {
          "author": "Thomas Ballasi (author)",
          "summary": "The author is addressing concerns about the patch's ability to attribute memory reclaim events to specific cgroups, making debugging challenging. The author explains that the field is defaulted to 0 for operations not associated with a specific cgroup and provides context on why this is necessary.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Memory reclaim events are currently difficult to attribute to\nspecific cgroups, making debugging memory pressure issues\nchallenging.  This patch adds memory cgroup ID (memcg_id) to key\nvmscan tracepoints to enable better correlation and analysis.\n\nFor operations not associated with a specific cgroup, the field\nis defaulted to 0.\n\nSigned-off-by: Thomas Ballasi <tballasi@linux.microsoft.com>\n---\n include/trace/events/vmscan.h | 83 ++++++++++++++++++++---------------\n mm/shrinker.c                 |  6 ++-\n mm/vmscan.c                   | 17 +++----\n 3 files changed, 61 insertions(+), 45 deletions(-)\n\ndiff --git a/include/trace/events/vmscan.h b/include/trace/events/vmscan.h\nindex 490958fa10dee..1212f6a7c223e 100644\n--- a/include/trace/events/vmscan.h\n+++ b/include/trace/events/vmscan.h\n@@ -114,85 +114,92 @@ TRACE_EVENT(mm_vmscan_wakeup_kswapd,\n \n DECLARE_EVENT_CLASS(mm_vmscan_direct_reclaim_begin_template,\n \n-\tTP_PROTO(int order, gfp_t gfp_flags),\n+\tTP_PROTO(gfp_t gfp_flags, int order, struct mem_cgroup *memcg),\n \n-\tTP_ARGS(order, gfp_flags),\n+\tTP_ARGS(gfp_flags, order, memcg),\n \n \tTP_STRUCT__entry(\n-\t\t__field(\tint,\torder\t\t)\n \t\t__field(\tunsigned long,\tgfp_flags\t)\n+\t\t__field(\tu64,\tmemcg_id\t)\n+\t\t__field(\tint,\torder\t\t)\n \t),\n \n \tTP_fast_assign(\n-\t\t__entry->order\t\t= order;\n \t\t__entry->gfp_flags\t= (__force unsigned long)gfp_flags;\n+\t\t__entry->order\t\t= order;\n+\t\t__entry->memcg_id\t= mem_cgroup_id(memcg);\n \t),\n \n-\tTP_printk(\"order=%d gfp_flags=%s\",\n+\tTP_printk(\"order=%d gfp_flags=%s memcg_id=%llu\",\n \t\t__entry->order,\n-\t\tshow_gfp_flags(__entry->gfp_flags))\n+\t\tshow_gfp_flags(__entry->gfp_flags),\n+\t\t__entry->memcg_id)\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_begin_template, mm_vmscan_direct_reclaim_begin,\n \n-\tTP_PROTO(int order, gfp_t gfp_flags),\n+\tTP_PROTO(gfp_t gfp_flags, int order, struct mem_cgroup *memcg),\n \n-\tTP_ARGS(order, gfp_flags)\n+\tTP_ARGS(gfp_flags, order, memcg)\n );\n \n #ifdef CONFIG_MEMCG\n DEFINE_EVENT(mm_vmscan_direct_reclaim_begin_template, mm_vmscan_memcg_reclaim_begin,\n \n-\tTP_PROTO(int order, gfp_t gfp_flags),\n+\tTP_PROTO(gfp_t gfp_flags, int order, struct mem_cgroup *memcg),\n \n-\tTP_ARGS(order, gfp_flags)\n+\tTP_ARGS(gfp_flags, order, memcg)\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_begin_template, mm_vmscan_memcg_softlimit_reclaim_begin,\n \n-\tTP_PROTO(int order, gfp_t gfp_flags),\n+\tTP_PROTO(gfp_t gfp_flags, int order, struct mem_cgroup *memcg),\n \n-\tTP_ARGS(order, gfp_flags)\n+\tTP_ARGS(gfp_flags, order, memcg)\n );\n #endif /* CONFIG_MEMCG */\n \n DECLARE_EVENT_CLASS(mm_vmscan_direct_reclaim_end_template,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, struct mem_cgroup *memcg),\n \n-\tTP_ARGS(nr_reclaimed),\n+\tTP_ARGS(nr_reclaimed, memcg),\n \n \tTP_STRUCT__entry(\n \t\t__field(\tunsigned long,\tnr_reclaimed\t)\n+\t\t__field(\tu64,\tmemcg_id\t)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->nr_reclaimed\t= nr_reclaimed;\n+\t\t__entry->memcg_id\t= mem_cgroup_id(memcg);\n \t),\n \n-\tTP_printk(\"nr_reclaimed=%lu\", __entry->nr_reclaimed)\n+\tTP_printk(\"nr_reclaimed=%lu memcg_id=%llu\",\n+\t\t__entry->nr_reclaimed,\n+\t\t__entry->memcg_id)\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_direct_reclaim_end,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, struct mem_cgroup *memcg),\n \n-\tTP_ARGS(nr_reclaimed)\n+\tTP_ARGS(nr_reclaimed, memcg)\n );\n \n #ifdef CONFIG_MEMCG\n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_memcg_reclaim_end,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, struct mem_cgroup *memcg),\n \n-\tTP_ARGS(nr_reclaimed)\n+\tTP_ARGS(nr_reclaimed, memcg)\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_memcg_softlimit_reclaim_end,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, struct mem_cgroup *memcg),\n \n-\tTP_ARGS(nr_reclaimed)\n+\tTP_ARGS(nr_reclaimed, memcg)\n );\n #endif /* CONFIG_MEMCG */\n \n@@ -200,39 +207,42 @@ TRACE_EVENT(mm_shrink_slab_start,\n \tTP_PROTO(struct shrinker *shr, struct shrink_control *sc,\n \t\tlong nr_objects_to_shrink, unsigned long cache_items,\n \t\tunsigned long long delta, unsigned long total_scan,\n-\t\tint priority),\n+\t\tint priority, struct mem_cgroup *memcg),\n \n \tTP_ARGS(shr, sc, nr_objects_to_shrink, cache_items, delta, total_scan,\n-\t\tpriority),\n+\t\tpriority, memcg),\n \n \tTP_STRUCT__entry(\n \t\t__field(struct shrinker *, shr)\n \t\t__field(void *, shrink)\n-\t\t__field(int, nid)\n \t\t__field(long, nr_objects_to_shrink)\n \t\t__field(unsigned long, gfp_flags)\n \t\t__field(unsigned long, cache_items)\n \t\t__field(unsigned long long, delta)\n \t\t__field(unsigned long, total_scan)\n \t\t__field(int, priority)\n+\t\t__field(int, nid)\n+\t\t__field(u64, memcg_id)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->shr = shr;\n \t\t__entry->shrink = shr->scan_objects;\n-\t\t__entry->nid = sc->nid;\n \t\t__entry->nr_objects_to_shrink = nr_objects_to_shrink;\n \t\t__entry->gfp_flags = (__force unsigned long)sc->gfp_mask;\n \t\t__entry->cache_items = cache_items;\n \t\t__entry->delta = delta;\n \t\t__entry->total_scan = total_scan;\n \t\t__entry->priority = priority;\n+\t\t__entry->nid = sc->nid;\n+\t\t__entry->memcg_id = mem_cgroup_id(memcg);\n \t),\n \n-\tTP_printk(\"%pS %p: nid: %d objects to shrink %ld gfp_flags %s cache items %ld delta %lld total_scan %ld priority %d\",\n+\tTP_printk(\"%pS %p: nid: %d memcg_id: %llu objects to shrink %ld gfp_flags %s cache items %ld delta %lld total_scan %ld priority %d\",\n \t\t__entry->shrink,\n \t\t__entry->shr,\n \t\t__entry->nid,\n+\t\t__entry->memcg_id,\n \t\t__entry->nr_objects_to_shrink,\n \t\tshow_gfp_flags(__entry->gfp_flags),\n \t\t__entry->cache_items,\n@@ -243,35 +253,38 @@ TRACE_EVENT(mm_shrink_slab_start,\n \n TRACE_EVENT(mm_shrink_slab_end,\n \tTP_PROTO(struct shrinker *shr, int nid, int shrinker_retval,\n-\t\tlong unused_scan_cnt, long new_scan_cnt, long total_scan),\n+\t\tlong unused_scan_cnt, long new_scan_cnt, long total_scan, struct mem_cgroup *memcg),\n \n \tTP_ARGS(shr, nid, shrinker_retval, unused_scan_cnt, new_scan_cnt,\n-\t\ttotal_scan),\n+\t\ttotal_scan, memcg),\n \n \tTP_STRUCT__entry(\n \t\t__field(struct shrinker *, shr)\n-\t\t__field(int, nid)\n \t\t__field(void *, shrink)\n \t\t__field(long, unused_scan)\n \t\t__field(long, new_scan)\n-\t\t__field(int, retval)\n \t\t__field(long, total_scan)\n+\t\t__field(int, nid)\n+\t\t__field(int, retval)\n+\t\t__field(u64, memcg_id)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->shr = shr;\n-\t\t__entry->nid = nid;\n \t\t__entry->shrink = shr->scan_objects;\n \t\t__entry->unused_scan = unused_scan_cnt;\n \t\t__entry->new_scan = new_scan_cnt;\n-\t\t__entry->retval = shrinker_retval;\n \t\t__entry->total_scan = total_scan;\n+\t\t__entry->nid = nid;\n+\t\t__entry->retval = shrinker_retval;\n+\t\t__entry->memcg_id = mem_cgroup_id(memcg);\n \t),\n \n-\tTP_printk(\"%pS %p: nid: %d unused scan count %ld new scan count %ld total_scan %ld last shrinker return val %d\",\n+\tTP_printk(\"%pS %p: nid: %d memcg_id: %llu unused scan count %ld new scan count %ld total_scan %ld last shrinker return val %d\",\n \t\t__entry->shrink,\n \t\t__entry->shr,\n \t\t__entry->nid,\n+\t\t__entry->memcg_id,\n \t\t__entry->unused_scan,\n \t\t__entry->new_scan,\n \t\t__entry->total_scan,\n@@ -504,9 +517,9 @@ TRACE_EVENT(mm_vmscan_node_reclaim_begin,\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_node_reclaim_end,\n \n-\tTP_PROTO(unsigned long nr_reclaimed),\n+\tTP_PROTO(unsigned long nr_reclaimed, struct mem_cgroup *memcg),\n \n-\tTP_ARGS(nr_reclaimed)\n+\tTP_ARGS(nr_reclaimed, memcg)\n );\n \n TRACE_EVENT(mm_vmscan_throttled,\ndiff --git a/mm/shrinker.c b/mm/shrinker.c\nindex 4a93fd433689a..ddf784f996a59 100644\n--- a/mm/shrinker.c\n+++ b/mm/shrinker.c\n@@ -410,7 +410,8 @@ static unsigned long do_shrink_slab(struct shrink_control *shrinkctl,\n \ttotal_scan = min(total_scan, (2 * freeable));\n \n \ttrace_mm_shrink_slab_start(shrinker, shrinkctl, nr,\n-\t\t\t\t   freeable, delta, total_scan, priority);\n+\t\t\t\t   freeable, delta, total_scan, priority,\n+\t\t\t\t   shrinkctl->memcg);\n \n \t/*\n \t * Normally, we should not scan less than batch_size objects in one\n@@ -461,7 +462,8 @@ static unsigned long do_shrink_slab(struct shrink_control *shrinkctl,\n \t */\n \tnew_nr = add_nr_deferred(next_deferred, shrinker, shrinkctl);\n \n-\ttrace_mm_shrink_slab_end(shrinker, shrinkctl->nid, freed, nr, new_nr, total_scan);\n+\ttrace_mm_shrink_slab_end(shrinker, shrinkctl->nid, freed, nr, new_nr, total_scan,\n+\t\t\t\t shrinkctl->memcg);\n \treturn freed;\n }\n \ndiff --git a/mm/vmscan.c b/mm/vmscan.c\nindex 614ccf39fe3fa..9d512fb354fcd 100644\n--- a/mm/vmscan.c\n+++ b/mm/vmscan.c\n@@ -6603,11 +6603,11 @@ unsigned long try_to_free_pages(struct zonelist *zonelist, int order,\n \t\treturn 1;\n \n \tset_task_reclaim_state(current, &sc.reclaim_state);\n-\ttrace_mm_vmscan_direct_reclaim_begin(order, sc.gfp_mask);\n+\ttrace_mm_vmscan_direct_reclaim_begin(sc.gfp_mask, order, 0);\n \n \tnr_reclaimed = do_try_to_free_pages(zonelist, &sc);\n \n-\ttrace_mm_vmscan_direct_reclaim_end(nr_reclaimed);\n+\ttrace_mm_vmscan_direct_reclaim_end(nr_reclaimed, 0);\n \tset_task_reclaim_state(current, NULL);\n \n \treturn nr_reclaimed;\n@@ -6636,8 +6636,9 @@ unsigned long mem_cgroup_shrink_node(struct mem_cgroup *memcg,\n \tsc.gfp_mask = (gfp_mask & GFP_RECLAIM_MASK) |\n \t\t\t(GFP_HIGHUSER_MOVABLE & ~GFP_RECLAIM_MASK);\n \n-\ttrace_mm_vmscan_memcg_softlimit_reclaim_begin(sc.order,\n-\t\t\t\t\t\t      sc.gfp_mask);\n+\ttrace_mm_vmscan_memcg_softlimit_reclaim_begin(sc.gfp_mask,\n+\t\t\t\t\t\t      sc.order,\n+\t\t\t\t\t\t      memcg);\n \n \t/*\n \t * NOTE: Although we can get the priority field, using it\n@@ -6648,7 +6649,7 @@ unsigned long mem_cgroup_shrink_node(struct mem_cgroup *memcg,\n \t */\n \tshrink_lruvec(lruvec, &sc);\n \n-\ttrace_mm_vmscan_memcg_softlimit_reclaim_end(sc.nr_reclaimed);\n+\ttrace_mm_vmscan_memcg_softlimit_reclaim_end(sc.nr_reclaimed, memcg);\n \n \t*nr_scanned = sc.nr_scanned;\n \n@@ -6684,13 +6685,13 @@ unsigned long try_to_free_mem_cgroup_pages(struct mem_cgroup *memcg,\n \tstruct zonelist *zonelist = node_zonelist(numa_node_id(), sc.gfp_mask);\n \n \tset_task_reclaim_state(current, &sc.reclaim_state);\n-\ttrace_mm_vmscan_memcg_reclaim_begin(0, sc.gfp_mask);\n+\ttrace_mm_vmscan_memcg_reclaim_begin(sc.gfp_mask, 0, memcg);\n \tnoreclaim_flag = memalloc_noreclaim_save();\n \n \tnr_reclaimed = do_try_to_free_pages(zonelist, &sc);\n \n \tmemalloc_noreclaim_restore(noreclaim_flag);\n-\ttrace_mm_vmscan_memcg_reclaim_end(nr_reclaimed);\n+\ttrace_mm_vmscan_memcg_reclaim_end(nr_reclaimed, memcg);\n \tset_task_reclaim_state(current, NULL);\n \n \treturn nr_reclaimed;\n@@ -7642,7 +7643,7 @@ static unsigned long __node_reclaim(struct pglist_data *pgdat, gfp_t gfp_mask,\n \tdelayacct_freepages_end();\n \tpsi_memstall_leave(&pflags);\n \n-\ttrace_mm_vmscan_node_reclaim_end(sc->nr_reclaimed);\n+\ttrace_mm_vmscan_node_reclaim_end(sc->nr_reclaimed, 0);\n \n \treturn sc->nr_reclaimed;\n }\n-- \n2.33.8",
          "reply_to": "",
          "message_date": "2026-02-23"
        },
        {
          "author": "Thomas Ballasi (author)",
          "summary": "The author addressed a concern about the reliability of PID detection in interrupt or RCU contexts, explaining that the PID field is set to -1 as a sentinel value when not in process context and using in_task() to safely access current->pid when in process context.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "The changes aims at adding additionnal tracepoints variables to help\ndebuggers attribute them to specific processes.\n\nThe PID field uses in_task() to reliably detect when we're in process\ncontext and can safely access current->pid.  When not in process\ncontext (such as in interrupt or in an asynchronous RCU context), the\nfield is set to -1 as a sentinel value.\n\nSigned-off-by: Thomas Ballasi <tballasi@linux.microsoft.com>\n---\n include/trace/events/vmscan.h | 34 +++++++++++++++++++++++++---------\n 1 file changed, 25 insertions(+), 9 deletions(-)\n\ndiff --git a/include/trace/events/vmscan.h b/include/trace/events/vmscan.h\nindex 1212f6a7c223e..15b31281f0955 100644\n--- a/include/trace/events/vmscan.h\n+++ b/include/trace/events/vmscan.h\n@@ -122,18 +122,22 @@ DECLARE_EVENT_CLASS(mm_vmscan_direct_reclaim_begin_template,\n \t\t__field(\tunsigned long,\tgfp_flags\t)\n \t\t__field(\tu64,\tmemcg_id\t)\n \t\t__field(\tint,\torder\t\t)\n+\t\t__field(\tint,\tpid\t\t)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->gfp_flags\t= (__force unsigned long)gfp_flags;\n \t\t__entry->order\t\t= order;\n+\t\t__entry->pid\t\t= current->pid;\n \t\t__entry->memcg_id\t= mem_cgroup_id(memcg);\n \t),\n \n-\tTP_printk(\"order=%d gfp_flags=%s memcg_id=%llu\",\n+\tTP_printk(\"order=%d gfp_flags=%s pid=%d memcg_id=%llu %s\",\n \t\t__entry->order,\n \t\tshow_gfp_flags(__entry->gfp_flags),\n-\t\t__entry->memcg_id)\n+\t\t__entry->pid,\n+\t\t__entry->memcg_id,\n+\t\t__event_in_irq() ? \"(in-irq)\" : \"\")\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_begin_template, mm_vmscan_direct_reclaim_begin,\n@@ -168,16 +172,20 @@ DECLARE_EVENT_CLASS(mm_vmscan_direct_reclaim_end_template,\n \tTP_STRUCT__entry(\n \t\t__field(\tunsigned long,\tnr_reclaimed\t)\n \t\t__field(\tu64,\tmemcg_id\t)\n+\t\t__field(\tint,\tpid\t\t)\n \t),\n \n \tTP_fast_assign(\n \t\t__entry->nr_reclaimed\t= nr_reclaimed;\n \t\t__entry->memcg_id\t= mem_cgroup_id(memcg);\n+\t\t__entry->pid\t\t= current->pid;\n \t),\n \n-\tTP_printk(\"nr_reclaimed=%lu memcg_id=%llu\",\n+\tTP_printk(\"nr_reclaimed=%lu pid=%d memcg_id=%llu %s\",\n \t\t__entry->nr_reclaimed,\n-\t\t__entry->memcg_id)\n+\t\t__entry->pid,\n+\t\t__entry->memcg_id,\n+\t\t__event_in_irq() ? \"(in-irq)\" : \"\")\n );\n \n DEFINE_EVENT(mm_vmscan_direct_reclaim_end_template, mm_vmscan_direct_reclaim_end,\n@@ -220,9 +228,10 @@ TRACE_EVENT(mm_shrink_slab_start,\n \t\t__field(unsigned long, cache_items)\n \t\t__field(unsigned long long, delta)\n \t\t__field(unsigned long, total_scan)\n+\t\t__field(u64, memcg_id)\n \t\t__field(int, priority)\n \t\t__field(int, nid)\n-\t\t__field(u64, memcg_id)\n+\t\t__field(int, pid)\n \t),\n \n \tTP_fast_assign(\n@@ -236,19 +245,22 @@ TRACE_EVENT(mm_shrink_slab_start,\n \t\t__entry->priority = priority;\n \t\t__entry->nid = sc->nid;\n \t\t__entry->memcg_id = mem_cgroup_id(memcg);\n+\t\t__entry->pid = current->pid;\n \t),\n \n-\tTP_printk(\"%pS %p: nid: %d memcg_id: %llu objects to shrink %ld gfp_flags %s cache items %ld delta %lld total_scan %ld priority %d\",\n+\tTP_printk(\"%pS %p: nid: %d pid: %d memcg_id: %llu objects to shrink %ld gfp_flags %s cache items %ld delta %lld total_scan %ld priority %d %s\",\n \t\t__entry->shrink,\n \t\t__entry->shr,\n \t\t__entry->nid,\n+\t\t__entry->pid,\n \t\t__entry->memcg_id,\n \t\t__entry->nr_objects_to_shrink,\n \t\tshow_gfp_flags(__entry->gfp_flags),\n \t\t__entry->cache_items,\n \t\t__entry->delta,\n \t\t__entry->total_scan,\n-\t\t__entry->priority)\n+\t\t__entry->priority,\n+\t\t__event_in_irq() ? \"(in-irq)\" : \"\")\n );\n \n TRACE_EVENT(mm_shrink_slab_end,\n@@ -266,6 +278,7 @@ TRACE_EVENT(mm_shrink_slab_end,\n \t\t__field(long, total_scan)\n \t\t__field(int, nid)\n \t\t__field(int, retval)\n+\t\t__field(int, pid)\n \t\t__field(u64, memcg_id)\n \t),\n \n@@ -277,18 +290,21 @@ TRACE_EVENT(mm_shrink_slab_end,\n \t\t__entry->total_scan = total_scan;\n \t\t__entry->nid = nid;\n \t\t__entry->retval = shrinker_retval;\n+\t\t__entry->pid = current->pid;\n \t\t__entry->memcg_id = mem_cgroup_id(memcg);\n \t),\n \n-\tTP_printk(\"%pS %p: nid: %d memcg_id: %llu unused scan count %ld new scan count %ld total_scan %ld last shrinker return val %d\",\n+\tTP_printk(\"%pS %p: nid: %d pid: %d memcg_id: %llu unused scan count %ld new scan count %ld total_scan %ld last shrinker return val %d %s\",\n \t\t__entry->shrink,\n \t\t__entry->shr,\n \t\t__entry->nid,\n+\t\t__entry->pid,\n \t\t__entry->memcg_id,\n \t\t__entry->unused_scan,\n \t\t__entry->new_scan,\n \t\t__entry->total_scan,\n-\t\t__entry->retval)\n+\t\t__entry->retval,\n+\t\t__event_in_irq() ? \"(in-irq)\" : \"\")\n );\n \n TRACE_EVENT(mm_vmscan_lru_isolate,\n-- \n2.33.8",
          "reply_to": "",
          "message_date": "2026-02-23"
        },
        {
          "author": "Shakeel Butt",
          "summary": "Gave Reviewed-by",
          "sentiment": "positive",
          "sentiment_signals": [],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "heuristic",
          "raw_body": "",
          "reply_to": "Thomas Ballasi",
          "message_date": "2026-02-23"
        },
        {
          "author": "Shakeel Butt",
          "summary": "Gave Acked-by",
          "sentiment": "positive",
          "sentiment_signals": [],
          "has_inline_review": false,
          "tags_given": [
            "Acked-by"
          ],
          "analysis_source": "heuristic",
          "raw_body": "",
          "reply_to": "Thomas Ballasi",
          "message_date": "2026-02-23"
        },
        {
          "author": "Shakeel Butt",
          "summary": "Reviewer Shakeel Butt questioned the necessity of the in_task() check and pointed out that memory reclaim only occurs in process context, making the __event_in_irq() check unnecessary.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested change",
            "technical clarification"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Where is this in_task() check happening? Also this patch is changing\ntracepoints for memory reclaim which never happens in any context other than\nprocess context, so we don't need __event_in_irq() checks for these tracepoints.",
          "reply_to": "Thomas Ballasi",
          "message_date": "2026-02-23"
        }
      ],
      "analysis_source": "llm-per-reviewer"
    },
    "2026-02-24": {
      "report_file": "2026-02-23_ollama_llama3.1-8b.html",
      "developer": "Shakeel Butt",
      "reviews": [
        {
          "author": "Masami (Google)",
          "summary": "reviewer noted that the patch does not handle the case where a task is being migrated to another node, and suggested adding a check for this condition\n\nReviewer Masami suggested using the existing common_pid field in the tracepoint format to store current->pid, instead of duplicating it.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes",
            "requested change"
          ],
          "has_inline_review": true,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Hi,\n\nOn Mon, 23 Feb 2026 09:15:44 -0800\nThomas Ballasi <tballasi@linux.microsoft.com> wrote:\n\n---\n\nAll entries saves current->pid in common_pid field. Can you use\nthis common field?\n\n# cat events/vmscan/mm_vmscan_reclaim_pages/format \nname: mm_vmscan_reclaim_pages\nID: 590\nformat:\n\tfield:unsigned short common_type;\toffset:0;\tsize:2;\tsigned:0;\n\tfield:unsigned char common_flags;\toffset:2;\tsize:1;\tsigned:0;\n\tfield:unsigned char common_preempt_count;\toffset:3;\tsize:1;\tsigned:0;\n\tfield:int common_pid;\toffset:4;\tsize:4;\tsigned:1;    ## <------------here\n\n\tfield:int nid;\toffset:8;\tsize:4;\tsigned:1;\n\tfield:unsigned long nr_scanned;\toffset:16;\tsize:8;\tsigned:0;\n\tfield:unsigned long nr_reclaimed;\toffset:24;\tsize:8;\tsigned:0;\n\tfield:unsigned long nr_dirty;\toffset:32;\tsize:8;\tsigned:0;\n\tfield:unsigned long nr_writeback;\toffset:40;\tsize:8;\tsigned:0;\n\tfield:unsigned long nr_congested;\toffset:48;\tsize:8;\tsigned:0;\n\tfield:unsigned long nr_immediate;\toffset:56;\tsize:8;\tsigned:0;\n\tfield:unsigned int nr_activate0;\toffset:64;\tsize:4;\tsigned:0;\n\tfield:unsigned int nr_activate1;\toffset:68;\tsize:4;\tsigned:0;\n\tfield:unsigned long nr_ref_keep;\toffset:72;\tsize:8;\tsigned:0;\n\tfield:unsigned long nr_unmap_fail;\toffset:80;\tsize:8;\tsigned:0;\n\nThank you,\n\n-- \nMasami Hiramatsu (Google) <mhiramat@kernel.org>",
          "reply_to": "Thomas Ballasi",
          "message_date": "2026-02-24"
        }
      ],
      "analysis_source": "llm-per-reviewer"
    }
  }
}