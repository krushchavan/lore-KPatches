{
  "thread_id": "20260212045109.255391-1-inwardvessel@gmail.com",
  "subject": "[PATCH 0/2] improve per-node allocation and reclaim visibility",
  "url": "https://lore.kernel.org/all/20260212045109.255391-1-inwardvessel@gmail.com/",
  "dates": {
    "2026-02-18": {
      "report_file": "2026-02-18_ollama_llama3.1-8b.html",
      "developer": "JP Kobryn",
      "reviews": [
        {
          "author": "kernel robot",
          "summary": "The reviewer noticed that the patch causes a lock ordering violation in __mod_node_page_state, which is triggered by reclaim paths, and requested further investigation.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "lock ordering issue",
            "reclaim paths"
          ],
          "has_inline_review": true,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Hello,\n\nkernel test robot noticed \"RIP:__mod_node_page_state\" on:\n\ncommit: 4b5f69459c0988d3b292aceb74633e04eea84c7f (\"[PATCH 1/2] mm/mempolicy: track page allocations per mempolicy\")\nurl: https://github.com/intel-lab-lkp/linux/commits/JP-Kobryn/mm-mempolicy-track-page-allocations-per-mempolicy/20260212-142941\nbase: https://git.kernel.org/cgit/linux/kernel/git/akpm/mm.git mm-everything\npatch link: https://lore.kernel.org/all/20260212045109.255391-2-inwardvessel@gmail.com/\npatch subject: [PATCH 1/2] mm/mempolicy: track page allocations per mempolicy\n\nin testcase: boot\n\nconfig: x86_64-randconfig-007-20250327\ncompiler: gcc-14\ntest machine: qemu-system-x86_64 -enable-kvm -cpu SandyBridge -smp 2 -m 32G\n\n(please refer to attached dmesg/kmsg for entire log/backtrace)\n\n\n+------------------------------------------------------------------+------------+------------+\n|                                                                  | 5cbf93e36f | 4b5f69459c |\n+------------------------------------------------------------------+------------+------------+\n| boot_successes                                                   | 244        | 0          |\n| boot_failures                                                    | 0          | 244        |\n| RIP:__mod_node_page_state                                        | 0          | 244        |\n| BUG:using__this_cpu_read()in_preemptible                         | 0          | 244        |\n| BUG:using__this_cpu_write()in_preemptible[#]code:kthreadd        | 0          | 244        |\n| BUG:using__this_cpu_write()in_preemptible[#]code:swapper         | 0          | 187        |\n| BUG:using__this_cpu_write()in_preemptible[#]code:kdevtmpfs       | 0          | 79         |\n| BUG:using__this_cpu_write()in_preemptible[#]code:kworker/u8      | 0          | 229        |\n| BUG:using__this_cpu_write()in_preemptible[#]code:udevd           | 0          | 62         |\n| BUG:using__this_cpu_write()in_preemptible[#]code:tail            | 0          | 21         |\n| BUG:using__this_cpu_write()in_preemptible[#]code:syslogd         | 0          | 54         |\n| BUG:using__this_cpu_write()in_preemptible[#]code:klogd           | 0          | 113        |\n| BUG:using__this_cpu_write()in_preemptible[#]code:sleep           | 0          | 98         |\n| BUG:using__this_cpu_write()in_preemptible[#]code:post-run        | 0          | 39         |\n| BUG:using__this_cpu_write()in_preemptible[#]code:rsync           | 0          | 9          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:modprobe        | 0          | 6          |\n| BUG:using__this_cpu_write()in_preemptible[#]code                 | 0          | 32         |\n| BUG:using__this_cpu_write()in_preemptible[#]code:udevadm         | 0          | 78         |\n| BUG:using__this_cpu_write()in_preemptible[#]code:systemd         | 0          | 39         |\n| BUG:using__this_cpu_write()in_preemptible[#]code:(udev-worker)   | 0          | 53         |\n| RIP:rep_movs_alternative                                         | 0          | 5          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:cat             | 0          | 7          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:sed             | 0          | 98         |\n| BUG:using__this_cpu_write()in_preemptible[#]code:systemd-udevd   | 0          | 19         |\n| BUG:using__this_cpu_write()in_preemptible[#]code:systemd-journal | 0          | 54         |\n| BUG:using__this_cpu_write()in_preemptible[#]code:systemd-random  | 0          | 4          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:journalctl      | 0          | 8          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:start_getty     | 0          | 4          |\n| RIP:__put_user_4                                                 | 0          | 24         |\n| BUG:using__this_cpu_write()in_preemptible[#]code:wget            | 0          | 82         |\n| BUG:using__this_cpu_write()in_preemptible[#]code:run-lkp         | 0          | 32         |\n| BUG:using__this_cpu_write()in_preemptible[#]code:boot-#-yocto-i3 | 0          | 24         |\n| BUG:using__this_cpu_write()in_preemptible[#]code:one-shot-monito | 0          | 4          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:vmstat          | 0          | 29         |\n| BUG:using__this_cpu_write()in_preemptible[#]code:rs:main_Q:Reg   | 0          | 9          |\n| RIP:rep_stos_alternative                                         | 0          | 11         |\n| BUG:using__this_cpu_write()in_preemptible[#]code:lkp-setup-rootf | 0          | 21         |\n| BUG:using__this_cpu_write()in_preemptible[#]code:stty            | 0          | 1          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:tee             | 0          | 7          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:systemd-rc-loca | 0          | 2          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:(exec-inner)    | 0          | 1          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:groupadd        | 0          | 1          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:(sd-exec-strv)  | 0          | 2          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:rc              | 0          | 14         |\n| BUG:using__this_cpu_write()in_preemptible[#]code:getty           | 0          | 18         |\n| BUG:using__this_cpu_write()in_preemptible[#]code:boot-#-debian   | 0          | 4          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:monitor         | 0          | 3          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:systemd-tmpfile | 0          | 6          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:lscpu           | 0          | 2          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:dirname         | 0          | 2          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:systemd-sysuser | 0          | 1          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:(d-sysctl)      | 0          | 2          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:mount           | 0          | 3          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:ls              | 0          | 1          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:pgrep           | 0          | 4          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:grep            | 0          | 8          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:S77lkp-bootstra | 0          | 3          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:date            | 0          | 3          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:systemd-sysctl  | 0          | 3          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:find            | 0          | 1          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:sshd            | 0          | 3          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:systemd-system  | 0          | 1          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:systemd-sysv-ge | 0          | 3          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:systemd-hiberna | 0          | 2          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:journal-offline | 0          | 3          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:sysctl          | 0          | 1          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:init            | 0          | 7          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:mkdir           | 0          | 6          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:mountpoint      | 0          | 1          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:systemd-logind  | 0          | 1          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:dmesg           | 0          | 2          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:systemd-ssh-gen | 0          | 3          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:cp              | 0          | 3          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:wakeup          | 0          | 3          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:dpkg-deb        | 0          | 1          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:dpkg            | 0          | 3          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:(modprobe)      | 0          | 1          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:sync            | 0          | 1          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:systemd-update  | 0          | 4          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:kmod            | 0          | 1          |\n| RIP:strncpy_from_user                                            | 0          | 2          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:sm-notify       | 0          | 2          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:systemd-remount | 0          | 2          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:blkmapd         | 0          | 1          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:mkfifo          | 0          | 2          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:ln              | 0          | 3          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:sh              | 0          | 5          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:bootlogd        | 0          | 2          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:run-test        | 0          | 1          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:S07bootlogd     | 0          | 1          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:hwclock.sh      | 0          | 2          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:(sd-mkdcreds)   | 0          | 1          |\n| RIP:filldir64                                                    | 0          | 2          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:chmod           | 0          | 2          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:ps              | 0          | 3          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:which           | 0          | 1          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:ip              | 0          | 1          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:start-stop-daem | 0          | 2          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:S20syslog       | 0          | 2          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:systemd-gpt-aut | 0          | 1          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:systemd-debug-g | 0          | 1          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:(rpcbind)       | 0          | 1          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:seq             | 0          | 1          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:systemd-run-gen | 0          | 2          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:wait            | 0          | 1          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:addgroup        | 0          | 1          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:rm              | 0          | 2          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:in:imklog       | 0          | 2          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:basename        | 0          | 1          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:touch           | 0          | 1          |\n| RIP:ia32_setup_frame                                             | 0          | 2          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:no-stdout-monit | 0          | 1          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:systemd-tpm#-ge | 0          | 1          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:(mount)         | 0          | 1          |\n| BUG:using__this_cpu_write()in_preemptible[#]code:ldconfig        | 0          | 1          |\n+------------------------------------------------------------------+------------+------------+\n\nIf you fix the issue in a separate patch/commit (i.e. not just a new version of\nthe same patch/commit), kindly add following tags\n| Reported-by: kernel test robot <oliver.sang@intel.com>\n| Closes: https://lore.kernel.org/oe-lkp/202602181136.f66ba888-lkp@intel.com\n\n\n\n[    0.624787][    T2] ------------[ cut here ]------------\n[    0.625191][    T2] WARNING: mm/vmstat.c:396 at __mod_node_page_state+0x88/0x1c0, CPU#0: kthreadd/2\n[    0.625887][    T2] Modules linked in:\n[    0.626070][    T2] CPU: 0 UID: 0 PID: 2 Comm: kthreadd Tainted: G                T   6.19.0-rc6-00596-g4b5f69459c09 #1 PREEMPT(lazy)  a55f7fce8adbfb8e52612c1f0ea71f4db1a1df23\n[    0.626084][    T2] Tainted: [T]=RANDSTRUCT\n[    0.626402][    T2] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.16.3-debian-1.16.3-2 04/01/2014\n[    0.627150][    T2] RIP: 0010:__mod_node_page_state (mm/vmstat.c:396 (discriminator 34))\n[    0.627592][    T2] Code: 8b 05 88 b9 73 02 48 c7 c7 d8 b0 b4 83 85 c0 89 45 d0 40 0f 95 c6 31 c9 31 d2 40 0f b6 f6 e8 3f 96 e4 ff 8b 45 d0 85 c0 74 1b <0f> 0b be 01 00 00 00 eb 14 31 c9 31 d2 31 f6 48 c7 c7 d8 b0 b4 83\nAll code\n========\n   0:\t8b 05 88 b9 73 02    \tmov    0x273b988(%rip),%eax        # 0x273b98e\n   6:\t48 c7 c7 d8 b0 b4 83 \tmov    $0xffffffff83b4b0d8,%rdi\n   d:\t85 c0                \ttest   %eax,%eax\n   f:\t89 45 d0             \tmov    %eax,-0x30(%rbp)\n  12:\t40 0f 95 c6          \tsetne  %sil\n  16:\t31 c9                \txor    %ecx,%ecx\n  18:\t31 d2                \txor    %edx,%edx\n  1a:\t40 0f b6 f6          \tmovzbl %sil,%esi\n  1e:\te8 3f 96 e4 ff       \tcall   0xffffffffffe49662\n  23:\t8b 45 d0             \tmov    -0x30(%rbp),%eax\n  26:\t85 c0                \ttest   %eax,%eax\n  28:\t74 1b                \tje     0x45\n  2a:*\t0f 0b                \tud2\t\t<-- trapping instruction\n  2c:\tbe 01 00 00 00       \tmov    $0x1,%esi\n  31:\teb 14                \tjmp    0x47\n  33:\t31 c9                \txor    %ecx,%ecx\n  35:\t31 d2                \txor    %edx,%edx\n  37:\t31 f6                \txor    %esi,%esi\n  39:\t48 c7 c7 d8 b0 b4 83 \tmov    $0xffffffff83b4b0d8,%rdi\n\nCode starting with the faulting instruction\n===========================================\n   0:\t0f 0b                \tud2\n   2:\tbe 01 00 00 00       \tmov    $0x1,%esi\n   7:\teb 14                \tjmp    0x1d\n   9:\t31 c9                \txor    %ecx,%ecx\n   b:\t31 d2                \txor    %edx,%edx\n   d:\t31 f6                \txor    %esi,%esi\n   f:\t48 c7 c7 d8 b0 b4 83 \tmov    $0xffffffff83b4b0d8,%rdi\n[    0.629418][    T2] RSP: 0000:ffff88810039fa20 EFLAGS: 00010202\n[    0.629869][    T2] RAX: 0000000000000001 RBX: 0000000000000002 RCX: 0000000000000000\n[    0.630445][    T2] RDX: 0000000000000000 RSI: 0000000000000000 RDI: 0000000000000000\n[    0.631089][    T2] RBP: ffff88810039fa50 R08: 0000000000000000 R09: 0000000000000000\n[    0.631671][    T2] R10: 0000000000000000 R11: 0000000000000000 R12: ffff88883ffe02c0\n[    0.632247][    T2] R13: ffffffff83f18971 R14: ffffffff83f18940 R15: 0000000000000030\n[    0.632746][    T2] FS:  0000000000000000(0000) GS:ffff88889bd1c000(0000) knlGS:0000000000000000\n[    0.633394][    T2] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\n[    0.633875][    T2] CR2: ffff88883ffff000 CR3: 000000000343d000 CR4: 00000000000406b0\n[    0.634478][    T2] Call Trace:\n[    0.634723][    T2]  <TASK>\n[    0.634951][    T2]  alloc_pages_mpol (mm/mempolicy.c:2513 (discriminator 1))\n[    0.635326][    T2]  alloc_frozen_pages_noprof (mm/mempolicy.c:2584)\n[    0.635746][    T2]  allocate_slab (mm/slub.c:3075 (discriminator 2) mm/slub.c:3248 (discriminator 2))\n[    0.636086][    T2]  new_slab (mm/slub.c:3304)\n[    0.636394][    T2]  ___slab_alloc (mm/slub.c:4657)\n[    0.636749][    T2]  ? dup_task_struct (kernel/fork.c:184 (discriminator 2) kernel/fork.c:915 (discriminator 2))\n[    0.637114][    T2]  __slab_alloc+0x8a/0x180\n[    0.637519][    T2]  slab_alloc_node+0x189/0x340\n[    0.637919][    T2]  ? dup_task_struct (kernel/fork.c:184 (discriminator 2) kernel/fork.c:915 (discriminator 2))\n[    0.638285][    T2]  kmem_cache_alloc_node_noprof (mm/slub.c:5317 (discriminator 1))\n[    0.638710][    T2]  dup_task_struct (kernel/fork.c:184 (discriminator 2) kernel/fork.c:915 (discriminator 2))\n[    0.639058][    T2]  ? ftrace_likely_update (arch/x86/include/asm/smap.h:90 kernel/trace/trace_branch.c:223)\n[    0.639416][    T2]  copy_process (kernel/fork.c:2052 (discriminator 1))\n[    0.639773][    T2]  kernel_clone (include/linux/random.h:26 kernel/fork.c:2652)\n[    0.640115][    T2]  ? kthread_fetch_affinity (kernel/kthread.c:412)\n[    0.640552][    T2]  kernel_thread (kernel/fork.c:2713)\n[    0.640892][    T2]  ? kthread_fetch_affinity (kernel/kthread.c:412)\n[    0.641310][    T2]  kthreadd (kernel/kthread.c:486 kernel/kthread.c:844)\n[    0.641621][    T2]  ? kthreadd (kernel/kthread.c:830 (discriminator 5))\n[    0.641938][    T2]  ? kthread_is_per_cpu (kernel/kthread.c:816)\n[    0.642316][    T2]  ret_from_fork (arch/x86/kernel/process.c:164)\n[    0.642657][    T2]  ? kthread_is_per_cpu (kernel/kthread.c:816)\n[    0.642744][    T2]  ? kthread_is_per_cpu (kernel/kthread.c:816)\n[    0.643127][    T2]  ret_from_fork_asm (arch/x86/entry/entry_64.S:256)\n[    0.643502][    T2]  </TASK>\n[    0.643755][    T2] irq event stamp: 393\n[    0.644054][    T2] hardirqs last  enabled at (401): __up_console_sem (arch/x86/include/asm/irqflags.h:42 arch/x86/include/asm/irqflags.h:119 arch/x86/include/asm/irqflags.h:159 kernel/printk/printk.c:345)\n[    0.644730][    T2] hardirqs last disabled at (408): __up_console_sem (kernel/printk/printk.c:343 (discriminator 3))\n[    0.645406][    T2] softirqs last  enabled at (54): handle_softirqs (kernel/softirq.c:469 (discriminator 1) kernel/softirq.c:650 (discriminator 1))\n[    0.646077][    T2] softirqs last disabled at (49): __irq_exit_rcu (kernel/softirq.c:657 kernel/softirq.c:496 kernel/softirq.c:723)\n[    0.646741][    T2] ---[ end trace 0000000000000000 ]---\n\n\nThe kernel config and materials to reproduce are available at:\nhttps://download.01.org/0day-ci/archive/20260218/202602181136.f66ba888-lkp@intel.com\n\n\n\n-- \n0-DAY CI Kernel Test Service\nhttps://github.com/intel/lkp-tests/wiki",
          "reply_to": "JP Kobryn",
          "message_date": "2026-02-18"
        }
      ],
      "analysis_source": "llm-per-reviewer",
      "patch_summary": "This patch series improves visibility into per-node memory allocation and reclaim by tracking allocations on a per-policy basis, adding new node stats to track the cause of NUMA imbalance, and changing reclaim-related stats to be tracked on a per-node basis. This allows for easier diagnosis of NUMA imbalance scenarios where reclaim kicks in despite available free memory. The approach taken involves modifying various kernel components, including mm/mempolicy, mm/memcontrol, and vmstat, to collect and display relevant statistics."
    },
    "2026-02-12": {
      "report_file": "2026-02-18_ollama_llama3.1-8b.html",
      "developer": "JP Kobryn",
      "reviews": [
        {
          "author": "Michal Hocko",
          "summary": "reviewer noted that the changelog could be more clear about the actual changes, specifically mentioning that /proc/vmstat will preserve reclaim stats and per-node stats will be displayed in /proc/zoneinfo",
          "sentiment": "neutral",
          "sentiment_signals": [
            "requested clarification"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "The changelog could have been more clear about the actual changes as\nthis is not overly clear for untrained eyes. The most important parts\nare that /proc/vmstat will preserve reclaim stats with slightly\ndifferent counters ordering (shouldn't break userspace much^W), per-node\nstats will be now newly displayed in /proc/zoneinfo - this is presumably\nthe primary motivation to have a better insight of per-node reclaim\nactivity, and memcg stats will now show their share of the global memory\nreclaim.\n\nHave I missed anything?",
          "reply_to": "JP Kobryn",
          "message_date": "2026-02-12"
        },
        {
          "author": "Michal Hocko",
          "summary": "reviewer requested clarification on the intended usage of the new counters",
          "sentiment": "neutral",
          "sentiment_signals": [
            "lack of clear explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Could you be more specific how exactly do you plan to use those\ncounters?\n\n-- \nMichal Hocko\nSUSE Labs",
          "reply_to": "JP Kobryn",
          "message_date": "2026-02-12"
        },
        {
          "author": "Shakeel Butt",
          "summary": "Reviewer Shakeel Butt requested to use mod_node_page_state() instead of __mod_node_page_state() because the latter requires preempt disable or IRQ disable, which is not done in this code path.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes"
          ],
          "has_inline_review": true,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Here and two places below, please use mod_node_page_state() instead of\n__mod_node_page_state() as __foo() requires preempt disable or if the\ngiven stat can be updated in IRQ, then IRQ disable. This code path does\nnot do either of that.",
          "reply_to": "JP Kobryn",
          "message_date": "2026-02-12"
        },
        {
          "author": "Vlastimil Babka",
          "summary": "reviewer questioned whether numa_{hit,miss,etc.} counters are sufficient for tracking policy type details, suggesting extension to capture missing information",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Are the numa_{hit,miss,etc.} counters insufficient? Could they be extended\nin a way that would capture any missing important details? A counter per\npolicy type seems exhaustive, but then on one hand it might be not important\nto distinguish beetween some of them, and on the other hand it doesn't track\nthe nodemask anyway.",
          "reply_to": "JP Kobryn",
          "message_date": "2026-02-12"
        },
        {
          "author": "syzbot ci",
          "summary": "The reviewer reported a WARNING in __mod_node_page_state due to a lock ordering violation between the per-vswap spinlock and the folio lock, which occurs when reclaim paths are executed.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "WARNING in __mod_node_page_state"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Tested-by"
          ],
          "analysis_source": "llm",
          "raw_body": "syzbot ci has tested the following series\n\n[v1] improve per-node allocation and reclaim visibility\nhttps://lore.kernel.org/all/20260212045109.255391-1-inwardvessel@gmail.com\n* [PATCH 1/2] mm/mempolicy: track page allocations per mempolicy\n* [PATCH 2/2] mm: move pgscan and pgsteal to node stats\n\nand found the following issue:\nWARNING in __mod_node_page_state\n\nFull report is available here:\nhttps://ci.syzbot.org/series/4ec12ede-3298-43a3-ab6b-79d47759672e\n\n***\n\nWARNING in __mod_node_page_state\n\ntree:      mm-new\nURL:       https://kernel.googlesource.com/pub/scm/linux/kernel/git/akpm/mm.git\nbase:      72a46cdd4ef13690beb8c5a2f6a2023fd7ef2eb4\narch:      amd64\ncompiler:  Debian clang version 21.1.8 (++20251221033036+2078da43e25a-1~exp1~20251221153213.50), Debian LLD 21.1.8\nconfig:    https://ci.syzbot.org/builds/0f678e4c-a4ba-4f17-8ed7-8ae99e56a463/config\n\n------------[ cut here ]------------\nIS_ENABLED(CONFIG_PREEMPT_COUNT) && __lockdep_enabled && (preempt_count() == 0 && this_cpu_read(hardirqs_enabled))\nWARNING: mm/vmstat.c:396 at __mod_node_page_state+0x126/0x170, CPU#0: kthreadd/2\nModules linked in:\nCPU: 0 UID: 0 PID: 2 Comm: kthreadd Not tainted syzkaller #0 PREEMPT(full) \nHardware name: QEMU Standard PC (Q35 + ICH9, 2009), BIOS 1.16.2-debian-1.16.2-1 04/01/2014\nRIP: 0010:__mod_node_page_state+0x126/0x170\nCode: 5c 41 5d 41 5e 41 5f 5d c3 cc cc cc cc cc 48 89 df 4c 89 e6 44 89 fa e8 68 00 00 00 31 db eb cc 90 0f 0b 90 e9 3e ff ff ff 90 <0f> 0b 90 eb 80 48 c7 c7 e0 c6 64 8e 4c 89 f6 e8 66 3c d3 02 e9 28\nRSP: 0000:ffffc900000773d0 EFLAGS: 00010202\nRAX: 0000000000000001 RBX: 0000000000000001 RCX: 0000000000000000\nRDX: 0000000000000001 RSI: 000000000000003d RDI: ffff88815fffb380\nRBP: dffffc0000000000 R08: ffffffff8fef2977 R09: 1ffffffff1fde52e\nR10: dffffc0000000000 R11: fffffbfff1fde52f R12: ffff88815fffb380\nR13: ffffffff92f50f00 R14: 000000000000003d R15: 000000000000003d\nFS:  0000000000000000(0000) GS:ffff88818e0f0000(0000) knlGS:0000000000000000\nCS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\nCR2: ffff88823ffff000 CR3: 000000000e346000 CR4: 00000000000006f0\nCall Trace:\n <TASK>\n alloc_pages_mpol+0x407/0x740\n alloc_pages_noprof+0xa8/0x190\n get_free_pages_noprof+0xf/0x80\n __kasan_populate_vmalloc+0x38/0x1d0\n alloc_vmap_area+0xd21/0x1460\n __get_vm_area_node+0x1f8/0x300\n __vmalloc_node_range_noprof+0x372/0x1730\n __vmalloc_node_noprof+0xc2/0x100\n dup_task_struct+0x228/0x9a0\n copy_process+0x508/0x3980\n kernel_clone+0x248/0x870\n kernel_thread+0x13f/0x1b0\n kthreadd+0x4f9/0x6f0\n ret_from_fork+0x51b/0xa40\n ret_from_fork_asm+0x1a/0x30\n </TASK>\n\n\n***\n\nIf these findings have caused you to resend the series or submit a\nseparate fix, please add the following tag to your commit message:\n  Tested-by: syzbot@syzkaller.appspotmail.com\n\n---\nThis report is generated by a bot. It may contain errors.\nsyzbot ci engineers can be reached at syzkaller@googlegroups.com.",
          "reply_to": "JP Kobryn",
          "message_date": "2026-02-12"
        },
        {
          "author": "JP Kobryn (author)",
          "summary": "Author acknowledged that the patch's new stats are not only available in /proc/zoneinfo but also in /sys/devices/system/node/nodeN/vmstat, agreed to add this information to the changelog in v2.",
          "sentiment": "positive",
          "sentiment_signals": [
            "acknowledged",
            "agreed"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "That's accurate. Plus aside from reading /proc/zoneinfo they will also\nbe in /sys/devices/system/node/nodeN/vmstat. I see I could have been\nmore explicit about this. Let me make additions to the changelog in v2.\nThanks for taking a look.",
          "reply_to": "Michal Hocko",
          "message_date": "2026-02-12"
        },
        {
          "author": "JP Kobryn (author)",
          "summary": "Author acknowledged that the current patch does not address reclaim visibility, but Patch 2 allows identification of affected nodes and correlation with mempolicy",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "acknowledged a limitation",
            "promised no fix in this patch"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Yes. Patch 2 allows us to find which nodes are undergoing reclaim. Once\nwe identify the affected node(s), the new mpol counters (this patch)\nallow us correlate the pressure to the mempolicy driving it.",
          "reply_to": "Michal Hocko",
          "message_date": "2026-02-12"
        },
        {
          "author": "JP Kobryn (author)",
          "summary": "Author acknowledged that the swapoff path needs to drop the per-vswap spinlock before calling try_to_unmap(), agreed to restructure in v2.",
          "sentiment": "needs_work",
          "sentiment_signals": [],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Thanks, I also see syzbot flagged this as well. I can make this change\nin v2.",
          "reply_to": "Shakeel Butt",
          "message_date": "2026-02-12"
        },
        {
          "author": "JP Kobryn (author)",
          "summary": "Author acknowledged that patch 2 provides visibility into affected nodes, but noted that extending numa_* counters would require additional permutations to account for policy-specific stats.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "acknowledged a technical consideration",
            "asked for clarification"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "The two patches of the series should complement each other. When\ninvestigating memory pressure, we could identify the affected nodes\n(patch 2). Then we can cross-reference the policy-specific stats to find\nany correlation (this patch).\n\nI think extending numa_* counters would call for more permutations to\naccount for the numa stat per policy. I think distinguishing between\nMPOL_DEFAULT and MPOL_BIND is meaningful, for example. Am I\nunderstanding your question?",
          "reply_to": "Vlastimil Babka",
          "message_date": "2026-02-12"
        },
        {
          "author": "Matthew Wilcox",
          "summary": "reviewer pointed out that the 'from' line in the patch header must be the first line, specifying the author's affiliation or sponsor if desired",
          "sentiment": "neutral",
          "sentiment_signals": [],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "^^^^^^^^^\n\nThe ``from`` line must be the very first line in the message body,\nand has the form:\n\n        From: Patch Author <author@example.com>\n\nThe ``from`` line specifies who will be credited as the author of the\npatch in the permanent changelog.  If the ``from`` line is missing,\nthen the ``From:`` line from the email header will be used to determine\nthe patch author in the changelog.\n\nThe author may indicate their affiliation or the sponsor of the work\nby adding the name of an organization to the ``from`` and ``SoB`` lines,\ne.g.:\n\n        From: Patch Author (Company) <author@example.com>\n\n\nI do this with ~/.gitconfig\n\n[user]\n        name = Matthew Wilcox (Oracle)\n        email = willy@infradead.org\n\nand it goes into the From and Signed-off-by lines correctly when\ngenerating patches.",
          "reply_to": "JP Kobryn",
          "message_date": "2026-02-12"
        }
      ],
      "analysis_source": "llm-per-reviewer",
      "patch_summary": "This patch series improves visibility into per-node memory allocation and reclaim by tracking allocations on a per-policy basis, adding new node stats to track the cause of NUMA imbalance, and changing reclaim-related stats to be tracked on a per-node basis. This allows for easier diagnosis of NUMA imbalance scenarios where reclaim kicks in despite available free memory. The approach taken involves modifying various kernel components, including mm/mempolicy, mm/memcontrol, and vmstat, to collect and display relevant statistics."
    },
    "2026-02-11": {
      "report_file": "2026-02-18_ollama_llama3.1-8b.html",
      "developer": "JP Kobryn",
      "reviews": [
        {
          "author": "JP Kobryn (author)",
          "summary": "The author acknowledged that the current patch does not provide a breakdown of allocations to understand which NUMA policies are driving them, and plans to add per-policy page allocation counters as new node stat items in v2.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "acknowledged a limitation",
            "planned changes for next version"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "It would be useful to see a breakdown of allocations to understand which\nNUMA policies are driving them. For example, when investigating memory\npressure, having policy-specific counts could show that allocations were\nbound to the affected node (via MPOL_BIND).\n\nAdd per-policy page allocation counters as new node stat items. These\ncounters can provide correlation between a mempolicy and pressure on a\ngiven node.\n\nSigned-off-by: JP Kobryn <inwardvessel@gmail.com>\nSuggested-by: Johannes Weiner <hannes@cmpxchg.org>\n---\n include/linux/mmzone.h |  9 +++++++++\n mm/mempolicy.c         | 30 ++++++++++++++++++++++++++++--\n mm/vmstat.c            |  9 +++++++++\n 3 files changed, 46 insertions(+), 2 deletions(-)\n\ndiff --git a/include/linux/mmzone.h b/include/linux/mmzone.h\nindex fc5d6c88d2f0..762609d5f0af 100644\n--- a/include/linux/mmzone.h\n+++ b/include/linux/mmzone.h\n@@ -255,6 +255,15 @@ enum node_stat_item {\n \tPGDEMOTE_DIRECT,\n \tPGDEMOTE_KHUGEPAGED,\n \tPGDEMOTE_PROACTIVE,\n+#ifdef CONFIG_NUMA\n+\tPGALLOC_MPOL_DEFAULT,\n+\tPGALLOC_MPOL_PREFERRED,\n+\tPGALLOC_MPOL_BIND,\n+\tPGALLOC_MPOL_INTERLEAVE,\n+\tPGALLOC_MPOL_LOCAL,\n+\tPGALLOC_MPOL_PREFERRED_MANY,\n+\tPGALLOC_MPOL_WEIGHTED_INTERLEAVE,\n+#endif\n #ifdef CONFIG_HUGETLB_PAGE\n \tNR_HUGETLB,\n #endif\ndiff --git a/mm/mempolicy.c b/mm/mempolicy.c\nindex 68a98ba57882..3c64784af761 100644\n--- a/mm/mempolicy.c\n+++ b/mm/mempolicy.c\n@@ -217,6 +217,21 @@ static void reduce_interleave_weights(unsigned int *bw, u8 *new_iw)\n \t\tnew_iw[nid] /= iw_gcd;\n }\n \n+#define CHECK_MPOL_NODE_STAT_OFFSET(mpol) \\\n+\tBUILD_BUG_ON(PGALLOC_##mpol - mpol != PGALLOC_MPOL_DEFAULT)\n+\n+static enum node_stat_item mpol_node_stat(unsigned short mode)\n+{\n+\tCHECK_MPOL_NODE_STAT_OFFSET(MPOL_PREFERRED);\n+\tCHECK_MPOL_NODE_STAT_OFFSET(MPOL_BIND);\n+\tCHECK_MPOL_NODE_STAT_OFFSET(MPOL_INTERLEAVE);\n+\tCHECK_MPOL_NODE_STAT_OFFSET(MPOL_LOCAL);\n+\tCHECK_MPOL_NODE_STAT_OFFSET(MPOL_PREFERRED_MANY);\n+\tCHECK_MPOL_NODE_STAT_OFFSET(MPOL_WEIGHTED_INTERLEAVE);\n+\n+\treturn PGALLOC_MPOL_DEFAULT + mode;\n+}\n+\n int mempolicy_set_node_perf(unsigned int node, struct access_coordinate *coords)\n {\n \tstruct weighted_interleave_state *new_wi_state, *old_wi_state = NULL;\n@@ -2446,8 +2461,14 @@ static struct page *alloc_pages_mpol(gfp_t gfp, unsigned int order,\n \n \tnodemask = policy_nodemask(gfp, pol, ilx, &nid);\n \n-\tif (pol->mode == MPOL_PREFERRED_MANY)\n-\t\treturn alloc_pages_preferred_many(gfp, order, nid, nodemask);\n+\tif (pol->mode == MPOL_PREFERRED_MANY) {\n+\t\tpage = alloc_pages_preferred_many(gfp, order, nid, nodemask);\n+\t\tif (page)\n+\t\t\t__mod_node_page_state(page_pgdat(page),\n+\t\t\t\t\tmpol_node_stat(MPOL_PREFERRED_MANY), 1 << order);\n+\n+\t\treturn page;\n+\t}\n \n \tif (IS_ENABLED(CONFIG_TRANSPARENT_HUGEPAGE) &&\n \t    /* filter \"hugepage\" allocation, unless from alloc_pages() */\n@@ -2472,6 +2493,9 @@ static struct page *alloc_pages_mpol(gfp_t gfp, unsigned int order,\n \t\t\tpage = __alloc_frozen_pages_noprof(\n \t\t\t\tgfp | __GFP_THISNODE | __GFP_NORETRY, order,\n \t\t\t\tnid, NULL);\n+\t\t\tif (page)\n+\t\t\t\t__mod_node_page_state(page_pgdat(page),\n+\t\t\t\t\t\tmpol_node_stat(pol->mode), 1 << order);\n \t\t\tif (page || !(gfp & __GFP_DIRECT_RECLAIM))\n \t\t\t\treturn page;\n \t\t\t/*\n@@ -2484,6 +2508,8 @@ static struct page *alloc_pages_mpol(gfp_t gfp, unsigned int order,\n \t}\n \n \tpage = __alloc_frozen_pages_noprof(gfp, order, nid, nodemask);\n+\tif (page)\n+\t\t__mod_node_page_state(page_pgdat(page), mpol_node_stat(pol->mode), 1 << order);\n \n \tif (unlikely(pol->mode == MPOL_INTERLEAVE ||\n \t\t     pol->mode == MPOL_WEIGHTED_INTERLEAVE) && page) {\ndiff --git a/mm/vmstat.c b/mm/vmstat.c\nindex 65de88cdf40e..74e0ddde1e93 100644\n--- a/mm/vmstat.c\n+++ b/mm/vmstat.c\n@@ -1291,6 +1291,15 @@ const char * const vmstat_text[] = {\n \t[I(PGDEMOTE_DIRECT)]\t\t\t= \"pgdemote_direct\",\n \t[I(PGDEMOTE_KHUGEPAGED)]\t\t= \"pgdemote_khugepaged\",\n \t[I(PGDEMOTE_PROACTIVE)]\t\t\t= \"pgdemote_proactive\",\n+#ifdef CONFIG_NUMA\n+\t[I(PGALLOC_MPOL_DEFAULT)]\t\t= \"pgalloc_mpol_default\",\n+\t[I(PGALLOC_MPOL_PREFERRED)]\t\t= \"pgalloc_mpol_preferred\",\n+\t[I(PGALLOC_MPOL_BIND)]\t\t\t= \"pgalloc_mpol_bind\",\n+\t[I(PGALLOC_MPOL_INTERLEAVE)]\t\t= \"pgalloc_mpol_interleave\",\n+\t[I(PGALLOC_MPOL_LOCAL)]\t\t\t= \"pgalloc_mpol_local\",\n+\t[I(PGALLOC_MPOL_PREFERRED_MANY)]\t= \"pgalloc_mpol_preferred_many\",\n+\t[I(PGALLOC_MPOL_WEIGHTED_INTERLEAVE)]\t= \"pgalloc_mpol_weighted_interleave\",\n+#endif\n #ifdef CONFIG_HUGETLB_PAGE\n \t[I(NR_HUGETLB)]\t\t\t\t= \"nr_hugetlb\",\n #endif\n-- \n2.47.3",
          "reply_to": "",
          "message_date": "2026-02-11"
        },
        {
          "author": "JP Kobryn (author)",
          "summary": "The author is addressing a concern about reclaim visibility being too global, and is proposing to change the pgscan and pgsteal stats from global vm_event_item's to node_stat_item's, which would provide per-node reclaim visibility.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "acknowledged a need for improvement",
            "proposed a solution"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "It would be useful to narrow down reclaim to specific nodes.\n\nProvide per-node reclaim visibility by changing the pgscan and pgsteal\nstats from global vm_event_item's to node_stat_item's. Note this change has\nthe side effect of now tracking these stats on a per-memcg basis.\n\nSigned-off-by: JP Kobryn <inwardvessel@gmail.com>\nSuggested-by: Johannes Weiner <hannes@cmpxchg.org>\n---\n drivers/virtio/virtio_balloon.c |  8 ++++----\n include/linux/mmzone.h          | 12 +++++++++++\n include/linux/vm_event_item.h   | 12 -----------\n mm/memcontrol.c                 | 36 ++++++++++++++++++---------------\n mm/vmscan.c                     | 32 +++++++++++------------------\n mm/vmstat.c                     | 24 +++++++++++-----------\n 6 files changed, 60 insertions(+), 64 deletions(-)\n\ndiff --git a/drivers/virtio/virtio_balloon.c b/drivers/virtio/virtio_balloon.c\nindex 74fe59f5a78c..1341d9d1a2a1 100644\n--- a/drivers/virtio/virtio_balloon.c\n+++ b/drivers/virtio/virtio_balloon.c\n@@ -374,13 +374,13 @@ static inline unsigned int update_balloon_vm_stats(struct virtio_balloon *vb)\n \tupdate_stat(vb, idx++, VIRTIO_BALLOON_S_ALLOC_STALL, stall);\n \n \tupdate_stat(vb, idx++, VIRTIO_BALLOON_S_ASYNC_SCAN,\n-\t\t    pages_to_bytes(events[PGSCAN_KSWAPD]));\n+\t\t    pages_to_bytes(global_node_page_state(PGSCAN_KSWAPD)));\n \tupdate_stat(vb, idx++, VIRTIO_BALLOON_S_DIRECT_SCAN,\n-\t\t    pages_to_bytes(events[PGSCAN_DIRECT]));\n+\t\t    pages_to_bytes(global_node_page_state(PGSCAN_DIRECT)));\n \tupdate_stat(vb, idx++, VIRTIO_BALLOON_S_ASYNC_RECLAIM,\n-\t\t    pages_to_bytes(events[PGSTEAL_KSWAPD]));\n+\t\t    pages_to_bytes(global_node_page_state(PGSTEAL_KSWAPD)));\n \tupdate_stat(vb, idx++, VIRTIO_BALLOON_S_DIRECT_RECLAIM,\n-\t\t    pages_to_bytes(events[PGSTEAL_DIRECT]));\n+\t\t    pages_to_bytes(global_node_page_state(PGSTEAL_DIRECT)));\n \n #ifdef CONFIG_HUGETLB_PAGE\n \tupdate_stat(vb, idx++, VIRTIO_BALLOON_S_HTLB_PGALLOC,\ndiff --git a/include/linux/mmzone.h b/include/linux/mmzone.h\nindex 762609d5f0af..fc39c107a4b5 100644\n--- a/include/linux/mmzone.h\n+++ b/include/linux/mmzone.h\n@@ -255,6 +255,18 @@ enum node_stat_item {\n \tPGDEMOTE_DIRECT,\n \tPGDEMOTE_KHUGEPAGED,\n \tPGDEMOTE_PROACTIVE,\n+\tPGSTEAL_KSWAPD,\n+\tPGSTEAL_DIRECT,\n+\tPGSTEAL_KHUGEPAGED,\n+\tPGSTEAL_PROACTIVE,\n+\tPGSTEAL_ANON,\n+\tPGSTEAL_FILE,\n+\tPGSCAN_KSWAPD,\n+\tPGSCAN_DIRECT,\n+\tPGSCAN_KHUGEPAGED,\n+\tPGSCAN_PROACTIVE,\n+\tPGSCAN_ANON,\n+\tPGSCAN_FILE,\n #ifdef CONFIG_NUMA\n \tPGALLOC_MPOL_DEFAULT,\n \tPGALLOC_MPOL_PREFERRED,\ndiff --git a/include/linux/vm_event_item.h b/include/linux/vm_event_item.h\nindex 92f80b4d69a6..6f1787680658 100644\n--- a/include/linux/vm_event_item.h\n+++ b/include/linux/vm_event_item.h\n@@ -40,19 +40,7 @@ enum vm_event_item { PGPGIN, PGPGOUT, PSWPIN, PSWPOUT,\n \t\tPGLAZYFREED,\n \t\tPGREFILL,\n \t\tPGREUSE,\n-\t\tPGSTEAL_KSWAPD,\n-\t\tPGSTEAL_DIRECT,\n-\t\tPGSTEAL_KHUGEPAGED,\n-\t\tPGSTEAL_PROACTIVE,\n-\t\tPGSCAN_KSWAPD,\n-\t\tPGSCAN_DIRECT,\n-\t\tPGSCAN_KHUGEPAGED,\n-\t\tPGSCAN_PROACTIVE,\n \t\tPGSCAN_DIRECT_THROTTLE,\n-\t\tPGSCAN_ANON,\n-\t\tPGSCAN_FILE,\n-\t\tPGSTEAL_ANON,\n-\t\tPGSTEAL_FILE,\n #ifdef CONFIG_NUMA\n \t\tPGSCAN_ZONE_RECLAIM_SUCCESS,\n \t\tPGSCAN_ZONE_RECLAIM_FAILED,\ndiff --git a/mm/memcontrol.c b/mm/memcontrol.c\nindex 86f43b7e5f71..bde0b6536be6 100644\n--- a/mm/memcontrol.c\n+++ b/mm/memcontrol.c\n@@ -328,6 +328,18 @@ static const unsigned int memcg_node_stat_items[] = {\n \tPGDEMOTE_DIRECT,\n \tPGDEMOTE_KHUGEPAGED,\n \tPGDEMOTE_PROACTIVE,\n+\tPGSTEAL_KSWAPD,\n+\tPGSTEAL_DIRECT,\n+\tPGSTEAL_KHUGEPAGED,\n+\tPGSTEAL_PROACTIVE,\n+\tPGSTEAL_ANON,\n+\tPGSTEAL_FILE,\n+\tPGSCAN_KSWAPD,\n+\tPGSCAN_DIRECT,\n+\tPGSCAN_KHUGEPAGED,\n+\tPGSCAN_PROACTIVE,\n+\tPGSCAN_ANON,\n+\tPGSCAN_FILE,\n #ifdef CONFIG_HUGETLB_PAGE\n \tNR_HUGETLB,\n #endif\n@@ -441,14 +453,6 @@ static const unsigned int memcg_vm_event_stat[] = {\n #endif\n \tPSWPIN,\n \tPSWPOUT,\n-\tPGSCAN_KSWAPD,\n-\tPGSCAN_DIRECT,\n-\tPGSCAN_KHUGEPAGED,\n-\tPGSCAN_PROACTIVE,\n-\tPGSTEAL_KSWAPD,\n-\tPGSTEAL_DIRECT,\n-\tPGSTEAL_KHUGEPAGED,\n-\tPGSTEAL_PROACTIVE,\n \tPGFAULT,\n \tPGMAJFAULT,\n \tPGREFILL,\n@@ -1496,15 +1500,15 @@ static void memcg_stat_format(struct mem_cgroup *memcg, struct seq_buf *s)\n \n \t/* Accumulated memory events */\n \tseq_buf_printf(s, \"pgscan %lu\\n\",\n-\t\t       memcg_events(memcg, PGSCAN_KSWAPD) +\n-\t\t       memcg_events(memcg, PGSCAN_DIRECT) +\n-\t\t       memcg_events(memcg, PGSCAN_PROACTIVE) +\n-\t\t       memcg_events(memcg, PGSCAN_KHUGEPAGED));\n+\t\t       memcg_page_state(memcg, PGSCAN_KSWAPD) +\n+\t\t       memcg_page_state(memcg, PGSCAN_DIRECT) +\n+\t\t       memcg_page_state(memcg, PGSCAN_PROACTIVE) +\n+\t\t       memcg_page_state(memcg, PGSCAN_KHUGEPAGED));\n \tseq_buf_printf(s, \"pgsteal %lu\\n\",\n-\t\t       memcg_events(memcg, PGSTEAL_KSWAPD) +\n-\t\t       memcg_events(memcg, PGSTEAL_DIRECT) +\n-\t\t       memcg_events(memcg, PGSTEAL_PROACTIVE) +\n-\t\t       memcg_events(memcg, PGSTEAL_KHUGEPAGED));\n+\t\t       memcg_page_state(memcg, PGSTEAL_KSWAPD) +\n+\t\t       memcg_page_state(memcg, PGSTEAL_DIRECT) +\n+\t\t       memcg_page_state(memcg, PGSTEAL_PROACTIVE) +\n+\t\t       memcg_page_state(memcg, PGSTEAL_KHUGEPAGED));\n \n \tfor (i = 0; i < ARRAY_SIZE(memcg_vm_event_stat); i++) {\n #ifdef CONFIG_MEMCG_V1\ndiff --git a/mm/vmscan.c b/mm/vmscan.c\nindex 614ccf39fe3f..16a0f21e3ea1 100644\n--- a/mm/vmscan.c\n+++ b/mm/vmscan.c\n@@ -1977,7 +1977,7 @@ static unsigned long shrink_inactive_list(unsigned long nr_to_scan,\n \tunsigned long nr_taken;\n \tstruct reclaim_stat stat;\n \tbool file = is_file_lru(lru);\n-\tenum vm_event_item item;\n+\tenum node_stat_item item;\n \tstruct pglist_data *pgdat = lruvec_pgdat(lruvec);\n \tbool stalled = false;\n \n@@ -2003,10 +2003,8 @@ static unsigned long shrink_inactive_list(unsigned long nr_to_scan,\n \n \t__mod_node_page_state(pgdat, NR_ISOLATED_ANON + file, nr_taken);\n \titem = PGSCAN_KSWAPD + reclaimer_offset(sc);\n-\tif (!cgroup_reclaim(sc))\n-\t\t__count_vm_events(item, nr_scanned);\n-\tcount_memcg_events(lruvec_memcg(lruvec), item, nr_scanned);\n-\t__count_vm_events(PGSCAN_ANON + file, nr_scanned);\n+\tmod_lruvec_state(lruvec, item, nr_scanned);\n+\tmod_lruvec_state(lruvec, PGSCAN_ANON + file, nr_scanned);\n \n \tspin_unlock_irq(&lruvec->lru_lock);\n \n@@ -2023,10 +2021,8 @@ static unsigned long shrink_inactive_list(unsigned long nr_to_scan,\n \t\t\t\t\tstat.nr_demoted);\n \t__mod_node_page_state(pgdat, NR_ISOLATED_ANON + file, -nr_taken);\n \titem = PGSTEAL_KSWAPD + reclaimer_offset(sc);\n-\tif (!cgroup_reclaim(sc))\n-\t\t__count_vm_events(item, nr_reclaimed);\n-\tcount_memcg_events(lruvec_memcg(lruvec), item, nr_reclaimed);\n-\t__count_vm_events(PGSTEAL_ANON + file, nr_reclaimed);\n+\tmod_lruvec_state(lruvec, item, nr_reclaimed);\n+\tmod_lruvec_state(lruvec, PGSTEAL_ANON + file, nr_reclaimed);\n \n \tlru_note_cost_unlock_irq(lruvec, file, stat.nr_pageout,\n \t\t\t\t\tnr_scanned - nr_reclaimed);\n@@ -4536,7 +4532,7 @@ static int scan_folios(unsigned long nr_to_scan, struct lruvec *lruvec,\n {\n \tint i;\n \tint gen;\n-\tenum vm_event_item item;\n+\tenum node_stat_item item;\n \tint sorted = 0;\n \tint scanned = 0;\n \tint isolated = 0;\n@@ -4595,13 +4591,11 @@ static int scan_folios(unsigned long nr_to_scan, struct lruvec *lruvec,\n \t}\n \n \titem = PGSCAN_KSWAPD + reclaimer_offset(sc);\n-\tif (!cgroup_reclaim(sc)) {\n-\t\t__count_vm_events(item, isolated);\n+\tif (!cgroup_reclaim(sc))\n \t\t__count_vm_events(PGREFILL, sorted);\n-\t}\n-\tcount_memcg_events(memcg, item, isolated);\n+\tmod_lruvec_state(lruvec, item, isolated);\n \tcount_memcg_events(memcg, PGREFILL, sorted);\n-\t__count_vm_events(PGSCAN_ANON + type, isolated);\n+\tmod_lruvec_state(lruvec, PGSCAN_ANON + type, isolated);\n \ttrace_mm_vmscan_lru_isolate(sc->reclaim_idx, sc->order, scan_batch,\n \t\t\t\tscanned, skipped, isolated,\n \t\t\t\ttype ? LRU_INACTIVE_FILE : LRU_INACTIVE_ANON);\n@@ -4686,7 +4680,7 @@ static int evict_folios(unsigned long nr_to_scan, struct lruvec *lruvec,\n \tLIST_HEAD(clean);\n \tstruct folio *folio;\n \tstruct folio *next;\n-\tenum vm_event_item item;\n+\tenum node_stat_item item;\n \tstruct reclaim_stat stat;\n \tstruct lru_gen_mm_walk *walk;\n \tbool skip_retry = false;\n@@ -4750,10 +4744,8 @@ static int evict_folios(unsigned long nr_to_scan, struct lruvec *lruvec,\n \t\t\t\t\tstat.nr_demoted);\n \n \titem = PGSTEAL_KSWAPD + reclaimer_offset(sc);\n-\tif (!cgroup_reclaim(sc))\n-\t\t__count_vm_events(item, reclaimed);\n-\tcount_memcg_events(memcg, item, reclaimed);\n-\t__count_vm_events(PGSTEAL_ANON + type, reclaimed);\n+\tmod_lruvec_state(lruvec, item, reclaimed);\n+\tmod_lruvec_state(lruvec, PGSTEAL_ANON + type, reclaimed);\n \n \tspin_unlock_irq(&lruvec->lru_lock);\n \ndiff --git a/mm/vmstat.c b/mm/vmstat.c\nindex 74e0ddde1e93..e4b259989d58 100644\n--- a/mm/vmstat.c\n+++ b/mm/vmstat.c\n@@ -1291,6 +1291,18 @@ const char * const vmstat_text[] = {\n \t[I(PGDEMOTE_DIRECT)]\t\t\t= \"pgdemote_direct\",\n \t[I(PGDEMOTE_KHUGEPAGED)]\t\t= \"pgdemote_khugepaged\",\n \t[I(PGDEMOTE_PROACTIVE)]\t\t\t= \"pgdemote_proactive\",\n+\t[I(PGSTEAL_KSWAPD)]\t\t\t= \"pgsteal_kswapd\",\n+\t[I(PGSTEAL_DIRECT)]\t\t\t= \"pgsteal_direct\",\n+\t[I(PGSTEAL_KHUGEPAGED)]\t\t\t= \"pgsteal_khugepaged\",\n+\t[I(PGSTEAL_PROACTIVE)]\t\t\t= \"pgsteal_proactive\",\n+\t[I(PGSTEAL_ANON)]\t\t\t= \"pgsteal_anon\",\n+\t[I(PGSTEAL_FILE)]\t\t\t= \"pgsteal_file\",\n+\t[I(PGSCAN_KSWAPD)]\t\t\t= \"pgscan_kswapd\",\n+\t[I(PGSCAN_DIRECT)]\t\t\t= \"pgscan_direct\",\n+\t[I(PGSCAN_KHUGEPAGED)]\t\t\t= \"pgscan_khugepaged\",\n+\t[I(PGSCAN_PROACTIVE)]\t\t\t= \"pgscan_proactive\",\n+\t[I(PGSCAN_ANON)]\t\t\t= \"pgscan_anon\",\n+\t[I(PGSCAN_FILE)]\t\t\t= \"pgscan_file\",\n #ifdef CONFIG_NUMA\n \t[I(PGALLOC_MPOL_DEFAULT)]\t\t= \"pgalloc_mpol_default\",\n \t[I(PGALLOC_MPOL_PREFERRED)]\t\t= \"pgalloc_mpol_preferred\",\n@@ -1344,19 +1356,7 @@ const char * const vmstat_text[] = {\n \n \t[I(PGREFILL)]\t\t\t\t= \"pgrefill\",\n \t[I(PGREUSE)]\t\t\t\t= \"pgreuse\",\n-\t[I(PGSTEAL_KSWAPD)]\t\t\t= \"pgsteal_kswapd\",\n-\t[I(PGSTEAL_DIRECT)]\t\t\t= \"pgsteal_direct\",\n-\t[I(PGSTEAL_KHUGEPAGED)]\t\t\t= \"pgsteal_khugepaged\",\n-\t[I(PGSTEAL_PROACTIVE)]\t\t\t= \"pgsteal_proactive\",\n-\t[I(PGSCAN_KSWAPD)]\t\t\t= \"pgscan_kswapd\",\n-\t[I(PGSCAN_DIRECT)]\t\t\t= \"pgscan_direct\",\n-\t[I(PGSCAN_KHUGEPAGED)]\t\t\t= \"pgscan_khugepaged\",\n-\t[I(PGSCAN_PROACTIVE)]\t\t\t= \"pgscan_proactive\",\n \t[I(PGSCAN_DIRECT_THROTTLE)]\t\t= \"pgscan_direct_throttle\",\n-\t[I(PGSCAN_ANON)]\t\t\t= \"pgscan_anon\",\n-\t[I(PGSCAN_FILE)]\t\t\t= \"pgscan_file\",\n-\t[I(PGSTEAL_ANON)]\t\t\t= \"pgsteal_anon\",\n-\t[I(PGSTEAL_FILE)]\t\t\t= \"pgsteal_file\",\n \n #ifdef CONFIG_NUMA\n \t[I(PGSCAN_ZONE_RECLAIM_SUCCESS)]\t= \"zone_reclaim_success\",\n-- \n2.47.3",
          "reply_to": "",
          "message_date": "2026-02-11"
        }
      ],
      "analysis_source": "llm-per-reviewer",
      "patch_summary": "This patch series improves visibility into per-node memory allocation and reclaim by tracking allocations on a per-policy basis, adding new node stats to track the cause of NUMA imbalance, and changing reclaim-related stats to be tracked on a per-node basis. This allows for easier diagnosis of NUMA imbalance scenarios where reclaim kicks in despite available free memory. The approach taken involves modifying various kernel components, including mm/mempolicy, mm/memcontrol, and vmstat, to collect and display relevant statistics."
    },
    "2026-02-13": {
      "report_file": "2026-02-18_ollama_llama3.1-8b.html",
      "developer": "JP Kobryn",
      "reviews": [
        {
          "author": "Vlastimil Babka",
          "summary": "Reviewer suggested that the always-on counters should be limited to only what is known to be useful, rather than tracking every possible metric, and proposed adding a numa_bind counter as an example",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Are there other useful examples or would it be enough to add e.g. a\nnuma_bind counter to the numa_hit/miss/etc?\nWhat I'm trying to say the level of detail you are trying to add to the\nalways-on counters seems like more suitable for tracepoints. The counters\nshould be limited to what's known to be useful and not \"everything we are\nable to track and possibly could need one day\".",
          "reply_to": "JP Kobryn",
          "message_date": "2026-02-13"
        },
        {
          "author": "JP (Meta) (author)",
          "summary": "Author acknowledges that numa stats may not be suitable for tracking allocation policies, and is open to alternative approaches.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "open-ended question",
            "acknowledgment of uncertainty"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Aside from bind, it's worth emphasizing that with default policy\ntracking we could see if the local node is the source of pressure. In\nthe interleave case, we would be able to see if the loads are being\nbalanced or, in the weighted case, being distributed properly.\n\nOn extending the numa stats instead, I looked into this some more. I'm\nnot sure if they're a good fit. They seem more about whether the\nallocator succeeded at placement rather than which policy drove the\nallocation. Thoughts?",
          "reply_to": "Vlastimil Babka",
          "message_date": "2026-02-13"
        },
        {
          "author": "JP (Meta) (author)",
          "summary": "Author acknowledged the need for historical stats collection in triage scenarios, explained that using a tool like below would provide this visibility, and described an improved triage workflow.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "acknowledged a limitation",
            "explained a workaround"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "In a triage scenario, having the stats collected up to the time of the\nreported issue would be better. We make use of the tool called below[0].\nIt periodically samples the system and allows us to view the\nhistorical state prior to the issue. If we started at the time of the\nincident and attached tracepoints it would be too late.\n\nThe triage workflow would look like this:\n1) Pressure/OOMs reported while system-wide memory is free.\n2) Check per-node pgscan/pgsteal stats (provided by patch 2) to narrow\ndown node(s) under pressure.\n3) Check per-policy allocation counters (this patch) on that node to\nfind what policy was driving it.\n\n[0] https://github.com/facebookincubator/below",
          "reply_to": "Vlastimil Babka",
          "message_date": "2026-02-13"
        }
      ],
      "analysis_source": "llm-per-reviewer",
      "patch_summary": "This patch series improves visibility into per-node memory allocation and reclaim by tracking allocations on a per-policy basis, adding new node stats to track the cause of NUMA imbalance, and changing reclaim-related stats to be tracked on a per-node basis. This allows for easier diagnosis of NUMA imbalance scenarios where reclaim kicks in despite available free memory. The approach taken involves modifying various kernel components, including mm/mempolicy, mm/memcontrol, and vmstat, to collect and display relevant statistics."
    },
    "2026-02-16": {
      "report_file": "2026-02-18_ollama_llama3.1-8b.html",
      "developer": "JP Kobryn",
      "reviews": [
        {
          "author": "Michal Hocko",
          "summary": "reviewer expressed concern that new counters added by the patch may be difficult to remove in the future, citing precedence of dropping some counters in past userspace APIs; specifically asked for more information on how mempolicy allocations are tolerated to specific nodes",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes",
            "lack of specificity"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "I would appreciate somehow more specificity. You are adding counters\nthat are not really easy to drop once they are in. Sure we have\nprecedence of dropping some counters in the past so this is not as hard\nas usual userspace APIs but still...\n\nHow exactly do you tolerate mempolicy allocations to specific nodes?\nWhile MPOL_MBIND is quite straightforward others are less so.\n-- \nMichal Hocko\nSUSE Labs",
          "reply_to": "JP Kobryn",
          "message_date": "2026-02-16"
        },
        {
          "author": "JP (Meta) (author)",
          "summary": "author acknowledged that the per-node stats are attributed to the correct NUMA node, regardless of policy",
          "sentiment": "positive",
          "sentiment_signals": [
            "acknowledged",
            "explained"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "The design does account for this regardless of the policy. In the call\nto __mod_node_page_state(), I'm using page_pgdat(page) so the stat is\nattributed to the node where the page actually landed.",
          "reply_to": "Michal Hocko",
          "message_date": "2026-02-16"
        },
        {
          "author": "Michal Hocko",
          "summary": "Reviewer Michal Hocko questioned the usefulness of tracking memory pressure on a per-node basis, noting that it's unclear how to determine which policy or part of the nodemask is causing the pressure, and suggested that the data would only be useful for a single node mempolicy (MBIND).",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "That much is clear[*]. The consumer side of things is not really clear to\nme. How do you know which policy or part of the nodemask of that policy\nis the source of the memory pressure on a particular node? In other\nwords how much is the data actually useful except for a single node\nmempolicy (i.e. MBIND).\n\n[*] btw. I believe you misaccount MPOL_LOCAL because you attribute the\ntarget node even when the allocation is from a remote node from the\n\"local\" POV.\n-- \nMichal Hocko\nSUSE Labs",
          "reply_to": "JP (Meta)",
          "message_date": "2026-02-16"
        },
        {
          "author": "JP (Meta) (author)",
          "summary": "Author addressed Michal Hocko's concern about visibility into per-node allocation and reclaim by explaining how the patch series can be used in conjunction with other tools to diagnose NUMA imbalance scenarios, specifically mentioning the use of node mask and numa_maps to identify tasks targeting affected nodes.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Other than the bind policy, having the interleave (and weighted) stats\nwould allow us to see the effective distribution of the policy. Pressure\ncould be linked to a user configured weight scheme. I would think it\ncould also help with confirming expected distributions.\n\nYou brought up the node mask so with the preferred policy, I think this\nis a good one for using the counters as well. Once we're at the point\nwhere we know the node(s) under pressure and then see significant\npreferred allocs accounted for, we could search the numa_maps that have\n\"prefer:<node>\" to find the tasks targeting the affected nodes.\n\nI mentioned this on another thread in this series but I'll include here\nas well and expand some more. For any given policy, the workflow would\nbe:\n1) Pressure/OOMs reported while system-wide memory is free.\n2) Check per-node pgscan/pgsteal stats (provided by patch 2) to narrow\ndown node(s) under pressure. They become available in\n/sys/devices/system/node/nodeN/vmstat.\n3) Check per-policy allocation counters (this patch) on that node to\nfind what policy was driving it. Same readout at nodeN/vmstat.\n4) Now use /proc/*/numa_maps to identify tasks using the policy.",
          "reply_to": "Michal Hocko",
          "message_date": "2026-02-16"
        },
        {
          "author": "JP (Meta) (author)",
          "summary": "Author acknowledged Michal Hocko's point about accounting for fallback cases, agreeing that these allocations can be considered acceptable noise in an investigation.",
          "sentiment": "positive",
          "sentiment_signals": [
            "acknowledged",
            "agreed"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "It's a good point. The accounting as a result of fallback cases\nshouldn't detract from an investigation though. We're interested in the\nnode(s) under pressure so the relatively few fallback allocations would\nland on nodes that are not under pressure and could be viewed as\nacceptable noise.",
          "reply_to": "Michal Hocko",
          "message_date": "2026-02-16"
        }
      ],
      "analysis_source": "llm-per-reviewer",
      "patch_summary": "This patch series improves visibility into per-node memory allocation and reclaim by tracking allocations on a per-policy basis, adding new node stats to track the cause of NUMA imbalance, and changing reclaim-related stats to be tracked on a per-node basis. This allows for easier diagnosis of NUMA imbalance scenarios where reclaim kicks in despite available free memory. The approach taken involves modifying various kernel components, including mm/mempolicy, mm/memcontrol, and vmstat, to collect and display relevant statistics."
    },
    "2026-02-17": {
      "report_file": "2026-02-18_ollama_llama3.1-8b.html",
      "developer": "JP Kobryn",
      "reviews": [
        {
          "author": "Michal Hocko",
          "summary": "Reviewer noted that the patch does not provide a way to distinguish between requested node and actual node used, making it impossible to determine whether memory pressure is caused by fallbacks or mempolicy configurations.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "This is really confusing. You simply have no means to tell the\ndifference between the requested node and the real node used so you\ncannot really say whether the memory pressure is because of fallbacks or\nyour mempolicy configurations. That means that you cannot tell the\ndifference between the source of the pressure and victim of that\npressure. \n\nI am not saying these scheme doesn't work in your particular setup but I\ndo not see this is long term maintainable thing. It is just too easy to\nget misleading numbers. If we want/need to track mempolicy allocations\nbetter than what existing numa_* counters offer then this needs to be\nthought through I believe.\n\nI do not think we should add these counters in this form. \n-- \nMichal Hocko\nSUSE Labs",
          "reply_to": "JP (Meta)",
          "message_date": "2026-02-17"
        },
        {
          "author": "JP (Meta) (author)",
          "summary": "Author suggests an alternative approach to address Michal Hocko's concern about determining the correct node for per-node allocation visibility, proposing to get the actual node from the allocated page and compare it against the requested node or node mask.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarifying question",
            "alternative approach"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "What if I excluded the fallback cases? I could get the actual node from\nthe allocated page and compare against the requested node or node mask.",
          "reply_to": "Michal Hocko",
          "message_date": "2026-02-17"
        },
        {
          "author": "Michal Hocko",
          "summary": "reviewer requested that per-node reclaim stats be sent separately, and asked for a clear definition of the semantic for each mempolicy before implementing new tracking",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "I think it would make sense to send the per-node reclaim stats\nseparately as there doesn't seem to be any dispute about that.\n\nFor mempolicy stats try to define semantic for each mempolicy first.\nWhat exactly do you miss from existing numa_*?\nDo you want to count number of requests/successes. Do you want to track\nfailures? In what kind of granularity (track fallback nodes)?\n\n-- \nMichal Hocko\nSUSE Labs",
          "reply_to": "JP (Meta)",
          "message_date": "2026-02-17"
        }
      ],
      "analysis_source": "llm-per-reviewer",
      "patch_summary": "This patch series improves visibility into per-node memory allocation and reclaim by tracking allocations on a per-policy basis, adding new node stats to track the cause of NUMA imbalance, and changing reclaim-related stats to be tracked on a per-node basis. This allows for easier diagnosis of NUMA imbalance scenarios where reclaim kicks in despite available free memory. The approach taken involves modifying various kernel components, including mm/mempolicy, mm/memcontrol, and vmstat, to collect and display relevant statistics."
    }
  }
}