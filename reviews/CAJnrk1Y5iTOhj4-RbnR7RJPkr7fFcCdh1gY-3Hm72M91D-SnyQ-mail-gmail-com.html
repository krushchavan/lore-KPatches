<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Review Comments: Re: [PATCH v1 03/11] io_uring/kbuf: add support for kernel-managed buffer rings</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
                         "Helvetica Neue", Arial, sans-serif;
            background: #f5f5f5;
            color: #333;
            line-height: 1.6;
            padding: 20px;
            max-width: 900px;
            margin: 0 auto;
        }
        .home-link { margin-bottom: 12px; display: block; }
        .home-link a { color: #0366d6; text-decoration: none; font-size: 0.9em; }
        .home-link a:hover { text-decoration: underline; }

        h1 { font-size: 1.3em; margin-bottom: 2px; color: #1a1a1a; line-height: 1.3; }

        .lore-link { font-size: 0.85em; margin: 4px 0 6px; display: block; }
        .lore-link a { color: #0366d6; text-decoration: none; }
        .lore-link a:hover { text-decoration: underline; }

        .date-range {
            font-size: 0.8em;
            color: #888;
            margin-bottom: 16px;
        }
        .date-range a { color: #0366d6; text-decoration: none; }
        .date-range a:hover { text-decoration: underline; }

        /* thread-node scroll margin so the card isn't clipped at the top */
        .thread-node { scroll-margin-top: 8px; }

        /* ── Patch summary ──────────────────────────────────────────── */
        .patch-summary-block {
            background: #fff;
            border-radius: 8px;
            padding: 12px 16px;
            margin-bottom: 20px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.08);
            border-left: 3px solid #4a90d9;
        }
        .patch-summary-label {
            font-size: 0.72em;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 0.06em;
            color: #4a90d9;
            margin-bottom: 4px;
        }
        .patch-summary-text {
            font-size: 0.88em;
            color: #444;
            line-height: 1.55;
        }

        /* ── Thread tree ────────────────────────────────────────────── */
        .thread-tree {
            display: flex;
            flex-direction: column;
            gap: 6px;
        }

        /* Depth indentation via left border */
        .thread-node { position: relative; }
        .thread-children {
            margin-left: 20px;
            padding-left: 12px;
            border-left: 2px solid #e0e0e0;
            margin-top: 6px;
            display: flex;
            flex-direction: column;
            gap: 6px;
        }

        /* ── Review comment card ────────────────────────────────────── */
        .review-comment {
            background: #fff;
            border-radius: 6px;
            padding: 10px 14px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.08);
            font-size: 0.88em;
        }
        .review-comment-header {
            display: flex;
            flex-wrap: wrap;
            align-items: center;
            gap: 6px;
            margin-bottom: 5px;
        }
        .review-author {
            font-weight: 700;
            color: #1a1a1a;
            font-size: 0.95em;
        }

        /* Date chip — links back to the daily report */
        .date-chip {
            font-size: 0.75em;
            color: #777;
            background: #f0f0f0;
            border-radius: 10px;
            padding: 1px 7px;
            text-decoration: none;
            white-space: nowrap;
        }
        a.date-chip:hover { background: #e0e8f5; color: #0366d6; }

        .badge {
            display: inline-block;
            padding: 1px 8px;
            border-radius: 10px;
            font-size: 0.75em;
            font-weight: 600;
        }
        .inline-review-badge {
            display: inline-block;
            padding: 0 6px;
            border-radius: 8px;
            font-size: 0.78em;
            font-weight: 500;
            background: #e3f2fd;
            color: #1565c0;
        }
        .review-tag-badge {
            display: inline-block;
            padding: 0 6px;
            border-radius: 8px;
            font-size: 0.78em;
            font-weight: 500;
            background: #e8f5e9;
            color: #2e7d32;
        }
        .analysis-source-badge {
            display: inline-block;
            padding: 1px 7px;
            border-radius: 10px;
            font-size: 0.72em;
            font-weight: 600;
            border: 1px solid rgba(0,0,0,0.1);
        }

        .review-comment-text {
            color: #444;
            line-height: 1.55;
            margin-bottom: 4px;
        }
        .review-comment-signals {
            margin-top: 3px;
            font-size: 0.85em;
            color: #aaa;
            font-style: italic;
        }

        /* ── Collapsible raw body ───────────────────────────────────── */
        .raw-body-toggle {
            margin-top: 5px;
            font-size: 0.85em;
        }
        .raw-body-toggle summary {
            cursor: pointer;
            color: #888;
            padding: 2px 0;
            font-weight: 500;
            font-size: 0.9em;
            list-style: none;
        }
        .raw-body-toggle summary::-webkit-details-marker { display: none; }
        .raw-body-toggle summary::before { content: "▶ "; font-size: 0.7em; }
        .raw-body-toggle[open] summary::before { content: "▼ "; }
        .raw-body-toggle summary:hover { color: #555; }
        .raw-body-text {
            white-space: pre-wrap;
            font-size: 0.95em;
            background: #f8f8f8;
            padding: 8px 10px;
            border-radius: 4px;
            max-height: 360px;
            overflow-y: auto;
            margin-top: 4px;
            line-height: 1.5;
            color: #444;
            border: 1px solid #e8e8e8;
        }

        .no-reviews {
            color: #aaa;
            font-size: 0.85em;
            font-style: italic;
            padding: 8px 0;
        }

        footer {
            text-align: center;
            color: #bbb;
            font-size: 0.78em;
            margin-top: 36px;
            padding: 16px;
        }
    </style>
</head>
<body>
    <div class="home-link"><a href="../">&larr; Back to reports</a></div>
    <h1>Re: [PATCH v1 03/11] io_uring/kbuf: add support for kernel-managed buffer rings</h1>
    <div class="lore-link"><a href="https://lore.kernel.org/all/CAJnrk1Y5iTOhj4_RbnR7RJPkr7fFcCdh1gY=3Hm72M91D-SnyQ@mail.gmail.com/" target="_blank">View on lore.kernel.org &rarr;</a></div>
    <div class="date-range">Active on: <a href="#2026-02-20">2026-02-20</a> &bull; <a href="#2026-02-18">2026-02-18</a> &bull; <a href="#2026-02-13">2026-02-13</a> &bull; <a href="#2026-02-12">2026-02-12</a> &bull; <a href="#2026-02-11">2026-02-11</a> &bull; <a href="#2026-02-10">2026-02-10</a> &bull; <a href="#2026-02-09">2026-02-09</a></div>
    
    <div class="thread-tree">
<div class="thread-node depth-0" id="2026-02-09">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-09">2026-02-09</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The author addressed a concern about the refactoring of io_register_pbuf_ring() logic into generic helpers, explaining that this is a preparatory change for upcoming kernel-managed buffer ring support which will need to reuse some of these helpers.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Refactor the logic in io_register_pbuf_ring() into generic helpers:
- io_copy_and_validate_buf_reg(): Copy out user arg and validate user
  arg and buffer registration parameters
- io_alloc_new_buffer_list(): Allocate and initialize a new buffer
  list for the given buffer group ID
- io_setup_pbuf_ring(): Sets up the physical buffer ring region and
  handles memory mapping for provided buffer rings

This is a preparatory change for upcoming kernel-managed buffer ring
support which will need to reuse some of these helpers.

Signed-off-by: Joanne Koong &lt;joannelkoong@gmail.com&gt;
---
 io_uring/kbuf.c | 129 +++++++++++++++++++++++++++++++-----------------
 1 file changed, 85 insertions(+), 44 deletions(-)

diff --git a/io_uring/kbuf.c b/io_uring/kbuf.c
index 67d4fe576473..850b836f32ee 100644
--- a/io_uring/kbuf.c
+++ b/io_uring/kbuf.c
@@ -596,55 +596,73 @@ int io_manage_buffers_legacy(struct io_kiocb *req, unsigned int issue_flags)
 	return IOU_COMPLETE;
 }
 
-int io_register_pbuf_ring(struct io_ring_ctx *ctx, void __user *arg)
+static int io_copy_and_validate_buf_reg(const void __user *arg,
+					struct io_uring_buf_reg *reg,
+					unsigned int permitted_flags)
 {
-	struct io_uring_buf_reg reg;
-	struct io_buffer_list *bl;
-	struct io_uring_region_desc rd;
-	struct io_uring_buf_ring *br;
-	unsigned long mmap_offset;
-	unsigned long ring_size;
-	int ret;
-
-	lockdep_assert_held(&amp;ctx-&gt;uring_lock);
-
-	if (copy_from_user(&amp;reg, arg, sizeof(reg)))
+	if (copy_from_user(reg, arg, sizeof(*reg)))
 		return -EFAULT;
-	if (!mem_is_zero(reg.resv, sizeof(reg.resv)))
+
+	if (!mem_is_zero(reg-&gt;resv, sizeof(reg-&gt;resv)))
 		return -EINVAL;
-	if (reg.flags &amp; ~(IOU_PBUF_RING_MMAP | IOU_PBUF_RING_INC))
+	if (reg-&gt;flags &amp; ~permitted_flags)
 		return -EINVAL;
-	if (!is_power_of_2(reg.ring_entries))
+	if (!is_power_of_2(reg-&gt;ring_entries))
 		return -EINVAL;
 	/* cannot disambiguate full vs empty due to head/tail size */
-	if (reg.ring_entries &gt;= 65536)
+	if (reg-&gt;ring_entries &gt;= 65536)
 		return -EINVAL;
+	return 0;
+}
 
-	bl = io_buffer_get_list(ctx, reg.bgid);
-	if (bl) {
+static struct io_buffer_list *
+io_alloc_new_buffer_list(struct io_ring_ctx *ctx,
+			 const struct io_uring_buf_reg *reg)
+{
+	struct io_buffer_list *list;
+
+	list = io_buffer_get_list(ctx, reg-&gt;bgid);
+	if (list) {
 		/* if mapped buffer ring OR classic exists, don&#x27;t allow */
-		if (bl-&gt;flags &amp; IOBL_BUF_RING || !list_empty(&amp;bl-&gt;buf_list))
-			return -EEXIST;
-		io_destroy_bl(ctx, bl);
+		if (list-&gt;flags &amp; IOBL_BUF_RING || !list_empty(&amp;list-&gt;buf_list))
+			return ERR_PTR(-EEXIST);
+		io_destroy_bl(ctx, list);
 	}
 
-	bl = kzalloc(sizeof(*bl), GFP_KERNEL_ACCOUNT);
-	if (!bl)
-		return -ENOMEM;
+	list = kzalloc(sizeof(*list), GFP_KERNEL_ACCOUNT);
+	if (!list)
+		return ERR_PTR(-ENOMEM);
+
+	list-&gt;nr_entries = reg-&gt;ring_entries;
+	list-&gt;mask = reg-&gt;ring_entries - 1;
+	list-&gt;flags = IOBL_BUF_RING;
+
+	return list;
+}
+
+static int io_setup_pbuf_ring(struct io_ring_ctx *ctx,
+			      const struct io_uring_buf_reg *reg,
+			      struct io_buffer_list *bl)
+{
+	struct io_uring_region_desc rd;
+	unsigned long mmap_offset;
+	unsigned long ring_size;
+	int ret;
 
-	mmap_offset = (unsigned long)reg.bgid &lt;&lt; IORING_OFF_PBUF_SHIFT;
-	ring_size = flex_array_size(br, bufs, reg.ring_entries);
+	mmap_offset = (unsigned long)reg-&gt;bgid &lt;&lt; IORING_OFF_PBUF_SHIFT;
+	ring_size = flex_array_size(bl-&gt;buf_ring, bufs, reg-&gt;ring_entries);
 
 	memset(&amp;rd, 0, sizeof(rd));
 	rd.size = PAGE_ALIGN(ring_size);
-	if (!(reg.flags &amp; IOU_PBUF_RING_MMAP)) {
-		rd.user_addr = reg.ring_addr;
+	if (!(reg-&gt;flags &amp; IOU_PBUF_RING_MMAP)) {
+		rd.user_addr = reg-&gt;ring_addr;
 		rd.flags |= IORING_MEM_REGION_TYPE_USER;
 	}
+
 	ret = io_create_region(ctx, &amp;bl-&gt;region, &amp;rd, mmap_offset);
 	if (ret)
-		goto fail;
-	br = io_region_get_ptr(&amp;bl-&gt;region);
+		return ret;
+	bl-&gt;buf_ring = io_region_get_ptr(&amp;bl-&gt;region);
 
 #ifdef SHM_COLOUR
 	/*
@@ -656,25 +674,48 @@ int io_register_pbuf_ring(struct io_ring_ctx *ctx, void __user *arg)
 	 * should use IOU_PBUF_RING_MMAP instead, and liburing will handle
 	 * this transparently.
 	 */
-	if (!(reg.flags &amp; IOU_PBUF_RING_MMAP) &amp;&amp;
-	    ((reg.ring_addr | (unsigned long)br) &amp; (SHM_COLOUR - 1))) {
-		ret = -EINVAL;
-		goto fail;
+	if (!(reg-&gt;flags &amp; IOU_PBUF_RING_MMAP) &amp;&amp;
+	    ((reg-&gt;ring_addr | (unsigned long)bl-&gt;buf_ring) &amp;
+	     (SHM_COLOUR - 1))) {
+		io_free_region(ctx-&gt;user, &amp;bl-&gt;region);
+		return -EINVAL;
 	}
 #endif
 
-	bl-&gt;nr_entries = reg.ring_entries;
-	bl-&gt;mask = reg.ring_entries - 1;
-	bl-&gt;flags |= IOBL_BUF_RING;
-	bl-&gt;buf_ring = br;
-	if (reg.flags &amp; IOU_PBUF_RING_INC)
+	if (reg-&gt;flags &amp; IOU_PBUF_RING_INC)
 		bl-&gt;flags |= IOBL_INC;
+
+	return 0;
+}
+
+int io_register_pbuf_ring(struct io_ring_ctx *ctx, void __user *arg)
+{
+	unsigned int permitted_flags;
+	struct io_uring_buf_reg reg;
+	struct io_buffer_list *bl;
+	int ret;
+
+	lockdep_assert_held(&amp;ctx-&gt;uring_lock);
+
+	permitted_flags = IOU_PBUF_RING_MMAP | IOU_PBUF_RING_INC;
+	ret = io_copy_and_validate_buf_reg(arg, &amp;reg, permitted_flags);
+	if (ret)
+		return ret;
+
+	bl = io_alloc_new_buffer_list(ctx, &amp;reg);
+	if (IS_ERR(bl))
+		return PTR_ERR(bl);
+
+	ret = io_setup_pbuf_ring(ctx, &amp;reg, bl);
+	if (ret) {
+		kfree(bl);
+		return ret;
+	}
+
 	ret = io_buffer_add_list(ctx, bl, reg.bgid);
-	if (!ret)
-		return 0;
-fail:
-	io_free_region(ctx-&gt;user, &amp;bl-&gt;region);
-	kfree(bl);
+	if (ret)
+		io_put_bl(ctx, bl);
+
 	return ret;
 }
 
-- 
2.47.3</pre>
</details>
<div class="review-comment-signals">Signals: neutral explanation, no clear resolution signal</div>
</div>
<div class="thread-children">
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Jens Axboe</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-09">2026-02-09</a>
<span class="inline-review-badge">Inline Review</span>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">reviewer suggested adding a WARN_ON_ONCE() check to prevent int promotion from affecting the calculation of (br-&gt;tail - bl-&gt;head) &gt;= bl-&gt;nr_entries, and noted that while it&#x27;s not a huge issue for now, some of these WARN_ON_ONCE() instances may be pruned later</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">I think you want:

	if (WARN_ON_ONCE((__u16)(br-&gt;tail - bl-&gt;head) &gt;= bl-&gt;nr_entries))

here to avoid int promotion from messing this up if tail has wrapped.

In general, across the patches for the WARN_ON_ONCE(), it&#x27;s not a huge
issue to have a litter of them for now. Hopefully we can prune some of
these down the line, however.

-- 
Jens Axboe</pre>
</details>
<div class="review-comment-signals">Signals: requested changes, optimization suggestion</div>
</div>
<div class="thread-children">
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Caleb Mateos</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-10">2026-02-10</a>
<span class="inline-review-badge">Inline Review</span>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Caleb Mateos noted that the patch&#x27;s optimization !(~bl-&gt;flags &amp; (IOBL_BUF_RING|IOBL_PINNED)) is unnecessary, as modern compilers will automatically perform this optimization and potentially optimize it further.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">FWIW, modern compilers will perform this optimization automatically.
They&#x27;ll even optimize it further to !(~bl-&gt;flags &amp;
(IOBL_BUF_RING|IOBL_PINNED)): https://godbolt.org/z/xGoP4TfhP

Best,
Caleb</pre>
</details>
<div class="review-comment-signals">Signals: requested change, optimization</div>
</div>
<div class="thread-children">
<div class="thread-node depth-3">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Jens Axboe</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-10">2026-02-10</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Jens Axboe suggested that the patch&#x27;s implementation should follow a more common and readable approach, citing an example where his own version is easier to read than the original.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Sure, it&#x27;s not about that, it&#x27;s more about the common way of doing it,
which makes it easier to read for people. FWIW, your example is easier
to read too than the original.

-- 
Jens Axboe</pre>
</details>
<div class="review-comment-signals">Signals: suggested improvement, example provided</div>
</div>
</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-10">2026-02-10</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author addressed Jens&#x27; concern about accessing buffer IDs from within the io_uring internals by suggesting a helper function or returning the buf ID as part of the io_br_sel struct, indicating a willingness to accommodate reviewer feedback.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">The caller can, but from the caller side they only have access to the
cmd so they would need to do something like

struct io_kiocb *req = cmd_to_iocb_kiocb(ent-&gt;cmd);
buf_id = req-&gt;buf_index;

which may be kind of ugly with looking inside io-uring internals.
Maybe a helper here would be nicer, something like
io_uring_cmd_buf_id() or io_uring_req_buf_id(). It seemed cleaner to
me to just return the buf id as part of the io_br_sel struct, but I&#x27;m
happy to do it another way if you have a preference.

Thanks,
Joanne</pre>
</details>
<div class="review-comment-signals">Signals: willingness to accommodate reviewer feedback, open to alternative solutions</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-10">2026-02-10</a>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author acknowledged the need for changes in v2, specifically mentioned making changes pointed out by reviewer and addressing discussion with Pavel before submitting a revised patchset.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Thanks for reviewing the patches. The branch containing the userside
changes on top of these patches is in [1]. I&#x27;ll make the changes you
pointed out in your other comments as part of v2. Once the discussion
with Pavel is resolved / figured out with the changes he wants for v2,
I&#x27;ll submit v2.

Thanks,
Joanne

[1] https://github.com/joannekoong/linux/commits/fuse_zero_copy/</pre>
</details>
<div class="review-comment-signals">Signals: acknowledged need for changes, v2</div>
</div>
</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Jens Axboe</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-09">2026-02-09</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Jens Axboe questioned the necessity of introducing a new field io_uring_cmd_data-&gt;kmbuf_idx, suggesting that req-&gt;buf_index could be used instead.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">I&#x27;m probably missing something here, but why can&#x27;t the caller just use
req-&gt;buf_index for this?

-- 
Jens Axboe</pre>
</details>
<div class="review-comment-signals">Signals: questioning, suggestion</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Jens Axboe</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-09">2026-02-09</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Jens Axboe requested that Joanne Koong provide a branch with all patches, including user code, for easier cross-referencing and evaluation of the helpers.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Generally looks pretty good - for context, do you have a branch with
these patches and the users on top too? Makes it a bit easier for cross
referencing, as some of these really do need an exposed user to make a
good judgement on the helpers.

I know there&#x27;s the older series, but I&#x27;m assuming the latter patches
changed somewhat too, and it&#x27;d be nicer to look at a current set rather
than go back to the older ones.

-- 
Jens Axboe</pre>
</details>
<div class="review-comment-signals">Signals: request, clarification</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Jens Axboe</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-09">2026-02-09</a>
<span class="inline-review-badge">Inline Review</span>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Jens Axboe suggested refactoring io_pbuf_get_region() to handle kernel-managed buffer rings by adding a new helper function, io_kbuf_get_region(), and checking the bl-&gt;flags in both functions for readability.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">For this, I think just add another helper - leave io_pbuf_get_region()
and add a bl-&gt;flags &amp; IOBL_KERNEL_MANAGED error check in there, and
add a io_kbuf_get_region() or similar and have a !(bl-&gt;flags &amp;
IOBL_KERNEL_MANAGED) error check in that one.

That&#x27;s easier to read, and there&#x27;s little reason to avoid duplicating
the xa_load() part.

Minor nit, but imho it&#x27;s more readable that way.

-- 
Jens Axboe</pre>
</details>
<div class="review-comment-signals">Signals: requested changes, minor nit</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Jens Axboe</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-09">2026-02-09</a>
<span class="inline-review-badge">Inline Review</span>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Jens Axboe suggested using a pointer to struct io_buffer_list instead of a reference to it, and recommended either returning an error pointer or renaming the parameter to indicate its return value.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Probably use the usual struct io_buffer_list *bl here and either use an
ERR_PTR return, or rename the passed on **bl to **blret or something.</pre>
</details>
<div class="review-comment-signals">Signals: requested changes</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Jens Axboe</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-09">2026-02-09</a>
<span class="inline-review-badge">Inline Review</span>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Jens Axboe suggested a more efficient way to check for pinned buffer rings by combining two flags into one condition, and also recommended adding an early return statement when the buffer list is empty.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Usually done as:

	if ((bl-&gt;flags &amp; (IOBL_BUF_RING|IOBL_PINNED)) == (IOBL_BUF_RING|IOBL_PINNED))

and maybe then just have an earlier

	if (!bl)
		goto err;</pre>
</details>
<div class="review-comment-signals">Signals: requested changes</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Jens Axboe</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-09">2026-02-09</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Jens Axboe suggested that the patch should be modified to avoid exceeding the 80 character limit for io_uring strings, citing a desire to keep code consistent and maintainable.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">to avoid making it way too long. For io_uring, it&#x27;s fine to exceed 80
chars where it makes sense.

-- 
Jens Axboe</pre>
</details>
<div class="review-comment-signals">Signals: requested changes</div>
</div>
</div>
<div class="thread-node depth-1" id="2026-02-10">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-10">2026-02-10</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Pavel Begunkov noted that the code should allow regions to work with user-passed memory, which would enable optimizations such as huge pages, and requested consideration of this.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">If you&#x27;re creating a region, there should be no reason why it
can&#x27;t work with user passed memory. You&#x27;re fencing yourself off
optimisations that are already there like huge pages.</pre>
</details>
<div class="review-comment-signals">Signals: requested changes</div>
</div>
<div class="thread-children">
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-10">2026-02-10</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author is asking for clarification on whether kernel-allocated buffers can be optimized further than user-allocated buffers, specifically in the case of huge pages.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Are there any optimizations with user-allocated buffers that wouldn&#x27;t
be possible with kernel-allocated buffers? For huge pages, can&#x27;t the
kernel do this as well (eg I see in io_mem_alloc_compound(), it calls
into alloc_pages() with order &gt; 0)?</pre>
</details>
<div class="review-comment-signals">Signals: clarifying question</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-10">2026-02-10</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author addressed Pavel Begunkov&#x27;s concern that using io_create_region() for both single and multi-buffer cases is insufficient, explaining that separate checks are needed between the two functions and different allocation calls.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">There&#x27;s separate checks needed between io_create_region() and
io_create_region_multi_buf() (eg IORING_MEM_REGION_TYPE_USER flag
checking) and different allocation calls (eg
io_region_allocate_pages() vs io_region_allocate_pages_multi_buf()).
Maybe I&#x27;m misinterpreting your comment (or the code), but I&#x27;m not
seeing how this can just use io_create_region().</pre>
</details>
<div class="review-comment-signals">Signals: clarification, explanation</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-10">2026-02-10</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author Joanne Koong is addressing Pavel Begunkov&#x27;s feedback about registering buffer rings from userspace, explaining that kernel-managed buffer rings simplify interface and lifecycle management, and guarantee contiguous page allocation. She asks for elaboration on the benefits of allocating buffers from userspace.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Conceptually, I think it makes the interface and lifecycle management
simpler/cleaner. With registering it from userspace, imo there&#x27;s
additional complications with no tangible benefits, eg it&#x27;s not
guaranteed that the memory regions registered for the buffers are the
same size, with allocating it from the kernel-side we can guarantee
that the pages are allocated physically contiguously, userspace setup
with user-allocated buffers is less straightforward, etc. In general,
I&#x27;m just not really seeing what advantages there are in allocating the
buffers from userspace. Could you elaborate on that part more?</pre>
</details>
<div class="review-comment-signals">Signals: asking_for_clarification</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-10">2026-02-10</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author addressed a concern about pbuf rings needing to support pinning if kmbuf rings are merged into them, explained that pinning is already needed in fuse due to atomic context and recycling buffer issues, and implied that this requirement will still apply even if the patches are restructured.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">If kmbuf rings are squashed into pbuf rings, then pbuf rings will need
to support pinning. In fuse, there are some contexts where you can&#x27;t
grab the uring mutex because you&#x27;re running in atomic context and this
can be encountered while recycling the buffer. I originally had a
patch adding pinning to pbuf rings (to mitigate the overhead of
registered buffers lookups) but dropped it when Jens and Caleb didn&#x27;t
like the idea. But for kmbuf rings, pinning will be necessary for
fuse.</pre>
</details>
<div class="review-comment-signals">Signals: acknowledged a technical concern, provided additional context</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-10">2026-02-10</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author responded to Pavel Begunkov&#x27;s question about what constitutes a &#x27;normal request&#x27; in the context of io_uring and kernel-managed buffer rings, explaining that for fuse&#x27;s use case, there are only fuse requests.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">What are &#x27;normal requests&#x27;? For fuse&#x27;s use case, there are only fuse requests.

Thanks,
Joanne</pre>
</details>
<div class="review-comment-signals">Signals: clarification, explanation</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Christoph Hellwig</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-11">2026-02-11</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#155724;background:#d4edda">Positive</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Christoph Hellwig noted that any pages mapped to userspace can be allocated in the kernel, allowing for a buffer ring that is only mapped read-only into userspace, enabling zero-copy raids if required by devices.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Any pages mapped to userspace can be allocated in the kernel as well.

And I really do like this design, because it means we can have a
buffer ring that is only mapped read-only into userspace.  That way
we can still do zero-copy raids if the device requires stable pages
for checksumming or raid.  I was going to implement this as soon
as this series lands upstream.</pre>
</details>
<div class="review-comment-signals">Signals: likes the design, zero-copy raids</div>
</div>
<div class="thread-children">
<div class="thread-node depth-3">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-12">2026-02-12</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Pavel Begunkov noted that the current pow2 round up for memory allocation will waste memory, as 1MB allocations will never become 2MB huge pages, and also questioned the handling of 1GB huge pages, suggesting users could make better placement decisions.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">pow2 round ups will waste memory. 1MB allocations will never
become 2MB huge pages. And there is a separate question of
1GB huge pages. The user can be smarter about all placement
decisions.</pre>
</details>
<div class="review-comment-signals">Signals: waste, question</div>
</div>
</div>
<div class="thread-node depth-3">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-12">2026-02-12</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The reviewer suggests that user-provided memory should be an optional feature for pbuf rings, and recommends adding fields in the io_uring uapi to accommodate this</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">That&#x27;s an interesting case. To be clear, user provided memory is
an optional feature for pbuf rings / regions / etc., and I think
the io_uring uapi should leave fields for the feature. However, I
have nothing against fuse refusing to bind to buffer rings it
doesn&#x27;t like.

-- 
Pavel Begunkov</pre>
</details>
<div class="review-comment-signals">Signals: optional feature, add fields</div>
</div>
</div>
<div class="thread-node depth-3">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-12">2026-02-12</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Pavel Begunkov suggested adding a new registration flag to IORING_REGISTER_MEM_REGION for read-only allocations, and making bounce avoidance optional or rejecting binding fuse to unsupported setups during init.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">IORING_REGISTER_MEM_REGION supports both types of allocations. It can
have a new registration flag for read-only, and then you either make
the bounce avoidance optional or reject binding fuse to unsupported
setups during init. Any arguments against that? I need to go over
Joanne&#x27;s reply, but I don&#x27;t see any contradiction in principal with
your use case.

-- 
Pavel Begunkov</pre>
</details>
<div class="review-comment-signals">Signals: request for clarification, no clear objection</div>
</div>
</div>
<div class="thread-node depth-3" id="2026-02-13">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The reviewer questioned the necessity of introducing kernel-managed buffer rings for io_uring, suggesting that fuse can contain all its needs within itself and reusing pbuf ring code as an internal memory allocator. They also pointed out inflexibilities in the current design, such as requiring a new io_uring uapi and binding buffer memory to ring entries.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Registered, aka fixed, buffers are the ones you pass to
IORING_OP_[READ,WRITE]_FIXED and some other requests. It&#x27;s normally
created by io_uring_register_buffers*() / IORING_REGISTER_BUFFERS*
with user memory, but there are special cases when it&#x27;s installed
internally by other kernel components, e.g. ublk.
This series has nothing to do with them, and relevant parts of
the discussion here don&#x27;t mention them either.

Provided buffer rings, a.k.a pbuf rings, IORING_REGISTER_PBUF_RING
is a kernel-user shared ring. The entries are user buffers
{uaddr, size}. The user space adds entries, the kernel (io_uring
requests) consumes them and issues I/O using the user addresses.
E.g. you can issue a IORING_OP_RECV request (+IOSQE_BUFFER_SELECT)
and it&#x27;ll grab a buffer from the ring instead of using sqe-&gt;addr.

pbuf rings, IORING_REGISTER_MEM_REGION, completion/submission
queues and all other kernel-user rings/etc. are internally based
on so called regions. All of them support both user allocated
memory and kernel allocations + mmap.

This series essentially creates provided buffer rings, where
1. the ring now contains kernel addresses
2. the ring itself is in-kernel only and not shared with user space
3. it also allocates kernel buffers (as a region), populates the ring
    with them, and allows mapping the buffers into the user space.

Fuse is doing both adding (kernel) buffers to the ring and consuming
them. At which point it&#x27;s not clear:

1. Why it even needs io_uring provided buffer rings, it can be all
    contained in fuse. Maybe it&#x27;s trying to reuse pbuf ring code as
    basically an internal memory allocator, but then why expose buffer
    rings as an io_uring uapi instead of keeping it internally.

    That&#x27;s also why I mentioned whether those buffers are supposed to
    be used with other types of io_uring requests like recv, etc.

2. Why making io_uring to allocate payload memory. The answer to which
    is probably to reuse the region api with mmap and so on. And why
    payload buffers are inseparably created together with the ring
    and via a new io_uring uapi.

    And yes, I believe in the current form it&#x27;s inflexible, it requires
    a new io_uring uapi. It requires the number of buffers to match
    the number of ring entries, which are related but not the same
    thing. You can&#x27;t easily add more memory as it&#x27;s bound to the ring
    object. The buffer memory won&#x27;t even have same lifetime as the
    ring object -- allow using that km buffer ring with recv requests
    and highly likely I&#x27;ll most likely give you a way to crash the
    kernel.

But hey, I&#x27;m tired. I don&#x27;t have any beef here and am only trying
to make it a bit cleaner and flexible for fuse in the first place
without even questioning the I/O path. If everyone believes
everything is right, just ask Jens to merge it.

-- 
Pavel Begunkov</pre>
</details>
<div class="review-comment-signals">Signals: infelicities, inflexibilities</div>
</div>
</div>
<div class="thread-node depth-3">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The reviewer expressed concern that the current use of kernel-managed buffer rings is not suitable for huge payload buffers and suggested respinning patches to place SQ/CQ onto a different area of memory.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Think of it as an area of memory for kernel-user communication. Used
for syscall parameters passing to avoid copy_from_user, but I added
it for a bunch of use cases. We&#x27;ll hopefully get support at some
point for passing request arguments like struct iovec. BPF patches
use it for communication. I need to respin patches placing SQ/CQ onto
it (avoid some memory waste).

Tbh, I never meant it nor io_uring regions to be used for huge
payload buffers, but this series already uses regions for that.</pre>
</details>
<div class="review-comment-signals">Signals: requested changes, concern about suitability</div>
</div>
</div>
<div class="thread-node depth-3">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Pavel Begunkov expressed confusion about how the kernel-managed buffer rings can work without a kernel component returning buffers into the ring, pointing out that io_uring does not currently support this.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Then I&#x27;m confused. Take a look at the other reply, this series is
about buffer rings with kernel memory, it can&#x27;t work without a kernel
component returning buffers into the ring, and io_uring doesn&#x27;t do
that. But maybe you&#x27;re thinking about adding some more elaborate API.

IIUC, Joanne also wants to add support for fuse installing registered
buffers, which would allow zero-copy, but those got split out of
this series.

-- 
Pavel Begunkov</pre>
</details>
<div class="review-comment-signals">Signals: confusion, lack of clear understanding</div>
</div>
</div>
<div class="thread-node depth-3">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Pavel Begunkov noted that the patch series does not address registered buffers and suggested separating kernel-managed buffer rings from io_uring, arguing that reusing buffer allocation would introduce unnecessary complexity.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">There is nothing about registered buffers in this series. And even
if you try to reuse buffer allocation out of it, it&#x27;ll come with
a circular buffer you&#x27;ll have no need for. And I&#x27;m pretty much
arguing about separating those for io_uring.

-- 
Pavel Begunkov</pre>
</details>
<div class="review-comment-signals">Signals: requested changes, separation of concerns</div>
</div>
</div>
<div class="thread-node depth-3">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author acknowledged that Christoph Hellwig&#x27;s use case for read-only buffers aligns with the benefits of kernel-managed buffer rings, and sees no need to modify the patch.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">(resending because I hit reply instead of reply-all)

I think we have the exact same use case, except your buffers need to
be read-only. I think your use case benefits from the same memory wins
we&#x27;ll get with incremental buffer consumption, which is the primary
reason fuse is using a bufring instead of fixed buffers.</pre>
</details>
<div class="review-comment-signals">Signals: acknowledged a similar use case, no clear resolution signal</div>
</div>
</div>
<div class="thread-node depth-3">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author addressed Christoph Hellwig&#x27;s concern about making mmap calls on kernel-managed buffer rings read-only, explained how to achieve this by passing a read-only flag from userspace and checking it in the kernel, and offered to add a patch to the series if needed.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">I think you can and it&#x27;ll be very easy to do so. All that would be
needed is to pass in a read-only flag from the userspace side when it
registers the bufring, and then when userspace makes the mmap call to
the bufring, the kernel checks if that read-only flag is set on the
bufring and if so returns a read-only mapping. I&#x27;m happy to add that
patch to this series if that would make things easier for you. The
io_uring_register_buffers() api registers fixed buffers (which have to
be user-allocated memory) so you would need to go through the
io_uring_register_buf_ring() api once kmbufs are squashed into the
pbuf interface.

With going through IORING_MEM_REGION, this would work for your use
case as well. The user would have to register the mem region with
io_uring_register_region() and pass in a read-only flag, and then the
kernel will allocate the memory region. Then userspace would mmap the
memory region and on the kernel side, it would set the mapping to be
read-only. When the kmbufring then gets registered, the buffers in it
will be empty. The filesystem will then have to populate the buffers
in it from the mem region that was previously registered.

Thanks,
Joanne</pre>
</details>
<div class="review-comment-signals">Signals: clarification, offer_to_add_patch</div>
</div>
</div>
<div class="thread-node depth-3" id="2026-02-18">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-18">2026-02-18</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The reviewer noted that buffer rings are not suitable for storage read/write operations because they immediately bind to a buffer, whereas other types of requests like recv allow io_uring to first poll the socket and then take a buffer from the ring. This leads to two issues: the inability to specify where data lands in storage rw requests, and the lack of a mechanism to return buffers back into the kernel private ring.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Provided buffer rings are not useful for storage read/write requests
because they bind to a buffer right away, that&#x27;s in contrast to some
recv request, where io_uring will first poll the socket to confirm
the data is there, and only then take a buffer from the buffer ring
and copy into it. With storage rw it makes more sense to specify
the buffer directly gain control over where exactly data lands
IOW, instead of the usual &quot;read data into a given pointer&quot; request
semantics like what read(2) gives you, buffer rings are rather
&quot;read data somewhere and return a pointer to where you placed it&quot;.

Another problem is that someone needs to return buffers back into
the buffer ring, and it&#x27;s a kernel private ring. For this patchset
it&#x27;s assumed the fuse driver is going to be doing that, but there
is no one for normal rw requests.</pre>
</details>
<div class="review-comment-signals">Signals: requested changes</div>
</div>
</div>
<div class="thread-node depth-3">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-18">2026-02-18</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Pavel Begunkov suggested replacing the current kernel-managed buffer ring implementation with a simpler approach based on IORING_MEM_REGION, which provides buffers/memory without extra semantics.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Yes. You only need buffers, and it&#x27;ll be better to base on sth that
gives you buffers/memory without extra semantics, i.e.
IORING_MEM_REGION. Or it can be a standalone registered buffer
extension, likely reusing regions internally. That might even yield
a finer API.

-- 
Pavel Begunkov</pre>
</details>
<div class="review-comment-signals">Signals: requested changes</div>
</div>
</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-11">2026-02-11</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author Joanne Koong addressed Pavel Begunkov&#x27;s concern that io_uring/kbuf should use io_create_region(), explaining that it fails due to excessive memory allocation and instead uses io_region_allocate_pages_multi_buf() to bypass this issue, with no indication of a fix planned for the original approach.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">When I originally implemented it, I had it use
io_region_allocate_pages() but this fails because it&#x27;s allocating way
too much memory at once. For fuse&#x27;s use case, each buffer is usually
at least 1 MB if not more. Allocating the memory one buffer a time in
io_region_allocate_pages_multi_buf() bypasses the allocation errors I
was seeing. That&#x27;s the main reason I don&#x27;t think this can just use
io_create_region().</pre>
</details>
<div class="review-comment-signals">Signals: no clear resolution signal, author explains reasoning</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-11">2026-02-11</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author clarified her understanding of Pavel&#x27;s feedback, confirming that she and Christoph thought the user should own buffer allocation, but now believes a different kernel-allocated approach is being proposed.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Oh okay, from your first message I (and I think christoph too) thought
what you were saying is that the user should be responsible for
allocating the buffers with complete ownership over them, and then
just pass those allocated to the kernel to use. But what you&#x27;re saying
is that just use a different way for getting the kernel to allocate
the buffers (eg through the IORING_REGISTER_MEM_REGION interface). Am
I reading this correctly?</pre>
</details>
<div class="review-comment-signals">Signals: clarifying question, request for confirmation</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-11">2026-02-11</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The author addressed Pavel Begunkov&#x27;s concern that combining kernel-managed buffer rings (kmbufs) and regular pbufs into a single API would make the pbuf API overly complex. The author explained that having separate APIs for pbufs, kmbufs, and regular pbufs clarifies their different expectations and behaviors.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">imo, it looked cleaner as a separate api because it has different
expectations and behaviors and squashing kmbuf into the pbuf api makes
the pbuf api needlessly more complex. Though I guess from the
userspace pov, liburing could have a wrapper that takes care of
setting up the pbuf details for kernel-managed pbufs. But in my head,
having pbufs vs. kmbufs makes it clearer what each one does vs regular
pbufs vs. pbufs that are kernel-managed.

Especially with now having kmbufs go through the ioring mem region
interface, it makes things more confusing imo if they&#x27;re combined, eg
pbufs that are kernel-managed are created empty and then populated
from the kernel side by whatever subsystem is using them. Right now
there&#x27;s only one mem region supported per ring, but in the future if
there&#x27;s the possibility that multiple mem regions can be registered
(eg if userspace doesn&#x27;t know upfront what mem region length they&#x27;ll
need), then we should also probably add in a region id param for the
registration arg, which if kmbuf rings go through the pbuf ring
registration api, is not possible to do.

But I&#x27;m happy to combine the interfaces and go with your suggestion.
I&#x27;ll make this change for v2 unless someone else objects.</pre>
</details>
<div class="review-comment-signals">Signals: acknowledged feedback, explained reasoning</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-11">2026-02-11</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author acknowledged that they previously pinned the wrong data structure (registered buffer table) instead of the intended one (pbuf ring), but it&#x27;s unclear if this will be fixed in a future version.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Yeah, you&#x27;re right I misremembered and the objections / patch I
dropped was pinning the registered buffer table, not the pbuf ring</pre>
</details>
<div class="review-comment-signals">Signals: acknowledgment of mistake, no clear resolution</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-11">2026-02-11</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The author is addressing Pavel Begunkov&#x27;s concern about sparse buffers populated by the kernel and their registration/unregistration. The author suggests that if those buffers are automatically pinned, users would need to unregister them individually instead of using IORING_UNREGISTER_BUFFERS, which could be annoying for them. The author notes that they dropped this feature from the fuse code because it didn&#x27;t seem to make a significant performance difference.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Hmm, I&#x27;m not sure this idea would work for sparse buffers populated by
the kernel, unless those are automatically pinned too but then from
the user POV for unregistration they&#x27;d need to unregister buffers
individually instead of just calling IORING_UNREGISTER_BUFFERS but it
might be annoying for them to now need to know which buffers are
pinned vs not. When i benchmarked the fuse code with vs without pinned
registered buffers, it didn&#x27;t seem to make much of a difference
performance-wise thankfully, so I just dropped it.</pre>
</details>
<div class="review-comment-signals">Signals: clarification, explanation</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-11">2026-02-11</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The author is addressing concerns about allocating individual buffers separately by the kernel, explaining that having separate allocations would not necessarily reduce mmap calls or userspace management, and may even improve physical contiguity of the buffer region.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">To clarify, is this in reply to why the individual buffers shouldn&#x27;t
be allocated separately by the kernel?
I added a comment about this above in the discussion about
io_region_allocate_pages_multi_buf(), and if the memory allocation
issue I was seeing is bypassable and the region can be allocated all
at once, I&#x27;m happy to make that change. With having the allocation be
separate buffers though, I&#x27;m not sure I agree that there are extra
mmaps / userspace management. All the pages across the buffers are
vmapped together and the userspace just needs to do 1 mmap call for
them. On the userspace side, I don&#x27;t think there&#x27;s more management
since the mmapped address represents the range across all the buffers.
I&#x27;m not seeing how there&#x27;s wasted space either since the only
requirement is that the buffer size is page aligned. I think also
there&#x27;s a higher chance of the entire buffer region being physically
contiguous if each buffer is allocated separately vs. all the buffers
are allocated as 1 region. I don&#x27;t feel strongly about this either way
and I&#x27;m happy to allocate the entire region at once if that&#x27;s
possible.</pre>
</details>
<div class="review-comment-signals">Signals: clarification, explaining reasoning</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-11">2026-02-11</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author asks for clarification on reviewer&#x27;s concerns about over-accounting and extra memory footprint in kernel-managed buffer rings.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Just out of curiosity, could you elaborate on the over-accounting and
extra memory footprint? I was under the impression it would be the
same since the accounting gets adjusted by the total bytes allocated?
For the extra memory footprint, is the extra footprint from the
metadata to describe each buffer region, or are you referring to
something else?</pre>
</details>
<div class="review-comment-signals">Signals: clarifying question, request for explanation</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-11">2026-02-11</a>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author addressed a concern about the API interface and kernel buffer allocation by proposing to modify the PBUF_RING API, register memory regions through IORING_REGISTER_MEM_REGION, and add APIs for subsystems to populate kernel-managed buffer rings.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Thanks for your input on the series. To iterate / sum up, these are
changes for v2 I&#x27;ll be making:
- api-wise from userspace/liburing: get rid of KMBUF_RING api
interface and have users go through PBUF_RING api instead with a flag
indicating the ring is kernel-managed
- have kernel buffer allocation go through IORING_REGISTER_MEM_REGION
instead, which means when the pbuf ring is created and the
kernel-managed flag is set, the ring will be empty. The memory region
will need to be registered before the mmap call to the ring fd.
- add apis for subsystems to populate a kernel-managed buffer ring
with addresses from the registered mem region

Does this align with your understanding of the conversation as well or
is there anything I&#x27;m missing?

And Christoph, do these changes for v2 work for your use case as well?

Thanks,
Joanne</pre>
</details>
<div class="review-comment-signals">Signals: acknowledged a fix is needed, proposed changes for v2</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-12">2026-02-12</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author clarified a concern about how kernel-managed buffer rings interact with user-space initiated kbuf ring setup, explaining that if the kernel initiates allocation, it&#x27;s semantically similar to IORING_REGISTER_MEM_REGION but with earlier buffer allocation.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">By &quot;control the allocation fully&quot; do you mean for your use case, the
allocation/setup isn&#x27;t triggered by userspace but is initiated by the
kernel (eg user never explicitly registers any kbuf ring, the kernel
just uses the kbuf ring data structure internally and users can read
the buffer contents)? If userspace initiates the setup of the kbuf
ring, going through IORING_REGISTER_MEM_REGION would be semantically
the same, except the buffer allocation by the kernel now happens
before the ring is created and then later populated into the ring.
userspace would still need to make an mmap call to the region and the
kernel could enforce that as read-only. But if userspace doesn&#x27;t
initiate the setup, then going through IORING_REGISTER_MEM_REGION gets
uglier.</pre>
</details>
<div class="review-comment-signals">Signals: clarifying a concern, no clear resolution</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-12">2026-02-12</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author acknowledged a potential over-engineering in the current design, suggesting an alternative approach where a straightforward kmbuf ring goes through the pbuf interface and future interfaces for pbuf rings can be added to go through IORING_REGISTERED_MEM_REGIONS.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">So i guess the flow would have to be:
a) user calls io_uring_register_region(&amp;ring, &amp;mem_region_reg) with
mem_region_reg.region_uptr&#x27;s size field set to the total buffer size
(and mem_region_reg.flags read-only bit set if needed)
     kernel allocates region
b) user calls mmap() to get the address of the region. If read-only
bit was set, it gets a read-only address
c) user calls io_uring_register_buf_ring(&amp;ring, &amp;buf_reg, flags) with
buf_reg.flags |= IOU_PBUF_RING_KERNEL_MANAGED
     kernel creates an empty kernel-managed ring. None of the buffers
are populated
d) user tells X subsystem to populate the ring starting from offset Z
in the registered mem region
e) on the kernel side, the subsystem populates the ring starting from
offset Z, filling it up using the buf_size and ring_entries values
that the user registered the ring with in c)

To be completely honest, the more I look at this the more this feels
like overkill / over-engineered to me. I get that now the user can do
the PMD optimization, but does that actually lead to noticeable
performance benefits? It seems especially confusing with them going
through the same pbuf ring interface but having totally different
expectations.

What about adding a straightforward kmbuf ring that goes through the
pbuf interface (eg the design in this patchset) and then in the future
adding an interface for pbuf rings (both kernel-managed and
non-kernel-managed) to go through IORING_REGISTERED_MEM_REGIONS if
users end up needing/wanting to have their rings populated that way?

Thanks,
Joanne</pre>
</details>
<div class="review-comment-signals">Signals: overkill, over-engineered</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Christoph Hellwig</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-12">2026-02-12</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer noted that if an application is concerned about TLB pressure, it can simply round up the buffer size to a multiple of PTE levels, making the proposed optimization unnecessary.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Sure.  But if the application cares that much about TLB pressure
I&#x27;d just round up to nice multtiple of PTE levels.</pre>
</details>
<div class="review-comment-signals">Signals: requested change, suggestion</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Christoph Hellwig</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-12">2026-02-12</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Christoph Hellwig questioned the meaning of &#x27;pbuf&#x27; in the patch description, expressing confusion about how it relates to io_uring_register_buffers*, which always takes user-provided buffers.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Can you clarify what you mean with &#x27;pbuf&#x27;?  The only fixed buffer API I
know is io_uring_register_buffers* which always takes user provided
buffers, so I have a hard time parsing what you&#x27;re saying there.  But
that might just be sign that I&#x27;m no expert in io_uring APIs, and that
web searches have degraded to the point of not being very useful
anymore.</pre>
</details>
<div class="review-comment-signals">Signals: confusion, lack of clarity</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Christoph Hellwig</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-12">2026-02-12</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">reviewer expressed confusion over the purpose of IORING_REGISTER_MEM_REGION, as it appears to be related to cqs (completion queues) but its name and documentation do not clearly convey this</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">IORING_REGISTER_MEM_REGION seems to be all about cqs from both your
commit message and the public documentation.  I&#x27;m confused.</pre>
</details>
<div class="review-comment-signals">Signals: confusion, lack of clarity</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Christoph Hellwig</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-12">2026-02-12</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">reviewer noted that the patch does not address their specific use case of block and file system I/O</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">My use case is not about fuse, but good old block and file system
I/O.</pre>
</details>
<div class="review-comment-signals">Signals: no clear signal</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="badge" style="color:#155724;background:#d4edda">Positive</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author addressed Pavel Begunkov&#x27;s concern about the efficiency of buffer allocation by explaining that a circular buffer will allow for shared buffers across entries, reducing memory waste and allocation needs.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">I think the circular buffer will be useful for Christoph&#x27;s use case in
the same way it&#x27;ll be useful for fuse&#x27;s. The read payload could be
differently sized across requests, so it&#x27;s a lot of wasted space to
have to allocate a buffer large enough to support the max-size request
per entry in the io_ring. With using a circular buffer, buffers have a
way to be shared across entries, which means we can significantly
reduce how much memory needs to be allocated.

Thanks,
Joanne</pre>
</details>
<div class="review-comment-signals">Signals: acknowledged, explained</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="badge" style="color:#155724;background:#d4edda">Positive</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The author addressed Pavel&#x27;s concern about fuse needing kernel-managed buffer rings to control when buffers get recycled back into the ring, explaining that this is necessary for passing data between the kernel and the server in fuse&#x27;s use case.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">The most important part and the whole reason fuse needs the buffer
ring to be kernel-managed is because the kernel needs to control when
buffers get recycled back into the ring. For fuse&#x27;s use case, the
buffer is used for passing data between the kernel and the server. We
can&#x27;t have the server recycle the buffer because the server writes
back data to the kernel in that buffer when it submits the sqe. After
fuse receives the sqe and reads the reply from the server, it then
needs to recycle that buffer back into the ring so it can be reused
for a future cqe (eg sending a future request).</pre>
</details>
<div class="review-comment-signals">Signals: acknowledged a specific requirement, explained technical reasoning</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author addressed Pavel&#x27;s concern about the use case of kernel-managed buffer rings, explaining that they are used for other io-uring operations in addition to reading and writing from/to a locally-backed file.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">On the userspace/server side, it uses the buffers for other io-uring
operations (eg reading or writing the contents from/to a
locally-backed file).</pre>
</details>
<div class="review-comment-signals">Signals: clarification, explanation</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The author addressed Pavel&#x27;s concern about adding non-trivial complexity by using a registered memory region, explaining that it allows optimizations but may not be beneficial for most kmbuf use cases. The author feels that offering both simple and advanced kernel-managed pbufs is the best approach.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">My main motivation for this is simplicity. I see (and thanks for
explaining) that using a registered mem region allows the use of some
optimizations (the only one I know of right now is the PMD one you
mentioned but maybe there&#x27;s more I&#x27;m missing) that could be useful for
some workloads, but I don&#x27;t think (and this could just be my lack of
understanding of what more optimizations there are) most use cases of
kmbufs benefit from those optimizations, so to me it feels like we&#x27;re
adding non-trivial complexity for no noticeable benefit.

I feel like we get the best of both worlds by letting users have both:
the simple kernel-managed pbuf where the kernel allocates the buffers
and the buffers are tied to the lifecycle of the ring, and the more
advanced kernel-managed pbuf where buffers are tied to a registered
memory region that the subsystem is responsible for later populating
the ring with.</pre>
</details>
<div class="review-comment-signals">Signals: lack of understanding, non-trivial complexity</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author addressed a concern about the user interface and behavior of kernel-managed buffer rings (kmbufs) versus process buffer rings (pbufs), agreeing that separating them into different types of ring buffers is cleaner, but also willing to revisit this decision in v2.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">imo it felt cleaner to have a new uapi for it because kmbufs and pbufs
have different expectations and behaviors (eg pbufs only work with
user-provided buffers and requires userspace to populate the ring
before using it, whereas for kmbufs the kernel allocates the buffers
and populates it for you; pbufs require userspace to recycle back the
buffer, whereas for kmbufs the kernel is the one in control of
recycling) and from the user pov it seemed confusing to have kmbufs as
part of the pbuf ring uapi, instead of separating it out as a
different type of ringbuffer with a different expectation and
behavior. I was trying to make the point that combining the interface
if we go with IORING_MEM_REGION gets even more confusing because now
pbufs that are kernel-managed are also empty at initialization and
only can point to areas inside a registered mem region and the
responsibility of populating it is now on whatever subsystem is using
it.

I still have this opinion but I also think in general, you likely know
better than I do what kind of io-uring uapi is best for io-uring&#x27;s
users. For v2 I&#x27;ll have kmbufs go through the pbuf uapi.</pre>
</details>
<div class="review-comment-signals">Signals: acknowledged a valid concern, willingness to reconsider</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author Joanne Koong is addressing a concern about the purpose and usage of ring entries without associated buffers, explaining that it can be easily fixed by passing in the number of buffers from the uapi for kernel-managed pbuf rings.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">I&#x27;m not really seeing what the purpose of having a ring entry with no
buffer associated with it is. In the existing code for non-kernel
managed pbuf rings, there&#x27;s the same tie between reg-&gt;ring_entries
being used as the marker for how many buffers the ring supports. But
if the number of buffers should be different than the number of ring
entries, this can be easily fixed by passing in the number of buffers
from the uapi for kernel-managed pbuf rings.</pre>
</details>
<div class="review-comment-signals">Signals: clarification, explanation</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author acknowledged that kernel-managed buffer rings require upfront allocation of memory for the lifetime of the ring, and explained that this may be challenging to determine in certain scenarios.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">To play devil&#x27;s advocate, we also can&#x27;t easily add more memory to the
mem region once it&#x27;s been registered. I think there&#x27;s also a worse
penalty where the user needs to know upfront how much memory to
allocate for the mem region for the lifetime of the ring, which imo
may be hard to do (eg if a kernel-managed buf ring only needs to be
registered for some code paths and not others, the mem region
registration would still have to allocate the memory a potential kbuf
ring would use).</pre>
</details>
<div class="review-comment-signals">Signals: acknowledged a challenge, explained reasoning</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author addressed Pavel Begunkov&#x27;s concern that the buffer memory and ring object have different lifetimes by explaining that the buffers are freed when the ring is freed.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">I&#x27;m a bit confused by this part. The buffer memory does have the same
lifetime as the ring object, no? The buffers only get freed when the
ring itself is freed.</pre>
</details>
<div class="review-comment-signals">Signals: clarification, explanation</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author is addressing Pavel Begunkov&#x27;s feedback on whether kernel-managed buffer rings should support both a simple interface and a more complex one that goes through registered memory regions, and she is open to making the change if necessary.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">I appreciate you looking at this and giving your feedback and insight.
Thank you for doing so. I don&#x27;t want to merge in something you&#x27;re
unhappy with.

Are you open to having support for both a simple kernel-managed pbuf
interface and later on if/when the need arises, a kernel-managed pbuf
interface that goes through a registered memory region? If the answer
is no, then I&#x27;ll make the change to have kmbufs go through the
registered memory region.

Thanks,
Joanne</pre>
</details>
<div class="review-comment-signals">Signals: openness to revision, acknowledgment of reviewer&#x27;s concerns</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-18">2026-02-18</a>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author acknowledged that a fix is needed and promised to modify v2 in response to reviewer feedback.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Sorry, I submitted v2 last night thinking the conversation on this
thread had died. After reading through your reply, I&#x27;ll modify v2.</pre>
</details>
<div class="review-comment-signals">Signals: acknowledged need for modification, promised to revise</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-18">2026-02-18</a>
<span class="badge" style="color:#155724;background:#d4edda">Positive</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author acknowledged that kernel-managed buffer rings are intended for use with other io-uring requests, confirming their purpose aligns with reviewer&#x27;s expectations.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Yes the buffer rings are intended to be used with other io-uring
requests. The ideal scenario is that the user can then do the
equivalent of IORING_OP_READ/WRITE_FIXED operations on the
kernel-managed buffers and avoid the per-i/o page pinning overhead
costs.</pre>
</details>
<div class="review-comment-signals">Signals: aligned_with_expectations</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-18">2026-02-18</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author Joanne Koong addressed Pavel Begunkov&#x27;s concern about the design of kernel-managed buffer rings, agreeing that having buffers owned by the ring and tied to its lifetime is more generically useful. She proposed a new design where the user creates a memory region for the io-uring, maps it, and passes an offset into the region to the subsystem, which then creates a locally managed buffer ring and adds buffers from the mem region. This design matches her original intention but requires further clarification on whether userspace can unregister the memory region while it&#x27;s being used.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">I agree 100%. The api we add should be what&#x27;s best for io-uring, not fuse.

For the majority of use cases, it seemed to me that having the buffers
separated from the buffer rings didn&#x27;t yield perceptible benefits but
added complexity and more restrictions like having to statically know
up front how big the mem region needs to be across the lifetime of the
io-uring for anything the io-uring might use the mem region for. It
seems more generically useful as a concept to have the buffers owned
by the ring and tied to the lifetime of the ring. I like how with this
design everything is self-contained and multiple subsystems can use it
without having to reimplement functionality locally in the subsystem.
On the other hand, I see your point about how it might be something
users want in the future if they want complete control over which
parts of the mem region get used as the backing buffers to do stuff
like PMD optimizations.

I think this is a matter of opinion/preference and I think in general
for anything io-uring related, yours should take precedence.

With it going through a mem region, I don&#x27;t think it should even go
through the &quot;pbuf ring&quot; interface then if it&#x27;s not going to specify
the number of entries and buffer sizes upfront, if support is added
for io-uring normal requests (eg IORING_OP_READ/WRITE) to use the
backing pages from a memory region and if we&#x27;re able to guarantee that
the registered memory region will never be able to be unregistered by
the user. I think if we repurpose the

union {
  __u64 addr; /* pointer to buffer or iovecs */
  __u64 splice_off_in;
};

fields in the struct io_uring_sqe to

union {
  __u64 addr; /* pointer to buffer or iovecs */
  __u64 splice_off_in;
  __u64 offset; /* offset into registered mem region */
};

and add some IOSQE_ flag to indicate it should find the pages from the
registered mem region, then that should work for normal requests.
Where on the kernel side, it looks up the associated pages stored in
the io_mapped_region&#x27;s pages array for the offset passed in.

Right now there&#x27;s only a uapi to register a memory region and none to
unregister one. Is it guaranteed that io-uring will never add
something in the future that will let userspace unregister the memory
region or at least unregister it while it&#x27;s being used (eg if we add
future refcounting to it to track active uses of it)?

If so, then end-to-end, with it going through the mem region, it would
be something like:
* user creates a mem region for the io-uring
* user mmaps the mem region
* user passes in offset into region, length of each buffer, and number
of entries in the ring to the subsystem
* subsystem creates a locally managed bufring and adds buffers to that
ring from the mem region
* on the cqe side, it sends the buffer id of the registered mem region
through the same &quot;IORING_CQE_F_BUFFER |  (buf_id &lt;&lt;
IORING_CQE_BUFFER_SHIFT)&quot; mechanism

Does this design match what you had in mind / prefer?

I think the above works for Christoph&#x27;s use case too (as his and my
use case are the same) but if not, please let me know.

Thanks,
Joanne</pre>
</details>
<div class="review-comment-signals">Signals: clarification, further_revision_needed</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-20">2026-02-20</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The author is addressing Pavel Begunkov&#x27;s question about whether kernel-managed buffer rings are fuse-specific, and responds that while they may be useful for fuse servers with certain characteristics, the concept is not exclusive to fuse and could benefit other subsystems/users.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Thanks for clarifying your question. Yes, this would be a useful
optimization in the future for fuse servers with certain workload
characteristics (eg network-backed servers with high concurrency and
unpredictable latencies). I don&#x27;t think the concept of kmbufrings is
exclusively fuse-specific though (for example, Christoph&#x27;s use case
being a recent instance); I think other subsystems/users that&#x27;ll use
kmbuf rings would also generically find it useful to have the option
of READ_OP_RECV/READ_OP_READ operating directly on the ring.</pre>
</details>
<div class="review-comment-signals">Signals: acknowledged a use case, explained reasoning</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-20">2026-02-20</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The author is addressing concerns about the added complexity and convoluted interface introduced by tying kernel-managed buffer rings to existing concepts, specifically buffer IDs. They express confusion about the benefits of this design and suggest that memory regions should be decoupled from other structures, implying that native support for using memory regions in io-uring requests would simplify things.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">I feel like this design makes the interface more convoluted and now
muddies different concepts together by adding new complexity /
relationships between them whereas they were otherwise cleanly
isolated. Maybe I&#x27;m just not seeing/understanding the overarching
vision for why conceptually it makes sense for them to be tied
together besides as a mechanism to tell io-uring requests where to
copy from by reusing what exists for fixed buffer ids. There&#x27;s more
complexity now on the kernel side (eg having to detect if the buffer
passed in is kernel-allocated to know whether to pin the pages /
charge it against the user&#x27;s RLIMIT_MEMLOCK limit) but I&#x27;m not
understanding what we gain from it. I got the sense from your previous
comments that memory regions are the de facto way to go and should be
decoupled from other structures, so if that&#x27;s the case, why doesn&#x27;t it
make sense for io-uring to add native support for using memory regions
for io-uring requests? I feel like from the userspace side it makes
things more confusing with this extra layer of indirection that now
has to go through a fixed buffer.</pre>
</details>
<div class="review-comment-signals">Signals: confusion, suggestion</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-20">2026-02-20</a>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author addressed Pavel Begunkov&#x27;s concern that the kernel cannot guarantee the caller will register the memory region as a fixed buffer, explaining that this would introduce extra overhead for every I/O operation and proposing two possible solutions: adding pinning to registered memory regions or implementing additional locking mechanisms.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">I don&#x27;t think we can guarantee that the caller will register the
memory region as a fixed buffer (eg if it doesn&#x27;t need/want to use the
buffer for normal io-uring requests). On the kernel side, the internal
buffer entry uses the kaddr of the registered memory region buffer for
any memcpys. If it&#x27;s not guaranteed that registered memory regions
persist for the lifetime of the ring, there&#x27;ll have to be extra
overhead for every I/O (eg grab the io-uring lock, checking if the mem
region is still registered, grab a refcount to that mem region, unlock
the ring, do the memcpy to the kaddr, then grab the io-uring lock
again, decrement the refcount, and unlock). Or I guess we could add
pinning to a registered memory region.

Thanks,
Joanne</pre>
</details>
<div class="review-comment-signals">Signals: acknowledged a problem, proposed potential fixes</div>
</div>
</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-10">2026-02-10</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The reviewer suggested refactoring io_uring/kbuf: IORING_REGISTER_KMBUF_RING should not allocate buffers, instead it should register a memory region and use that for buffer allocation. They also proposed creating a new flag or internal API to handle this.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Please use io_create_region(), the new function does nothing new
and only violates abstractions.

Provided buffer rings with kernel addresses could be an interesting
abstraction, but why is it also responsible for allocating buffers?
What I&#x27;d do:

1. Strip buffer allocation from IORING_REGISTER_KMBUF_RING.
2. Replace *_REGISTER_KMBUF_RING with *_REGISTER_PBUF_RING + a new flag.
    Or maybe don&#x27;t expose it to the user at all and create it from
    fuse via internal API.
3. Require the user to register a memory region of appropriate size,
    see IORING_REGISTER_MEM_REGION, ctx-&gt;param_region. Make fuse
    populating the buffer ring using the memory region.

I wanted to make regions shareable anyway (need it for other purposes),
I can toss patches for that tomorrow.

A separate question is whether extending buffer rings is the right
approach as it seems like you&#x27;re only using it for fuse requests and
not for passing buffers to normal requests, but I don&#x27;t see the
big picture here.</pre>
</details>
<div class="review-comment-signals">Signals: requested changes</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-10">2026-02-10</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Pavel Begunkov noted that the removal of io_create_region_multi_buf() eliminates the need for aligning every buffer, which could result in wasted memory due to 64KB page sizes.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">With io_create_region_multi_buf() gone, you shouldn&#x27;t need
to align every buffer, that could be a lot of wasted memory
(thinking about 64KB pages).</pre>
</details>
<div class="review-comment-signals">Signals: requested optimization, memory efficiency concern</div>
</div>
</div>
<div class="thread-node depth-1" id="2026-02-11">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-11">2026-02-11</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer noted that allocating 1MB in kernel space won&#x27;t result in a PMD mappable huge page, unlike user space allocation which can register 2MB and reuse the rest for other purposes.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Yes, there is handful of differences. To name one, 1MB allocation won&#x27;t
get you a PMD mappable huge page, while user space can allocate 2MB,
register the first 1MB and reuse the rest for other purposes.</pre>
</details>
<div class="review-comment-signals">Signals: requested change, technical concern</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-11">2026-02-11</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Pavel Begunkov suggested that instead of modifying io_create_region() to be less strict, the caller should filter arguments to ensure only necessary types are passed, specifically advising against passing IORING_MEM_REGION_TYPE_USER if it&#x27;s not used.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">If io_create_region() is too strict, let&#x27;s discuss that in
examples if there are any, but it&#x27;s likely not a good idea changing
that. If it&#x27;s too lax, filter arguments in the caller. IOW, don&#x27;t
pass IORING_MEM_REGION_TYPE_USER if it&#x27;s not used.</pre>
</details>
<div class="review-comment-signals">Signals: requested changes</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-11">2026-02-11</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Pavel Begunkov noted that the memmap.c changes in the patch can be dropped because they are essentially replicating the functionality of io_create_region(), and suggested removing them to avoid potential issues such as disabling io_mem_alloc_compound()</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">I saw that and saying that all memmap.c changes can get dropped.
You&#x27;re using it as one big virtually contig kernel memory range then
chunked into buffers, and that&#x27;s pretty much what you&#x27;re getting with
normal io_create_region(). I get that you only need it to be
contiguous within a single buffer, but that&#x27;s not what you&#x27;re doing,
and it&#x27;ll be only worse than default io_create_region() e.g.
effectively disabling any usefulness of io_mem_alloc_compound(),
and ultimately you don&#x27;t need to care.

Regions shouldn&#x27;t know anything about your buffers, how it&#x27;s
subdivided after, etc.</pre>
</details>
<div class="review-comment-signals">Signals: requested changes, potential issues</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-11">2026-02-11</a>
<span class="inline-review-badge">Inline Review</span>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Pavel Begunkov suggested adding a check for user-provided memory to the io_create_region() call, providing an example of how this could be done by setting rd.user_addr and rd.flags</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">struct io_uring_region_desc rd = {};
total_size = nr_bufs * buf_size;
rd.size = PAGE_ALIGN(total_size);
io_create_region(&amp;region, &amp;rd);

Add something like this for user provided memory:

if (use_user_memory) {
	rd.user_addr = uaddr;
	rd.flags |= IORING_MEM_REGION_TYPE_USER;
}</pre>
</details>
<div class="review-comment-signals">Signals: requested changes</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-11">2026-02-11</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The reviewer suggests separating ring creation from population on the kernel API level, allowing other users like fuse to create rings and populate them independently.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">I don&#x27;t think I follow. I&#x27;m saying that it might be interesting
to separate rings from how and with what they&#x27;re populated on the
kernel API level, but the fuse kernel module can do the population
and get exactly same layout as you currently have:

int fuse_create_ring(size_t region_offset /* user space argument */) {
	struct io_mapped_region *mr = get_mem_region(ctx);
	// that can take full control of the ring
	ring = grab_empty_ring(io_uring_ctx);

	size = nr_bufs * buf_size;
	if (region_offset + size &gt; get_size(mr)) // + other validation
		return error;

	buf = mr_get_ptr(mr) + offset;
	for (i = 0; i &lt; nr_bufs; i++) {
		ring_push_buffer(ring, buf, buf_size);
		buf += buf_size;
	}
}

fuse might not care, but with empty rings other users will get a
channel they can use to do IO (e.g. read requests) using their
kernel addresses in the future.</pre>
</details>
<div class="review-comment-signals">Signals: requested changes, suggested improvement</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-11">2026-02-11</a>
<span class="inline-review-badge">Inline Review</span>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Pavel Begunkov suggested that instead of introducing new UAPI and internal changes for kernel-managed buffer rings, the existing pbuf implementation could be used with a flag to differentiate between them. This would simplify the code and reduce duplication.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">It&#x27;d change uapi but not internals, you already piggy back it
on pbuf implementation and differentiate with a flag.

It could basically be:

if (flags &amp; IOU_PBUF_RING_KM)
	bl-&gt;flags |= IOBL_KERNEL_MANAGED;

Pinning can be gated on that flag as well. Pretty likely uapi
and internals will be a bit cleaner, but that&#x27;s not a huge deal,
just don&#x27;t see why would you roll out a separate set of uapi
([un]register, offsets, etc.) when essentially it can be treated
as the same thing.</pre>
</details>
<div class="review-comment-signals">Signals: suggested alternative approach, flag-based differentiation</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-11">2026-02-11</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The reviewer noted that the original patch was pinning the registered buffer table without providing buffer rings, which is a bad idea; instead, the patch could have used a single larger registered buffer and pinned only it, leveraging its existing refcounting mechanism.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">IIRC, you was pinning the registered buffer table and not provided
buffer rings? Which would indeed be a bad idea. Thinking about it,
fwiw, instead of creating multiple registered buffers and trying to
lock the entire table, you could&#x27;ve kept all memory in one larger
registered buffer and pinned only it. It&#x27;s already refcounted, so
shouldn&#x27;t have been much of a problem.</pre>
</details>
<div class="review-comment-signals">Signals: requested changes, alternative solution</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-11">2026-02-11</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Pavel Begunkov expressed concerns that creating many small regions for kernel-managed buffer rings would lead to unnecessary mmap()s, extra user space management, and wasted space, and also questioned the ring bound memory approach due to potential issues with buffer lifetimes.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">To explain why, I don&#x27;t think that creating many small regions
is a good direction going forward. In case of kernel allocation,
it&#x27;s extra mmap()s, extra user space management, and wasted space.
For user provided memory it&#x27;s over-accounting and extra memory
footprint. It&#x27;ll also give you better lifecycle guarantees, i.e.
you won&#x27;t be able to free buffers while there are requests for the
context. I&#x27;m not so sure about ring bound memory, let&#x27;s say I have
my suspicions, and you&#x27;d need to be extra careful about buffer
lifetimes even after a fuse instance dies.</pre>
</details>
<div class="review-comment-signals">Signals: requested changes, expressed concerns</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-11">2026-02-11</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Pavel Begunkov noted that kernel-managed buffer rings would be particularly useful for operations like read and recv, where the kernel can fill provided buffers without requiring changes to opcode-specific code in kbuf.c.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Any kind of read/recv/etc. that can use provided buffers. It&#x27;s
where kernel memory filled rings would shine, as you&#x27;d be able
to use them together without changing any opcode specific code.
I.e. not changes in read request implementation, only kbuf.c

-- 
Pavel Begunkov</pre>
</details>
<div class="review-comment-signals">Signals: no specific request or objection</div>
</div>
</div>
<div class="thread-node depth-1" id="2026-02-12">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Christoph Hellwig</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-12">2026-02-12</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Christoph Hellwig expressed a need for kernel-controlled buffer allocation, guaranteeing user processes can only read the memory and not write to it, and requested to piggyback on the existing work.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">I&#x27;m arguing exactly against this.  For my use case I need a setup
where the kernel controls the allocation fully and guarantees user
processes can only read the memory but never write to it.  I&#x27;d love
to be able to piggy back than onto your work.</pre>
</details>
<div class="review-comment-signals">Signals: requested changes</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Christoph Hellwig</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-12">2026-02-12</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Christoph Hellwig noted that io_uring_register_buffers() currently only pins memory, allowing applications or other processes to modify it, which can cause issues for file systems and storage devices that need to verify checksums or rebuild data from parity. He suggested implementing a version of io_uring_register_buffers where the kernel provides buffers and maps them into the application&#x27;s address space read-only.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">The idea is that the application tells the kernel that it wants to use
a fixed buffer pool for reads.  Right now the application does this
using io_uring_register_buffers().  The problem with that is that
io_uring_register_buffers ends up just doing a pin of the memory,
but the application or, in case of shared memory, someone else could
still modify the memory.  If the underlying file system or storage
device needs verify checksums, or worse rebuild data from parity
(or uncompress), it needs to ensure that the memory it is operating
on can&#x27;t be modified by someone else.

So I&#x27;ve been thinking of a version of io_uring_register_buffers where
the buffers are not provided by the application, but instead by the
kernel and mapped into the application address space read-only for
a while, and I thought I could implement this on top of your series,
but I have to admit I haven&#x27;t really looked into the details all
that much.</pre>
</details>
<div class="review-comment-signals">Signals: requested changes</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Christoph Hellwig</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-12">2026-02-12</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">reviewer noted that the PMD mapping is less relevant than previously thought, and mentioned that both AMD and ARM architectures have optimizations for contiguous PTEs</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Yes.  The PMD mapping also is not that relevant.  Both AMD (implicit)
and ARM (explicit) have optimizations for contiguous PTEs that are
almost as valuable.</pre>
</details>
<div class="review-comment-signals">Signals: neutral comment, technical discussion</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="inline-review-badge">Inline Review</span>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Pavel Begunkov noted that the patch introduces a potential issue where the kernel-managed buffer ring&#x27;s metadata is not properly handled, and suggested working around it by wrapping the affected code in a loop.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Let&#x27;s fix that then. For now, just work it around by wrapping
into a loop.

Btw, I thought you&#x27;re going to use it for metadata like some
fuse headers and payloads would be zero copied by installing
it as registered buffers.

...</pre>
</details>
<div class="review-comment-signals">Signals: potential issue, requested changes</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Pavel Begunkov suggested moving ring population into fuse, disentangling memory allocation from ring creation in the io_uring uapi, and using IORING_REGISTER_MEM_REGION to achieve this without extra uapi</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">The main point is disentangling memory allocation from ring
creation in the io_uring uapi, and moving ring population
into fuse instead of doing it at creation. And it&#x27;ll still be
populated by the kernel (fuse), user space doesn&#x27;t have access
to the ring. IORING_REGISTER_MEM_REGION is just the easiest way
to achieve that without any extra uapi.

...</pre>
</details>
<div class="review-comment-signals">Signals: requested changes</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Pavel Begunkov noted that the differences between io_uring and kbuf are mainly due to special region path and embedded buffer allocations, but is open to making a separate opcode if the submitter prefers.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">It appeared to me that they&#x27;re different because of special
region path and embedded buffer allocations, and otherwise
differences would be minimal. But if you think it&#x27;s still
better to be made as a separate opcode, I&#x27;m not opposing it,
go for it.</pre>
</details>
<div class="review-comment-signals">Signals: open-minded, non-confrontational</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="inline-review-badge">Inline Review</span>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The reviewer noted that the current implementation does not provide a clear control path for looking up buffer rings from io_uring, and suggested adding a new command to handle this case. They also proposed passing necessary parameters through this command, including region ID and buffer ring ID.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Not having patches using the functionality is inconvenient. How
fuse looks up the buffer ring from io_uring? I could imagine you
have some control path io-uring command:

case FUSE_CMD_BIND_BUFFER_RING:
	return bind_queue(params);

Then you can pass all necessary parameters to it, pseudo code:

struct fuse_bind_kmbuf_ring_params {
	region_id;
	buf_ring_id;
	...
};

bind_queue(cmd, struct fuse_bind_kmbuf_ring_params *p)
{
	region = io_uring_get_region(cmd, p-&gt;region_id);
	// get exclusive access:
	buf_ring = io_uring_get_buf_ring(cmd, p-&gt;buf_ring_id);

	if (!validate_buf_ring(buf_ring))
		return NOTSUPPORTED;

	io_uring_pin(buf_ring);
	fuse_populate_buf_ring(buf_ring, region, ...);
}

Does that match expectations? I don&#x27;t think you even need
the ring part exposed as an io_uring uapi, tbh, as it
stays completely in fuse and doesn&#x27;t meaningfully interact
with the rest of io_uring.

...</pre>
</details>
<div class="review-comment-signals">Signals: requested changes, suggested improvements</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Pavel Begunkov pointed out that the patch could use IORING_REGISTER_MEM_REGION instead of a separate registration for buffer regions, and noted that this is a separate issue from binding buffers to the ring.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">That was about an argument for using IORING_REGISTER_MEM_REGION
instead a separate region. And it&#x27;s separate from whether
buffers should be bound to the ring.</pre>
</details>
<div class="review-comment-signals">Signals: requested changes</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Pavel Begunkov noted that when allocating huge pages for non-pow2 buffer sizes, the kernel may allocate a larger huge page than needed, potentially wasting memory.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">I shouldn&#x27;t affect you much since you have such large buffers,
but imagine the total allocation size is not being pow2, and
the kernel allocating it as a single folio. E.g. 3 buffers,
0.5 MB each, total = 1.5MB, and the kernel allocates a 2MB
huge page.

-- 
Pavel Begunkov</pre>
</details>
<div class="review-comment-signals">Signals: potential memory waste</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Pavel Begunkov noted that the io_uring uapi should not be tied to fuse-specific requirements, such as uniform buffer sizes, ring size matching number of buffers, and kernel-allocated buffers. He questioned why these constraints are necessary and suggested considering alternative use cases where memory is allocated elsewhere.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">No, it&#x27;s mainly about not keeping payload buffers and rings in the same
object from the io_uring uapi perspective.

1. If it&#x27;s an io_uring uapi, it shouldn&#x27;t be fuse specific or with
a bunch of use case specific expectations attached. Why does it
require all buffers to be uniform in size? Why does it require
the ring size to match the number of buffers? Why does it require
buffers to be allocated by io_uring in the first place? Maybe some
subsystem got memory from somewhere else and wants to do use it
with io_uring. Why does it need to know the total size at creation,
and what would you do if you want to add more memory at runtime
while using the same ring?

2. If it&#x27;s meant to be fuse specific and _not_ used with other requests
like recv/read/etc., then what&#x27;s the point of having it as an io_uring
uapi? Which also adds additional trouble like the once you&#x27;re solving
with pinning.

If it&#x27;s supposed to be used with other requests, then buffers and
rings will have different in-kernel lifetime expectations imposed
by io_uring, so having them together won&#x27;t even help with
management.

I have a strong opinion about the memmap.c change. For the
rest, if you believe it&#x27;s fine, just send it out and let Jens
decide.</pre>
</details>
<div class="review-comment-signals">Signals: requested changes, strong opinion</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Pavel Begunkov expressed confusion about the distinction between kernel-managed buffer rings and user-visible buffer rings, questioning what expectations are different apart from one being in-kernel with kernel addresses and the other user visible with user addresses.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">It&#x27;s predicated on separating buffers from rings, see above,
and assuming that I&#x27;m not sure what expectations are different
apart from one being in-kernel with kernel addresses and the
other user visible with user addresses.

-- 
Pavel Begunkov</pre>
</details>
<div class="review-comment-signals">Signals: confusion, questioning</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Bernd Schubert</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Bernd Schubert expressed skepticism about the kernel-managed buffer rings feature, questioning its purpose and suggesting that sharing buffers across entries would only reduce ring size without providing any benefits.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Dunno, what we actually want is requests of multiple sizes. Sharing
buffers across entries sounds like just reducing the ring size - I
personally don&#x27;t see the point here.


Thanks,
Bernd</pre>
</details>
<div class="review-comment-signals">Signals: requested changes, suggested alternative approach</div>
</div>
<div class="thread-children">
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author clarified that kernel-managed buffer rings allow concurrent access to different regions of a shared buffer across multiple io_uring entries, addressing concerns about buffer sharing.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">By &quot;sharing buffers across entries&quot; what I mean is different regions
of the buffer can now be used concurrently by multiple entries.

Thanks,
Joanne</pre>
</details>
<div class="review-comment-signals">Signals: clarification, no clear resolution</div>
</div>
</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-18">2026-02-18</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">reviewer asked whether kernel-managed buffer rings can be used with other requests, specifically IORING_OP_RECV with IOSQE_BUFFER_SELECT</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Oops, typo. I was asking whether the buffer rings (not buffers) are
supposed to be used with other requests. E.g. submitting a
IORING_OP_RECV with IOSQE_BUFFER_SELECT set and the bgid specifying
your kernel-managed buffer ring.</pre>
</details>
<div class="review-comment-signals">Signals: clarification_request</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-18">2026-02-18</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The reviewer has two main concerns: first, that buffers should not be inseparable from buffer rings in the io_uring user API; second, that there should be an option to allow user memory for buffer creation.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">There are two separate arguments. The first is about not making buffers
inseparable from buffer rings in the io_uring user API. Whether it&#x27;s
IORING_REGISTER_MEM_REGION or something else is not that important.
I have no objection if it&#x27;s a part of fuse instead though, e.g. if
fuse binds two objects together when you register it with fuse, or even
if fuse create a buffer ring internally (assuming it doesn&#x27;t indirectly
leak into io_uring uapi).

And the second was about optionally allowing user memory for buffer
creation as you&#x27;re reusing the region abstraction. You can find pros
and cons for both modes, and funnily enough, SQ/CQ were first kernel
allocated and then people asked for backing it by user memory, and IIRC
it was in the reverse order for pbuf rings.

Implementing this is trivial as well, you just need to pass an argument
while creating a region. All new region users use struct
io_uring_region_desc for uapi and forward it to io_create_region()
without caring if it&#x27;s user or kernel allocated memory.</pre>
</details>
<div class="review-comment-signals">Signals: no objection, trivial implementation</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-18">2026-02-18</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Pavel Begunkov questioned the necessity of tying kernel-managed buffer rings to io_uring, suggesting it might be simpler to implement in fuse or as an implementation detail within io_uring</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">The stress is on why it&#x27;s an _io_uring_ API. It doesn&#x27;t matter to me
whether it&#x27;s a separate opcode or not. Currently, buffer rings don&#x27;t give
you anything that can&#x27;t be pure fuse, and it might be simpler to have
it implemented in fuse than binding to some io_uring object. Or it could
create buffer rings internally to reuse code but it doesn&#x27;t become an
io_uring uapi but rather implementation detail. And that predicates on
whether km rings are intended to be used with other / non-fuse requests.</pre>
</details>
<div class="review-comment-signals">Signals: requested changes, alternative approach</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-18">2026-02-18</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Pavel Begunkov expressed concerns that the kernel-managed buffer ring feature is not reusable for all io_uring users and suggested a middle ground where km rings can be registered together with memory, but without a notion of a buffer.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">I believe the source of disagreement is that you&#x27;re thinking
about how it&#x27;s going to look like for fuse specifically, and I
believe you that it&#x27;ll be nicer for the fuse use case. However,
on the other hand it&#x27;s an io_uring uapi, and if it is an io_uring
uapi, we need reusable blocks that are not specific to particular
users.

If it km rings has to stay an io_uring uapi, I guess a middle
ground would be to allow registering km rings together with memory,
but make it a pure region without a notion of a buffer, and let
fuse to chunk it. Later, we can make payload memory allocation
optional.</pre>
</details>
<div class="review-comment-signals">Signals: requested changes, suggested alternative approach</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-18">2026-02-18</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Pavel Begunkov pointed out that the patch introduces a fuse-specific API, which is masquerading as a generic io_uring API, and noted that various parts of the code make assumptions based on this incorrect assumption.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Right, intentionally so, because otherwise it&#x27;s a fuse uapi that
pretends to be a generic io_uring uapi but it&#x27;s not because of
all assumptions in different places.</pre>
</details>
<div class="review-comment-signals">Signals: assumptions in different places</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-18">2026-02-18</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The reviewer noted that the current implementation of kernel-managed buffer rings only specifies the ring depth but not the allocated memory, which could lead to inconsistencies between the expected and actual memory usage.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Not really, it tells the buffer ring depth but says nothing about
how much memory user space allocated and how it&#x27;s pushed. It&#x27;s a
reasonable default but they could be different. For example, if you
expect adding more memory at runtime, you might create the buffer
ring a bit larger. Or when server processing takes a while and you
can&#x27;t recycle until it finishes, you might have more buffers than
you need ring entries. Or you might might decide to split buffers
and as you mentioned incremental consumption, which is an entire
separate topic because it doesn&#x27;t do de-fragmentation and you&#x27;d
need to have it in fuse, just like user space does with pbufs.</pre>
</details>
<div class="review-comment-signals">Signals: inconsistency, potential issue</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-18">2026-02-18</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Pavel Begunkov suggested that instead of passing the number of buffers to io_uring, the kernel should create a large chunk of memory and let fuse manage it by splitting it into smaller chunks</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">My entire point is that we&#x27;re making lots of assumptions for io_uring
uapi, and if it&#x27;s moved to fuse because it knows better what it
needs, it should be a win.

IOW, it sounds better if instead of passing the number of buffers to
io_uring, you just ask it to create a large chunk of memory, and then
fuse chunks it up and puts into the ring.</pre>
</details>
<div class="review-comment-signals">Signals: requested changes</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-18">2026-02-18</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Pavel Begunkov agreed that additional memory is needed but suggested it does not necessarily have to be added through IORING_REGISTER_MEM_REGION specifically.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">I agree, and you&#x27;d need something new in either case to add more
memory, and it doesn&#x27;t need to be IORING_REGISTER_MEM_REGION
specifically.</pre>
</details>
<div class="review-comment-signals">Signals: agreed, suggested</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-18">2026-02-18</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The reviewer noted that unregistering a kernel-managed buffer ring does not guarantee the absence of in-flight requests using buffers from the ring, and suggested synchronizing with all other io_uring requests to address this issue.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Unregistering a buffer ring doesn&#x27;t guarantee that there are no
inflight requests that are still using buffers that came out of
the buffer ring. The fuse driver can wait/terminate its requests
before unregisteration, but allow userspace issued IORING_OP_RECV
to use this km buffer ring, and you&#x27;ll need to somehow synchronise
with all other io_uring requests.

-- 
Pavel Begunkov</pre>
</details>
<div class="review-comment-signals">Signals: synchronization, inflight requests</div>
</div>
</div>
<div class="thread-node depth-1" id="2026-02-20">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-20">2026-02-20</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Pavel Begunkov questioned whether a server or user space program can issue I/O requests that consume buffers/entries from kernel-managed buffer rings without involving fuse kernel code, and asked for clarification on the expected use case.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">You mention OP_READ_FIXED and below agreed not exposing km rings
an io_uring uapi, which makes me believe we&#x27;re still talking about
different things.

Correct me if I&#x27;m wrong. Currently, only fuse cmds use the buffer
ring itself, I&#x27;m not talking about buffer, i.e. fuse cmds consume
entries from the ring (!!! that&#x27;s the part I&#x27;m interested in), then
process them and tell the server &quot;this offset in the region has user
data to process or should be populated with data&quot;.

Naturally, the server should be able to use the buffers to issue
some I/O and process it in other ways, whether it&#x27;s a normal
OP_READ to which you pass the user space address (you can since
it&#x27;s mmap()&#x27;ed by the server) or something else is important but
a separate question than the one I&#x27;m trying to understand.

So I&#x27;m asking whether you expect that a server or other user space
program should be able to issue a READ_OP_RECV, READ_OP_READ or any
other similar request, which would consume buffers/entries from the
km ring without any fuse kernel code involved? Do you have some
use case for that in mind?

Understanding that is the key in deciding whether km rings should
be exposed as io_uring uapi or not, regardless of where buffers
to populate the ring come from.

...</pre>
</details>
<div class="review-comment-signals">Signals: clarification needed, use case unclear</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-20">2026-02-20</a>
<span class="inline-review-badge">Inline Review</span>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Pavel Begunkov suggested reusing registered buffers instead of introducing a new mechanism for kernel-managed buffer rings, citing efficiency and similarity to zero-copy internally registered buffers as benefits.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">So you already can do all that using the mmap()&#x27;ed region user
pointer, and you just want it to be more efficient, right?
For that let&#x27;s just reuse registered buffers, we don&#x27;t need a
new mechanism that needs to be propagated to all request types.
And registered buffer are already optimised for I/O in a bunch
of ways. And as a bonus, it&#x27;ll be similar to the zero-copy
internally registered buffers if you still plan to add them.

The simplest way to do that is to create a registered buffer out
of the mmap&#x27;ed region pointer. Pseudo code:

// mmap&#x27;ed if it&#x27;s kernel allocated.
{region_ptr, region_size} = create_region();

struct iovec iov;
iov.iov_base = region_ptr;
iov.iov_len = region_size;
io_uring_register_buffers(ring, &amp;iov, 1);

// later instead of this:
ptr = region_ptr + off;
io_uring_prep_read(sqe, fd, ptr, ...);

// you use registered buffers as usual:
io_uring_prep_read_fixed(sqe, fd, off, regbuf_idx, ...);


IIRC the registration would fail because it doesn&#x27;t allow file
backed pages, but it should be fine if we know it&#x27;s io_uring
region memory, so that would need to be patched.

There might be a bunch of other ways you can do that like
create a kernel allocated registered buffer like what Cristoph
wants, and then register it as a region. Or allow creating
registered buffers out of a region. etc.

I wanted to unify registered buffers and regions internally
at some point, but then drifted away from active io_uring core
infrastructure development, so I guess that could&#x27;ve been useful.</pre>
</details>
<div class="review-comment-signals">Signals: requested changes, suggested reuse of existing mechanism</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-20">2026-02-20</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer noted that kernel-managed buffer rings would require handling page references and/or pinning regions, which could be complex and unnecessary if registered buffers are used instead.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Let&#x27;s talk about it when it&#x27;s needed or something changes, but if
you do registered buffers instead as per above, they&#x27;ll be holding
page references and or have to pin the region in some other way.</pre>
</details>
<div class="review-comment-signals">Signals: requested changes</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-20">2026-02-20</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Pavel Begunkov suggested adding a liburing helper to handle mmap&#x27;ing for the fuse server, eliminating its need to directly manage memory mapping.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">FWIW, we should just add a liburing helper, so that fuse server
doesn&#x27;t need to deal with mmap&#x27;ing.</pre>
</details>
<div class="review-comment-signals">Signals: requested changes</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-20">2026-02-20</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer expressed conditional approval, requesting confirmation that the patch allows for all desired fast path optimizations.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">That&#x27;s sounds clean to me _if_ it allows you to achieve all
(fast path) optimisations you want to have. I hope it does?

-- 
Pavel Begunkov</pre>
</details>
<div class="review-comment-signals">Signals: conditional approval, request for confirmation</div>
</div>
</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-09">2026-02-09</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The author addressed a concern about the naming of io_unregister_pbuf_ring() to make it more generic and applicable for both provided buffer rings and kernel-managed buffer rings. The author agreed to rename the function as part of preparatory changes for upcoming kernel-managed buffer ring support.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Use the more generic name io_unregister_buf_ring() as this function will
be used for unregistering both provided buffer rings and kernel-managed
buffer rings.

This is a preparatory change for upcoming kernel-managed buffer ring
support.

Signed-off-by: Joanne Koong &lt;joannelkoong@gmail.com&gt;
---
 io_uring/kbuf.c     | 2 +-
 io_uring/kbuf.h     | 2 +-
 io_uring/register.c | 2 +-
 3 files changed, 3 insertions(+), 3 deletions(-)

diff --git a/io_uring/kbuf.c b/io_uring/kbuf.c
index 850b836f32ee..aa9b70b72db4 100644
--- a/io_uring/kbuf.c
+++ b/io_uring/kbuf.c
@@ -719,7 +719,7 @@ int io_register_pbuf_ring(struct io_ring_ctx *ctx, void __user *arg)
 	return ret;
 }
 
-int io_unregister_pbuf_ring(struct io_ring_ctx *ctx, void __user *arg)
+int io_unregister_buf_ring(struct io_ring_ctx *ctx, void __user *arg)
 {
 	struct io_uring_buf_reg reg;
 	struct io_buffer_list *bl;
diff --git a/io_uring/kbuf.h b/io_uring/kbuf.h
index bf15e26520d3..40b44f4fdb15 100644
--- a/io_uring/kbuf.h
+++ b/io_uring/kbuf.h
@@ -74,7 +74,7 @@ int io_provide_buffers_prep(struct io_kiocb *req, const struct io_uring_sqe *sqe
 int io_manage_buffers_legacy(struct io_kiocb *req, unsigned int issue_flags);
 
 int io_register_pbuf_ring(struct io_ring_ctx *ctx, void __user *arg);
-int io_unregister_pbuf_ring(struct io_ring_ctx *ctx, void __user *arg);
+int io_unregister_buf_ring(struct io_ring_ctx *ctx, void __user *arg);
 int io_register_pbuf_status(struct io_ring_ctx *ctx, void __user *arg);
 
 bool io_kbuf_recycle_legacy(struct io_kiocb *req, unsigned issue_flags);
diff --git a/io_uring/register.c b/io_uring/register.c
index 594b1f2ce875..0882cb34f851 100644
--- a/io_uring/register.c
+++ b/io_uring/register.c
@@ -841,7 +841,7 @@ static int __io_uring_register(struct io_ring_ctx *ctx, unsigned opcode,
 		ret = -EINVAL;
 		if (!arg || nr_args != 1)
 			break;
-		ret = io_unregister_pbuf_ring(ctx, arg);
+		ret = io_unregister_buf_ring(ctx, arg);
 		break;
 	case IORING_REGISTER_SYNC_CANCEL:
 		ret = -EINVAL;
-- 
2.47.3</pre>
</details>
<div class="review-comment-signals">Signals: preparatory change, rename function</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-09">2026-02-09</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The author addressed a concern about the implementation of kernel-managed buffer rings, explaining that they reuse validation and buffer list allocation helpers from earlier refactoring and introducing new registration opcodes for kernel-managed ring buffers.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Add support for kernel-managed buffer rings (kmbuf rings), which allow
the kernel to allocate and manage the backing buffers for a buffer
ring, rather than requiring the application to provide and manage them.

This introduces two new registration opcodes:
- IORING_REGISTER_KMBUF_RING: Register a kernel-managed buffer ring
- IORING_UNREGISTER_KMBUF_RING: Unregister a kernel-managed buffer ring

The existing io_uring_buf_reg structure is extended with a union to
support both application-provided buffer rings (pbuf) and kernel-managed
buffer rings (kmbuf):
- For pbuf rings: ring_addr specifies the user-provided ring address
- For kmbuf rings: buf_size specifies the size of each buffer. buf_size
  must be non-zero and page-aligned.

The implementation follows the same pattern as pbuf ring registration,
reusing the validation and buffer list allocation helpers introduced in
earlier refactoring. The IOBL_KERNEL_MANAGED flag marks buffer lists as
kernel-managed for appropriate handling in the I/O path.

Signed-off-by: Joanne Koong &lt;joannelkoong@gmail.com&gt;
---
 include/uapi/linux/io_uring.h |  15 ++++-
 io_uring/kbuf.c               |  81 ++++++++++++++++++++++++-
 io_uring/kbuf.h               |   7 ++-
 io_uring/memmap.c             | 111 ++++++++++++++++++++++++++++++++++
 io_uring/memmap.h             |   4 ++
 io_uring/register.c           |   7 +++
 6 files changed, 219 insertions(+), 6 deletions(-)

diff --git a/include/uapi/linux/io_uring.h b/include/uapi/linux/io_uring.h
index fc473af6feb4..a0889c1744bd 100644
--- a/include/uapi/linux/io_uring.h
+++ b/include/uapi/linux/io_uring.h
@@ -715,6 +715,10 @@ enum io_uring_register_op {
 	/* register bpf filtering programs */
 	IORING_REGISTER_BPF_FILTER		= 37,
 
+	/* register/unregister kernel-managed ring buffer group */
+	IORING_REGISTER_KMBUF_RING		= 38,
+	IORING_UNREGISTER_KMBUF_RING		= 39,
+
 	/* this goes last */
 	IORING_REGISTER_LAST,
 
@@ -891,9 +895,16 @@ enum io_uring_register_pbuf_ring_flags {
 	IOU_PBUF_RING_INC	= 2,
 };
 
-/* argument for IORING_(UN)REGISTER_PBUF_RING */
+/* argument for IORING_(UN)REGISTER_PBUF_RING and
+ * IORING_(UN)REGISTER_KMBUF_RING
+ */
 struct io_uring_buf_reg {
-	__u64	ring_addr;
+	union {
+		/* used for pbuf rings */
+		__u64	ring_addr;
+		/* used for kmbuf rings */
+		__u32   buf_size;
+	};
 	__u32	ring_entries;
 	__u16	bgid;
 	__u16	flags;
diff --git a/io_uring/kbuf.c b/io_uring/kbuf.c
index aa9b70b72db4..9bc36451d083 100644
--- a/io_uring/kbuf.c
+++ b/io_uring/kbuf.c
@@ -427,10 +427,13 @@ static int io_remove_buffers_legacy(struct io_ring_ctx *ctx,
 
 static void io_put_bl(struct io_ring_ctx *ctx, struct io_buffer_list *bl)
 {
-	if (bl-&gt;flags &amp; IOBL_BUF_RING)
+	if (bl-&gt;flags &amp; IOBL_BUF_RING) {
 		io_free_region(ctx-&gt;user, &amp;bl-&gt;region);
-	else
+		if (bl-&gt;flags &amp; IOBL_KERNEL_MANAGED)
+			kfree(bl-&gt;buf_ring);
+	} else {
 		io_remove_buffers_legacy(ctx, bl, -1U);
+	}
 
 	kfree(bl);
 }
@@ -779,3 +782,77 @@ struct io_mapped_region *io_pbuf_get_region(struct io_ring_ctx *ctx,
 		return NULL;
 	return &amp;bl-&gt;region;
 }
+
+static int io_setup_kmbuf_ring(struct io_ring_ctx *ctx,
+			       struct io_buffer_list *bl,
+			       struct io_uring_buf_reg *reg)
+{
+	struct io_uring_buf_ring *ring;
+	unsigned long ring_size;
+	void *buf_region;
+	unsigned int i;
+	int ret;
+
+	/* allocate pages for the ring structure */
+	ring_size = flex_array_size(ring, bufs, bl-&gt;nr_entries);
+	ring = kzalloc(ring_size, GFP_KERNEL_ACCOUNT);
+	if (!ring)
+		return -ENOMEM;
+
+	ret = io_create_region_multi_buf(ctx, &amp;bl-&gt;region, bl-&gt;nr_entries,
+					 reg-&gt;buf_size);
+	if (ret) {
+		kfree(ring);
+		return ret;
+	}
+
+	/* initialize ring buf entries to point to the buffers */
+	buf_region = bl-&gt;region.ptr;
+	for (i = 0; i &lt; bl-&gt;nr_entries; i++) {
+		struct io_uring_buf *buf = &amp;ring-&gt;bufs[i];
+
+		buf-&gt;addr = (u64)(uintptr_t)buf_region;
+		buf-&gt;len = reg-&gt;buf_size;
+		buf-&gt;bid = i;
+
+		buf_region += reg-&gt;buf_size;
+	}
+	ring-&gt;tail = bl-&gt;nr_entries;
+
+	bl-&gt;buf_ring = ring;
+	bl-&gt;flags |= IOBL_KERNEL_MANAGED;
+
+	return 0;
+}
+
+int io_register_kmbuf_ring(struct io_ring_ctx *ctx, void __user *arg)
+{
+	struct io_uring_buf_reg reg;
+	struct io_buffer_list *bl;
+	int ret;
+
+	lockdep_assert_held(&amp;ctx-&gt;uring_lock);
+
+	ret = io_copy_and_validate_buf_reg(arg, &amp;reg, 0);
+	if (ret)
+		return ret;
+
+	if (!reg.buf_size || !PAGE_ALIGNED(reg.buf_size))
+		return -EINVAL;
+
+	bl = io_alloc_new_buffer_list(ctx, &amp;reg);
+	if (IS_ERR(bl))
+		return PTR_ERR(bl);
+
+	ret = io_setup_kmbuf_ring(ctx, bl, &amp;reg);
+	if (ret) {
+		kfree(bl);
+		return ret;
+	}
+
+	ret = io_buffer_add_list(ctx, bl, reg.bgid);
+	if (ret)
+		io_put_bl(ctx, bl);
+
+	return ret;
+}
diff --git a/io_uring/kbuf.h b/io_uring/kbuf.h
index 40b44f4fdb15..62c80a1ebf03 100644
--- a/io_uring/kbuf.h
+++ b/io_uring/kbuf.h
@@ -7,9 +7,11 @@
 
 enum {
 	/* ring mapped provided buffers */
-	IOBL_BUF_RING	= 1,
+	IOBL_BUF_RING		= 1,
 	/* buffers are consumed incrementally rather than always fully */
-	IOBL_INC	= 2,
+	IOBL_INC		= 2,
+	/* buffers are kernel managed */
+	IOBL_KERNEL_MANAGED	= 4,
 };
 
 struct io_buffer_list {
@@ -74,6 +76,7 @@ int io_provide_buffers_prep(struct io_kiocb *req, const struct io_uring_sqe *sqe
 int io_manage_buffers_legacy(struct io_kiocb *req, unsigned int issue_flags);
 
 int io_register_pbuf_ring(struct io_ring_ctx *ctx, void __user *arg);
+int io_register_kmbuf_ring(struct io_ring_ctx *ctx, void __user *arg);
 int io_unregister_buf_ring(struct io_ring_ctx *ctx, void __user *arg);
 int io_register_pbuf_status(struct io_ring_ctx *ctx, void __user *arg);
 
diff --git a/io_uring/memmap.c b/io_uring/memmap.c
index 89f56609e50a..8d37e93c0433 100644
--- a/io_uring/memmap.c
+++ b/io_uring/memmap.c
@@ -15,6 +15,28 @@
 #include &quot;rsrc.h&quot;
 #include &quot;zcrx.h&quot;
 
+static void release_multi_buf_pages(struct page **pages, unsigned long nr_pages)
+{
+	struct page *page;
+	unsigned int nr, i = 0;
+
+	while (nr_pages) {
+		page = pages[i];
+
+		if (!page || WARN_ON_ONCE(page != compound_head(page)))
+			return;
+
+		nr = compound_nr(page);
+		put_page(page);
+
+		if (WARN_ON_ONCE(nr &gt; nr_pages))
+			return;
+
+		i += nr;
+		nr_pages -= nr;
+	}
+}
+
 static bool io_mem_alloc_compound(struct page **pages, int nr_pages,
 				  size_t size, gfp_t gfp)
 {
@@ -86,6 +108,8 @@ enum {
 	IO_REGION_F_USER_PROVIDED		= 2,
 	/* only the first page in the array is ref&#x27;ed */
 	IO_REGION_F_SINGLE_REF			= 4,
+	/* pages in the array belong to multiple discrete allocations */
+	IO_REGION_F_MULTI_BUF			= 8,
 };
 
 void io_free_region(struct user_struct *user, struct io_mapped_region *mr)
@@ -98,6 +122,8 @@ void io_free_region(struct user_struct *user, struct io_mapped_region *mr)
 
 		if (mr-&gt;flags &amp; IO_REGION_F_USER_PROVIDED)
 			unpin_user_pages(mr-&gt;pages, nr_refs);
+		else if (mr-&gt;flags &amp; IO_REGION_F_MULTI_BUF)
+			release_multi_buf_pages(mr-&gt;pages, nr_refs);
 		else
 			release_pages(mr-&gt;pages, nr_refs);
 
@@ -149,6 +175,54 @@ static int io_region_pin_pages(struct io_mapped_region *mr,
 	return 0;
 }
 
+static int io_region_allocate_pages_multi_buf(struct io_mapped_region *mr,
+					      unsigned int nr_bufs,
+					      unsigned int buf_size)
+{
+	gfp_t gfp = GFP_USER | __GFP_ACCOUNT | __GFP_ZERO | __GFP_NOWARN;
+	struct page **pages, **cur_pages;
+	unsigned int nr_allocated;
+	unsigned int buf_pages;
+	unsigned int i;
+
+	if (!PAGE_ALIGNED(buf_size))
+		return -EINVAL;
+
+	buf_pages = buf_size &gt;&gt; PAGE_SHIFT;
+
+	pages = kvmalloc_array(mr-&gt;nr_pages, sizeof(*pages), gfp);
+	if (!pages)
+		return -ENOMEM;
+
+	cur_pages = pages;
+
+	for (i = 0; i &lt; nr_bufs; i++) {
+		if (io_mem_alloc_compound(cur_pages, buf_pages, buf_size,
+					  gfp)) {
+			cur_pages += buf_pages;
+			continue;
+		}
+
+		nr_allocated = alloc_pages_bulk_node(gfp, NUMA_NO_NODE,
+						     buf_pages, cur_pages);
+		if (nr_allocated != buf_pages) {
+			unsigned int total =
+				(cur_pages - pages) + nr_allocated;
+
+			release_multi_buf_pages(pages, total);
+			kvfree(pages);
+			return -ENOMEM;
+		}
+
+		cur_pages += buf_pages;
+	}
+
+	mr-&gt;flags |= IO_REGION_F_MULTI_BUF;
+	mr-&gt;pages = pages;
+
+	return 0;
+}
+
 static int io_region_allocate_pages(struct io_mapped_region *mr,
 				    struct io_uring_region_desc *reg,
 				    unsigned long mmap_offset)
@@ -181,6 +255,43 @@ static int io_region_allocate_pages(struct io_mapped_region *mr,
 	return 0;
 }
 
+int io_create_region_multi_buf(struct io_ring_ctx *ctx,
+			       struct io_mapped_region *mr,
+			       unsigned int nr_bufs, unsigned int buf_size)
+{
+	unsigned int nr_pages;
+	int ret;
+
+	if (WARN_ON_ONCE(mr-&gt;pages || mr-&gt;ptr || mr-&gt;nr_pages))
+		return -EFAULT;
+
+	if (WARN_ON_ONCE(!nr_bufs || !buf_size || !PAGE_ALIGNED(buf_size)))
+		return -EINVAL;
+
+	if (check_mul_overflow(buf_size &gt;&gt; PAGE_SHIFT, nr_bufs, &amp;nr_pages))
+		return -EINVAL;
+
+	if (ctx-&gt;user) {
+		ret = __io_account_mem(ctx-&gt;user, nr_pages);
+		if (ret)
+			return ret;
+	}
+	mr-&gt;nr_pages = nr_pages;
+
+	ret = io_region_allocate_pages_multi_buf(mr, nr_bufs, buf_size);
+	if (ret)
+		goto out_free;
+
+	ret = io_region_init_ptr(mr);
+	if (ret)
+		goto out_free;
+
+	return 0;
+out_free:
+	io_free_region(ctx-&gt;user, mr);
+	return ret;
+}
+
 int io_create_region(struct io_ring_ctx *ctx, struct io_mapped_region *mr,
 		     struct io_uring_region_desc *reg,
 		     unsigned long mmap_offset)
diff --git a/io_uring/memmap.h b/io_uring/memmap.h
index f4cfbb6b9a1f..3aa1167462ae 100644
--- a/io_uring/memmap.h
+++ b/io_uring/memmap.h
@@ -22,6 +22,10 @@ int io_create_region(struct io_ring_ctx *ctx, struct io_mapped_region *mr,
 		     struct io_uring_region_desc *reg,
 		     unsigned long mmap_offset);
 
+int io_create_region_multi_buf(struct io_ring_ctx *ctx,
+			       struct io_mapped_region *mr,
+			       unsigned int nr_bufs, unsigned int buf_size);
+
 static inline void *io_region_get_ptr(struct io_mapped_region *mr)
 {
 	return mr-&gt;ptr;
diff --git a/io_uring/register.c b/io_uring/register.c
index 0882cb34f851..2db8daaf8fde 100644
--- a/io_uring/register.c
+++ b/io_uring/register.c
@@ -837,7 +837,14 @@ static int __io_uring_register(struct io_ring_ctx *ctx, unsigned opcode,
 			break;
 		ret = io_register_pbuf_ring(ctx, arg);
 		break;
+	case IORING_REGISTER_KMBUF_RING:
+		ret = -EINVAL;
+		if (!arg || nr_args != 1)
+			break;
+		ret = io_register_kmbuf_ring(ctx, arg);
+		break;
 	case IORING_UNREGISTER_PBUF_RING:
+	case IORING_UNREGISTER_KMBUF_RING:
 		ret = -EINVAL;
 		if (!arg || nr_args != 1)
 			break;
-- 
2.47.3</pre>
</details>
<div class="review-comment-signals">Signals: clarification, explanation</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-09">2026-02-09</a>
<span class="badge" style="color:#155724;background:#d4edda">Positive</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author addressed a concern about the implementation of kernel-managed buffer rings (kmbuf) and how they interact with mmap, explaining that kmbuf rings use the same pattern as application-provided buffer rings (pbuf) but introduce new constants for encoding the buffer group ID. The author confirmed that userspace can access the kernel-allocated buffers directly through mmap.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Add support for mmapping kernel-managed buffer rings (kmbuf) to
userspace, allowing applications to access the kernel-allocated buffers.

Similar to application-provided buffer rings (pbuf), kmbuf rings use the
buffer group ID encoded in the mmap offset to identify which buffer ring
to map. The implementation follows the same pattern as pbuf rings.

New mmap offset constants are introduced:
  - IORING_OFF_KMBUF_RING (0x88000000): Base offset for kmbuf mappings
  - IORING_OFF_KMBUF_SHIFT (16): Shift value to encode buffer group ID

The mmap offset encodes the bgid shifted by IORING_OFF_KMBUF_SHIFT.
The io_buf_get_region() helper retrieves the appropriate region.

This allows userspace to mmap the kernel-allocated buffer region and
access the buffers directly.

Signed-off-by: Joanne Koong &lt;joannelkoong@gmail.com&gt;
---
 include/uapi/linux/io_uring.h |  2 ++
 io_uring/kbuf.c               | 11 +++++++++--
 io_uring/kbuf.h               |  5 +++--
 io_uring/memmap.c             |  5 ++++-
 4 files changed, 18 insertions(+), 5 deletions(-)

diff --git a/include/uapi/linux/io_uring.h b/include/uapi/linux/io_uring.h
index a0889c1744bd..42a2812c9922 100644
--- a/include/uapi/linux/io_uring.h
+++ b/include/uapi/linux/io_uring.h
@@ -545,6 +545,8 @@ struct io_uring_cqe {
 #define IORING_OFF_SQES			0x10000000ULL
 #define IORING_OFF_PBUF_RING		0x80000000ULL
 #define IORING_OFF_PBUF_SHIFT		16
+#define IORING_OFF_KMBUF_RING		0x88000000ULL
+#define IORING_OFF_KMBUF_SHIFT		16
 #define IORING_OFF_MMAP_MASK		0xf8000000ULL
 
 /*
diff --git a/io_uring/kbuf.c b/io_uring/kbuf.c
index 9bc36451d083..ccf5b213087b 100644
--- a/io_uring/kbuf.c
+++ b/io_uring/kbuf.c
@@ -770,16 +770,23 @@ int io_register_pbuf_status(struct io_ring_ctx *ctx, void __user *arg)
 	return 0;
 }
 
-struct io_mapped_region *io_pbuf_get_region(struct io_ring_ctx *ctx,
-					    unsigned int bgid)
+struct io_mapped_region *io_buf_get_region(struct io_ring_ctx *ctx,
+					   unsigned int bgid,
+					   bool kernel_managed)
 {
 	struct io_buffer_list *bl;
+	bool is_kernel_managed;
 
 	lockdep_assert_held(&amp;ctx-&gt;mmap_lock);
 
 	bl = xa_load(&amp;ctx-&gt;io_bl_xa, bgid);
 	if (!bl || !(bl-&gt;flags &amp; IOBL_BUF_RING))
 		return NULL;
+
+	is_kernel_managed = !!(bl-&gt;flags &amp; IOBL_KERNEL_MANAGED);
+	if (is_kernel_managed != kernel_managed)
+		return NULL;
+
 	return &amp;bl-&gt;region;
 }
 
diff --git a/io_uring/kbuf.h b/io_uring/kbuf.h
index 62c80a1ebf03..11d165888b8e 100644
--- a/io_uring/kbuf.h
+++ b/io_uring/kbuf.h
@@ -88,8 +88,9 @@ unsigned int __io_put_kbufs(struct io_kiocb *req, struct io_buffer_list *bl,
 bool io_kbuf_commit(struct io_kiocb *req,
 		    struct io_buffer_list *bl, int len, int nr);
 
-struct io_mapped_region *io_pbuf_get_region(struct io_ring_ctx *ctx,
-					    unsigned int bgid);
+struct io_mapped_region *io_buf_get_region(struct io_ring_ctx *ctx,
+					   unsigned int bgid,
+					   bool kernel_managed);
 
 static inline bool io_kbuf_recycle_ring(struct io_kiocb *req,
 					struct io_buffer_list *bl)
diff --git a/io_uring/memmap.c b/io_uring/memmap.c
index 8d37e93c0433..916315122323 100644
--- a/io_uring/memmap.c
+++ b/io_uring/memmap.c
@@ -356,7 +356,10 @@ static struct io_mapped_region *io_mmap_get_region(struct io_ring_ctx *ctx,
 		return &amp;ctx-&gt;sq_region;
 	case IORING_OFF_PBUF_RING:
 		id = (offset &amp; ~IORING_OFF_MMAP_MASK) &gt;&gt; IORING_OFF_PBUF_SHIFT;
-		return io_pbuf_get_region(ctx, id);
+		return io_buf_get_region(ctx, id, false);
+	case IORING_OFF_KMBUF_RING:
+		id = (offset &amp; ~IORING_OFF_MMAP_MASK) &gt;&gt; IORING_OFF_KMBUF_SHIFT;
+		return io_buf_get_region(ctx, id, true);
 	case IORING_MAP_OFF_PARAM_REGION:
 		return &amp;ctx-&gt;param_region;
 	case IORING_MAP_OFF_ZCRX_REGION:
-- 
2.47.3</pre>
</details>
<div class="review-comment-signals">Signals: author provided a clear explanation of their implementation, author confirmed that userspace can access kernel-allocated buffers</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-09">2026-02-09</a>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The author addressed a concern about distinguishing between kernel-managed buffer addresses and negative values when error checking, explaining that the io_br_sel struct needs to be modified to separate address and value fields for kernel-managed buffers. The author provided a patch that modifies the io_uring_types.h file and the kbuf.c file to implement this change.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Allow kernel-managed buffers to be selected. This requires modifying the
io_br_sel struct to separate the fields for address and val, since a
kernel address cannot be distinguished from a negative val when error
checking.

Auto-commit any selected kernel-managed buffer.

Signed-off-by: Joanne Koong &lt;joannelkoong@gmail.com&gt;
---
 include/linux/io_uring_types.h |  8 ++++----
 io_uring/kbuf.c                | 16 ++++++++++++----
 2 files changed, 16 insertions(+), 8 deletions(-)

diff --git a/include/linux/io_uring_types.h b/include/linux/io_uring_types.h
index 3e4a82a6f817..36cc2e0346d9 100644
--- a/include/linux/io_uring_types.h
+++ b/include/linux/io_uring_types.h
@@ -93,13 +93,13 @@ struct io_mapped_region {
  */
 struct io_br_sel {
 	struct io_buffer_list *buf_list;
-	/*
-	 * Some selection parts return the user address, others return an error.
-	 */
 	union {
+		/* for classic/ring provided buffers */
 		void __user *addr;
-		ssize_t val;
+		/* for kernel-managed buffers */
+		void *kaddr;
 	};
+	ssize_t val;
 };
 
 
diff --git a/io_uring/kbuf.c b/io_uring/kbuf.c
index ccf5b213087b..1e8395270227 100644
--- a/io_uring/kbuf.c
+++ b/io_uring/kbuf.c
@@ -155,7 +155,8 @@ static int io_provided_buffers_select(struct io_kiocb *req, size_t *len,
 	return 1;
 }
 
-static bool io_should_commit(struct io_kiocb *req, unsigned int issue_flags)
+static bool io_should_commit(struct io_kiocb *req, struct io_buffer_list *bl,
+			     unsigned int issue_flags)
 {
 	/*
 	* If we came in unlocked, we have no choice but to consume the
@@ -170,7 +171,11 @@ static bool io_should_commit(struct io_kiocb *req, unsigned int issue_flags)
 	if (issue_flags &amp; IO_URING_F_UNLOCKED)
 		return true;
 
-	/* uring_cmd commits kbuf upfront, no need to auto-commit */
+	/* kernel-managed buffers are auto-committed */
+	if (bl-&gt;flags &amp; IOBL_KERNEL_MANAGED)
+		return true;
+
+	/* multishot uring_cmd commits kbuf upfront, no need to auto-commit */
 	if (!io_file_can_poll(req) &amp;&amp; req-&gt;opcode != IORING_OP_URING_CMD)
 		return true;
 	return false;
@@ -200,9 +205,12 @@ static struct io_br_sel io_ring_buffer_select(struct io_kiocb *req, size_t *len,
 	req-&gt;flags |= REQ_F_BUFFER_RING | REQ_F_BUFFERS_COMMIT;
 	req-&gt;buf_index = READ_ONCE(buf-&gt;bid);
 	sel.buf_list = bl;
-	sel.addr = u64_to_user_ptr(READ_ONCE(buf-&gt;addr));
+	if (bl-&gt;flags &amp; IOBL_KERNEL_MANAGED)
+		sel.kaddr = (void *)(uintptr_t)READ_ONCE(buf-&gt;addr);
+	else
+		sel.addr = u64_to_user_ptr(READ_ONCE(buf-&gt;addr));
 
-	if (io_should_commit(req, issue_flags)) {
+	if (io_should_commit(req, bl, issue_flags)) {
 		io_kbuf_commit(req, sel.buf_list, *len, 1);
 		sel.buf_list = NULL;
 	}
-- 
2.47.3</pre>
</details>
<div class="review-comment-signals">Signals: acknowledged fix needed</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-09">2026-02-09</a>
<span class="badge" style="color:#155724;background:#d4edda">Positive</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The author addressed a concern about userspace unregistering a buffer ring while it is pinned by the kernel, and added APIs to pin and unpin buffer rings, preventing this issue. The pinning mechanism ensures that the buffer ring remains valid for kernel subsystems accessing its contents in atomic contexts.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Add kernel APIs to pin and unpin buffer rings, preventing userspace from
unregistering a buffer ring while it is pinned by the kernel.

This provides a mechanism for kernel subsystems to safely access buffer
ring contents while ensuring the buffer ring remains valid. A pinned
buffer ring cannot be unregistered until explicitly unpinned. On the
userspace side, trying to unregister a pinned buffer will return -EBUSY.

This is a preparatory change for upcoming fuse usage of kernel-managed
buffer rings. It is necessary for fuse to pin the buffer ring because
fuse may need to select a buffer in atomic contexts, which it can only
do so by using the underlying buffer list pointer.

Signed-off-by: Joanne Koong &lt;joannelkoong@gmail.com&gt;
---
 include/linux/io_uring/cmd.h | 17 +++++++++++++
 io_uring/kbuf.c              | 48 ++++++++++++++++++++++++++++++++++++
 io_uring/kbuf.h              |  5 ++++
 3 files changed, 70 insertions(+)

diff --git a/include/linux/io_uring/cmd.h b/include/linux/io_uring/cmd.h
index 375fd048c4cb..702b1903e6ee 100644
--- a/include/linux/io_uring/cmd.h
+++ b/include/linux/io_uring/cmd.h
@@ -84,6 +84,10 @@ struct io_br_sel io_uring_cmd_buffer_select(struct io_uring_cmd *ioucmd,
 bool io_uring_mshot_cmd_post_cqe(struct io_uring_cmd *ioucmd,
 				 struct io_br_sel *sel, unsigned int issue_flags);
 
+int io_uring_buf_ring_pin(struct io_uring_cmd *cmd, unsigned buf_group,
+			  unsigned issue_flags, struct io_buffer_list **bl);
+int io_uring_buf_ring_unpin(struct io_uring_cmd *cmd, unsigned buf_group,
+			    unsigned issue_flags);
 #else
 static inline int
 io_uring_cmd_import_fixed(u64 ubuf, unsigned long len, int rw,
@@ -126,6 +130,19 @@ static inline bool io_uring_mshot_cmd_post_cqe(struct io_uring_cmd *ioucmd,
 {
 	return true;
 }
+static inline int io_uring_buf_ring_pin(struct io_uring_cmd *cmd,
+					unsigned buf_group,
+					unsigned issue_flags,
+					struct io_buffer_list **bl)
+{
+	return -EOPNOTSUPP;
+}
+static inline int io_uring_buf_ring_unpin(struct io_uring_cmd *cmd,
+					  unsigned buf_group,
+					  unsigned issue_flags)
+{
+	return -EOPNOTSUPP;
+}
 #endif
 
 static inline struct io_uring_cmd *io_uring_cmd_from_tw(struct io_tw_req tw_req)
diff --git a/io_uring/kbuf.c b/io_uring/kbuf.c
index 1e8395270227..dee1764ed19f 100644
--- a/io_uring/kbuf.c
+++ b/io_uring/kbuf.c
@@ -9,6 +9,7 @@
 #include &lt;linux/poll.h&gt;
 #include &lt;linux/vmalloc.h&gt;
 #include &lt;linux/io_uring.h&gt;
+#include &lt;linux/io_uring/cmd.h&gt;
 
 #include &lt;uapi/linux/io_uring.h&gt;
 
@@ -237,6 +238,51 @@ struct io_br_sel io_buffer_select(struct io_kiocb *req, size_t *len,
 	return sel;
 }
 
+int io_uring_buf_ring_pin(struct io_uring_cmd *cmd, unsigned buf_group,
+			  unsigned issue_flags, struct io_buffer_list **bl)
+{
+	struct io_ring_ctx *ctx = cmd_to_io_kiocb(cmd)-&gt;ctx;
+	struct io_buffer_list *buffer_list;
+	int ret = -EINVAL;
+
+	io_ring_submit_lock(ctx, issue_flags);
+
+	buffer_list = io_buffer_get_list(ctx, buf_group);
+	if (buffer_list &amp;&amp; (buffer_list-&gt;flags &amp; IOBL_BUF_RING)) {
+		if (unlikely(buffer_list-&gt;flags &amp; IOBL_PINNED)) {
+			ret = -EALREADY;
+		} else {
+			buffer_list-&gt;flags |= IOBL_PINNED;
+			ret = 0;
+			*bl = buffer_list;
+		}
+	}
+
+	io_ring_submit_unlock(ctx, issue_flags);
+	return ret;
+}
+EXPORT_SYMBOL_GPL(io_uring_buf_ring_pin);
+
+int io_uring_buf_ring_unpin(struct io_uring_cmd *cmd, unsigned buf_group,
+		       unsigned issue_flags)
+{
+	struct io_ring_ctx *ctx = cmd_to_io_kiocb(cmd)-&gt;ctx;
+	struct io_buffer_list *bl;
+	int ret = -EINVAL;
+
+	io_ring_submit_lock(ctx, issue_flags);
+
+	bl = io_buffer_get_list(ctx, buf_group);
+	if (bl &amp;&amp; (bl-&gt;flags &amp; IOBL_BUF_RING) &amp;&amp; (bl-&gt;flags &amp; IOBL_PINNED)) {
+		bl-&gt;flags &amp;= ~IOBL_PINNED;
+		ret = 0;
+	}
+
+	io_ring_submit_unlock(ctx, issue_flags);
+	return ret;
+}
+EXPORT_SYMBOL_GPL(io_uring_buf_ring_unpin);
+
 /* cap it at a reasonable 256, will be one page even for 4K */
 #define PEEK_MAX_IMPORT		256
 
@@ -747,6 +793,8 @@ int io_unregister_buf_ring(struct io_ring_ctx *ctx, void __user *arg)
 		return -ENOENT;
 	if (!(bl-&gt;flags &amp; IOBL_BUF_RING))
 		return -EINVAL;
+	if (bl-&gt;flags &amp; IOBL_PINNED)
+		return -EBUSY;
 
 	scoped_guard(mutex, &amp;ctx-&gt;mmap_lock)
 		xa_erase(&amp;ctx-&gt;io_bl_xa, bl-&gt;bgid);
diff --git a/io_uring/kbuf.h b/io_uring/kbuf.h
index 11d165888b8e..781630c2cc10 100644
--- a/io_uring/kbuf.h
+++ b/io_uring/kbuf.h
@@ -12,6 +12,11 @@ enum {
 	IOBL_INC		= 2,
 	/* buffers are kernel managed */
 	IOBL_KERNEL_MANAGED	= 4,
+	/*
+	 * buffer ring is pinned and cannot be unregistered by userspace until
+	 * it has been unpinned
+	 */
+	IOBL_PINNED		= 8,
 };
 
 struct io_buffer_list {
-- 
2.47.3</pre>
</details>
<div class="review-comment-signals">Signals: acknowledged a fix, added preparatory change</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-09">2026-02-09</a>
<span class="badge" style="color:#155724;background:#d4edda">Positive</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author addressed a concern about the lack of an interface for recycling buffers back into kernel-managed buffer rings, added an interface (io_uring_kmbuf_recycle) to recycle buffers and update the io_kiocb flags accordingly.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Add an interface for buffers to be recycled back into a kernel-managed
buffer ring.

This is a preparatory patch for fuse over io-uring.

Signed-off-by: Joanne Koong &lt;joannelkoong@gmail.com&gt;
---
 include/linux/io_uring/cmd.h | 11 +++++++++
 io_uring/kbuf.c              | 44 ++++++++++++++++++++++++++++++++++++
 2 files changed, 55 insertions(+)

diff --git a/include/linux/io_uring/cmd.h b/include/linux/io_uring/cmd.h
index 702b1903e6ee..a488e945f883 100644
--- a/include/linux/io_uring/cmd.h
+++ b/include/linux/io_uring/cmd.h
@@ -88,6 +88,10 @@ int io_uring_buf_ring_pin(struct io_uring_cmd *cmd, unsigned buf_group,
 			  unsigned issue_flags, struct io_buffer_list **bl);
 int io_uring_buf_ring_unpin(struct io_uring_cmd *cmd, unsigned buf_group,
 			    unsigned issue_flags);
+
+int io_uring_kmbuf_recycle(struct io_uring_cmd *cmd, unsigned int buf_group,
+			   u64 addr, unsigned int len, unsigned int bid,
+			   unsigned int issue_flags);
 #else
 static inline int
 io_uring_cmd_import_fixed(u64 ubuf, unsigned long len, int rw,
@@ -143,6 +147,13 @@ static inline int io_uring_buf_ring_unpin(struct io_uring_cmd *cmd,
 {
 	return -EOPNOTSUPP;
 }
+static inline int io_uring_kmbuf_recycle(struct io_uring_cmd *cmd,
+					 unsigned int buf_group, u64 addr,
+					 unsigned int len, unsigned int bid,
+					 unsigned int issue_flags)
+{
+	return -EOPNOTSUPP;
+}
 #endif
 
 static inline struct io_uring_cmd *io_uring_cmd_from_tw(struct io_tw_req tw_req)
diff --git a/io_uring/kbuf.c b/io_uring/kbuf.c
index dee1764ed19f..17b6178be4ce 100644
--- a/io_uring/kbuf.c
+++ b/io_uring/kbuf.c
@@ -102,6 +102,50 @@ void io_kbuf_drop_legacy(struct io_kiocb *req)
 	req-&gt;kbuf = NULL;
 }
 
+int io_uring_kmbuf_recycle(struct io_uring_cmd *cmd, unsigned int buf_group,
+			   u64 addr, unsigned int len, unsigned int bid,
+			   unsigned int issue_flags)
+{
+	struct io_kiocb *req = cmd_to_io_kiocb(cmd);
+	struct io_ring_ctx *ctx = req-&gt;ctx;
+	struct io_uring_buf_ring *br;
+	struct io_uring_buf *buf;
+	struct io_buffer_list *bl;
+	int ret = -EINVAL;
+
+	if (WARN_ON_ONCE(req-&gt;flags &amp; REQ_F_BUFFERS_COMMIT))
+		return ret;
+
+	io_ring_submit_lock(ctx, issue_flags);
+
+	bl = io_buffer_get_list(ctx, buf_group);
+
+	if (!bl || WARN_ON_ONCE(!(bl-&gt;flags &amp; IOBL_BUF_RING)) ||
+	    WARN_ON_ONCE(!(bl-&gt;flags &amp; IOBL_KERNEL_MANAGED)))
+		goto done;
+
+	br = bl-&gt;buf_ring;
+
+	if (WARN_ON_ONCE((br-&gt;tail - bl-&gt;head) &gt;= bl-&gt;nr_entries))
+		goto done;
+
+	buf = &amp;br-&gt;bufs[(br-&gt;tail) &amp; bl-&gt;mask];
+
+	buf-&gt;addr = addr;
+	buf-&gt;len = len;
+	buf-&gt;bid = bid;
+
+	req-&gt;flags &amp;= ~REQ_F_BUFFER_RING;
+
+	br-&gt;tail++;
+	ret = 0;
+
+done:
+	io_ring_submit_unlock(ctx, issue_flags);
+	return ret;
+}
+EXPORT_SYMBOL_GPL(io_uring_kmbuf_recycle);
+
 bool io_kbuf_recycle_legacy(struct io_kiocb *req, unsigned issue_flags)
 {
 	struct io_ring_ctx *ctx = req-&gt;ctx;
-- 
2.47.3</pre>
</details>
<div class="review-comment-signals">Signals: addressed_concern, added_feature</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-09">2026-02-09</a>
<span class="badge" style="color:#155724;background:#d4edda">Positive</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The author addressed a concern about the io_uring_is_kmbuf_ring() function, which was missing an implementation to check if a buffer ring is kernel-managed. The author added this implementation in the latest patch version, checking for the IOBL_KERNEL_MANAGED flag and verifying that the buffer ring is not empty.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">io_uring_is_kmbuf_ring() returns true if there is a kernel-managed
buffer ring at the specified buffer group.

This is a preparatory patch for upcoming fuse kernel-managed buffer
support, which needs to ensure the buffer ring registered by the server
is a kernel-managed buffer ring.

Signed-off-by: Joanne Koong &lt;joannelkoong@gmail.com&gt;
---
 include/linux/io_uring/cmd.h |  9 +++++++++
 io_uring/kbuf.c              | 20 ++++++++++++++++++++
 2 files changed, 29 insertions(+)

diff --git a/include/linux/io_uring/cmd.h b/include/linux/io_uring/cmd.h
index a488e945f883..04a937f6f4d3 100644
--- a/include/linux/io_uring/cmd.h
+++ b/include/linux/io_uring/cmd.h
@@ -92,6 +92,9 @@ int io_uring_buf_ring_unpin(struct io_uring_cmd *cmd, unsigned buf_group,
 int io_uring_kmbuf_recycle(struct io_uring_cmd *cmd, unsigned int buf_group,
 			   u64 addr, unsigned int len, unsigned int bid,
 			   unsigned int issue_flags);
+
+bool io_uring_is_kmbuf_ring(struct io_uring_cmd *cmd, unsigned int buf_group,
+			    unsigned int issue_flags);
 #else
 static inline int
 io_uring_cmd_import_fixed(u64 ubuf, unsigned long len, int rw,
@@ -154,6 +157,12 @@ static inline int io_uring_kmbuf_recycle(struct io_uring_cmd *cmd,
 {
 	return -EOPNOTSUPP;
 }
+static inline bool io_uring_is_kmbuf_ring(struct io_uring_cmd *cmd,
+					  unsigned int buf_group,
+					  unsigned int issue_flags)
+{
+	return false;
+}
 #endif
 
 static inline struct io_uring_cmd *io_uring_cmd_from_tw(struct io_tw_req tw_req)
diff --git a/io_uring/kbuf.c b/io_uring/kbuf.c
index 17b6178be4ce..797cc2f0a5e9 100644
--- a/io_uring/kbuf.c
+++ b/io_uring/kbuf.c
@@ -963,3 +963,23 @@ int io_register_kmbuf_ring(struct io_ring_ctx *ctx, void __user *arg)
 
 	return ret;
 }
+
+bool io_uring_is_kmbuf_ring(struct io_uring_cmd *cmd, unsigned int buf_group,
+			    unsigned int issue_flags)
+{
+	struct io_ring_ctx *ctx = cmd_to_io_kiocb(cmd)-&gt;ctx;
+	struct io_buffer_list *bl;
+	bool is_kmbuf_ring = false;
+
+	io_ring_submit_lock(ctx, issue_flags);
+
+	bl = io_buffer_get_list(ctx, buf_group);
+	if (likely(bl) &amp;&amp; (bl-&gt;flags &amp; IOBL_KERNEL_MANAGED)) {
+		WARN_ON_ONCE(!(bl-&gt;flags &amp; IOBL_BUF_RING));
+		is_kmbuf_ring = true;
+	}
+
+	io_ring_submit_unlock(ctx, issue_flags);
+	return is_kmbuf_ring;
+}
+EXPORT_SYMBOL_GPL(io_uring_is_kmbuf_ring);
-- 
2.47.3</pre>
</details>
<div class="review-comment-signals">Signals: acknowledged fix needed, added implementation</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-09">2026-02-09</a>
<span class="badge" style="color:#155724;background:#d4edda">Positive</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The author is addressing a concern about the io_uring mutex being held by in-progress commits and atomic contexts when selecting a buffer from a kernel-managed bufring. The author agrees that exporting io_ring_buffer_select() is necessary to allow fuse io-uring to select a buffer without needing to grab the io_uring mutex, and has added this export to the patch.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Export io_ring_buffer_select() so that it may be used by callers who
pass in a pinned bufring without needing to grab the io_uring mutex.

This is a preparatory patch that will be needed by fuse io-uring, which
will need to select a buffer from a kernel-managed bufring while the
uring mutex may already be held by in-progress commits, and may need to
select a buffer in atomic contexts.

Signed-off-by: Joanne Koong &lt;joannelkoong@gmail.com&gt;
---
 include/linux/io_uring/cmd.h | 14 ++++++++++++++
 io_uring/kbuf.c              |  7 ++++---
 2 files changed, 18 insertions(+), 3 deletions(-)

diff --git a/include/linux/io_uring/cmd.h b/include/linux/io_uring/cmd.h
index 04a937f6f4d3..d4b5943bdeb1 100644
--- a/include/linux/io_uring/cmd.h
+++ b/include/linux/io_uring/cmd.h
@@ -95,6 +95,10 @@ int io_uring_kmbuf_recycle(struct io_uring_cmd *cmd, unsigned int buf_group,
 
 bool io_uring_is_kmbuf_ring(struct io_uring_cmd *cmd, unsigned int buf_group,
 			    unsigned int issue_flags);
+
+struct io_br_sel io_ring_buffer_select(struct io_kiocb *req, size_t *len,
+				       struct io_buffer_list *bl,
+				       unsigned int issue_flags);
 #else
 static inline int
 io_uring_cmd_import_fixed(u64 ubuf, unsigned long len, int rw,
@@ -163,6 +167,16 @@ static inline bool io_uring_is_kmbuf_ring(struct io_uring_cmd *cmd,
 {
 	return false;
 }
+static inline struct io_br_sel io_ring_buffer_select(struct io_kiocb *req,
+						     size_t *len,
+						     struct io_buffer_list *bl,
+						     unsigned int issue_flags)
+{
+	struct io_br_sel sel = {
+		.val = -EOPNOTSUPP,
+	};
+	return sel;
+}
 #endif
 
 static inline struct io_uring_cmd *io_uring_cmd_from_tw(struct io_tw_req tw_req)
diff --git a/io_uring/kbuf.c b/io_uring/kbuf.c
index 797cc2f0a5e9..9a93f10d3214 100644
--- a/io_uring/kbuf.c
+++ b/io_uring/kbuf.c
@@ -226,9 +226,9 @@ static bool io_should_commit(struct io_kiocb *req, struct io_buffer_list *bl,
 	return false;
 }
 
-static struct io_br_sel io_ring_buffer_select(struct io_kiocb *req, size_t *len,
-					      struct io_buffer_list *bl,
-					      unsigned int issue_flags)
+struct io_br_sel io_ring_buffer_select(struct io_kiocb *req, size_t *len,
+				       struct io_buffer_list *bl,
+				       unsigned int issue_flags)
 {
 	struct io_uring_buf_ring *br = bl-&gt;buf_ring;
 	__u16 tail, head = bl-&gt;head;
@@ -261,6 +261,7 @@ static struct io_br_sel io_ring_buffer_select(struct io_kiocb *req, size_t *len,
 	}
 	return sel;
 }
+EXPORT_SYMBOL_GPL(io_ring_buffer_select);
 
 struct io_br_sel io_buffer_select(struct io_kiocb *req, size_t *len,
 				  unsigned buf_group, unsigned int issue_flags)
-- 
2.47.3</pre>
</details>
<div class="review-comment-signals">Signals: agreement, preparatory patch</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-09">2026-02-09</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The author is addressing a concern about returning the id of the selected buffer in io_buffer_select(). They are modifying the function to return the selected buffer address, size, and id by adding a new field &#x27;buf_id&#x27; to the struct io_br_sel. The patch includes changes to include/linux/io_uring/cmd.h, include/linux/io_uring_types.h, and io_uring/kbuf.c.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Return the id of the selected buffer in io_buffer_select(). This is
needed for kernel-managed buffer rings to later recycle the selected
buffer.

Signed-off-by: Joanne Koong &lt;joannelkoong@gmail.com&gt;
---
 include/linux/io_uring/cmd.h   | 2 +-
 include/linux/io_uring_types.h | 2 ++
 io_uring/kbuf.c                | 7 +++++--
 3 files changed, 8 insertions(+), 3 deletions(-)

diff --git a/include/linux/io_uring/cmd.h b/include/linux/io_uring/cmd.h
index d4b5943bdeb1..94df2bdebe77 100644
--- a/include/linux/io_uring/cmd.h
+++ b/include/linux/io_uring/cmd.h
@@ -71,7 +71,7 @@ void io_uring_cmd_issue_blocking(struct io_uring_cmd *ioucmd);
 
 /*
  * Select a buffer from the provided buffer group for multishot uring_cmd.
- * Returns the selected buffer address and size.
+ * Returns the selected buffer address, size, and id.
  */
 struct io_br_sel io_uring_cmd_buffer_select(struct io_uring_cmd *ioucmd,
 					    unsigned buf_group, size_t *len,
diff --git a/include/linux/io_uring_types.h b/include/linux/io_uring_types.h
index 36cc2e0346d9..5a56bb341337 100644
--- a/include/linux/io_uring_types.h
+++ b/include/linux/io_uring_types.h
@@ -100,6 +100,8 @@ struct io_br_sel {
 		void *kaddr;
 	};
 	ssize_t val;
+	/* id of the selected buffer */
+	unsigned buf_id;
 };
 
 
diff --git a/io_uring/kbuf.c b/io_uring/kbuf.c
index 9a93f10d3214..24c1e34ea23e 100644
--- a/io_uring/kbuf.c
+++ b/io_uring/kbuf.c
@@ -250,6 +250,7 @@ struct io_br_sel io_ring_buffer_select(struct io_kiocb *req, size_t *len,
 	req-&gt;flags |= REQ_F_BUFFER_RING | REQ_F_BUFFERS_COMMIT;
 	req-&gt;buf_index = READ_ONCE(buf-&gt;bid);
 	sel.buf_list = bl;
+	sel.buf_id = req-&gt;buf_index;
 	if (bl-&gt;flags &amp; IOBL_KERNEL_MANAGED)
 		sel.kaddr = (void *)(uintptr_t)READ_ONCE(buf-&gt;addr);
 	else
@@ -274,10 +275,12 @@ struct io_br_sel io_buffer_select(struct io_kiocb *req, size_t *len,
 
 	bl = io_buffer_get_list(ctx, buf_group);
 	if (likely(bl)) {
-		if (bl-&gt;flags &amp; IOBL_BUF_RING)
+		if (bl-&gt;flags &amp; IOBL_BUF_RING) {
 			sel = io_ring_buffer_select(req, len, bl, issue_flags);
-		else
+		} else {
 			sel.addr = io_provided_buffer_select(req, len, bl);
+			sel.buf_id = req-&gt;buf_index;
+		}
 	}
 	io_ring_submit_unlock(req-&gt;ctx, issue_flags);
 	return sel;
-- 
2.47.3</pre>
</details>
<div class="review-comment-signals">Signals: clarifying change, no clear resolution</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Joanne Koong (author)</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-09">2026-02-09</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author addressed a concern about indicating which buffer was selected in the completion queue entry, explained that setting IORING_CQE_F_BUFFER and encoding the buffer index is necessary for fuse to relay this information to userspace.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">When uring_cmd operations select a buffer, the completion queue entry
should indicate which buffer was selected.

Set IORING_CQE_F_BUFFER on the completed entry and encode the buffer
index if a buffer was selected.

This will be needed for fuse, which needs to relay to userspace which
selected buffer contains the data.

Signed-off-by: Joanne Koong &lt;joannelkoong@gmail.com&gt;
---
 io_uring/uring_cmd.c | 6 +++++-
 1 file changed, 5 insertions(+), 1 deletion(-)

diff --git a/io_uring/uring_cmd.c b/io_uring/uring_cmd.c
index ee7b49f47cb5..6d38df1a812d 100644
--- a/io_uring/uring_cmd.c
+++ b/io_uring/uring_cmd.c
@@ -151,6 +151,7 @@ void __io_uring_cmd_done(struct io_uring_cmd *ioucmd, s32 ret, u64 res2,
 		       unsigned issue_flags, bool is_cqe32)
 {
 	struct io_kiocb *req = cmd_to_io_kiocb(ioucmd);
+	u32 cflags = 0;
 
 	if (WARN_ON_ONCE(req-&gt;flags &amp; REQ_F_APOLL_MULTISHOT))
 		return;
@@ -160,7 +161,10 @@ void __io_uring_cmd_done(struct io_uring_cmd *ioucmd, s32 ret, u64 res2,
 	if (ret &lt; 0)
 		req_set_fail(req);
 
-	io_req_set_res(req, ret, 0);
+	if (req-&gt;flags &amp; (REQ_F_BUFFER_SELECTED | REQ_F_BUFFER_RING))
+		cflags |= IORING_CQE_F_BUFFER |
+			(req-&gt;buf_index &lt;&lt; IORING_CQE_BUFFER_SHIFT);
+	io_req_set_res(req, ret, cflags);
 	if (is_cqe32) {
 		if (req-&gt;ctx-&gt;flags &amp; IORING_SETUP_CQE_MIXED)
 			req-&gt;cqe.flags |= IORING_CQE_F_32;
-- 
2.47.3</pre>
</details>
<div class="review-comment-signals">Signals: clarification, explanation</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Pavel Begunkov</span>
<a class="date-chip" href="../2026-02-18_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Pavel Begunkov suggested reusing internal regions for allocations and mmap() operations, wrapping them in a registered buffer, and making vmap&#x27;ing optional as it&#x27;s not needed.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">FWIW, the easiest solution is to internally reuse regions for
allocations and mmap()&#x27;ing and wrap it into a registered buffer.
It just need to make vmap&#x27;ing optional as it won&#x27;t be needed.

-- 
Pavel Begunkov</pre>
</details>
<div class="review-comment-signals">Signals: suggested improvement, optional vmap</div>
</div>
</div>
</div>

    <footer>LKML Daily Activity Tracker</footer>
    <script>
    // When arriving via a date anchor (e.g. #2026-02-15 from a daily report),
    // scroll the anchor into view after a brief delay so layout is complete.
    (function () {
        var hash = window.location.hash;
        if (!hash) return;
        var target = document.getElementById(hash.slice(1));
        if (!target) return;
        setTimeout(function () {
            target.scrollIntoView({behavior: 'smooth', block: 'start'});
        }, 80);
    })();
    </script>
</body>
</html>