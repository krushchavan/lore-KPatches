<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Review Comments: [LSF/MM/BPF TOPIC] 64k (or 16k) base page size on x86</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
                         "Helvetica Neue", Arial, sans-serif;
            background: #f5f5f5;
            color: #333;
            line-height: 1.6;
            padding: 20px;
            max-width: 900px;
            margin: 0 auto;
        }
        .home-link { margin-bottom: 12px; display: block; }
        .home-link a { color: #0366d6; text-decoration: none; font-size: 0.9em; }
        .home-link a:hover { text-decoration: underline; }

        h1 { font-size: 1.3em; margin-bottom: 2px; color: #1a1a1a; line-height: 1.3; }

        .lore-link { font-size: 0.85em; margin: 4px 0 6px; display: block; }
        .lore-link a { color: #0366d6; text-decoration: none; }
        .lore-link a:hover { text-decoration: underline; }

        .date-range {
            font-size: 0.8em;
            color: #888;
            margin-bottom: 16px;
        }
        .date-range a { color: #0366d6; text-decoration: none; }
        .date-range a:hover { text-decoration: underline; }

        /* thread-node scroll margin so the card isn't clipped at the top */
        .thread-node { scroll-margin-top: 8px; }

        /* ── Patch summary ──────────────────────────────────────────── */
        .patch-summary-block {
            background: #fff;
            border-radius: 8px;
            padding: 12px 16px;
            margin-bottom: 20px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.08);
            border-left: 3px solid #4a90d9;
        }
        .patch-summary-label {
            font-size: 0.72em;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 0.06em;
            color: #4a90d9;
            margin-bottom: 4px;
        }
        .patch-summary-text {
            font-size: 0.88em;
            color: #444;
            line-height: 1.55;
        }

        /* ── Thread tree ────────────────────────────────────────────── */
        .thread-tree {
            display: flex;
            flex-direction: column;
            gap: 6px;
        }

        /* Depth indentation via left border */
        .thread-node { position: relative; }
        .thread-children {
            margin-left: 20px;
            padding-left: 12px;
            border-left: 2px solid #e0e0e0;
            margin-top: 6px;
            display: flex;
            flex-direction: column;
            gap: 6px;
        }

        /* ── Review comment card ────────────────────────────────────── */
        .review-comment {
            background: #fff;
            border-radius: 6px;
            padding: 10px 14px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.08);
            font-size: 0.88em;
        }
        .review-comment-header {
            display: flex;
            flex-wrap: wrap;
            align-items: center;
            gap: 6px;
            margin-bottom: 5px;
        }
        .review-author {
            font-weight: 700;
            color: #1a1a1a;
            font-size: 0.95em;
        }

        /* Date chip — links back to the daily report */
        .date-chip {
            font-size: 0.75em;
            color: #777;
            background: #f0f0f0;
            border-radius: 10px;
            padding: 1px 7px;
            text-decoration: none;
            white-space: nowrap;
        }
        a.date-chip:hover { background: #e0e8f5; color: #0366d6; }

        .badge {
            display: inline-block;
            padding: 1px 8px;
            border-radius: 10px;
            font-size: 0.75em;
            font-weight: 600;
        }
        .inline-review-badge {
            display: inline-block;
            padding: 0 6px;
            border-radius: 8px;
            font-size: 0.78em;
            font-weight: 500;
            background: #e3f2fd;
            color: #1565c0;
        }
        .review-tag-badge {
            display: inline-block;
            padding: 0 6px;
            border-radius: 8px;
            font-size: 0.78em;
            font-weight: 500;
            background: #e8f5e9;
            color: #2e7d32;
        }
        .analysis-source-badge {
            display: inline-block;
            padding: 1px 7px;
            border-radius: 10px;
            font-size: 0.72em;
            font-weight: 600;
            border: 1px solid rgba(0,0,0,0.1);
        }

        .review-comment-text {
            color: #444;
            line-height: 1.55;
            margin-bottom: 4px;
        }
        .review-comment-signals {
            margin-top: 3px;
            font-size: 0.85em;
            color: #aaa;
            font-style: italic;
        }

        /* ── Collapsible raw body ───────────────────────────────────── */
        .raw-body-toggle {
            margin-top: 5px;
            font-size: 0.85em;
        }
        .raw-body-toggle summary {
            cursor: pointer;
            color: #888;
            padding: 2px 0;
            font-weight: 500;
            font-size: 0.9em;
            list-style: none;
        }
        .raw-body-toggle summary::-webkit-details-marker { display: none; }
        .raw-body-toggle summary::before { content: "▶ "; font-size: 0.7em; }
        .raw-body-toggle[open] summary::before { content: "▼ "; }
        .raw-body-toggle summary:hover { color: #555; }
        .raw-body-text {
            white-space: pre-wrap;
            font-size: 0.95em;
            background: #f8f8f8;
            padding: 8px 10px;
            border-radius: 4px;
            max-height: 360px;
            overflow-y: auto;
            margin-top: 4px;
            line-height: 1.5;
            color: #444;
            border: 1px solid #e8e8e8;
        }
        .reply-to-label {
            font-size: 0.8em;
            color: #999;
            font-style: italic;
            margin-top: 3px;
        }
        .lore-link {
            display: inline-block;
            margin-top: 4px;
            font-size: 0.82em;
            color: #0366d6;
            text-decoration: none;
            font-weight: 500;
            white-space: nowrap;
        }
        .lore-link:hover { text-decoration: underline; color: #0056b3; }

        .no-reviews {
            color: #aaa;
            font-size: 0.85em;
            font-style: italic;
            padding: 8px 0;
        }

        footer {
            text-align: center;
            color: #bbb;
            font-size: 0.78em;
            margin-top: 36px;
            padding: 16px;
        }
    </style>
</head>
<body>
    <div class="home-link"><a href="../index.html">&larr; Back to reports</a></div>
    <h1>[LSF/MM/BPF TOPIC] 64k (or 16k) base page size on x86</h1>
    <div class="lore-link"><a href="https://lore.kernel.org/all/aZhErt9DZcWI24_v@thinkstation/" target="_blank">View on lore.kernel.org &rarr;</a></div>
    <div class="date-range">Active on: <a href="#2026-02-23">2026-02-23</a> &bull; <a href="#2026-02-20">2026-02-20</a> &bull; <a href="#2026-02-19">2026-02-19</a></div>
    
    <div class="thread-tree">
<div class="thread-node depth-0" id="2026-02-20">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">David (Arm)</span>
<a class="date-chip" href="../2026-02-20.html" title="First appeared in report for 2026-02-20">2026-02-20</a>
<span class="inline-review-badge">Inline Review</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#6c4b00;background:#ffeeba" title="Analysis source: Heuristic">Heuristic</span>
</div>
<div class="review-comment-text">I&#x27;d assume that many applications nowadays can deal with differing page sizes (thanks to some other architectures paving the way). But yes, some real legacy stuff, or stuff that ever only cared about intel still hardcodes pagesize=4k. In Meta&#x27;s fleet, I&#x27;d be quite interesting how much conversion there would have to be done. For legacy apps, you could still run them as 4k pagesize on the same system, of course. I still have to wrap my head around the sub-page mapping here as well. It&#x27;s scary. Re mapcount: I think if any part of the page is mapped, it would be considered mapped -&gt; mapcount += 1. I&#x27;d assume that would work. Devil is in the detail with these things before we have memdescs. E.g., page table have a dedicated type (PGTY_table) and store separate metadata in the ptdesc.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">On 2/20/26 13:07, Kiryl Shutsemau wrote:
&gt; On Fri, Feb 20, 2026 at 11:24:37AM +0100, David Hildenbrand (Arm) wrote:
&gt;&gt;&gt;
&gt;&gt;&gt; Just to clarify, do you want it to be enforced on userspace ABI.
&gt;&gt;&gt; Like, all mappings are 64k aligned?
&gt;&gt;
&gt;&gt; Right, see the proposal from Dev on the list.
&gt;&gt;
&gt;&gt;  From user-space POV, the pagesize would be 64K for these emulated processes.
&gt;&gt; That is, VMAs must be suitable aligned etc.
&gt; 
&gt; Well, it will drastically limit the adoption. We have too much legacy
&gt; stuff on x86.

I&#x27;d assume that many applications nowadays can deal with differing page 
sizes (thanks to some other architectures paving the way).

But yes, some real legacy stuff, or stuff that ever only cared about 
intel still hardcodes pagesize=4k.

In Meta&#x27;s fleet, I&#x27;d be quite interesting how much conversion there 
would have to be done.

For legacy apps, you could still run them as 4k pagesize on the same 
system, of course.

&gt; 
&gt;&gt;&gt;
&gt;&gt;&gt; Waste of memory for page table is solvable and pretty straight forward.
&gt;&gt;&gt; Most of such cases can be solve mechanically by switching to slab.
&gt;&gt;
&gt;&gt; Well, yes, like Willy says, there are already similar custom solutions for
&gt;&gt; s390x and ppc.
&gt;&gt;
&gt;&gt; Pasha talked recently about the memory waste of 16k kernel stacks and how we
&gt;&gt; would want to reduce that to 4k. In your proposal, it would be 64k, unless
&gt;&gt; you somehow manage to allocate multiple kernel stacks from the same 64k
&gt;&gt; page. My head hurts thinking about whether that could work, maybe it could
&gt;&gt; (no idea about guard pages in there, though).
&gt; 
&gt; Kernel stack is allocated from vmalloc. I think mapping them with
&gt; sub-page granularity should be doable.

I still have to wrap my head around the sub-page mapping here as well. 
It&#x27;s scary.

Re mapcount: I think if any part of the page is mapped, it would be 
considered mapped -&gt; mapcount += 1.

&gt; 
&gt; BTW, do you see any reason why slab-allocated stack wouldn&#x27;t work for
&gt; large base page sizes? There&#x27;s no requirement for it be aligned to page
&gt; or PTE, right?

I&#x27;d assume that would work. Devil is in the detail with these things 
before we have memdescs.

E.g., page table have a dedicated type (PGTY_table) and store separate 
metadata in the ptdesc. For kernel stack there was once a proposal to 
have a type but it is not upstream.

&gt; 
&gt;&gt; Let&#x27;s take a look at the history of page size usage on Arm (people can feel
&gt;&gt; free to correct me):
&gt;&gt;
&gt;&gt; (1) Most distros were using 64k on Arm.
&gt;&gt;
&gt;&gt; (2) People realized that 64k was suboptimal many use cases (memory
&gt;&gt;      waste for stacks, pagecache, etc) and started to switch to 4k. I
&gt;&gt;      remember that mostly HPC-centric users sticked to 64k, but there was
&gt;&gt;      also demand from others to be able to stay on 64k.
&gt;&gt;
&gt;&gt; (3) Arm improved performance on a 4k kernel by adding cont-pte support,
&gt;&gt;      trying to get closer to 64k native performance.
&gt;&gt;
&gt;&gt; (4) Achieving 64k native performance is hard, which is why per-process
&gt;&gt;      page sizes are being explored to get the best out of both worlds
&gt;&gt;      (use 64k page size only where it really matters for performance).
&gt;&gt;
&gt;&gt; Arm clearly has the added benefit of actually benefiting from hardware
&gt;&gt; support for 64k.
&gt;&gt;
&gt;&gt; IIUC, what you are proposing feels a bit like traveling back in time when it
&gt;&gt; comes to the memory waste problem that Arm users encountered.
&gt;&gt;
&gt;&gt; Where do you see the big difference to 64k on Arm in your proposal? Would
&gt;&gt; you currently also be running 64k Arm in production and the memory waste etc
&gt;&gt; is acceptable?
&gt; 
&gt; That&#x27;s the point. I don&#x27;t see a big difference to 64k Arm. I want to
&gt; bring this option to x86: at some machine size it makes sense trade
&gt; memory consumption for scalability. I am targeting it to machines with
&gt; over 2TiB of RAM.
&gt; 
&gt; BTW, we do run 64k Arm in our fleet. There&#x27;s some growing pains, but it
&gt; looks good in general We have no plans to switch to 4k (or 16k) at the
&gt; moment. 512M THPs also look good on some workloads.

Okay, that&#x27;s valuable information, thanks!

Being able to remove the sub-page mapping part (or being able to just 
hide it somewhere deep down in arch code) would make this a lot easier 
to digest.

-- 
Cheers,

David
</pre>
</details>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Kalesh Singh</span>
<a class="date-chip" href="../2026-02-20.html" title="First appeared in report for 2026-02-20">2026-02-20</a>
<span class="inline-review-badge">Inline Review</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#6c4b00;background:#ffeeba" title="Analysis source: Heuristic">Heuristic</span>
</div>
<div class="review-comment-text">On Fri, Feb 20, 2026 at 8:30 AM David Hildenbrand (Arm) I think most issues will stem from linkers setting the default ELF segment alignment (max-page-size) for x86 to 4096. So those ELFs will not load correctly or at all on the larger emulated granularity.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">On Fri, Feb 20, 2026 at 8:30 AM David Hildenbrand (Arm)
&lt;david@kernel.org&gt; wrote:
&gt;
&gt; On 2/20/26 13:07, Kiryl Shutsemau wrote:
&gt; &gt; On Fri, Feb 20, 2026 at 11:24:37AM +0100, David Hildenbrand (Arm) wrote:
&gt; &gt;&gt;&gt;
&gt; &gt;&gt;&gt; Just to clarify, do you want it to be enforced on userspace ABI.
&gt; &gt;&gt;&gt; Like, all mappings are 64k aligned?
&gt; &gt;&gt;
&gt; &gt;&gt; Right, see the proposal from Dev on the list.
&gt; &gt;&gt;
&gt; &gt;&gt;  From user-space POV, the pagesize would be 64K for these emulated processes.
&gt; &gt;&gt; That is, VMAs must be suitable aligned etc.
&gt; &gt;
&gt; &gt; Well, it will drastically limit the adoption. We have too much legacy
&gt; &gt; stuff on x86.
&gt;
&gt; I&#x27;d assume that many applications nowadays can deal with differing page
&gt; sizes (thanks to some other architectures paving the way).
&gt;
&gt; But yes, some real legacy stuff, or stuff that ever only cared about
&gt; intel still hardcodes pagesize=4k.

I think most issues will stem from linkers setting the default ELF
segment alignment (max-page-size) for x86 to 4096. So those ELFs will
not load correctly or at all on the larger emulated granularity.

-- Kalesh

&gt;
&gt; In Meta&#x27;s fleet, I&#x27;d be quite interesting how much conversion there
&gt; would have to be done.
&gt;
&gt; For legacy apps, you could still run them as 4k pagesize on the same
&gt; system, of course.
&gt;
&gt; &gt;
&gt; &gt;&gt;&gt;
&gt; &gt;&gt;&gt; Waste of memory for page table is solvable and pretty straight forward.
&gt; &gt;&gt;&gt; Most of such cases can be solve mechanically by switching to slab.
&gt; &gt;&gt;
&gt; &gt;&gt; Well, yes, like Willy says, there are already similar custom solutions for
&gt; &gt;&gt; s390x and ppc.
&gt; &gt;&gt;
&gt; &gt;&gt; Pasha talked recently about the memory waste of 16k kernel stacks and how we
&gt; &gt;&gt; would want to reduce that to 4k. In your proposal, it would be 64k, unless
&gt; &gt;&gt; you somehow manage to allocate multiple kernel stacks from the same 64k
&gt; &gt;&gt; page. My head hurts thinking about whether that could work, maybe it could
&gt; &gt;&gt; (no idea about guard pages in there, though).
&gt; &gt;
&gt; &gt; Kernel stack is allocated from vmalloc. I think mapping them with
&gt; &gt; sub-page granularity should be doable.
&gt;
&gt; I still have to wrap my head around the sub-page mapping here as well.
&gt; It&#x27;s scary.
&gt;
&gt; Re mapcount: I think if any part of the page is mapped, it would be
&gt; considered mapped -&gt; mapcount += 1.
&gt;
&gt; &gt;
&gt; &gt; BTW, do you see any reason why slab-allocated stack wouldn&#x27;t work for
&gt; &gt; large base page sizes? There&#x27;s no requirement for it be aligned to page
&gt; &gt; or PTE, right?
&gt;
&gt; I&#x27;d assume that would work. Devil is in the detail with these things
&gt; before we have memdescs.
&gt;
&gt; E.g., page table have a dedicated type (PGTY_table) and store separate
&gt; metadata in the ptdesc. For kernel stack there was once a proposal to
&gt; have a type but it is not upstream.
&gt;
&gt; &gt;
&gt; &gt;&gt; Let&#x27;s take a look at the history of page size usage on Arm (people can feel
&gt; &gt;&gt; free to correct me):
&gt; &gt;&gt;
&gt; &gt;&gt; (1) Most distros were using 64k on Arm.
&gt; &gt;&gt;
&gt; &gt;&gt; (2) People realized that 64k was suboptimal many use cases (memory
&gt; &gt;&gt;      waste for stacks, pagecache, etc) and started to switch to 4k. I
&gt; &gt;&gt;      remember that mostly HPC-centric users sticked to 64k, but there was
&gt; &gt;&gt;      also demand from others to be able to stay on 64k.
&gt; &gt;&gt;
&gt; &gt;&gt; (3) Arm improved performance on a 4k kernel by adding cont-pte support,
&gt; &gt;&gt;      trying to get closer to 64k native performance.
&gt; &gt;&gt;
&gt; &gt;&gt; (4) Achieving 64k native performance is hard, which is why per-process
&gt; &gt;&gt;      page sizes are being explored to get the best out of both worlds
&gt; &gt;&gt;      (use 64k page size only where it really matters for performance).
&gt; &gt;&gt;
&gt; &gt;&gt; Arm clearly has the added benefit of actually benefiting from hardware
&gt; &gt;&gt; support for 64k.
&gt; &gt;&gt;
&gt; &gt;&gt; IIUC, what you are proposing feels a bit like traveling back in time when it
&gt; &gt;&gt; comes to the memory waste problem that Arm users encountered.
&gt; &gt;&gt;
&gt; &gt;&gt; Where do you see the big difference to 64k on Arm in your proposal? Would
&gt; &gt;&gt; you currently also be running 64k Arm in production and the memory waste etc
&gt; &gt;&gt; is acceptable?
&gt; &gt;
&gt; &gt; That&#x27;s the point. I don&#x27;t see a big difference to 64k Arm. I want to
&gt; &gt; bring this option to x86: at some machine size it makes sense trade
&gt; &gt; memory consumption for scalability. I am targeting it to machines with
&gt; &gt; over 2TiB of RAM.
&gt; &gt;
&gt; &gt; BTW, we do run 64k Arm in our fleet. There&#x27;s some growing pains, but it
&gt; &gt; looks good in general We have no plans to switch to 4k (or 16k) at the
&gt; &gt; moment. 512M THPs also look good on some workloads.
&gt;
&gt; Okay, that&#x27;s valuable information, thanks!
&gt;
&gt; Being able to remove the sub-page mapping part (or being able to just
&gt; hide it somewhere deep down in arch code) would make this a lot easier
&gt; to digest.
&gt;
&gt; --
&gt; Cheers,
&gt;
&gt; David
&gt;
</pre>
</details>
</div>
</div>
<div class="thread-node depth-0" id="2026-02-23">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">David (Arm)</span>
<a class="date-chip" href="../2026-02-20_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-23">2026-02-23</a>
<span class="inline-review-badge">Inline Review</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#6c4b00;background:#ffeeba" title="Analysis source: Heuristic">Heuristic</span>
</div>
<div class="review-comment-text">Right, I assume that they will have to be thought about that, and possibly, some binaries/libraries recompiled.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">On 2/20/26 20:33, Kalesh Singh wrote:
&gt; On Fri, Feb 20, 2026 at 8:30\u202fAM David Hildenbrand (Arm)
&gt; &lt;david@kernel.org&gt; wrote:
&gt;&gt;
&gt;&gt; On 2/20/26 13:07, Kiryl Shutsemau wrote:
&gt;&gt;&gt;
&gt;&gt;&gt; Well, it will drastically limit the adoption. We have too much legacy
&gt;&gt;&gt; stuff on x86.
&gt;&gt;
&gt;&gt; I&#x27;d assume that many applications nowadays can deal with differing page
&gt;&gt; sizes (thanks to some other architectures paving the way).
&gt;&gt;
&gt;&gt; But yes, some real legacy stuff, or stuff that ever only cared about
&gt;&gt; intel still hardcodes pagesize=4k.
&gt; 
&gt; I think most issues will stem from linkers setting the default ELF
&gt; segment alignment (max-page-size) for x86 to 4096. So those ELFs will
&gt; not load correctly or at all on the larger emulated granularity.

Right, I assume that they will have to be thought about that, and 
possibly, some binaries/libraries recompiled.

-- 
Cheers,

David
</pre>
</details>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Kiryl Shutsemau (author)</span>
<a class="date-chip" href="../2026-02-20_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-23">2026-02-23</a>
<span class="inline-review-badge">Inline Review</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#6c4b00;background:#ffeeba" title="Analysis source: Heuristic">Heuristic</span>
</div>
<div class="review-comment-text">I think backward compatibility is important and I believe we can get there without ABI break. And optimize from there. BTW, x86-64 SysV ABI allows for 64k page size: Systems are permitted to use any power-of-two page size between 4KB and 64KB, inclusive. But it doesn&#x27;t work in practice.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">On Mon, Feb 23, 2026 at 12:04:10PM +0100, David Hildenbrand (Arm) wrote:
&gt; On 2/20/26 20:33, Kalesh Singh wrote:
&gt; &gt; On Fri, Feb 20, 2026 at 8:30\u202fAM David Hildenbrand (Arm)
&gt; &gt; &lt;david@kernel.org&gt; wrote:
&gt; &gt; &gt; 
&gt; &gt; &gt; On 2/20/26 13:07, Kiryl Shutsemau wrote:
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; Well, it will drastically limit the adoption. We have too much legacy
&gt; &gt; &gt; &gt; stuff on x86.
&gt; &gt; &gt; 
&gt; &gt; &gt; I&#x27;d assume that many applications nowadays can deal with differing page
&gt; &gt; &gt; sizes (thanks to some other architectures paving the way).
&gt; &gt; &gt; 
&gt; &gt; &gt; But yes, some real legacy stuff, or stuff that ever only cared about
&gt; &gt; &gt; intel still hardcodes pagesize=4k.
&gt; &gt; 
&gt; &gt; I think most issues will stem from linkers setting the default ELF
&gt; &gt; segment alignment (max-page-size) for x86 to 4096. So those ELFs will
&gt; &gt; not load correctly or at all on the larger emulated granularity.
&gt; 
&gt; Right, I assume that they will have to be thought about that, and possibly,
&gt; some binaries/libraries recompiled.

I think backward compatibility is important and I believe we can get
there without ABI break. And optimize from there.

BTW, x86-64 SysV ABI allows for 64k page size:

	Systems are permitted to use any power-of-two page size between
	4KB and 64KB, inclusive.

But it doesn&#x27;t work in practice.

-- 
  Kiryl Shutsemau / Kirill A. Shutemov
</pre>
</details>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">David (Arm)</span>
<a class="date-chip" href="../2026-02-20_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-23">2026-02-23</a>
<span class="inline-review-badge">Inline Review</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#6c4b00;background:#ffeeba" title="Analysis source: Heuristic">Heuristic</span>
</div>
<div class="review-comment-text">Even in well controlled environments you would run in a hyperscaler?</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">On 2/23/26 12:13, Kiryl Shutsemau wrote:
&gt; On Mon, Feb 23, 2026 at 12:04:10PM +0100, David Hildenbrand (Arm) wrote:
&gt;&gt; On 2/20/26 20:33, Kalesh Singh wrote:
&gt;&gt;&gt; On Fri, Feb 20, 2026 at 8:30\u202fAM David Hildenbrand (Arm)
&gt;&gt;&gt; &lt;david@kernel.org&gt; wrote:
&gt;&gt;&gt;
&gt;&gt;&gt; I think most issues will stem from linkers setting the default ELF
&gt;&gt;&gt; segment alignment (max-page-size) for x86 to 4096. So those ELFs will
&gt;&gt;&gt; not load correctly or at all on the larger emulated granularity.
&gt;&gt;
&gt;&gt; Right, I assume that they will have to be thought about that, and possibly,
&gt;&gt; some binaries/libraries recompiled.
&gt; 
&gt; I think backward compatibility is important and I believe we can get
&gt; there without ABI break. And optimize from there.
&gt; 
&gt; BTW, x86-64 SysV ABI allows for 64k page size:
&gt; 
&gt; 	Systems are permitted to use any power-of-two page size between
&gt; 	4KB and 64KB, inclusive.
&gt; 
&gt; But it doesn&#x27;t work in practice.

Even in well controlled environments you would run in a hyperscaler?

-- 
Cheers,

David
</pre>
</details>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Kiryl Shutsemau (author)</span>
<a class="date-chip" href="../2026-02-20_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-23">2026-02-23</a>
<span class="inline-review-badge">Inline Review</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#6c4b00;background:#ffeeba" title="Analysis source: Heuristic">Heuristic</span>
</div>
<div class="review-comment-text">I have not invested much time into investigating this. I intentionally targeted compatible version assuming it will be better received by upstream. I want it to be usable outside specially cured userspace. 64k might not be good fit for a desktop, but 16k can be a different story.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">On Mon, Feb 23, 2026 at 12:27:33PM +0100, David Hildenbrand (Arm) wrote:
&gt; On 2/23/26 12:13, Kiryl Shutsemau wrote:
&gt; &gt; On Mon, Feb 23, 2026 at 12:04:10PM +0100, David Hildenbrand (Arm) wrote:
&gt; &gt; &gt; On 2/20/26 20:33, Kalesh Singh wrote:
&gt; &gt; &gt; &gt; On Fri, Feb 20, 2026 at 8:30\u202fAM David Hildenbrand (Arm)
&gt; &gt; &gt; &gt; &lt;david@kernel.org&gt; wrote:
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; I think most issues will stem from linkers setting the default ELF
&gt; &gt; &gt; &gt; segment alignment (max-page-size) for x86 to 4096. So those ELFs will
&gt; &gt; &gt; &gt; not load correctly or at all on the larger emulated granularity.
&gt; &gt; &gt; 
&gt; &gt; &gt; Right, I assume that they will have to be thought about that, and possibly,
&gt; &gt; &gt; some binaries/libraries recompiled.
&gt; &gt; 
&gt; &gt; I think backward compatibility is important and I believe we can get
&gt; &gt; there without ABI break. And optimize from there.
&gt; &gt; 
&gt; &gt; BTW, x86-64 SysV ABI allows for 64k page size:
&gt; &gt; 
&gt; &gt; 	Systems are permitted to use any power-of-two page size between
&gt; &gt; 	4KB and 64KB, inclusive.
&gt; &gt; 
&gt; &gt; But it doesn&#x27;t work in practice.
&gt; 
&gt; Even in well controlled environments you would run in a hyperscaler?

I have not invested much time into investigating this.

I intentionally targeted compatible version assuming it will be better
received by upstream. I want it to be usable outside specially cured
userspace. 64k might not be good fit for a desktop, but 16k can be a
different story.

-- 
  Kiryl Shutsemau / Kirill A. Shutemov
</pre>
</details>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Dave Hansen</span>
<a class="date-chip" href="../2026-02-20_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-23">2026-02-23</a>
<span class="inline-review-badge">Inline Review</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#6c4b00;background:#ffeeba" title="Analysis source: Heuristic">Heuristic</span>
</div>
<div class="review-comment-text">I think what Kirill is trying to say is that &quot;it breaks userspace&quot;. ;) A hyperscaler (or other &quot;embedded&quot; environment) might be willing or able to go fix up userspace breakage. I would suspect our high frequency trading friends would be all over this if it shaved a microsecond off their receive times. The more important question is what it breaks and how badly it breaks things.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">On 2/23/26 03:27, David Hildenbrand (Arm) wrote:
...
&gt;&gt; BTW, x86-64 SysV ABI allows for 64k page size:
&gt;&gt;
&gt;&gt; Systems are permitted to use any power-of-two page size between
&gt;&gt; 4KB and 64KB, inclusive.
&gt;&gt;
&gt;&gt; But it doesn&#x27;t work in practice.
&gt; 
&gt; Even in well controlled environments you would run in a hyperscaler?

I think what Kirill is trying to say is that &quot;it breaks userspace&quot;. ;)

A hyperscaler (or other &quot;embedded&quot; environment) might be willing or able
to go fix up userspace breakage. I would suspect our high frequency
trading friends would be all over this if it shaved a microsecond off
their receive times.

The more important question is what it breaks and how badly it breaks
things. 5-level paging, for instance, broke some JITs that historically
used the new (&gt;48) upper virtual address bits for metadata. The gains
from 5-level paging were big enough and the userspace breakage was
confined and fixable enough that 5-level paging was viable.

I&#x27;m not sure which side a larger base page side will fall on, though. Is
it going to be an out-of-tree hack that a few folks use, or will it be
more like 5-level paging and be good enough that it goes into mainline?
</pre>
</details>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">David (Arm)</span>
<a class="date-chip" href="../2026-02-20_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-23">2026-02-23</a>
<span class="inline-review-badge">Inline Review</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#6c4b00;background:#ffeeba" title="Analysis source: Heuristic">Heuristic</span>
</div>
<div class="review-comment-text">Yes. Probably similar to Intel proposing an actual 64k page size. Expected. :) Just thinking about VMAs spanning partial pages makes me shiver. Or A single page spanning multiple VMAs. I haven&#x27;t seen the code yet, but I am certain that I will not like it. I&#x27;m happy to be proven wrong :)</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">On 2/23/26 16:14, Dave Hansen wrote:
&gt; On 2/23/26 03:27, David Hildenbrand (Arm) wrote:
&gt; ...
&gt;&gt;&gt; BTW, x86-64 SysV ABI allows for 64k page size:
&gt;&gt;&gt;
&gt;&gt;&gt;  Systems are permitted to use any power-of-two page size between
&gt;&gt;&gt;  4KB and 64KB, inclusive.
&gt;&gt;&gt;
&gt;&gt;&gt; But it doesn&#x27;t work in practice.
&gt;&gt;
&gt;&gt; Even in well controlled environments you would run in a hyperscaler?
&gt; 
&gt; I think what Kirill is trying to say is that &quot;it breaks userspace&quot;. ;)

Yes. Probably similar to Intel proposing an actual 64k page size. 
Expected. :)

&gt; 
&gt; A hyperscaler (or other &quot;embedded&quot; environment) might be willing or able
&gt; to go fix up userspace breakage. I would suspect our high frequency
&gt; trading friends would be all over this if it shaved a microsecond off
&gt; their receive times.
&gt; 
&gt; The more important question is what it breaks and how badly it breaks
&gt; things. 5-level paging, for instance, broke some JITs that historically
&gt; used the new (&gt;48) upper virtual address bits for metadata. The gains
&gt; from 5-level paging were big enough and the userspace breakage was
&gt; confined and fixable enough that 5-level paging was viable.
&gt; 
&gt; I&#x27;m not sure which side a larger base page side will fall on, though. Is
&gt; it going to be an out-of-tree hack that a few folks use, or will it be
&gt; more like 5-level paging and be good enough that it goes into mainline?

Just thinking about VMAs spanning partial pages makes me shiver. Or A 
single page spanning multiple VMAs.

I haven&#x27;t seen the code yet, but I am certain that I will not like it.

I&#x27;m happy to be proven wrong :)

-- 
Cheers,

David
</pre>
</details>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Kiryl Shutsemau (author)</span>
<a class="date-chip" href="../2026-02-20_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-23">2026-02-23</a>
<span class="inline-review-badge">Inline Review</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#6c4b00;background:#ffeeba" title="Analysis source: Heuristic">Heuristic</span>
</div>
<div class="review-comment-text">Hate to break it to you, but we have it now upstream :P THP can span multiple VMAs. And can be partially mapped. The only new thing is that we allow this for order-0 page now. And you cannot realistically recover wasted memory -- no deferred split. I will do my best, but no promises :)</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">On Mon, Feb 23, 2026 at 04:31:56PM +0100, David Hildenbrand (Arm) wrote:
&gt; On 2/23/26 16:14, Dave Hansen wrote:
&gt; &gt; On 2/23/26 03:27, David Hildenbrand (Arm) wrote:
&gt; &gt; ...
&gt; &gt; &gt; &gt; BTW, x86-64 SysV ABI allows for 64k page size:
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt;  Systems are permitted to use any power-of-two page size between
&gt; &gt; &gt; &gt;  4KB and 64KB, inclusive.
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; But it doesn&#x27;t work in practice.
&gt; &gt; &gt; 
&gt; &gt; &gt; Even in well controlled environments you would run in a hyperscaler?
&gt; &gt; 
&gt; &gt; I think what Kirill is trying to say is that &quot;it breaks userspace&quot;. ;)
&gt; 
&gt; Yes. Probably similar to Intel proposing an actual 64k page size. Expected.
&gt; :)
&gt; 
&gt; &gt; 
&gt; &gt; A hyperscaler (or other &quot;embedded&quot; environment) might be willing or able
&gt; &gt; to go fix up userspace breakage. I would suspect our high frequency
&gt; &gt; trading friends would be all over this if it shaved a microsecond off
&gt; &gt; their receive times.
&gt; &gt; 
&gt; &gt; The more important question is what it breaks and how badly it breaks
&gt; &gt; things. 5-level paging, for instance, broke some JITs that historically
&gt; &gt; used the new (&gt;48) upper virtual address bits for metadata. The gains
&gt; &gt; from 5-level paging were big enough and the userspace breakage was
&gt; &gt; confined and fixable enough that 5-level paging was viable.
&gt; &gt; 
&gt; &gt; I&#x27;m not sure which side a larger base page side will fall on, though. Is
&gt; &gt; it going to be an out-of-tree hack that a few folks use, or will it be
&gt; &gt; more like 5-level paging and be good enough that it goes into mainline?
&gt; 
&gt; Just thinking about VMAs spanning partial pages makes me shiver. Or A
&gt; single page spanning multiple VMAs.

Hate to break it to you, but we have it now upstream :P

THP can span multiple VMAs. And can be partially mapped.

The only new thing is that we allow this for order-0 page now. And you
cannot realistically recover wasted memory -- no deferred split.

&gt; I haven&#x27;t seen the code yet, but I am certain that I will not like it.
&gt; 
&gt; I&#x27;m happy to be proven wrong :)

I will do my best, but no promises :)

-- 
  Kiryl Shutsemau / Kirill A. Shutemov
</pre>
</details>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">David (Arm)</span>
<a class="date-chip" href="../2026-02-20_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-23">2026-02-23</a>
<span class="inline-review-badge">Inline Review</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#6c4b00;background:#ffeeba" title="Analysis source: Heuristic">Heuristic</span>
</div>
<div class="review-comment-text">Single mapcount, single anon-exclusive flag. Completely different story :P</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">&gt;&gt;
&gt;&gt; Just thinking about VMAs spanning partial pages makes me shiver. Or A
&gt;&gt; single page spanning multiple VMAs.
&gt; 
&gt; Hate to break it to you, but we have it now upstream :P
&gt; 
&gt; THP can span multiple VMAs. And can be partially mapped.

Single mapcount, single anon-exclusive flag.

Completely different story :P

-- 
Cheers,

David
</pre>
</details>
</div>
</div>
</div>

    <footer>LKML Daily Activity Tracker</footer>
    <script>
    // When arriving via a date anchor (e.g. #2026-02-15 from a daily report),
    // scroll the anchor into view after a brief delay so layout is complete.
    (function () {
        var hash = window.location.hash;
        if (!hash) return;
        var target = document.getElementById(hash.slice(1));
        if (!target) return;
        setTimeout(function () {
            target.scrollIntoView({behavior: 'smooth', block: 'start'});
        }, 80);
    })();
    </script>
</body>
</html>