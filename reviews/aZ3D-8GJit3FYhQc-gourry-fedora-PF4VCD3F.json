{
  "thread_id": "aZ3D_8GJit3FYhQc@gourry-fedora-PF4VCD3F",
  "subject": "[RFC PATCH v5 00/10] mm: Hot page tracking and promotion infrastructure",
  "url": "https://lore.kernel.org/all/aZ3D_8GJit3FYhQc@gourry-fedora-PF4VCD3F/",
  "dates": {
    "2026-02-09": {
      "report_file": "2026-02-24_ollama_llama3.1-8b.html",
      "developer": "Gregory Price",
      "reviews": [
        {
          "author": "Bharata Rao (author)",
          "summary": "The author addressed a concern about the performance of the pghot subsystem in certain scenarios, specifically the NUMAB2 benchmark and the hwhints source. The author provided results from microbenchmarks that show the patched case performing similarly to the base case in most scenarios, but noted that the pgtscan source needs tuning. The author did not commit to making any changes or fixes, instead presenting the results as evidence of the subsystem's performance.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "no clear resolution signal",
            "author presents results without committing to change"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Here is the first set of results from a microbenchmark:\n\nTest system details\n-------------------\n3 node AMD Zen5 system with 2 regular NUMA nodes (0, 1) and a CXL node (2)\n\n$ numactl -H\navailable: 3 nodes (0-2)\nnode 0 cpus: 0-95,192-287\nnode 0 size: 128460 MB\nnode 1 cpus: 96-191,288-383\nnode 1 size: 128893 MB\nnode 2 cpus:\nnode 2 size: 257993 MB\nnode distances:\nnode   0   1   2\n  0:  10  32  50\n  1:  32  10  60\n  2:  255  255  10\n\nHotness sources\n---------------\nNUMAB0 - Without NUMA Balancing in base case and with no source enabled\n         in the patched case. No migrations occur.\nNUMAB2 - Existing hot page promotion for the base case and\n         use of hint faults as source in the patched case.\npgtscan - Klruscand (MGLRU based PTE A bit scanning) source\nhwhints - IBS as source\n\nPghot by default promotes after two accesses but for NUMAB2 source,\npromotion is done after one access to match the base behaviour.\n(/sys/kernel/debug/pghot/freq_threshold=1)\n\n==============================================================\nScenario 1 - Enough memory in toptier and hence only promotion\n==============================================================\nMulti-threaded application with 64 threads that access memory at 4K granularity\nrepetitively and randomly. The number of accesses per thread and the randomness\npattern for each thread are fixed beforehand. The accesses are divided into\nstores and loads in the ratio of 50:50.\n\nBenchmark threads run on Node 0, while memory is initially provisioned on\nCXL node 2 before the accesses start.\n\nRepetitive accesses results in lowertier pages becoming hot and kmigrated\ndetecting and migrating them. The benchmark score is the time taken to finish\nthe accesses in microseconds. The sooner it finishes the better it is. All the\nnumbers shown below are average of 3 runs.\n\nDefault mode - Time taken (microseconds, lower is better)\n---------------------------------------------------------\nSource          Base            Pghot\n---------------------------------------------------------\nNUMAB0          117,069,417     115,802,776\nNUMAB2          102,918,471     103,378,828\npgtscan         NA              110,203,286\nhwhints         NA              92,880,388\n---------------------------------------------------------\n\nDefault mode - Pages migrated (pgpromote_success)\n---------------------------------------------------------\nSource          Base            Pghot\n---------------------------------------------------------\nNUMAB0          0               0\nNUMAB2          2097147         2097131\npgtscan         NA              2097130\nhwhints         NA              1706556\n---------------------------------------------------------\n\nPrecision mode - Time taken (microseconds, lower is better)\n-----------------------------------------------------------\nSource          Base            Pghot\n-----------------------------------------------------------\nNUMAB0          117,069,417     115,078,527\nNUMAB2          102,918,471     101,742,985\npgtscan         NA              110,024,513     NA\nhwhints         NA              101,163,603     NA\n-----------------------------------------------------------\n\nPrecision mode - Pages migrated (pgpromote_success)\n---------------------------------------------------\nSource          Base            Pghot\n---------------------------------------------------\nNUMAB0          0               0\nNUMAB2          2097147         2097144\npgtscan         NA              2097129\nhwhints         NA              1144304\n---------------------------------------------------\n\n- The NUMAB2 benchmark numbers and pgpromote_success numbers more\n  or less match in base and patched case.\n- Though the pgtscan case promotes all possible pages, the\n  benchmark number suffers. This source needs tuning.\n- Hwhints case is able to provide benchmark numbers similar to\n  base NUMAB2 even with less number of migrations.\n- With both default and precision modes of pghot the benchmark\n  behaves more or less similarly.\n\n==============================================================\nScenario 2 - Toptier memory overcommited, promotion + demotion\n==============================================================\nSingle threaded application that allocates memory on both DRAM and CXL nodes\nusing mmap(MAP_POPULATE). Every 1G region of allocated memory on CXL node is\naccessed at 4K granularity randomly and repetitively to build up the notion\nof hotness in the 1GB region that is under access. This should drive promotion.\nFor promotion to work successfully, the DRAM memory that has been provisioned\n(and not being accessed) should be demoted first. There is enough free memory\nin the CXL node to for demotions.\n\nIn summary, this benchmark creates a memory pressure on DRAM node and does\nCXL memory accesses to drive both demotion and promotion.\n\nThe number of accesses are fixed and hence, the quicker the accessed pages\nget promoted to DRAM, the sooner the benchmark is expected to finish.\nAll the numbers shown below are average of 3 runs.\n\nDRAM-node                       = 1\nCXL-node                        = 2\nInitial DRAM alloc ratio        = 75%\nAllocation-size                 = 171798691840\nInitial DRAM Alloc-size         = 128849018880\nInitial CXL Alloc-size          = 42949672960\nHot-region-size                 = 1073741824\nNr-regions                      = 160\nNr-regions DRAM                 = 120 (provisioned but not accessed)\nNr-hot-regions CXL              = 40\nAccess pattern                  = random\nAccess granularity              = 4096\nDelay b/n accesses              = 0\nLoad/store ratio                = 50l50s\nTHP used                        = no\nNr accesses                     = 42949672960\nNr repetitions                  = 1024\n\nDefault mode - Time taken (microseconds, lower is better)\n------------------------------------------------------\nSource          Base            Pghot\n------------------------------------------------------\nNUMAB0          63,809,267      60,794,786\nNUMAB2          67,541,601      62,376,991\npgtscan         NA              67,902,126\nhwhints         NA              59,872,525\n------------------------------------------------------\n\nDefault mode - Pages migrated (pgpromote_success)\n-------------------------------------------------\nSource          Base            Pghot\n-------------------------------------------------\nNUMAB0          0               0\nNUMAB2          179635          932693  (High R2R variation in base)\npgtscan         NA              27487\nhwhints         NA              274\n---------------------------------------\n\nPrecision mode - Time taken (microseconds, lower is better)\n------------------------------------------------------\nSource          Base            Pghot\n------------------------------------------------------\nNUMAB0          63,809,267      64,553,914\nNUMAB2          67,541,601      62,148,082\npgtscan         NA              65,073,396\nhwhints         NA              59,958,655\n------------------------------------------------------\n\nPrecision mode - Pages migrated (pgpromote_success)\n---------------------------------------------------\nSource          Base            Pghot\n---------------------------------------------------\nNUMAB0          0               0\nNUMAB2          179635          988360  (High R2R variaion in base)\npgtscan         NA              21418   (High R2R variation in patched)\nhwhints         NA              174     (High R2R variation in patched)\n---------------------------------------------------\n\n- The base case itself doesn't show any improvement in benchmark numbers due\n  to hot page promotion. The same pattern is seen in pghot case with all\n  the sources except hwhints. The benchmark itself may need tuning so that\n  promotion helps.\n- There is a high run to run variation in the number of pages promoted in\n  base case.\n- Most promotion attempts in base case fail because the NUMA hint fault\n  latency is found to exceed the threshold value (default threshold\n  is 1000ms) in majority of the promotion attempts.\n- Unlike base NUMAB2 where the hint fault latency is the difference between the\n  PTE update time (during scanning) and the access time (hint fault), pghot uses\n  a single latency threshold (4000ms in pghot-default and 5000ms in\n  pghot-precise) for two purposes.\n        1. If the time difference between successive accesses are within the\n           threshold, the page is marked as hot.\n        2. Later when kmigrated picks up the page for migration, it will migrate\n           only if the difference between the current time and the time when the\n          page was marked hot is with the threshold.\n  Because of the above difference in behaviour, more number of pages get\n  qualified for promotion compared to base NUMAB2.",
          "reply_to": "",
          "message_date": "2026-02-09",
          "message_id": ""
        },
        {
          "author": "Bharata Rao (author)",
          "summary": "The author addressed a concern about the performance benefits of hot page promotion, specifically in scenarios where toptier memory is overcommitted. They provided benchmark results from redis-memtier and explained that while there's no clear benefit seen in one scenario, the number of pages promoted remains similar across all cases.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "no clear benefit",
            "similar performance"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Numbers from redis-memtier benchmark:\n\nTest system details\n-------------------\n3 node AMD Zen5 system with 2 regular NUMA nodes (0, 1) and a CXL node (2)\n\n$ numactl -H\navailable: 3 nodes (0-2)\nnode 0 cpus: 0-95,192-287\nnode 0 size: 128460 MB\nnode 1 cpus: 96-191,288-383\nnode 1 size: 128893 MB\nnode 2 cpus:\nnode 2 size: 257993 MB\nnode distances:\nnode   0   1   2\n  0:  10  32  50\n  1:  32  10  60\n  2:  255  255  10\n\nHotness sources\n---------------\nNUMAB0 - Without NUMA Balancing in base case and with no source enabled\n         in the patched case. No migrations occur.\nNUMAB2 - Existing hot page promotion for the base case and\n         use of hint faults as source in the patched case.\n\nPghot by default promotes after two accesses but for NUMAB2 source,\npromotion is done after one access to match the base behaviour.\n(/sys/kernel/debug/pghot/freq_threshold=1)\n\n==============================================================\nScenario 1 - Enough memory in toptier and hence only promotion\n==============================================================\nIn the setup phase, 64GB database is provisioned and explicitly moved\nto Node 2 by migrating redis-server's memory to Node 2.\nMemtier is run on Node 1.\n\nParallel distribution, 50% of the keys accessed, each 4 times.\n16        Threads\n100       Connections per thread\n77808     Requests per client\n\n==================================================================================================\nType         Ops/sec    Avg. Latency     p50 Latency     p99 Latency   p99.9\nLatency       KB/sec\n--------------------------------------------------------------------------------------------------\nBase, NUMAB0\nTotals     225827.75       226.49746       225.27900       425.98300\n454.65500    513106.09\n--------------------------------------------------------------------------------------------------\nBase, NUMAB2\nTotals     254869.29       205.61759       216.06300       399.35900\n454.65500    579091.74\n--------------------------------------------------------------------------------------------------\npghot-default, NUMAB2\nTotals     264229.35       202.81411       215.03900       393.21500\n446.46300    600358.86\n--------------------------------------------------------------------------------------------------\npghot-precise, NUMAB2\nTotals     261136.17       203.32692       215.03900       391.16700\n446.46300    593330.81\n==================================================================================================\n\npgpromote_success\n==================================\nBase, NUMAB0            0\nBase, NUMAB2            10,435,178\npghot-default, NUMAB2   10,435,031\npghot-precise, NUMAB2   10,435,245\n==================================\n\n- There is a clear benefit of hot page promotion seen. Both\n  base and pghot show similar benefits.\n- The number of pages promoted in both cases are more or less\n  same.\n\n==============================================================\nScenario 2 - Toptier memory overcommited, promotion + demotion\n==============================================================\nIn the setup phase, 192GB database is provisioned. The database occupies\nNode 1 entirely(~128GB) and spills over to Node 2 (~64GB).\nMemtier is run on Node 1.\n\nParallel distribution, 50% of the keys accessed, each 4 times.\n16        Threads\n100       Connections per thread\n233424    Requests per client\n\n==================================================================================================\nType         Ops/sec    Avg. Latency     p50 Latency     p99 Latency   p99.9\nLatency       KB/sec\n--------------------------------------------------------------------------------------------------\nBase, NUMAB0\nTotals     246474.55       211.90623       192.51100       370.68700\n448.51100    560235.63\n--------------------------------------------------------------------------------------------------\nBase, NUMAB2\nTotals     232790.88       221.18604       214.01500       419.83900\n509.95100    529132.72\n--------------------------------------------------------------------------------------------------\npghot-default, NUMAB2\nTotals     241615.60       216.12761       210.94300       391.16700\n475.13500    549191.27\n--------------------------------------------------------------------------------------------------\npghot-precise, NUMAB2\nTotals     238557.37       217.57630       207.87100       395.26300\n471.03900    542239.92\n==================================================================================================\n                        pgpromote_success       pgdemote_kswapd\n===============================================================\nBase, NUMAB0            0                       832,494\nBase, NUMAB2            352,075                 720,409\npghot-default, NUMAB2   25,865,321              26,154,984\npghot-precise, NUMAB2   25,525,429              25,838,095\n===============================================================\n\n- No clear benefit is seen with hot page promotion both in base and pghot case.\n- Most promotion attempts in base case fail because the NUMA hint fault latency\n  is found to exceed the threshold value (default threshold of 1000ms) in\n  majority of the promotion attempts.\n- Unlike base NUMAB2 where the hint fault latency is the difference between the\n  PTE update time (during scanning) and the access time (hint fault), pghot uses\n  a single latency threshold (4000ms in pghot-default and 5000ms in\n  pghot-precise) for two purposes.\n        1. If the time difference between successive accesses are within the\n           threshold, the page is marked as hot.\n        2. Later when kmigrated picks up the page for migration, it will migrate\n           only if the difference between the current time and the time when the\n          page was marked hot is with the threshold.\n  Because of the above difference in behaviour, more number of pages get\n  qualified for promotion compared to base NUMAB2.",
          "reply_to": "",
          "message_date": "2026-02-09",
          "message_id": ""
        }
      ],
      "analysis_source": "llm"
    },
    "2026-02-11": {
      "report_file": "2026-02-24_ollama_llama3.1-8b.html",
      "developer": "Gregory Price",
      "reviews": [
        {
          "author": "Bharata Rao (author)",
          "summary": "The author is addressing a concern about the performance of pghot-default mode, specifically why it doesn't show benefits despite achieving similar page promotion numbers as NUMAB2. The author explains that this is because pghot-default promotes to NID=0 by default, which may not be beneficial since processes are running on both Node 0 and Node 1.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "no clear resolution signal",
            "author provides explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Here are Graph500 numbers for the hint fault source:\n\nTest system details\n-------------------\n3 node AMD Zen5 system with 2 regular NUMA nodes (0, 1) and a CXL node (2)\n\n$ numactl -H\navailable: 3 nodes (0-2)\nnode 0 cpus: 0-95,192-287\nnode 0 size: 128460 MB\nnode 1 cpus: 96-191,288-383\nnode 1 size: 128893 MB\nnode 2 cpus:\nnode 2 size: 257993 MB\nnode distances:\nnode   0   1   2\n  0:  10  32  50\n  1:  32  10  60\n  2:  255  255  10\n\nHotness sources\n---------------\nNUMAB0 - Without NUMA Balancing in base case and with no source enabled\n         in the pghot case. No migrations occur.\nNUMAB2 - Existing hot page promotion for the base case and\n         use of hint faults as source in the pghot case.\n\nPghot by default promotes after two accesses but for NUMAB2 source,\npromotion is done after one access to match the base behaviour.\n(/sys/kernel/debug/pghot/freq_threshold=1)\n\nGraph500 details\n----------------\nCommand: mpirun -n 128 --bind-to core --map-by core\ngraph500/src/graph500_reference_bfs 28 16\n\nAfter the graph creation, the processes are stopped and data is migrated\nto CXL node 2 before continuing so that BFS phase starts accessing lower\ntier memory.\n\nTotal memory usage is slightly over 100GB and will fit within Node 0 and 1.\nHence there is no memory pressure to induce demotions.\n\n=====================================================================================\n                        Base            Base            pghot-default\npghot-precise\n                        NUMAB0          NUMAB2          NUMAB2          NUMAB2\n=====================================================================================\nharmonic_mean_TEPS      5.10676e+08     7.56804e+08     5.92473e+08     7.47091e+08\nmean_time               8.41027         5.67508         7.24915         5.74886\nmedian_TEPS             5.11535e+08     7.24252e+08     5.63155e+08     7.71638e+08\nmax_TEPS                5.1785e+08      1.06051e+09     7.88018e+08     1.0504e+09\n\npgpromote_success       0               13557718        13737730        13734469\nnuma_pte_updates        0               26491591        26848847        26726856\nnuma_hint_faults        0               13558077        13882743        13798024\n=====================================================================================\n\n\n- The base case shows a good improvement with NUMAB2(48%) in harmonic_mean_TEPS.\n- The same improvement gets maintained with pghot-precise too (46%).\n- pghot-default mode doesn't show benefit even when achieving similar page promotion\n  numbers. This mode doesn't track accessing NID and by default promotes to NID=0\n  which probably isn't all that beneficial as processes are running on both Node 0\n  and Node 1.",
          "reply_to": "",
          "message_date": "2026-02-11",
          "message_id": ""
        },
        {
          "author": "Bharata Rao (author)",
          "summary": "Author acknowledged a bug in the folio isolation code, specifically that it should hold a folio reference before calling folio_isolate_lru(), which would prevent VM_BUG_ON_FOLIO() from being triggered; they have already fixed this issue on their GitHub branch and the numbers for Graph500 benchmark are with this fix.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "acknowledged a bug",
            "has already fixed"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "We should hold a folio reference before the above call which will isolate the\nfolio from LRU. Otherwise we may hit\n\nVM_BUG_ON_FOLIO(!folio_ref_count(folio), folio)\n\nin folio_isolate_lru().\n\nI hit this only when running Graph500 benchmark and have fixed it in\nthe github at: https://github.com/AMDESE/linux-mm/tree/bharata/pghot-rfcv6-pre\n\nThe numbers that I have posted for micro-benchmarks and redis-memtier are\nwithout this fix while Graph500 numbers are with this fix.\n\nRegards,\nBharata.",
          "reply_to": "",
          "message_date": "2026-02-11",
          "message_id": ""
        },
        {
          "author": "Gregory Price",
          "summary": "Reviewer Gregory Price requested clarification on the meaning of TEPS, a benchmark used in the patchset, and asked whether higher values are better or worse.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "lack of understanding",
            "request for clarification"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Can you contextualize TEPS?  Higher better? Higher worse? etc.\nUnfamiliar with this benchmark.\n\n~Gregory",
          "reply_to": "Bharata Rao",
          "message_date": "2026-02-11",
          "message_id": ""
        },
        {
          "author": "Gregory Price",
          "summary": "Reviewer suggested selecting a random or round-robin node from the upper tier to improve promotion accuracy, as the current implementation lacks access-nid data.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Lacking access-nid data, maybe it's better to select a random (or\nround-robin) node in the upper tier?  That would at least approach 1/N\naccuracy in promotion for most access patterns.\n\n~Gregory",
          "reply_to": "Bharata Rao",
          "message_date": "2026-02-11",
          "message_id": ""
        },
        {
          "author": "Gregory Price",
          "summary": "Reviewer Gregory Price noted that zone-device folios should not be tracked by pghot, suggesting a fast-out for these cases to avoid unnecessary tracking and potentially generalizing this check to private-node memory as well.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Also relevant note from other work I'm doing, we may want a fast-out for\nzone-device folios here.  We should not bother tracking those at all.\n\n(this may also become relevant for private-node memory as well, but I\nmay try to generalize zone_device & private-node checks as the\nconditions are very similar).\n\n~Gregory",
          "reply_to": "Bharata Rao",
          "message_date": "2026-02-11",
          "message_id": ""
        }
      ],
      "analysis_source": "llm"
    },
    "2026-02-12": {
      "report_file": "2026-02-24_ollama_llama3.1-8b.html",
      "developer": "Gregory Price",
      "reviews": [
        {
          "author": "Bharata Rao (author)",
          "summary": "The author acknowledged that zone device folios are not tracked by pghot, explaining they are discarded by the pghot_record_access() function.\n\nAuthor acknowledges that the patch needs further work, but does not provide a clear plan for addressing the issue.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "acknowledgment",
            "clarification",
            "acknowledges need for further work",
            "does not provide a clear plan"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Yes, zone device folios aren't not tracked by pghot. They get discarded\nby pghot_record_access() itself.\n\n---\n\nGood.\n\nRegards,\nBharata.",
          "reply_to": "Gregory Price",
          "message_date": "2026-02-12",
          "message_id": ""
        },
        {
          "author": "Bharata Rao (author)",
          "summary": "Author responded to feedback about the Graph500 benchmark results, stating that higher TEPS values are better.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "no clear resolution signal"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "In the Graph500 benchmark, higher TEPS (Traversed Edges Per Second) values are\nbetter.\n\nRegards,\nBharata.",
          "reply_to": "Gregory Price",
          "message_date": "2026-02-12",
          "message_id": ""
        },
        {
          "author": "Bharata Rao (author)",
          "summary": "The author is addressing concerns about performance issues in the hot page tracking and promotion subsystem, specifically in scenarios where demotion is present. They provided benchmark results showing that both default and precise modes of pghot exhibit similar behavior to the base case when promotion and demotion are enabled (NUMAB2 case). The author notes that while overall benchmark numbers remain consistent, there is a spike in PTE updates and hint faults during some runs, but they have yet to understand the exact reason for this. They do not indicate any plans to fix these issues or revise the patch.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "no clear resolution signal",
            "acknowledges performance issue"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "These numbers are from scenario where demotion is present:\n\n=============================================\nOver-committed scenario, promotion + demotion\n=============================================\nCommand: mpirun -n 128 --bind-to core --map-by core\n/home/bharata/benchmarks/graph500/src/graph500_reference_bfs 30 16\n\nThe scale factor of 30 results in around 400GB of memory being\nprovisioned resulting in the data spilling over to CXL node.\nNo explicit migration of data is done in this case unlike the\nprevious case.\n\n=====================================================================================\n                        Base            Base            pghot-default\npghot-precise\n                        NUMAB0          NUMAB2          NUMAB2          NUMAB2\n=====================================================================================\nharmonic_mean_TEPS      9.28713e+08     7.90431e+08     7.32193e+08     7.81051e+08\nmean_time               18.4984         21.7346         23.4634         21.9956\nmedian_TEPS             9.25707e+08     7.86684e+08     7.27053e+08     7.82823e+08\nmax_TEPS                9.57632e+08     8.4758e+08      8.22172e+08     7.9889e+08\n\npgpromote_success       0               22846743        22807167        25994988\npgpromote_candidate     0               24628924        29436044        27029173\npgpromote_candidate_nrl 0               140921          220             38387\npgdemote_kswapd         0               41523110        45121134        50042594\nnuma_pte_updates        0               121904763       71503891        68779424\nnuma_hint_faults        0               81708126        29583391        27176332\n=====================================================================================\n\n- In the base case, the benchmark suffers when promotion and demotion are\n  enabled (NUMAB2 case).\n- Same behaviour is seen with both modes of pghot.\n- Though the overall benchmark numbers remain more or less same with base and\n  pghot NUMAB2 cases, the number of pte updates and hint faults are seen\n  to spike up during some runs. Yet to understand the exact reason for this.",
          "reply_to": "",
          "message_date": "2026-02-12",
          "message_id": ""
        }
      ],
      "analysis_source": "llm"
    },
    "2026-02-13": {
      "report_file": "2026-02-24_ollama_llama3.1-8b.html",
      "developer": "Gregory Price",
      "reviews": [
        {
          "author": "Gregory Price",
          "summary": "Reviewer Gregory Price requested that the patch series include a base-commit hash, which would facilitate automated testing and backporting.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "In the future can you add a \n\nbase-commit:\n\nfor the series?  Make's it easier to automate pulling it in for testing\nand backports etc.\n\n~Gregory",
          "reply_to": "Bharata Rao",
          "message_date": "2026-02-13",
          "message_id": ""
        }
      ],
      "analysis_source": "llm"
    },
    "2026-02-16": {
      "report_file": "2026-02-24_ollama_llama3.1-8b.html",
      "developer": "Gregory Price",
      "reviews": [
        {
          "author": "Bharata Rao (author)",
          "summary": "Author acknowledged a concern about the patch series' application and agreed to make changes, providing a link to the latest GitHub branch.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "acknowledged a concern",
            "agreed to make changes"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Good suggestion, will do thanks.\n\nBTW this series applies on f0b9d8eb98df.\nLatest github branch:\nhttps://github.com/AMDESE/linux-mm/tree/bharata/pghot-rfcv6-pre\n\nRegards,\nBharata.",
          "reply_to": "Gregory Price",
          "message_date": "2026-02-16",
          "message_id": ""
        }
      ],
      "analysis_source": "llm"
    },
    "2026-02-23": {
      "report_file": "2026-02-24_ollama_llama3.1-8b.html",
      "developer": "Gregory Price",
      "reviews": [
        {
          "author": "Bharata Rao (author)",
          "summary": "The author is addressing concerns about the performance of their hot page tracking and promotion subsystem in comparison to existing NUMA balancing-based promotion. They provided benchmark results from NAS Parallel Benchmark (NPB) showing that their subsystem, especially in precision mode, can match or even outperform the base case numbers. The author attributes the poor performance in the default mode to promotion being limited to a single NID.",
          "sentiment": "positive",
          "sentiment_signals": [
            "acknowledges concerns",
            "provides evidence"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Here are some numbers from NAS Parallel Benchmark (NPB) with BT application:\n\nTest system details\n-------------------\n3 node AMD Zen5 system with 2 regular NUMA nodes (0, 1) and a CXL node (2)\n\n$ numactl -H\navailable: 3 nodes (0-2)\nnode 0 cpus: 0-95,192-287\nnode 0 size: 128460 MB\nnode 1 cpus: 96-191,288-383\nnode 1 size: 128893 MB\nnode 2 cpus:\nnode 2 size: 257993 MB\nnode distances:\nnode   0   1   2\n  0:  10  32  50\n  1:  32  10  60\n  2:  255  255  10\n\nHotness sources\n---------------\nNUMAB0 - Without NUMA Balancing in base case and with no source enabled\n         in the pghot case. No migrations occur.\nNUMAB2 - Existing hot page promotion for the base case and\n         use of hint faults as source in the pghot case.\n         Both promotion and demotion are enabled in this case.\n\nPghot by default promotes after two accesses but for NUMAB2 source,\npromotion is done after one access to match the base behaviour.\n(/sys/kernel/debug/pghot/freq_threshold=1)\n\n\nNAS-BT details\n--------------\nCommand: mpirun -np 16 /usr/bin/numactl --cpunodebind=0,1\nNPB3.4.4/NPB3.4-MPI/bin/bt.F.x\n\nWhile class D uses around 24G of memory (which is too less to show the benefit\nof promition), class E results in around 368G of memory which overflows my\ntoptier. Hence I wanted something in between these classes. So I have  modified\nclass F to the problem size of 768 which results in around 160GB of memory.\n\nAfter the memory consumption stabilizes, all the rank PIDs are paused and\ntheir memory is moved to CXL node using migratepages command. This simulates\nthe situation of memory residing on lower tier node and access by BT processes\nleading to promotion.\n\nTime in seconds - Lower is better\nMop/s total - Higher is better\n=====================================================================================\n                        Base            Base            pghot-default\npghot-precise\n                        NUMAB0          NUMAB2          NUMAB2          NUMAB2\n=====================================================================================\nTime in seconds         7349.86         4422.50         6219.71         4113.56\nMop/s total             53247.66        88493.630       62923.030       95139.810\n\npgpromote_success       0               42181834        248503390       41955718\npgpromote_candidate     0               0               577086192       0\npgpromote_candidate_nrl 0               42181834        29410329        41956171\npgdemote_kswapd         0               0               216489010       0\nnuma_pte_updates        0               42252749        607470975       42037882\nnuma_hint_faults        0               42183772        606540729       41968150\n=====================================================================================\n\n- In the base case, the benchmark numbers improve significantly due to hot page\n  promotion.\n- Though the benchmark runs for hundreds of minutes, the pages get promoted\n  within the first few mins.\n- pghot-precise is able to match the base case numbers.\n- The benchmark suffers in pghot-default case due to promotion being limited\n  to the default NID (0) only. This leads to excessive PTE updates, hint faults,\n  demotion and promotion churn.",
          "reply_to": "",
          "message_date": "2026-02-23",
          "message_id": ""
        },
        {
          "author": "Gregory Price",
          "summary": "Reviewer suggested modifying pghot-default to randomly select a top-tier node instead of always using NID(0), which would improve its correctness and allow for comparison with NUMAB2.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Wow, this really seems to justify the extra memory usage.\n\nIs it possible for you to change pghot-default to move the page to a\nrandom (or round-robin) node on the top tier instead of NID(0) by default?\n\nAt least then pghot-default would be correct 1/N % of the time (in theory).\nI'd be curious to see how close it gets to NUMAB2 with that.\n\n~Gregory",
          "reply_to": "Bharata Rao",
          "message_date": "2026-02-23",
          "message_id": ""
        }
      ],
      "analysis_source": "llm"
    },
    "2026-02-24": {
      "report_file": "2026-02-24_ollama_llama3.1-8b.html",
      "developer": "Gregory Price",
      "reviews": [
        {
          "author": "Bharata Rao (author)",
          "summary": "The author is addressing a concern about the performance of pghot-default compared to pghot-precise and base NUMAB2 case, providing data that shows numbers catch up after some time.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "For pghot-default, with target_nid alternating between the available\ntoptier nodes 0 and 1, the numbers catch up with pghot-precise and base\nNUMAB2 case as seen below:\n================================\nTime in seconds         4337.98\nMop/s total             90217.86\n\npgpromote_success       42170085\npgpromote_candidate     0\npgpromote_candidate_nrl 42171963\npgdemote_kswapd         0\nnuma_pte_updates        42338538\nnuma_hint_faults        42185662\n================================\n\nRegards,\nBharata.",
          "reply_to": "Gregory Price",
          "message_date": "2026-02-24",
          "message_id": ""
        },
        {
          "author": "Gregory Price",
          "summary": "Reviewer expressed skepticism about the patch's performance, suggesting that its success might be due to chance rather than actual optimization.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "skepticism",
            "questioning"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Fascinating! Thank you for the quick follow up.\n\nI wonder if this was a lucky run, it almost seems *too* perfect.\n\n~Gregory",
          "reply_to": "Bharata Rao",
          "message_date": "2026-02-24",
          "message_id": ""
        }
      ],
      "analysis_source": "llm"
    },
    "2026-02-25": {
      "report_file": "2026-02-24_ollama_llama3.1-8b.html",
      "developer": "Gregory Price",
      "reviews": [
        {
          "author": "Bharata Rao",
          "summary": "It consistently performs that way. Here are the numbers from another run: ================================ Time in seconds         4329.22 Mop/s total             90400.27 pgpromote_success       41967282 pgpromote_candidate     0 pgpromote_candidate_nrl 41968339 pgdemote_kswapd         0 numa_pte_updates        42253854 numa_hint_faults        42019449 ================================ grep -E \"pgpromote|pgdemote\" /sys/devices/system/node/node0/vmstat pgpromote_success 20996597 pgpromote_candidate 0 pgpromote_candidate_nrl 41968339 (*) pgdemote_kswapd 0...",
          "sentiment": "neutral",
          "sentiment_signals": [],
          "has_inline_review": true,
          "tags_given": [],
          "analysis_source": "heuristic",
          "raw_body": "On 24-Feb-26 9:00 PM, Gregory Price wrote:\n>>\n>> For pghot-default, with target_nid alternating between the available\n>> toptier nodes 0 and 1, the numbers catch up with pghot-precise and base\n>> NUMAB2 case as seen below:\n>> ================================\n>> Time in seconds         4337.98\n>> Mop/s total             90217.86\n>>\n>> pgpromote_success       42170085\n>> pgpromote_candidate     0\n>> pgpromote_candidate_nrl 42171963\n>> pgdemote_kswapd         0\n>> numa_pte_updates        42338538\n>> numa_hint_faults        42185662\n>> ================================\n>>\n> \n> Fascinating! Thank you for the quick follow up.\n> \n> I wonder if this was a lucky run, it almost seems *too* perfect.\n\nIt consistently performs that way. Here are the numbers from another\nrun:\n\n================================\nTime in seconds         4329.22\nMop/s total             90400.27\n\npgpromote_success       41967282\npgpromote_candidate     0\npgpromote_candidate_nrl 41968339\npgdemote_kswapd         0\nnuma_pte_updates        42253854\nnuma_hint_faults        42019449\n================================\n\ngrep -E \"pgpromote|pgdemote\" /sys/devices/system/node/node0/vmstat\npgpromote_success 20996597\npgpromote_candidate 0\npgpromote_candidate_nrl 41968339 (*)\npgdemote_kswapd 0\npgdemote_direct 0\npgdemote_khugepaged 0\npgdemote_proactive 0\n\ngrep -E \"pgpromote|pgdemote\" /sys/devices/system/node/node1/vmstat\npgpromote_success 20970685\npgpromote_candidate 0\npgpromote_candidate_nrl 0\npgdemote_kswapd 0\npgdemote_direct 0\npgdemote_khugepaged 0\npgdemote_proactive 0\n\n\n(*) The round-robin b/n nodes 0 and 1 happens after this metric is\nattributed to the original default target_nid. Hence nrl metric\ngets populated for node 0 only.\n\n",
          "reply_to": "",
          "message_date": "2026-02-25",
          "message_id": ""
        }
      ],
      "analysis_source": "heuristic"
    }
  }
}