{
  "thread_id": "aY9Mf8oZODGiDoXp@thinkstation",
  "subject": "Re: [PATCH 1/2] efi: Fix reservation of unaccepted memory table",
  "url": "https://lore.kernel.org/all/aY9Mf8oZODGiDoXp@thinkstation/",
  "dates": {
    "2026-02-13": {
      "report_file": "2026-02-13_ollama_llama3.1-8b.html",
      "developer": "Kiryl Shutsemau",
      "reviews": [
        {
          "author": "Kiryl (Meta) (author)",
          "summary": "The reviewer pointed out a potential issue in the patch where the reservation of unaccepted memory table might not cover the entire range if its start address is not page-aligned, which could lead to kernel panics.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "potential sources of kernel panics",
            "fixes: 8dbe33956d96"
          ],
          "has_inline_review": true,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "The reserve_unaccepted() function incorrectly calculates the size of the\nmemblock reservation for the unaccepted memory table. It aligns the\nsize of the table, but fails to account for cases where the table's\nstarting physical address (efi.unaccepted) is not page-aligned.\n\nIf the table starts at an offset within a page and its end crosses into\na subsequent page that the aligned size does not cover, the end of the\ntable will not be reserved. This can lead to the table being overwritten\nor inaccessible, causing a kernel panic in accept_memory().\n\nThis issue was observed when starting Intel TDX VMs with specific memory\nsizes (e.g., > 64GB).\n\nFix this by calculating the end address first (including the unaligned\nstart) and then aligning it up, ensuring the entire range is covered\nby the reservation.\n\nFixes: 8dbe33956d96 (\"efi/unaccepted: Make sure unaccepted table is mapped\")\nReported-by: Moritz Sanft <ms@edgeless.systems>\nSigned-off-by: Kiryl Shutsemau (Meta) <kas@kernel.org>\n---\n drivers/firmware/efi/efi.c | 8 ++++----\n 1 file changed, 4 insertions(+), 4 deletions(-)\n\ndiff --git a/drivers/firmware/efi/efi.c b/drivers/firmware/efi/efi.c\nindex 111e87a618e5..56e9d73412fa 100644\n--- a/drivers/firmware/efi/efi.c\n+++ b/drivers/firmware/efi/efi.c\n@@ -692,13 +692,13 @@ static __init int match_config_table(const efi_guid_t *guid,\n \n static __init void reserve_unaccepted(struct efi_unaccepted_memory *unaccepted)\n {\n-\tphys_addr_t start, size;\n+\tphys_addr_t start, end;\n \n \tstart = PAGE_ALIGN_DOWN(efi.unaccepted);\n-\tsize = PAGE_ALIGN(sizeof(*unaccepted) + unaccepted->size);\n+\tend = PAGE_ALIGN(efi.unaccepted + sizeof(*unaccepted) + unaccepted->size);\n \n-\tmemblock_add(start, size);\n-\tmemblock_reserve(start, size);\n+\tmemblock_add(start, end - start);\n+\tmemblock_reserve(start, end - start);\n }\n \n int __init efi_config_parse_tables(const efi_config_table_t *config_tables,\n-- \n2.51.2\n\n\n\n---\n\nThe accept_memory() and range_contains_unaccepted_memory() functions\nemploy a \"guard page\" logic to prevent crashes with load_unaligned_zeropad().\nThis logic extends the range to be accepted (or checked) by one unit_size\nif the end of the range is aligned to a unit_size boundary.\n\nHowever, if the caller passes a range that is not page-aligned, the\n'end' of the range might not be numerically aligned to unit_size, even\nif it covers the last page of a unit. This causes the \"if (!(end % unit_size))\"\ncheck to fail, skipping the necessary extension and leaving the next\nunit unaccepted, which can lead to a kernel panic when accessed by\nload_unaligned_zeropad().\n\nAlign the start address down and the size up to the nearest page\nboundary before performing the unit_size alignment check. This ensures\nthat the guard unit is correctly added when the range effectively ends\non a unit boundary.\n\nSigned-off-by: Kiryl Shutsemau (Meta) <kas@kernel.org>\n---\n drivers/firmware/efi/unaccepted_memory.c | 12 ++++++++++--\n 1 file changed, 10 insertions(+), 2 deletions(-)\n\ndiff --git a/drivers/firmware/efi/unaccepted_memory.c b/drivers/firmware/efi/unaccepted_memory.c\nindex c2c067eff634..9ddf3dedd514 100644\n--- a/drivers/firmware/efi/unaccepted_memory.c\n+++ b/drivers/firmware/efi/unaccepted_memory.c\n@@ -35,14 +35,18 @@ void accept_memory(phys_addr_t start, unsigned long size)\n \tstruct efi_unaccepted_memory *unaccepted;\n \tunsigned long range_start, range_end;\n \tstruct accept_range range, *entry;\n-\tphys_addr_t end = start + size;\n \tunsigned long flags;\n+\tphys_addr_t end;\n \tu64 unit_size;\n \n \tunaccepted = efi_get_unaccepted_table();\n \tif (!unaccepted)\n \t\treturn;\n \n+\tstart = PAGE_ALIGN_DOWN(start);\n+\tsize = PAGE_ALIGN(size);\n+\tend = start + size;\n+\n \tunit_size = unaccepted->unit_size;\n \n \t/*\n@@ -160,15 +164,19 @@ void accept_memory(phys_addr_t start, unsigned long size)\n bool range_contains_unaccepted_memory(phys_addr_t start, unsigned long size)\n {\n \tstruct efi_unaccepted_memory *unaccepted;\n-\tphys_addr_t end = start + size;\n \tunsigned long flags;\n \tbool ret = false;\n+\tphys_addr_t end;\n \tu64 unit_size;\n \n \tunaccepted = efi_get_unaccepted_table();\n \tif (!unaccepted)\n \t\treturn false;\n \n+\tstart = PAGE_ALIGN_DOWN(start);\n+\tsize = PAGE_ALIGN(size);\n+\tend = start + size;\n+\n \tunit_size = unaccepted->unit_size;\n \n \t/*\n-- \n2.51.2\n\n\n\n---\n\nOn Fri, Feb 13, 2026 at 08:01:55AM -0800, Dave Hansen wrote:\n> On 2/13/26 07:48, Kiryl Shutsemau (Meta) wrote:\n> >  static __init void reserve_unaccepted(struct efi_unaccepted_memory *unaccepted)\n> >  {\n> > -\tphys_addr_t start, size;\n> > +\tphys_addr_t start, end;\n> >  \n> >  \tstart = PAGE_ALIGN_DOWN(efi.unaccepted);\n> \n> Why are we even aligning the start? Isn't *that* the bug?\n\nHow so? It is up to EFI how the table is allocated. We need to be sure\nthat this memory is mapped and not overwritten.\n\n> The memblock code seems to be able to handle arbitrary alignment just fine.\n\nMemblock will track it, but, as the comment says, anything smaller than\npage size will not be mapped, but we need the table to be accessible by\nkernel.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov\n\n\n---\n\nOn Fri, Feb 13, 2026 at 08:46:55AM -0800, Dave Hansen wrote:\n> On 2/13/26 08:14, Kiryl Shutsemau wrote:\n> >> The memblock code seems to be able to handle arbitrary alignment just fine.\n> > Memblock will track it, but, as the comment says, anything smaller than\n> > page size will not be mapped, but we need the table to be accessible by\n> > kernel.\n> \n> That seems really, really fragile.\n> \n> We should first make sure this is intentional memblock behavior and not\n> a bug before we go add more hacks on top of it.\n> \n> Why would you even present a byte-level reservation interface if it is\n> free to just silently ignore some of the ranges by rounding them off later?\n\n+Mike.\n\nMy guess that multiple memblock_add() calls might add up to the full\npage size.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov\n\n\n---\n\nOn Sat, Feb 14, 2026 at 05:51:47PM +0200, Mike Rapoport wrote:\n> > My guess that multiple memblock_add() calls might add up to the full\n> > page size.\n> \n> I'm not following here. Can you explain what do you mean?\n> \n> Multiple memblock_add() calls to adjacent ranges will coalesce into one\n> larger range. But I don't see how is that related.\n\nI tried to find justification for the byte-level tracking by memblock.\nNot in relation to this case, but in general.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov\n\n\n---\n\nOn Mon, Feb 16, 2026 at 08:51:17AM -0600, Tom Lendacky wrote:\n> On 2/13/26 09:48, Kiryl Shutsemau (Meta) wrote:\n> > The accept_memory() and range_contains_unaccepted_memory() functions\n> > employ a \"guard page\" logic to prevent crashes with load_unaligned_zeropad().\n> > This logic extends the range to be accepted (or checked) by one unit_size\n> > if the end of the range is aligned to a unit_size boundary.\n> > \n> > However, if the caller passes a range that is not page-aligned, the\n> > 'end' of the range might not be numerically aligned to unit_size, even\n> > if it covers the last page of a unit. This causes the \"if (!(end % unit_size))\"\n> > check to fail, skipping the necessary extension and leaving the next\n> > unit unaccepted, which can lead to a kernel panic when accessed by\n> > load_unaligned_zeropad().\n> > \n> > Align the start address down and the size up to the nearest page\n> > boundary before performing the unit_size alignment check. This ensures\n> > that the guard unit is correctly added when the range effectively ends\n> > on a unit boundary.\n> > \n> > Signed-off-by: Kiryl Shutsemau (Meta) <kas@kernel.org>\n> > ---\n> >  drivers/firmware/efi/unaccepted_memory.c | 12 ++++++++++--\n> >  1 file changed, 10 insertions(+), 2 deletions(-)\n> > \n> > diff --git a/drivers/firmware/efi/unaccepted_memory.c b/drivers/firmware/efi/unaccepted_memory.c\n> > index c2c067eff634..9ddf3dedd514 100644\n> > --- a/drivers/firmware/efi/unaccepted_memory.c\n> > +++ b/drivers/firmware/efi/unaccepted_memory.c\n> > @@ -35,14 +35,18 @@ void accept_memory(phys_addr_t start, unsigned long size)\n> >  \tstruct efi_unaccepted_memory *unaccepted;\n> >  \tunsigned long range_start, range_end;\n> >  \tstruct accept_range range, *entry;\n> > -\tphys_addr_t end = start + size;\n> >  \tunsigned long flags;\n> > +\tphys_addr_t end;\n> >  \tu64 unit_size;\n> >  \n> >  \tunaccepted = efi_get_unaccepted_table();\n> >  \tif (!unaccepted)\n> >  \t\treturn;\n> >  \n> > +\tstart = PAGE_ALIGN_DOWN(start);\n> > +\tsize = PAGE_ALIGN(size);\n> > +\tend = start + size;\n> \n> Should this really be:\n> \n> \tend = PAGE_ALIGN(start + size);\n> \tstart = PAGE_ALIGN_DOWN(start);\n> \n> ?\n\nDoh! Yes, you are right.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov\n",
          "reply_to": ""
        },
        {
          "author": "Dave Hansen",
          "summary": "Reviewer Dave Hansen questioned the patch's approach to aligning the start of unaccepted memory table reservation, suggesting that this might be the actual bug rather than a fix.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes",
            "technical concerns"
          ],
          "has_inline_review": true,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "On 2/13/26 07:48, Kiryl Shutsemau (Meta) wrote:\n>  static __init void reserve_unaccepted(struct efi_unaccepted_memory *unaccepted)\n>  {\n> -\tphys_addr_t start, size;\n> +\tphys_addr_t start, end;\n>  \n>  \tstart = PAGE_ALIGN_DOWN(efi.unaccepted);\n\nWhy are we even aligning the start? Isn't *that* the bug?\n\nThe memblock code seems to be able to handle arbitrary alignment just fine.\n\n\n---\n\nOn 2/13/26 08:14, Kiryl Shutsemau wrote:\n>> The memblock code seems to be able to handle arbitrary alignment just fine.\n> Memblock will track it, but, as the comment says, anything smaller than\n> page size will not be mapped, but we need the table to be accessible by\n> kernel.\n\nThat seems really, really fragile.\n\nWe should first make sure this is intentional memblock behavior and not\na bug before we go add more hacks on top of it.\n\nWhy would you even present a byte-level reservation interface if it is\nfree to just silently ignore some of the ranges by rounding them off later?\n\n\n---\n\nOn 2/14/26 07:51, Mike Rapoport wrote:\n> Heh, it's x86's choice of memblock iterator that's rounding the ranges \\U0001f609\n\nAhh, good point. I was just assuming that the memblock iteration _had_\nto be over PFNs. Silly me.\n\n> Maybe I miss some context, but my understanding is that for crash kernels\n> the unaccepted table is E820_TYPE_RESERVED and those are never added to\n> memblock.memory by e820 code, hence the call to memblock_add() in\n> reserve_unaccepted().\n> \n> When x86 creates page tables, init_range_memory_mapping() walks\n> memblock.memory with for_each_mem_pfn_range() that rounds ranges that are\n> not page-aligned, which is normally fine, because it would mean that we\n> miss some partial pages that are divided between E820_RAM and\n> E820_SOMETHING_ELSE.\n> \n> And Kiryl's intention to round up unaccepted to page boundary seems correct\n> to me.\n\nIt fixes the bug for sure.\n\nI'm more worried about the next feature, or the existing features that\nalso only working because memory is page-aligned somewhere (even though\nit isn't guaranteed to remain that way).\n\nThere are two choices for fixing this: One, we do Kiryl's fix plus\nchecks to ensure that all the memblocks that generate direct mappings\n(is it _just_ the \"memory\" type?) are padded out to page-aligned boundaries.\n\nThe other alternative is to do for_each_mem_range() and do the padding\nuniversally when creating the mappings. Maybe _also_ with warnings or\nmaybe a pr_debug().\n\nI do still think it's a little wonky for memblock_add()'s management of\nthe \"memory\" type to allow unaligned arguments when that type is also\nused to create page-aligned mapping structures. Memblocks themselves\nobviously need to be byte-level, but I'm not sure it's the right thing\nfor the \"memory\" type API.\n",
          "reply_to": ""
        },
        {
          "author": "Mike Rapoport",
          "summary": "Reviewer Mike Rapoport questioned the patch's intention to round up unaccepted memory table to page boundary, suggesting it might not be necessary due to memblock iterator rounding ranges.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes",
            "clarification needed"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "On Fri, Feb 13, 2026 at 05:20:14PM +0000, Kiryl Shutsemau wrote:\n> On Fri, Feb 13, 2026 at 08:46:55AM -0800, Dave Hansen wrote:\n> > On 2/13/26 08:14, Kiryl Shutsemau wrote:\n> > >> The memblock code seems to be able to handle arbitrary alignment just fine.\n> > > Memblock will track it, but, as the comment says, anything smaller than\n> > > page size will not be mapped, but we need the table to be accessible by\n> > > kernel.\n> > \n> > That seems really, really fragile.\n> > \n> > We should first make sure this is intentional memblock behavior and not\n> > a bug before we go add more hacks on top of it.\n> > \n> > Why would you even present a byte-level reservation interface if it is\n> > free to just silently ignore some of the ranges by rounding them off later?\n\nHeh, it's x86's choice of memblock iterator that's rounding the ranges ;)\n\nMaybe I miss some context, but my understanding is that for crash kernels\nthe unaccepted table is E820_TYPE_RESERVED and those are never added to\nmemblock.memory by e820 code, hence the call to memblock_add() in\nreserve_unaccepted().\n\nWhen x86 creates page tables, init_range_memory_mapping() walks\nmemblock.memory with for_each_mem_pfn_range() that rounds ranges that are\nnot page-aligned, which is normally fine, because it would mean that we\nmiss some partial pages that are divided between E820_RAM and\nE820_SOMETHING_ELSE.\n\nAnd Kiryl's intention to round up unaccepted to page boundary seems correct\nto me.\n\n> My guess that multiple memblock_add() calls might add up to the full\n> page size.\n\nI'm not following here. Can you explain what do you mean?\n\nMultiple memblock_add() calls to adjacent ranges will coalesce into one\nlarger range. But I don't see how is that related.\n\n> \n> -- \n>   Kiryl Shutsemau / Kirill A. Shutemov\n\n-- \nSincerely yours,\nMike.\n\n\n---\n\nOn Mon, Feb 16, 2026 at 02:22:49PM +0000, Kiryl Shutsemau wrote:\n> On Sat, Feb 14, 2026 at 05:51:47PM +0200, Mike Rapoport wrote:\n> > > My guess that multiple memblock_add() calls might add up to the full\n> > > page size.\n> > \n> > I'm not following here. Can you explain what do you mean?\n> > \n> > Multiple memblock_add() calls to adjacent ranges will coalesce into one\n> > larger range. But I don't see how is that related.\n> \n> I tried to find justification for the byte-level tracking by memblock.\n> Not in relation to this case, but in general.\n\nProbably somewhere deep in git archaeology :)\n\nI presume to not waste a page for every small allocation.\n \n> -- \n>   Kiryl Shutsemau / Kirill A. Shutemov\n\n-- \nSincerely yours,\nMike.\n\n\n---\n\nOn Mon, Feb 16, 2026 at 07:53:24AM -0800, Dave Hansen wrote:\n> On 2/14/26 07:51, Mike Rapoport wrote:\n> > Heh, it's x86's choice of memblock iterator that's rounding the ranges \\U0001f609\n> \n> Ahh, good point. I was just assuming that the memblock iteration _had_\n> to be over PFNs. Silly me.\n> \n> > Maybe I miss some context, but my understanding is that for crash kernels\n> > the unaccepted table is E820_TYPE_RESERVED and those are never added to\n> > memblock.memory by e820 code, hence the call to memblock_add() in\n> > reserve_unaccepted().\n> > \n> > When x86 creates page tables, init_range_memory_mapping() walks\n> > memblock.memory with for_each_mem_pfn_range() that rounds ranges that are\n> > not page-aligned, which is normally fine, because it would mean that we\n> > miss some partial pages that are divided between E820_RAM and\n> > E820_SOMETHING_ELSE.\n> > \n> > And Kiryl's intention to round up unaccepted to page boundary seems correct\n> > to me.\n> \n> It fixes the bug for sure.\n> \n> I'm more worried about the next feature, or the existing features that\n> also only working because memory is page-aligned somewhere (even though\n> it isn't guaranteed to remain that way).\n> \n> There are two choices for fixing this: One, we do Kiryl's fix plus\n> checks to ensure that all the memblocks that generate direct mappings\n> (is it _just_ the \"memory\" type?) are padded out to page-aligned boundaries.\n> \n> The other alternative is to do for_each_mem_range() and do the padding\n> universally when creating the mappings. Maybe _also_ with warnings or\n> maybe a pr_debug().\n> \n> I do still think it's a little wonky for memblock_add()'s management of\n> the \"memory\" type to allow unaligned arguments when that type is also\n> used to create page-aligned mapping structures. Memblocks themselves\n> obviously need to be byte-level, but I'm not sure it's the right thing\n> for the \"memory\" type API.\n\nWell, we could make memblock_add() implicitly cut down the edges when it's\nadding to memblock.memory and make everything there page aligned, but I\ntruly have no idea what will break and I'm sure something will :)\n\nAnother thing that's more on x86 side, is that translation from e820 to\nmemblock only adds E820_TYPE_RAM to memblock. And since in e820 these are\nmutually exclusive with other e820 types, this could create non-aligned\nchunks when firmware reservations are not page aligned. It also creates\nunnecessary holes in memblock.memory that slow down memblock interation a\nbit and more interestingly, everything that's not in E820_TYPE_RAM is\ntreated as IO and requires ioremap/memremap for access, even it is in DRAM.\n\nIf these reserved regions were added to memblock.memory along with being\nmemblock_reserve()ed we wouldn't hit the bug with unaccepted I believe some\nothers as well.\n\n-- \nSincerely yours,\nMike.\n\n",
          "reply_to": ""
        },
        {
          "author": "Tom Lendacky",
          "summary": "Reviewer Tom Lendacky questioned the alignment calculation in the patch, suggesting a different approach.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "questioning code"
          ],
          "has_inline_review": true,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "On 2/13/26 09:48, Kiryl Shutsemau (Meta) wrote:\n> The accept_memory() and range_contains_unaccepted_memory() functions\n> employ a \"guard page\" logic to prevent crashes with load_unaligned_zeropad().\n> This logic extends the range to be accepted (or checked) by one unit_size\n> if the end of the range is aligned to a unit_size boundary.\n> \n> However, if the caller passes a range that is not page-aligned, the\n> 'end' of the range might not be numerically aligned to unit_size, even\n> if it covers the last page of a unit. This causes the \"if (!(end % unit_size))\"\n> check to fail, skipping the necessary extension and leaving the next\n> unit unaccepted, which can lead to a kernel panic when accessed by\n> load_unaligned_zeropad().\n> \n> Align the start address down and the size up to the nearest page\n> boundary before performing the unit_size alignment check. This ensures\n> that the guard unit is correctly added when the range effectively ends\n> on a unit boundary.\n> \n> Signed-off-by: Kiryl Shutsemau (Meta) <kas@kernel.org>\n> ---\n>  drivers/firmware/efi/unaccepted_memory.c | 12 ++++++++++--\n>  1 file changed, 10 insertions(+), 2 deletions(-)\n> \n> diff --git a/drivers/firmware/efi/unaccepted_memory.c b/drivers/firmware/efi/unaccepted_memory.c\n> index c2c067eff634..9ddf3dedd514 100644\n> --- a/drivers/firmware/efi/unaccepted_memory.c\n> +++ b/drivers/firmware/efi/unaccepted_memory.c\n> @@ -35,14 +35,18 @@ void accept_memory(phys_addr_t start, unsigned long size)\n>  \tstruct efi_unaccepted_memory *unaccepted;\n>  \tunsigned long range_start, range_end;\n>  \tstruct accept_range range, *entry;\n> -\tphys_addr_t end = start + size;\n>  \tunsigned long flags;\n> +\tphys_addr_t end;\n>  \tu64 unit_size;\n>  \n>  \tunaccepted = efi_get_unaccepted_table();\n>  \tif (!unaccepted)\n>  \t\treturn;\n>  \n> +\tstart = PAGE_ALIGN_DOWN(start);\n> +\tsize = PAGE_ALIGN(size);\n> +\tend = start + size;\n\nShould this really be:\n\n\tend = PAGE_ALIGN(start + size);\n\tstart = PAGE_ALIGN_DOWN(start);\n\n?\n\nThanks,\nTom\n\n> +\n>  \tunit_size = unaccepted->unit_size;\n>  \n>  \t/*\n> @@ -160,15 +164,19 @@ void accept_memory(phys_addr_t start, unsigned long size)\n>  bool range_contains_unaccepted_memory(phys_addr_t start, unsigned long size)\n>  {\n>  \tstruct efi_unaccepted_memory *unaccepted;\n> -\tphys_addr_t end = start + size;\n>  \tunsigned long flags;\n>  \tbool ret = false;\n> +\tphys_addr_t end;\n>  \tu64 unit_size;\n>  \n>  \tunaccepted = efi_get_unaccepted_table();\n>  \tif (!unaccepted)\n>  \t\treturn false;\n>  \n> +\tstart = PAGE_ALIGN_DOWN(start);\n> +\tsize = PAGE_ALIGN(size);\n> +\tend = start + size;\n> +\n>  \tunit_size = unaccepted->unit_size;\n>  \n>  \t/*\n\n",
          "reply_to": ""
        }
      ],
      "analysis_source": "llm"
    }
  }
}