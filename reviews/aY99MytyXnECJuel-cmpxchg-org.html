<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Review Comments: Re: [PATCH v9] mm/page_alloc: boost watermarks on atomic allocation failure</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
                         "Helvetica Neue", Arial, sans-serif;
            background: #f5f5f5;
            color: #333;
            line-height: 1.6;
            padding: 20px;
            max-width: 900px;
            margin: 0 auto;
        }
        .home-link { margin-bottom: 12px; display: block; }
        .home-link a { color: #0366d6; text-decoration: none; font-size: 0.9em; }
        .home-link a:hover { text-decoration: underline; }

        h1 { font-size: 1.3em; margin-bottom: 2px; color: #1a1a1a; line-height: 1.3; }

        .lore-link { font-size: 0.85em; margin: 4px 0 6px; display: block; }
        .lore-link a { color: #0366d6; text-decoration: none; }
        .lore-link a:hover { text-decoration: underline; }

        .date-range {
            font-size: 0.8em;
            color: #888;
            margin-bottom: 16px;
        }
        .date-range a { color: #0366d6; text-decoration: none; }
        .date-range a:hover { text-decoration: underline; }

        /* thread-node scroll margin so the card isn't clipped at the top */
        .thread-node { scroll-margin-top: 8px; }

        /* ── Patch summary ──────────────────────────────────────────── */
        .patch-summary-block {
            background: #fff;
            border-radius: 8px;
            padding: 12px 16px;
            margin-bottom: 20px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.08);
            border-left: 3px solid #4a90d9;
        }
        .patch-summary-label {
            font-size: 0.72em;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 0.06em;
            color: #4a90d9;
            margin-bottom: 4px;
        }
        .patch-summary-text {
            font-size: 0.88em;
            color: #444;
            line-height: 1.55;
        }

        /* ── Thread tree ────────────────────────────────────────────── */
        .thread-tree {
            display: flex;
            flex-direction: column;
            gap: 6px;
        }

        /* Depth indentation via left border */
        .thread-node { position: relative; }
        .thread-children {
            margin-left: 20px;
            padding-left: 12px;
            border-left: 2px solid #e0e0e0;
            margin-top: 6px;
            display: flex;
            flex-direction: column;
            gap: 6px;
        }

        /* ── Review comment card ────────────────────────────────────── */
        .review-comment {
            background: #fff;
            border-radius: 6px;
            padding: 10px 14px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.08);
            font-size: 0.88em;
        }
        .review-comment-header {
            display: flex;
            flex-wrap: wrap;
            align-items: center;
            gap: 6px;
            margin-bottom: 5px;
        }
        .review-author {
            font-weight: 700;
            color: #1a1a1a;
            font-size: 0.95em;
        }

        /* Date chip — links back to the daily report */
        .date-chip {
            font-size: 0.75em;
            color: #777;
            background: #f0f0f0;
            border-radius: 10px;
            padding: 1px 7px;
            text-decoration: none;
            white-space: nowrap;
        }
        a.date-chip:hover { background: #e0e8f5; color: #0366d6; }

        .badge {
            display: inline-block;
            padding: 1px 8px;
            border-radius: 10px;
            font-size: 0.75em;
            font-weight: 600;
        }
        .inline-review-badge {
            display: inline-block;
            padding: 0 6px;
            border-radius: 8px;
            font-size: 0.78em;
            font-weight: 500;
            background: #e3f2fd;
            color: #1565c0;
        }
        .review-tag-badge {
            display: inline-block;
            padding: 0 6px;
            border-radius: 8px;
            font-size: 0.78em;
            font-weight: 500;
            background: #e8f5e9;
            color: #2e7d32;
        }
        .analysis-source-badge {
            display: inline-block;
            padding: 1px 7px;
            border-radius: 10px;
            font-size: 0.72em;
            font-weight: 600;
            border: 1px solid rgba(0,0,0,0.1);
        }

        .review-comment-text {
            color: #444;
            line-height: 1.55;
            margin-bottom: 4px;
        }
        .review-comment-signals {
            margin-top: 3px;
            font-size: 0.85em;
            color: #aaa;
            font-style: italic;
        }

        /* ── Collapsible raw body ───────────────────────────────────── */
        .raw-body-toggle {
            margin-top: 5px;
            font-size: 0.85em;
        }
        .raw-body-toggle summary {
            cursor: pointer;
            color: #888;
            padding: 2px 0;
            font-weight: 500;
            font-size: 0.9em;
            list-style: none;
        }
        .raw-body-toggle summary::-webkit-details-marker { display: none; }
        .raw-body-toggle summary::before { content: "▶ "; font-size: 0.7em; }
        .raw-body-toggle[open] summary::before { content: "▼ "; }
        .raw-body-toggle summary:hover { color: #555; }
        .raw-body-text {
            white-space: pre-wrap;
            font-size: 0.95em;
            background: #f8f8f8;
            padding: 8px 10px;
            border-radius: 4px;
            max-height: 360px;
            overflow-y: auto;
            margin-top: 4px;
            line-height: 1.5;
            color: #444;
            border: 1px solid #e8e8e8;
        }

        .no-reviews {
            color: #aaa;
            font-size: 0.85em;
            font-style: italic;
            padding: 8px 0;
        }

        footer {
            text-align: center;
            color: #bbb;
            font-size: 0.78em;
            margin-top: 36px;
            padding: 16px;
        }
    </style>
</head>
<body>
    <div class="home-link"><a href="../">&larr; Back to reports</a></div>
    <h1>Re: [PATCH v9] mm/page_alloc: boost watermarks on atomic allocation failure</h1>
    <div class="lore-link"><a href="https://lore.kernel.org/all/aY99MytyXnECJuel@cmpxchg.org/" target="_blank">View on lore.kernel.org &rarr;</a></div>
    <div class="date-range">Active on: <a href="#2026-02-13">2026-02-13</a></div>
    
    <div class="thread-tree">
<div class="thread-node depth-0" id="2026-02-13">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Vlastimil Babka</span>
<a class="date-chip" href="../2026-02-13_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Vlastimil Babka raised concerns about the hardcoded value of 1000 in the patch, suggesting that it makes little sense without the constant being used elsewhere. He also expressed disagreement with the use of mult_frac() for a simple right shift operation.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">On 2/13/26 04:17, Qiliang Yuan wrote:
&gt; Atomic allocations (GFP_ATOMIC) are prone to failure under heavy memory
&gt; pressure as they cannot enter direct reclaim. This patch introduces a
&gt; watermark boost mechanism to mitigate this issue.
&gt; 
&gt; When a GFP_ATOMIC request enters the slowpath, the preferred zone&#x27;s
&gt; watermark_boost is increased under zone-&gt;lock protection. This triggers
&gt; kswapd to proactively reclaim memory, creating a safety buffer for
&gt; future atomic allocations. A 1-second debounce timer prevents excessive
&gt; boosts during traffic bursts.
&gt; 
&gt; This approach reuses existing watermark_boost infrastructure with
&gt; minimal overhead and proper locking to ensure thread safety.
&gt; 
&gt; Allocation failure logs:
&gt; [38535644.718700] node 0: slabs: 1031, objs: 43328, free: 0
&gt; [38535644.725059] node 1: slabs: 339, objs: 17616, free: 317
&gt; [38535645.428345] SLUB: Unable to allocate memory on node -1, gfp=0x480020(GFP_ATOMIC)
&gt; [38535645.436888] cache: skbuff_head_cache, object size: 232, buffer size: 256, default order: 2, min order: 0
&gt; [38535645.447664] node 0: slabs: 940, objs: 40864, free: 144
&gt; [38535645.454026] node 1: slabs: 322, objs: 19168, free: 383
&gt; [38535645.556122] SLUB: Unable to allocate memory on node -1, gfp=0x480020(GFP_ATOMIC)
&gt; [38535645.564576] cache: skbuff_head_cache, object size: 232, buffer size: 256, default order: 2, min order: 0
&gt; [38535649.655523] warn_alloc: 59 callbacks suppressed
&gt; [38535649.655527] swapper/100: page allocation failure: order:0, mode:0x480020(GFP_ATOMIC), nodemask=(null)
&gt; [38535649.671692] swapper/100 cpuset=/ mems_allowed=0-1
&gt; 
&gt; Acked-by: Vlastimil Babka &lt;vbabka@suse.cz&gt;
&gt; Signed-off-by: Qiliang Yuan &lt;realwujing@gmail.com&gt;
&gt; ---
&gt; v9:
&gt; - Use mult_frac() for boost calculation. (SJ)
&gt; - Add !can_direct_reclaim check. (Vlastimil)
&gt; - Code cleanup: naming, scope, and line limits. (SJ)
&gt; - Update tags: Add Vlastimil&#x27;s Acked-by.
&gt; 
&gt; v8:
&gt; - Use spin_lock_irqsave() to prevent inconsistent lock state.
&gt; 
&gt; v7:
&gt; - Use local variable for boost_amount.
&gt; - Add zone-&gt;lock protection.
&gt; - Add lockdep assertion.
&gt; 
&gt; v6:
&gt; - Use ATOMIC_BOOST_SCALE_SHIFT define.
&gt; - Add documentation for 0.1% rationale.
&gt; 
&gt; v5:
&gt; - Use native boost_watermark().
&gt; 
&gt; v4:
&gt; - Add watermark_scale_boost and gradual decay.
&gt; 
&gt; v3:
&gt; - Per-zone debounce timer.
&gt; 
&gt; v2:
&gt; - Debounce logic and zone-proportional boosting.
&gt; 
&gt; v1:
&gt; - Initial version.
&gt; ---
&gt; Link to v8: https://lore.kernel.org/r/20260212-wujing-mm-page_alloc-v8-v8-1-daba38990cd3@gmail.com
&gt; ---
&gt;  include/linux/mmzone.h |  1 +
&gt;  mm/page_alloc.c        | 49 +++++++++++++++++++++++++++++++++++++++++++++++--
&gt;  2 files changed, 48 insertions(+), 2 deletions(-)
&gt; 
&gt; diff --git a/include/linux/mmzone.h b/include/linux/mmzone.h
&gt; index 75ef7c9f9307..8e37e4e6765b 100644
&gt; --- a/include/linux/mmzone.h
&gt; +++ b/include/linux/mmzone.h
&gt; @@ -882,6 +882,7 @@ struct zone {
&gt;  	/* zone watermarks, access with *_wmark_pages(zone) macros */
&gt;  	unsigned long _watermark[NR_WMARK];
&gt;  	unsigned long watermark_boost;
&gt; +	unsigned long last_boost_jiffies;
&gt;  
&gt;  	unsigned long nr_reserved_highatomic;
&gt;  	unsigned long nr_free_highatomic;
&gt; diff --git a/mm/page_alloc.c b/mm/page_alloc.c
&gt; index c380f063e8b7..8af88584a8bd 100644
&gt; --- a/mm/page_alloc.c
&gt; +++ b/mm/page_alloc.c
&gt; @@ -218,6 +218,13 @@ unsigned int pageblock_order __read_mostly;
&gt;  static void __free_pages_ok(struct page *page, unsigned int order,
&gt;  			    fpi_t fpi_flags);
&gt;  
&gt; +/*
&gt; + * Boost watermarks by ~0.1% of zone size on atomic allocation pressure.
&gt; + * This provides zone-proportional safety buffers: ~1MB per 1GB of zone size.
&gt; + * Larger zones under GFP_ATOMIC pressure need proportionally larger reserves.
&gt; + */
&gt; +#define ATOMIC_BOOST_FACTOR 1

... so now we #define 1 but it makes little sense without that hardcoded
1000 below.

&gt; +
&gt;  /*
&gt;   * results with 256, 32 in the lowmem_reserve sysctl:
&gt;   *	1G machine -&gt; (16M dma, 800M-16M normal, 1G-800M high)
&gt; @@ -2161,6 +2168,9 @@ bool pageblock_unisolate_and_move_free_pages(struct zone *zone, struct page *pag
&gt;  static inline bool boost_watermark(struct zone *zone)
&gt;  {
&gt;  	unsigned long max_boost;
&gt; +	unsigned long boost_amount;
&gt; +
&gt; +	lockdep_assert_held(&amp;zone-&gt;lock);
&gt;  
&gt;  	if (!watermark_boost_factor)
&gt;  		return false;
&gt; @@ -2189,12 +2199,43 @@ static inline bool boost_watermark(struct zone *zone)
&gt;  
&gt;  	max_boost = max(pageblock_nr_pages, max_boost);
&gt;  
&gt; -	zone-&gt;watermark_boost = min(zone-&gt;watermark_boost + pageblock_nr_pages,
&gt; -		max_boost);
&gt; +	boost_amount = max(pageblock_nr_pages,
&gt; +			   mult_frac(zone_managed_pages(zone), ATOMIC_BOOST_FACTOR, 1000));

I don&#x27;t think mult_frac() was a great suggestion. We&#x27;re talking about right
shifting by a constant 10. In the other cases of mult_frac() we use dynamic
values for x and n so it&#x27;s justified. But this IMHO is unnecessary complication.

&gt; +	zone-&gt;watermark_boost = min(zone-&gt;watermark_boost + boost_amount,
&gt; +				    max_boost);
&gt;  
&gt;  	return true;
&gt;  }
&gt;  
&gt; +static void boost_zone_for_atomic(struct alloc_context *ac, gfp_t gfp_mask)
&gt; +{
&gt; +	struct zoneref *z;
&gt; +	struct zone *zone;
&gt; +	unsigned long now = jiffies;
&gt; +
&gt; +	for_each_zone_zonelist(zone, z, ac-&gt;zonelist, ac-&gt;highest_zoneidx) {
&gt; +		/* Rate-limit boosts to once per second per zone */
&gt; +		if (time_after(now, zone-&gt;last_boost_jiffies + HZ)) {
&gt; +			unsigned long flags;
&gt; +			bool should_wake;
&gt; +
&gt; +			zone-&gt;last_boost_jiffies = now;
&gt; +
&gt; +			/* Modify watermark under lock, wake kswapd outside */
&gt; +			spin_lock_irqsave(&amp;zone-&gt;lock, flags);
&gt; +			should_wake = boost_watermark(zone);
&gt; +			spin_unlock_irqrestore(&amp;zone-&gt;lock, flags);
&gt; +
&gt; +			if (should_wake)
&gt; +				wakeup_kswapd(zone, gfp_mask, 0,
&gt; +					      ac-&gt;highest_zoneidx);
&gt; +
&gt; +			/* Boost only the preferred zone */
&gt; +			break;
&gt; +		}
&gt; +	}
&gt; +}
&gt; +
&gt;  /*
&gt;   * When we are falling back to another migratetype during allocation, should we
&gt;   * try to claim an entire block to satisfy further allocations, instead of
&gt; @@ -4742,6 +4783,10 @@ __alloc_pages_slowpath(gfp_t gfp_mask, unsigned int order,
&gt;  	if (page)
&gt;  		goto got_pg;
&gt;  
&gt; +	/* Boost watermarks for atomic requests entering slowpath */
&gt; +	if ((gfp_mask &amp; GFP_ATOMIC) &amp;&amp; order == 0 &amp;&amp; !can_direct_reclaim)
&gt; +		boost_zone_for_atomic(ac, gfp_mask);
&gt; +
&gt;  	/*
&gt;  	 * For costly allocations, try direct compaction first, as it&#x27;s likely
&gt;  	 * that we have enough base pages and don&#x27;t need to reclaim. For non-
&gt; 
&gt; ---
&gt; base-commit: b54345928fa1dbde534e32ecaa138678fd5d2135
&gt; change-id: 20260206-wujing-mm-page_alloc-v8-fb1979bac6fe
&gt; 
&gt; Best regards,

</pre>
</details>
<div class="review-comment-signals">Signals: requested changes, disagreement</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">SeongJae Park</span>
<a class="date-chip" href="../2026-02-13_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer SeongJae Park suggested using a consistent denominator for the watermark boost calculation and proposed defining ATOMIC_BOOST_SHIFT as a constant local variable or hard-coding its value to improve readability.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">On Fri, 13 Feb 2026 09:46:14 +0100 Vlastimil Babka &lt;vbabka@suse.cz&gt; wrote:

&gt; On 2/13/26 04:17, Qiliang Yuan wrote:
&gt; &gt; Atomic allocations (GFP_ATOMIC) are prone to failure under heavy memory
&gt; &gt; pressure as they cannot enter direct reclaim. This patch introduces a
&gt; &gt; watermark boost mechanism to mitigate this issue.
&gt; &gt; 
&gt; &gt; When a GFP_ATOMIC request enters the slowpath, the preferred zone&#x27;s
&gt; &gt; watermark_boost is increased under zone-&gt;lock protection. This triggers
&gt; &gt; kswapd to proactively reclaim memory, creating a safety buffer for
&gt; &gt; future atomic allocations. A 1-second debounce timer prevents excessive
&gt; &gt; boosts during traffic bursts.
&gt; &gt; 
&gt; &gt; This approach reuses existing watermark_boost infrastructure with
&gt; &gt; minimal overhead and proper locking to ensure thread safety.
[...]
&gt; &gt; diff --git a/mm/page_alloc.c b/mm/page_alloc.c
&gt; &gt; index c380f063e8b7..8af88584a8bd 100644
&gt; &gt; --- a/mm/page_alloc.c
&gt; &gt; +++ b/mm/page_alloc.c
&gt; &gt; @@ -218,6 +218,13 @@ unsigned int pageblock_order __read_mostly;
&gt; &gt;  static void __free_pages_ok(struct page *page, unsigned int order,
&gt; &gt;  			    fpi_t fpi_flags);
&gt; &gt;  
&gt; &gt; +/*
&gt; &gt; + * Boost watermarks by ~0.1% of zone size on atomic allocation pressure.
&gt; &gt; + * This provides zone-proportional safety buffers: ~1MB per 1GB of zone size.
&gt; &gt; + * Larger zones under GFP_ATOMIC pressure need proportionally larger reserves.
&gt; &gt; + */
&gt; &gt; +#define ATOMIC_BOOST_FACTOR 1
&gt; 
&gt; ... so now we #define 1 but it makes little sense without that hardcoded
&gt; 1000 below.

I agree.  I think it could be easier to understand if we use 10000 as the
denominator, consistent to other similar ones, like watermark_scale_factor.
Or, defining as a constant local variable or hard-coded value before its real
single use case might be easier to read, for below-mentioned reason.

&gt; 
&gt; &gt; +
&gt; &gt;  /*
&gt; &gt;   * results with 256, 32 in the lowmem_reserve sysctl:
&gt; &gt;   *	1G machine -&gt; (16M dma, 800M-16M normal, 1G-800M high)
&gt; &gt; @@ -2161,6 +2168,9 @@ bool pageblock_unisolate_and_move_free_pages(struct zone *zone, struct page *pag
&gt; &gt;  static inline bool boost_watermark(struct zone *zone)
&gt; &gt;  {
&gt; &gt;  	unsigned long max_boost;
&gt; &gt; +	unsigned long boost_amount;
&gt; &gt; +
&gt; &gt; +	lockdep_assert_held(&amp;zone-&gt;lock);
&gt; &gt;  
&gt; &gt;  	if (!watermark_boost_factor)
&gt; &gt;  		return false;
&gt; &gt; @@ -2189,12 +2199,43 @@ static inline bool boost_watermark(struct zone *zone)
&gt; &gt;  
&gt; &gt;  	max_boost = max(pageblock_nr_pages, max_boost);
&gt; &gt;  
&gt; &gt; -	zone-&gt;watermark_boost = min(zone-&gt;watermark_boost + pageblock_nr_pages,
&gt; &gt; -		max_boost);
&gt; &gt; +	boost_amount = max(pageblock_nr_pages,
&gt; &gt; +			   mult_frac(zone_managed_pages(zone), ATOMIC_BOOST_FACTOR, 1000));
&gt; 
&gt; I don&#x27;t think mult_frac() was a great suggestion. We&#x27;re talking about right
&gt; shifting by a constant 10. In the other cases of mult_frac() we use dynamic
&gt; values for x and n so it&#x27;s justified. But this IMHO is unnecessary complication.

This file uses multi_frac() in two places with hard-coded denominator 10000.
Hence I feel it is more consistent to use mutl_frac() with the same denominator
(10000) and consistent naming.  In terms of overhead, I think the added
overhead is negligible, since this is called only once per second.

No strong opinion but just a trivial and personal taste, though.  Right
shifting should also be good to me. :)

And now I find I was thinking the ATOMIC_BOOST_SHIFT coulb be better to be
consistent with other similar code, because it is defined as a macro.  That is,
I was assuming it would be used in multiple places and therefore better to be
easily understood by readers.  Now I find it is actually being used only here.
What about defining it as a constant local variable here, or just hard-coding?


Thanks,
SJ

[...]
</pre>
</details>
<div class="review-comment-signals">Signals: suggested improvement, personal taste</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Johannes Weiner</span>
<a class="date-chip" href="../2026-02-13_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="inline-review-badge">Inline Review</span>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Johannes Weiner raised concerns about the patch&#x27;s implementation of watermark boosting for atomic allocation failure. He suggested separating the paths for fragmentation management and atomic boosting, simplifying the mult_frac() calculation, and improving the logic for boosting all eligible zones.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">On Fri, Feb 13, 2026 at 11:17:59AM +0800, Qiliang Yuan wrote:
&gt; Atomic allocations (GFP_ATOMIC) are prone to failure under heavy memory
&gt; pressure as they cannot enter direct reclaim. This patch introduces a
&gt; watermark boost mechanism to mitigate this issue.
&gt; 
&gt; When a GFP_ATOMIC request enters the slowpath, the preferred zone&#x27;s
&gt; watermark_boost is increased under zone-&gt;lock protection. This triggers
&gt; kswapd to proactively reclaim memory, creating a safety buffer for
&gt; future atomic allocations. A 1-second debounce timer prevents excessive
&gt; boosts during traffic bursts.
&gt; 
&gt; This approach reuses existing watermark_boost infrastructure with
&gt; minimal overhead and proper locking to ensure thread safety.
&gt; 
&gt; Allocation failure logs:
&gt; [38535644.718700] node 0: slabs: 1031, objs: 43328, free: 0
&gt; [38535644.725059] node 1: slabs: 339, objs: 17616, free: 317
&gt; [38535645.428345] SLUB: Unable to allocate memory on node -1, gfp=0x480020(GFP_ATOMIC)
&gt; [38535645.436888] cache: skbuff_head_cache, object size: 232, buffer size: 256, default order: 2, min order: 0
&gt; [38535645.447664] node 0: slabs: 940, objs: 40864, free: 144
&gt; [38535645.454026] node 1: slabs: 322, objs: 19168, free: 383
&gt; [38535645.556122] SLUB: Unable to allocate memory on node -1, gfp=0x480020(GFP_ATOMIC)
&gt; [38535645.564576] cache: skbuff_head_cache, object size: 232, buffer size: 256, default order: 2, min order: 0
&gt; [38535649.655523] warn_alloc: 59 callbacks suppressed
&gt; [38535649.655527] swapper/100: page allocation failure: order:0, mode:0x480020(GFP_ATOMIC), nodemask=(null)
&gt; [38535649.671692] swapper/100 cpuset=/ mems_allowed=0-1
&gt; 
&gt; Acked-by: Vlastimil Babka &lt;vbabka@suse.cz&gt;
&gt; Signed-off-by: Qiliang Yuan &lt;realwujing@gmail.com&gt;
&gt; ---
&gt; v9:
&gt; - Use mult_frac() for boost calculation. (SJ)
&gt; - Add !can_direct_reclaim check. (Vlastimil)
&gt; - Code cleanup: naming, scope, and line limits. (SJ)
&gt; - Update tags: Add Vlastimil&#x27;s Acked-by.
&gt; 
&gt; v8:
&gt; - Use spin_lock_irqsave() to prevent inconsistent lock state.
&gt; 
&gt; v7:
&gt; - Use local variable for boost_amount.
&gt; - Add zone-&gt;lock protection.
&gt; - Add lockdep assertion.
&gt; 
&gt; v6:
&gt; - Use ATOMIC_BOOST_SCALE_SHIFT define.
&gt; - Add documentation for 0.1% rationale.
&gt; 
&gt; v5:
&gt; - Use native boost_watermark().
&gt; 
&gt; v4:
&gt; - Add watermark_scale_boost and gradual decay.
&gt; 
&gt; v3:
&gt; - Per-zone debounce timer.
&gt; 
&gt; v2:
&gt; - Debounce logic and zone-proportional boosting.
&gt; 
&gt; v1:
&gt; - Initial version.
&gt; ---
&gt; Link to v8: https://lore.kernel.org/r/20260212-wujing-mm-page_alloc-v8-v8-1-daba38990cd3@gmail.com
&gt; ---
&gt;  include/linux/mmzone.h |  1 +
&gt;  mm/page_alloc.c        | 49 +++++++++++++++++++++++++++++++++++++++++++++++--
&gt;  2 files changed, 48 insertions(+), 2 deletions(-)
&gt; 
&gt; diff --git a/include/linux/mmzone.h b/include/linux/mmzone.h
&gt; index 75ef7c9f9307..8e37e4e6765b 100644
&gt; --- a/include/linux/mmzone.h
&gt; +++ b/include/linux/mmzone.h
&gt; @@ -882,6 +882,7 @@ struct zone {
&gt;  	/* zone watermarks, access with *_wmark_pages(zone) macros */
&gt;  	unsigned long _watermark[NR_WMARK];
&gt;  	unsigned long watermark_boost;
&gt; +	unsigned long last_boost_jiffies;
&gt;  
&gt;  	unsigned long nr_reserved_highatomic;
&gt;  	unsigned long nr_free_highatomic;
&gt; diff --git a/mm/page_alloc.c b/mm/page_alloc.c
&gt; index c380f063e8b7..8af88584a8bd 100644
&gt; --- a/mm/page_alloc.c
&gt; +++ b/mm/page_alloc.c
&gt; @@ -218,6 +218,13 @@ unsigned int pageblock_order __read_mostly;
&gt;  static void __free_pages_ok(struct page *page, unsigned int order,
&gt;  			    fpi_t fpi_flags);
&gt;  
&gt; +/*
&gt; + * Boost watermarks by ~0.1% of zone size on atomic allocation pressure.
&gt; + * This provides zone-proportional safety buffers: ~1MB per 1GB of zone size.
&gt; + * Larger zones under GFP_ATOMIC pressure need proportionally larger reserves.
&gt; + */
&gt; +#define ATOMIC_BOOST_FACTOR 1
&gt; +
&gt;  /*
&gt;   * results with 256, 32 in the lowmem_reserve sysctl:
&gt;   *	1G machine -&gt; (16M dma, 800M-16M normal, 1G-800M high)
&gt; @@ -2161,6 +2168,9 @@ bool pageblock_unisolate_and_move_free_pages(struct zone *zone, struct page *pag
&gt;  static inline bool boost_watermark(struct zone *zone)
&gt;  {
&gt;  	unsigned long max_boost;
&gt; +	unsigned long boost_amount;
&gt; +
&gt; +	lockdep_assert_held(&amp;zone-&gt;lock);
&gt;  
&gt;  	if (!watermark_boost_factor)
&gt;  		return false;

watermark_boost_factor is for fragmentation management. It&#x27;s valid to
have this set to 0 and still want boosting for atomic.

&gt; @@ -2189,12 +2199,43 @@ static inline bool boost_watermark(struct zone *zone)
&gt;  
&gt;  	max_boost = max(pageblock_nr_pages, max_boost);
&gt;  
&gt; -	zone-&gt;watermark_boost = min(zone-&gt;watermark_boost + pageblock_nr_pages,
&gt; -		max_boost);
&gt; +	boost_amount = max(pageblock_nr_pages,
&gt; +			   mult_frac(zone_managed_pages(zone), ATOMIC_BOOST_FACTOR, 1000));
&gt; +	zone-&gt;watermark_boost = min(zone-&gt;watermark_boost + boost_amount,
&gt; +				    max_boost);

Likewise, you don&#x27;t want to add the atomic boost every time there is a
fragmentation event. You need to separate these paths.

The mult_frac() with constants seems a bit funny to me. Just do
zone_managed_pages(zone) / 1000, drop the define, and move the comment
and move the comment here.

&gt; +static void boost_zone_for_atomic(struct alloc_context *ac, gfp_t gfp_mask)
&gt; +{
&gt; +	struct zoneref *z;
&gt; +	struct zone *zone;
&gt; +	unsigned long now = jiffies;
&gt; +
&gt; +	for_each_zone_zonelist(zone, z, ac-&gt;zonelist, ac-&gt;highest_zoneidx) {

for_each_zone_zonelist_nodemask() with ac-&gt;nodemask?

&gt; +		/* Rate-limit boosts to once per second per zone */
&gt; +		if (time_after(now, zone-&gt;last_boost_jiffies + HZ)) {
&gt; +			unsigned long flags;
&gt; +			bool should_wake;
&gt; +
&gt; +			zone-&gt;last_boost_jiffies = now;
&gt; +
&gt; +			/* Modify watermark under lock, wake kswapd outside */
&gt; +			spin_lock_irqsave(&amp;zone-&gt;lock, flags);
&gt; +			should_wake = boost_watermark(zone);
&gt; +			spin_unlock_irqrestore(&amp;zone-&gt;lock, flags);
&gt; +
&gt; +			if (should_wake)
&gt; +				wakeup_kswapd(zone, gfp_mask, 0,
&gt; +					      ac-&gt;highest_zoneidx);
&gt; +
&gt; +			/* Boost only the preferred zone */
&gt; +			break;
&gt; +		}
&gt; +	}

This is a bit strange to me. By the time you boost, all eligible zones
have been tried, and ALL their reserves were found to be inadequate
for the incoming atomic requests. They all *should* be boosted.

By doing them one by one, you risk additional failures even though you
already KNOW at this point that these other zones are problematic too.

So IMO, by the time you reach here, they should all be boosted.

&gt; @@ -4742,6 +4783,10 @@ __alloc_pages_slowpath(gfp_t gfp_mask, unsigned int order,
&gt;  	if (page)
&gt;  		goto got_pg;
&gt;  
&gt; +	/* Boost watermarks for atomic requests entering slowpath */
&gt; +	if ((gfp_mask &amp; GFP_ATOMIC) &amp;&amp; order == 0 &amp;&amp; !can_direct_reclaim)

This is a bit weird. GFP_ATOMIC is a mask, so this check will trigger
on anything that has __GFP_KSWAPD_RECLAIM set (which is most things),
so in turn you then have to filter out direct reclaim again (which the
real GFP_ATOMIC implies).

	if (gfp_has_flags(gfp_mask, GFP_ATOMIC))

&gt; +		boost_zone_for_atomic(ac, gfp_mask);
&gt; +

</pre>
</details>
<div class="review-comment-signals">Signals: requested changes, technical concerns</div>
</div>
</div>
</div>

    <footer>LKML Daily Activity Tracker</footer>
    <script>
    // When arriving via a date anchor (e.g. #2026-02-15 from a daily report),
    // scroll the anchor into view after a brief delay so layout is complete.
    (function () {
        var hash = window.location.hash;
        if (!hash) return;
        var target = document.getElementById(hash.slice(1));
        if (!target) return;
        setTimeout(function () {
            target.scrollIntoView({behavior: 'smooth', block: 'start'});
        }, 80);
    })();
    </script>
</body>
</html>