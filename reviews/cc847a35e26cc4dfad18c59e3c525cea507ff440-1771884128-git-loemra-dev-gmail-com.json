{
  "thread_id": "cc847a35e26cc4dfad18c59e3c525cea507ff440.1771884128.git.loemra.dev@gmail.com",
  "subject": "[PATCH v3 2/3] btrfs: inhibit extent buffer writeback to prevent COW amplification",
  "url": "https://lore.kernel.org/all/cc847a35e26cc4dfad18c59e3c525cea507ff440.1771884128.git.loemra.dev@gmail.com/",
  "dates": {
    "2026-02-24": {
      "report_file": "2026-02-24_ollama_llama3.1-8b.html",
      "developer": "Leo Martins",
      "reviews": [
        {
          "author": "David Hildenbrand",
          "summary": "The patch looks good, but the author should consider adding a comment to explain why the per-restart-site tracepoint is necessary and how it improves over the existing counter-based approach.",
          "sentiment": "positive",
          "sentiment_signals": [
            "NEEDS_WORK"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "",
          "reply_to": "",
          "message_date": "",
          "message_id": ""
        }
      ],
      "analysis_source": "llm",
      "patch_summary": "This patch adds a new tracepoint to the Btrfs kernel module, allowing for tracking of search slot restarts in btrfs_search_slot(). The tracepoint records the root, tree level, and reason for each restart, enabling more detailed analysis of COW amplification under memory pressure."
    },
    "2026-02-25": {
      "report_file": "2026-02-25_ollama_llama3.1-8b.html",
      "developer": "Leo Martins",
      "reviews": [
        {
          "author": "Sun YangKai",
          "summary": "I might be missing something here, but I'm curious whether this atomic counter can ever go above 1. If not, and it's strictly binary, perhaps using atomic_set(1/0) instead of atomic_inc/dec would make the intent clearer? Otherwise looks good. Thanks.",
          "sentiment": "neutral",
          "sentiment_signals": [],
          "has_inline_review": true,
          "tags_given": [],
          "analysis_source": "heuristic",
          "raw_body": "\n\nOn 2026/2/25 03:22, Leo Martins wrote:\n> Inhibit writeback on COW'd extent buffers for the lifetime of the\n> transaction handle, preventing background writeback from setting\n> BTRFS_HEADER_FLAG_WRITTEN and causing unnecessary re-COW.\n> \n> COW amplification occurs when background writeback flushes an extent\n> buffer that a transaction handle is still actively modifying. When\n> lock_extent_buffer_for_io() transitions a buffer from dirty to\n> writeback, it sets BTRFS_HEADER_FLAG_WRITTEN, marking the block as\n> having been persisted to disk at its current bytenr. Once WRITTEN is\n> set, should_cow_block() must either COW the block again or overwrite\n> it in place, both of which are unnecessary overhead when the buffer\n> is still being modified by the same handle that allocated it. By\n> inhibiting background writeback on actively-used buffers, WRITTEN is\n> never set while a transaction handle holds a reference to the buffer,\n> avoiding this overhead entirely.\n> \n> Add an atomic_t writeback_inhibitors counter to struct extent_buffer,\n> which fits in an existing 6-byte hole without increasing struct size.\n> When a buffer is COW'd in btrfs_force_cow_block(), call\n> btrfs_inhibit_eb_writeback() to store the eb in the transaction\n> handle's writeback_inhibited_ebs xarray (keyed by eb->start), take a\n> reference, and increment writeback_inhibitors. The function handles\n> dedup (same eb inhibited twice by the same handle) and replacement\n> (different eb at the same logical address). Allocation failure is\n> graceful: the buffer simply falls back to the pre-existing behavior\n> where it may be written back and re-COW'd.\n> \n> In lock_extent_buffer_for_io(), when writeback_inhibitors is non-zero\n> and the writeback mode is WB_SYNC_NONE, skip the buffer. WB_SYNC_NONE\n> is used by the VM flusher threads for background and periodic\n> writeback, which are the only paths that cause COW amplification by\n> opportunistically writing out dirty extent buffers mid-transaction.\n> Skipping these is safe because the buffers remain dirty in the page\n> cache and will be written out at transaction commit time.\n> \n> WB_SYNC_ALL must always proceed regardless of writeback_inhibitors.\n> This is required for correctness in the fsync path: btrfs_sync_log()\n> writes log tree blocks via filemap_fdatawrite_range() (WB_SYNC_ALL)\n> while the transaction handle that inhibited those same blocks is still\n> active. Without the WB_SYNC_ALL bypass, those inhibited log tree\n> blocks would be silently skipped, resulting in an incomplete log on\n> disk and corruption on replay. btrfs_write_and_wait_transaction()\n> also uses WB_SYNC_ALL via filemap_fdatawrite_range(); for that path,\n> inhibitors are already cleared beforehand, but the bypass ensures\n> correctness regardless.\n> \n> Uninhibit in __btrfs_end_transaction() before atomic_dec(num_writers)\n> to prevent a race where the committer proceeds while buffers are still\n> inhibited. Also uninhibit in btrfs_commit_transaction() before writing\n> and in cleanup_transaction() for the error path.\n> \n> Signed-off-by: Leo Martins <loemra.dev@gmail.com>\n> Reviewed-by: Filipe Manana <fdmanana@suse.com>\n> ---\n>   fs/btrfs/ctree.c       |  4 +++\n>   fs/btrfs/extent_io.c   | 63 +++++++++++++++++++++++++++++++++++++++++-\n>   fs/btrfs/extent_io.h   |  6 ++++\n>   fs/btrfs/transaction.c | 19 +++++++++++++\n>   fs/btrfs/transaction.h |  3 ++\n>   5 files changed, 94 insertions(+), 1 deletion(-)\n> \n> diff --git a/fs/btrfs/ctree.c b/fs/btrfs/ctree.c\n> index 0e02b7b14adc..d4da65bb9096 100644\n> --- a/fs/btrfs/ctree.c\n> +++ b/fs/btrfs/ctree.c\n> @@ -590,6 +590,10 @@ int btrfs_force_cow_block(struct btrfs_trans_handle *trans,\n>   \t\tbtrfs_tree_unlock(buf);\n>   \tfree_extent_buffer_stale(buf);\n>   \tbtrfs_mark_buffer_dirty(trans, cow);\n> +\n> +\t/* Inhibit writeback on the COW'd buffer for this transaction handle. */\n> +\tbtrfs_inhibit_eb_writeback(trans, cow);\n> +\n>   \t*cow_ret = cow;\n>   \treturn 0;\n>   \n> diff --git a/fs/btrfs/extent_io.c b/fs/btrfs/extent_io.c\n> index ff1fc699a6ca..e04e42a81978 100644\n> --- a/fs/btrfs/extent_io.c\n> +++ b/fs/btrfs/extent_io.c\n> @@ -1940,7 +1940,9 @@ static noinline_for_stack bool lock_extent_buffer_for_io(struct extent_buffer *e\n>   \t * of time.\n>   \t */\n>   \tspin_lock(&eb->refs_lock);\n> -\tif (test_and_clear_bit(EXTENT_BUFFER_DIRTY, &eb->bflags)) {\n> +\tif ((wbc->sync_mode == WB_SYNC_ALL ||\n> +\t     atomic_read(&eb->writeback_inhibitors) == 0) &&\n> +\t    test_and_clear_bit(EXTENT_BUFFER_DIRTY, &eb->bflags)) {\n>   \t\tXA_STATE(xas, &fs_info->buffer_tree, eb->start >> fs_info->nodesize_bits);\n>   \t\tunsigned long flags;\n>   \n> @@ -2999,6 +3001,64 @@ static inline void btrfs_release_extent_buffer(struct extent_buffer *eb)\n>   \tkmem_cache_free(extent_buffer_cache, eb);\n>   }\n>   \n> +/*\n> + * btrfs_inhibit_eb_writeback - Inhibit writeback on buffer during transaction.\n> + * @trans: transaction handle that will own the inhibitor\n> + * @eb: extent buffer to inhibit writeback on\n> + *\n> + * Attempts to track this extent buffer in the transaction's inhibited set.\n> + * If memory allocation fails, the buffer is simply not tracked. It may\n> + * be written back and need re-COW, which is the original behavior.\n> + * This is acceptable since inhibiting writeback is an optimization.\n> + */\n> +void btrfs_inhibit_eb_writeback(struct btrfs_trans_handle *trans,\n> +\t\t\t\tstruct extent_buffer *eb)\n> +{\n> +\tunsigned long index = eb->start >> trans->fs_info->nodesize_bits;\n> +\tvoid *old;\n> +\n> +\t/* Check if already inhibited by this handle. */\n> +\told = xa_load(&trans->writeback_inhibited_ebs, index);\n> +\tif (old == eb)\n> +\t\treturn;\n> +\n> +\t/* Take reference for the xarray entry. */\n> +\trefcount_inc(&eb->refs);\n> +\n> +\told = xa_store(&trans->writeback_inhibited_ebs, index, eb, GFP_NOFS);\n> +\tif (xa_is_err(old)) {\n> +\t\t/* Allocation failed, just skip inhibiting this buffer. */\n> +\t\tfree_extent_buffer(eb);\n> +\t\treturn;\n> +\t}\n> +\n> +\t/* Handle replacement of different eb at same index. */\n> +\tif (old && old != eb) {\n> +\t\tstruct extent_buffer *old_eb = old;\n> +\n> +\t\tatomic_dec(&old_eb->writeback_inhibitors);\n> +\t\tfree_extent_buffer(old_eb);\n> +\t}\n> +\n> +\tatomic_inc(&eb->writeback_inhibitors);\n> +}\n> +\n> +/*\n> + * btrfs_uninhibit_all_eb_writeback - Uninhibit writeback on all buffers.\n> + * @trans: transaction handle to clean up\n> + */\n> +void btrfs_uninhibit_all_eb_writeback(struct btrfs_trans_handle *trans)\n> +{\n> +\tstruct extent_buffer *eb;\n> +\tunsigned long index;\n> +\n> +\txa_for_each(&trans->writeback_inhibited_ebs, index, eb) {\n> +\t\tatomic_dec(&eb->writeback_inhibitors);\n> +\t\tfree_extent_buffer(eb);\n> +\t}\n> +\txa_destroy(&trans->writeback_inhibited_ebs);\n> +}\n> +\n>   static struct extent_buffer *__alloc_extent_buffer(struct btrfs_fs_info *fs_info,\n>   \t\t\t\t\t\t   u64 start)\n>   {\n> @@ -3009,6 +3069,7 @@ static struct extent_buffer *__alloc_extent_buffer(struct btrfs_fs_info *fs_info\n>   \teb->len = fs_info->nodesize;\n>   \teb->fs_info = fs_info;\n>   \tinit_rwsem(&eb->lock);\n> +\tatomic_set(&eb->writeback_inhibitors, 0);\n>   \n>   \tbtrfs_leak_debug_add_eb(eb);\n>   \n> diff --git a/fs/btrfs/extent_io.h b/fs/btrfs/extent_io.h\n> index 73571d5d3d5a..fb68fbd4866c 100644\n> --- a/fs/btrfs/extent_io.h\n> +++ b/fs/btrfs/extent_io.h\n> @@ -102,6 +102,8 @@ struct extent_buffer {\n>   \t/* >= 0 if eb belongs to a log tree, -1 otherwise */\n>   \ts8 log_index;\n>   \tu8 folio_shift;\n> +\t/* Inhibits WB_SYNC_NONE writeback when > 0. */\n> +\tatomic_t writeback_inhibitors;\n\nI might be missing something here, but I'm curious whether this atomic \ncounter can ever go above 1. If not, and it's strictly binary, perhaps \nusing atomic_set(1/0) instead of atomic_inc/dec would make the intent \nclearer?\n\nOtherwise looks good. Thanks.\n\n>   \tstruct rcu_head rcu_head;\n>   \n>   \tstruct rw_semaphore lock;\n> @@ -381,4 +383,8 @@ void btrfs_extent_buffer_leak_debug_check(struct btrfs_fs_info *fs_info);\n>   #define btrfs_extent_buffer_leak_debug_check(fs_info)\tdo {} while (0)\n>   #endif\n>   \n> +void btrfs_inhibit_eb_writeback(struct btrfs_trans_handle *trans,\n> +\t\t\t       struct extent_buffer *eb);\n> +void btrfs_uninhibit_all_eb_writeback(struct btrfs_trans_handle *trans);\n> +\n>   #endif\n> diff --git a/fs/btrfs/transaction.c b/fs/btrfs/transaction.c\n> index f4cc9e1a1b93..a9a22629b49d 100644\n> --- a/fs/btrfs/transaction.c\n> +++ b/fs/btrfs/transaction.c\n> @@ -15,6 +15,7 @@\n>   #include \"misc.h\"\n>   #include \"ctree.h\"\n>   #include \"disk-io.h\"\n> +#include \"extent_io.h\"\n>   #include \"transaction.h\"\n>   #include \"locking.h\"\n>   #include \"tree-log.h\"\n> @@ -688,6 +689,8 @@ start_transaction(struct btrfs_root *root, unsigned int num_items,\n>   \t\tgoto alloc_fail;\n>   \t}\n>   \n> +\txa_init(&h->writeback_inhibited_ebs);\n> +\n>   \t/*\n>   \t * If we are JOIN_NOLOCK we're already committing a transaction and\n>   \t * waiting on this guy, so we don't need to do the sb_start_intwrite\n> @@ -1083,6 +1086,13 @@ static int __btrfs_end_transaction(struct btrfs_trans_handle *trans,\n>   \tif (trans->type & __TRANS_FREEZABLE)\n>   \t\tsb_end_intwrite(info->sb);\n>   \n> +\t/*\n> +\t * Uninhibit extent buffer writeback before decrementing num_writers,\n> +\t * since the decrement wakes the committing thread which needs all\n> +\t * buffers uninhibited to write them to disk.\n> +\t */\n> +\tbtrfs_uninhibit_all_eb_writeback(trans);\n> +\n>   \tWARN_ON(cur_trans != info->running_transaction);\n>   \tWARN_ON(atomic_read(&cur_trans->num_writers) < 1);\n>   \tatomic_dec(&cur_trans->num_writers);\n> @@ -2110,6 +2120,7 @@ static void cleanup_transaction(struct btrfs_trans_handle *trans, int err)\n>   \tif (!test_bit(BTRFS_FS_RELOC_RUNNING, &fs_info->flags))\n>   \t\tbtrfs_scrub_cancel(fs_info);\n>   \n> +\tbtrfs_uninhibit_all_eb_writeback(trans);\n>   \tkmem_cache_free(btrfs_trans_handle_cachep, trans);\n>   }\n>   \n> @@ -2556,6 +2567,14 @@ int btrfs_commit_transaction(struct btrfs_trans_handle *trans)\n>   \t    fs_info->cleaner_kthread)\n>   \t\twake_up_process(fs_info->cleaner_kthread);\n>   \n> +\t/*\n> +\t * Uninhibit writeback on all extent buffers inhibited during this\n> +\t * transaction before writing them to disk. Inhibiting prevented\n> +\t * writeback while the transaction was building, but now we need\n> +\t * them written.\n> +\t */\n> +\tbtrfs_uninhibit_all_eb_writeback(trans);\n> +\n>   \tret = btrfs_write_and_wait_transaction(trans);\n>   \tif (unlikely(ret)) {\n>   \t\tbtrfs_err(fs_info, \"error while writing out transaction: %d\", ret);\n> diff --git a/fs/btrfs/transaction.h b/fs/btrfs/transaction.h\n> index 18ef069197e5..7d70fe486758 100644\n> --- a/fs/btrfs/transaction.h\n> +++ b/fs/btrfs/transaction.h\n> @@ -12,6 +12,7 @@\n>   #include <linux/time64.h>\n>   #include <linux/mutex.h>\n>   #include <linux/wait.h>\n> +#include <linux/xarray.h>\n>   #include \"btrfs_inode.h\"\n>   #include \"delayed-ref.h\"\n>   \n> @@ -162,6 +163,8 @@ struct btrfs_trans_handle {\n>   \tstruct btrfs_fs_info *fs_info;\n>   \tstruct list_head new_bgs;\n>   \tstruct btrfs_block_rsv delayed_rsv;\n> +\t/* Extent buffers with writeback inhibited by this handle. */\n> +\tstruct xarray writeback_inhibited_ebs;\n>   };\n>   \n>   /*\n\n",
          "reply_to": "",
          "message_date": "2026-02-25",
          "message_id": ""
        }
      ],
      "analysis_source": "heuristic",
      "patch_summary": "Inhibit writeback on COW'd extent buffers for the lifetime of the transaction handle, preventing background writeback from setting BTRFS_HEADER_FLAG_WRITTEN and causing unnecessary re-COW.\n\nCOW amplification occurs when background writeback flushes an extent buffer that a transaction handle is still actively modifying. When lock_extent_buffer_for_io() transitions a buffer from dirty to writeback, it sets BTRFS_HEADER_FLAG_WRITTEN, marking the block as having been persisted to disk at its current bytenr. Once WRITTEN is set, should_cow_block() must either COW the block again or overwrite it in place, both of which are unnecessary overhead when the buffer is still being modified by the same handle that allocated it. By inhibiting background writeback on actively-used buffers, WRITTEN is never set while a transaction handle holds a reference to the buffer, avoiding this overhead entirely."
    },
    "2026-02-26": {
      "report_file": "2026-02-26_ollama_llama3.1-8b.html",
      "developer": "Leo Martins",
      "reviews": [
        {
          "author": "Sun YangKai",
          "summary": "Reviewer noted that the current implementation only inhibits writeback when an extent buffer (eb) is COW'd, but does not account for cases where a transaction handle reuses a previously COW'd eb without re-COWing it, potentially leading to COW amplification.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "potential bug",
            "requested change"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Oh, I've just got the idea. It's inhibited per trans handle. Then it \nmakes a lot of sense.\n\nThere might be some ebs that were inhibited due to tree rebalancing or \ntree walking and are no longer used, but I don't think this is a blocker \nfor this patch.\n\nLooking forward to your next patch version :)",
          "reply_to": "Leo Martins",
          "message_date": "2026-02-26",
          "message_id": "f5788abc-f4de-4f3a-9ab1-7aaa579c89c9@gmail.com"
        }
      ],
      "analysis_source": "llm-per-reviewer",
      "patch_summary": "This patch addresses a potential issue in the Btrfs file system where COW (Copy On Write) amplification could occur due to incorrect handling of extent buffer writeback. The problem arises when multiple transactions modify the same extent buffer, and one transaction inhibits writeback after COWing the buffer, while another transaction reuses the buffer without re-COWing it. To fix this, the patch modifies the code to inhibit writeback not only when a buffer is COWed but also whenever a handle reuses a COWed buffer without re-COWing it."
    }
  }
}