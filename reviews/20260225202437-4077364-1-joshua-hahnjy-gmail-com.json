{
  "thread_id": "20260225202437.4077364-1-joshua.hahnjy@gmail.com",
  "subject": "[RFC PATCH v1 0/7] Open HugeTLB allocation routine for more generic use",
  "url": "https://lore.kernel.org/all/20260225202437.4077364-1-joshua.hahnjy@gmail.com/",
  "dates": {
    "2026-02-25": {
      "report_file": "2026-02-25_ollama_llama3.1-8b.html",
      "developer": "Joshua Hahn",
      "reviews": [
        {
          "author": "Ackerley Tng",
          "summary": "Reviewer noted that huge pages from the buddy allocator have advantages over HugeTLB, including faster allocation and guaranteed huge page size, but suggested using HugeTLB for administrative/scheduling purposes due to existing workload scheduling across machines.\n\nReviewer noted that reintroducing the try-commit-cancel protocol may be necessary due to new paths for hugetlb pages to be consumed without reservation or vma, which could increase the cost of assuming the memcg limit is OK and requested explicit justification for its reintroduction.\n\nReviewer Ackerley Tng noted that reintroducing the try-commit-cancel protocol in this patch series is necessary to cleanly refactor out hugetlb_alloc_folio() without worrying about edge cases around HugeTLB reservations and charging, as alternative approaches would introduce additional complexities such as depending on freeing the new hugetlb folio on memcg charging failure or dealing with subpool influences. They also mentioned that reintroducing the protocol has benefits like avoiding allocations when the memcg limit is hit and simplifying the code.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes",
            "reintroducing the try-commit-cancel protocol is necessary",
            "alternative approaches introduce additional complexities"
          ],
          "has_inline_review": true,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "The one other huge page source that we've explored is THP pages from the\nbuddy allocator. Compared to HugeTLB, huge pages from the buddy\nallocator\n\n+ Has a maximum size of 2M\n+ Does not guarantee huge pages the way HugeTLB does - HugeTLB pages are\n  allocated at boot, and guest_memfd can reserve pages at guest_memfd\n  creation time.\n+ Allocation of HugeTLB pages is also really fast, it's just dequeuing\n  from a preallocated pool\n\nThe last reason to use HugeTLB is not because of any inherent advantage\nof using HugeTLB over other sources of huge pages, but for\nadministrative/scheduling purposes:\n\n  Given that existing non-guest_memfd workloads are already using\n  HugeTLB, for optimal scheduling, machine memory is already carved up\n  in HugeTLB pages for these workloads. Workloads that require using\n  guest_memfd (like Confidential VMs) must also use HugeTLB to\n  participate in optimial workload scheduling across machines.\n\n---\n\nThanks for this! I saw your patch to just optimistically grab a HugeTLB\npage :) For that patch, the primary reason was to simplify the logic,\nand the simplification was justifiable because grabbing a folio is\ncheap, right? (And so grabbing a folio being cheap wasn't a reason in\nitself?)\n\n---\n\nYes, I should have done that. Will copy the following to the next\nrevision.\n\nThe main reason is that reintroducing the charging protocol is the\nclearest way (for me) to cleanly refactor out hugetlb_alloc_folio()\nwithout worrying about the edge cases around HugeTLB reservations and\ncharging.\n\nIf I didn't reintroduce the charging protocol, I would have to depend on\nfreeing the new hugetlb folio on memcg charging failure, and the freeing\nin turn depends on the subpool correctly being set in the folio, and the\npresence of the subpool influences (in free_huge_folio()) whether the\nreservation was returned to the global hstate. Aaannnd... there's also a\nhugetlb_restore_reserve flag that controls whether to return the folio\nto the subpool (and the hstate). I find folio_clear_hugetlb_restore_reserve()\non certain code paths kind of magical/unexplained too.\n\nI would rather iron out those charging and reservation details\nseparately from this series (with more testing support).\n\n\nOn the other hand, reintroducing the charging protocol has the benefit\nof avoiding allocations (not just dequeuing, if surplus HugeTLB pages\nare required) if the memcg limit is hit. Also, if the original reason\nfor removing the protocol was to simplify the code, refactoring out\nhugetlb_alloc_folio() also simplifies the code, and I think it's\nactually nice that memcg charging is done the same way as the other two\n(h_cg and h_cg_rsvd charging). After hugetlb_alloc_folio() is refactored\nout, the gotos make all three charging systems consistent and symmetric,\nwhich I think is nice to have :)\n\nI hope the consistent/symmetric charging among all 3 systems is welcome,\nwhat do you think?",
          "reply_to": "Joshua Hahn",
          "message_date": "2026-02-25",
          "message_id": "CAEvNRgGaJXbOGPQSgvo3rVDfis22DC4hYy=2Rczas0Vm3o66kQ@mail.gmail.com"
        }
      ],
      "analysis_source": "llm-per-reviewer",
      "patch_summary": "This patch introduces new paths for hugetlb pages to be consumed without a reservation or vma, which may increase the frequency of slowpath operations and make the cost of assuming the memcg limit is OK higher. The patch reintroduces the try-commit-cancel protocol to mitigate this issue. The goal of the series is to decouple hugeTLB from hugeTLBfs, but it's unclear what benefits hugeTLB offers over other hugepage solutions for guest_memfd."
    }
  }
}