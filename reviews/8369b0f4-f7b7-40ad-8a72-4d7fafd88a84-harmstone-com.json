{
  "thread_id": "8369b0f4-f7b7-40ad-8a72-4d7fafd88a84@harmstone.com",
  "subject": "Re: [PATCH v8 09/17] btrfs: redirect I/O for remapped block groups",
  "url": "https://lore.kernel.org/all/8369b0f4-f7b7-40ad-8a72-4d7fafd88a84@harmstone.com/",
  "dates": {
    "2026-02-18": {
      "report_file": "2026-02-18_ollama_llama3.1-8b.html",
      "developer": "Mark Harmstone",
      "reviews": [
        {
          "author": "Mark Harmstone (author)",
          "summary": "Reviewer Mark Harmstone pointed out a mistake in the code where a return value was leaked due to copying from another section of code.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "leaked return value"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Add an incompat flag for the new remap-tree feature, and the constants\nand definitions needed to support it.\n\nSigned-off-by: Mark Harmstone <mark@harmstone.com>\nReviewed-by: Boris Burkov <boris@bur.io>\n---\n fs/btrfs/accessors.h            |  4 ++++\n fs/btrfs/locking.c              |  1 +\n fs/btrfs/sysfs.c                |  2 ++\n fs/btrfs/tree-checker.c         |  6 ++----\n fs/btrfs/tree-checker.h         |  5 +++++\n fs/btrfs/volumes.c              |  1 +\n include/uapi/linux/btrfs.h      |  1 +\n include/uapi/linux/btrfs_tree.h | 17 +++++++++++++++++\n 8 files changed, 33 insertions(+), 4 deletions(-)\n\ndiff --git a/fs/btrfs/accessors.h b/fs/btrfs/accessors.h\nindex 78721412951c..09cdd6bfddf5 100644\n--- a/fs/btrfs/accessors.h\n+++ b/fs/btrfs/accessors.h\n@@ -1010,6 +1010,10 @@ BTRFS_SETGET_STACK_FUNCS(stack_verity_descriptor_encryption,\n BTRFS_SETGET_STACK_FUNCS(stack_verity_descriptor_size,\n \t\t\t struct btrfs_verity_descriptor_item, size, 64);\n \n+BTRFS_SETGET_FUNCS(remap_address, struct btrfs_remap_item, address, 64);\n+BTRFS_SETGET_STACK_FUNCS(stack_remap_address, struct btrfs_remap_item,\n+\t\t\t address, 64);\n+\n /* Cast into the data area of the leaf. */\n #define btrfs_item_ptr(leaf, slot, type)\t\t\t\t\\\n \t((type *)(btrfs_item_nr_offset(leaf, 0) + btrfs_item_offset(leaf, slot)))\ndiff --git a/fs/btrfs/locking.c b/fs/btrfs/locking.c\nindex 0035851d72b0..e3df5ca0b552 100644\n--- a/fs/btrfs/locking.c\n+++ b/fs/btrfs/locking.c\n@@ -73,6 +73,7 @@ static struct btrfs_lockdep_keyset {\n \t{ .id = BTRFS_FREE_SPACE_TREE_OBJECTID,\tDEFINE_NAME(\"free-space\") },\n \t{ .id = BTRFS_BLOCK_GROUP_TREE_OBJECTID, DEFINE_NAME(\"block-group\") },\n \t{ .id = BTRFS_RAID_STRIPE_TREE_OBJECTID, DEFINE_NAME(\"raid-stripe\") },\n+\t{ .id = BTRFS_REMAP_TREE_OBJECTID,      DEFINE_NAME(\"remap\") },\n \t{ .id = 0,\t\t\t\tDEFINE_NAME(\"tree\")\t},\n };\n \ndiff --git a/fs/btrfs/sysfs.c b/fs/btrfs/sysfs.c\nindex f0974f4c0ae4..0e2ed8072443 100644\n--- a/fs/btrfs/sysfs.c\n+++ b/fs/btrfs/sysfs.c\n@@ -291,6 +291,7 @@ BTRFS_FEAT_ATTR_COMPAT_RO(free_space_tree, FREE_SPACE_TREE);\n BTRFS_FEAT_ATTR_COMPAT_RO(block_group_tree, BLOCK_GROUP_TREE);\n BTRFS_FEAT_ATTR_INCOMPAT(raid1c34, RAID1C34);\n BTRFS_FEAT_ATTR_INCOMPAT(simple_quota, SIMPLE_QUOTA);\n+BTRFS_FEAT_ATTR_INCOMPAT(remap_tree, REMAP_TREE);\n #ifdef CONFIG_BLK_DEV_ZONED\n BTRFS_FEAT_ATTR_INCOMPAT(zoned, ZONED);\n #endif\n@@ -331,6 +332,7 @@ static struct attribute *btrfs_supported_feature_attrs[] = {\n #ifdef CONFIG_BTRFS_EXPERIMENTAL\n \tBTRFS_FEAT_ATTR_PTR(extent_tree_v2),\n \tBTRFS_FEAT_ATTR_PTR(raid_stripe_tree),\n+\tBTRFS_FEAT_ATTR_PTR(remap_tree),\n #endif\n #ifdef CONFIG_FS_VERITY\n \tBTRFS_FEAT_ATTR_PTR(verity),\ndiff --git a/fs/btrfs/tree-checker.c b/fs/btrfs/tree-checker.c\nindex c21c21adf61e..aedc208a95b8 100644\n--- a/fs/btrfs/tree-checker.c\n+++ b/fs/btrfs/tree-checker.c\n@@ -913,12 +913,10 @@ int btrfs_check_chunk_valid(const struct btrfs_fs_info *fs_info,\n \t\t\t  length, btrfs_stripe_nr_to_offset(U32_MAX));\n \t\treturn -EUCLEAN;\n \t}\n-\tif (unlikely(type & ~(BTRFS_BLOCK_GROUP_TYPE_MASK |\n-\t\t\t      BTRFS_BLOCK_GROUP_PROFILE_MASK))) {\n+\tif (unlikely(type & ~BTRFS_BLOCK_GROUP_VALID)) {\n \t\tchunk_err(fs_info, leaf, chunk, logical,\n \t\t\t  \"unrecognized chunk type: 0x%llx\",\n-\t\t\t  ~(BTRFS_BLOCK_GROUP_TYPE_MASK |\n-\t\t\t    BTRFS_BLOCK_GROUP_PROFILE_MASK) & type);\n+\t\t\t  type & ~BTRFS_BLOCK_GROUP_VALID);\n \t\treturn -EUCLEAN;\n \t}\n \ndiff --git a/fs/btrfs/tree-checker.h b/fs/btrfs/tree-checker.h\nindex eb201f4ec3c7..833e2fd989eb 100644\n--- a/fs/btrfs/tree-checker.h\n+++ b/fs/btrfs/tree-checker.h\n@@ -57,6 +57,11 @@ enum btrfs_tree_block_status {\n \tBTRFS_TREE_BLOCK_WRITTEN_NOT_SET,\n };\n \n+\n+#define BTRFS_BLOCK_GROUP_VALID\t(BTRFS_BLOCK_GROUP_TYPE_MASK | \\\n+\t\t\t\t BTRFS_BLOCK_GROUP_PROFILE_MASK | \\\n+\t\t\t\t BTRFS_BLOCK_GROUP_REMAPPED)\n+\n /*\n  * Exported simply for btrfs-progs which wants to have the\n  * btrfs_tree_block_status return codes.\ndiff --git a/fs/btrfs/volumes.c b/fs/btrfs/volumes.c\nindex ce0535c0264d..1134474926ff 100644\n--- a/fs/btrfs/volumes.c\n+++ b/fs/btrfs/volumes.c\n@@ -231,6 +231,7 @@ void btrfs_describe_block_groups(u64 bg_flags, char *buf, u32 size_buf)\n \tDESCRIBE_FLAG(BTRFS_BLOCK_GROUP_DATA, \"data\");\n \tDESCRIBE_FLAG(BTRFS_BLOCK_GROUP_SYSTEM, \"system\");\n \tDESCRIBE_FLAG(BTRFS_BLOCK_GROUP_METADATA, \"metadata\");\n+\tDESCRIBE_FLAG(BTRFS_BLOCK_GROUP_REMAPPED, \"remapped\");\n \n \tDESCRIBE_FLAG(BTRFS_AVAIL_ALLOC_BIT_SINGLE, \"single\");\n \tfor (i = 0; i < BTRFS_NR_RAID_TYPES; i++)\ndiff --git a/include/uapi/linux/btrfs.h b/include/uapi/linux/btrfs.h\nindex e8fd92789423..9165154a274d 100644\n--- a/include/uapi/linux/btrfs.h\n+++ b/include/uapi/linux/btrfs.h\n@@ -336,6 +336,7 @@ struct btrfs_ioctl_fs_info_args {\n #define BTRFS_FEATURE_INCOMPAT_EXTENT_TREE_V2\t(1ULL << 13)\n #define BTRFS_FEATURE_INCOMPAT_RAID_STRIPE_TREE\t(1ULL << 14)\n #define BTRFS_FEATURE_INCOMPAT_SIMPLE_QUOTA\t(1ULL << 16)\n+#define BTRFS_FEATURE_INCOMPAT_REMAP_TREE\t(1ULL << 17)\n \n struct btrfs_ioctl_feature_flags {\n \t__u64 compat_flags;\ndiff --git a/include/uapi/linux/btrfs_tree.h b/include/uapi/linux/btrfs_tree.h\nindex fc29d273845d..f011d34cb699 100644\n--- a/include/uapi/linux/btrfs_tree.h\n+++ b/include/uapi/linux/btrfs_tree.h\n@@ -76,6 +76,9 @@\n /* Tracks RAID stripes in block groups. */\n #define BTRFS_RAID_STRIPE_TREE_OBJECTID 12ULL\n \n+/* Holds details of remapped addresses after relocation. */\n+#define BTRFS_REMAP_TREE_OBJECTID 13ULL\n+\n /* device stats in the device tree */\n #define BTRFS_DEV_STATS_OBJECTID 0ULL\n \n@@ -282,6 +285,10 @@\n \n #define BTRFS_RAID_STRIPE_KEY\t230\n \n+#define BTRFS_IDENTITY_REMAP_KEY \t234\n+#define BTRFS_REMAP_KEY\t\t \t235\n+#define BTRFS_REMAP_BACKREF_KEY\t \t236\n+\n /*\n  * Records the overall state of the qgroups.\n  * There's only one instance of this key present,\n@@ -1161,6 +1168,7 @@ struct btrfs_dev_replace_item {\n #define BTRFS_BLOCK_GROUP_RAID6         (1ULL << 8)\n #define BTRFS_BLOCK_GROUP_RAID1C3       (1ULL << 9)\n #define BTRFS_BLOCK_GROUP_RAID1C4       (1ULL << 10)\n+#define BTRFS_BLOCK_GROUP_REMAPPED      (1ULL << 11)\n #define BTRFS_BLOCK_GROUP_RESERVED\t(BTRFS_AVAIL_ALLOC_BIT_SINGLE | \\\n \t\t\t\t\t BTRFS_SPACE_INFO_GLOBAL_RSV)\n \n@@ -1323,4 +1331,13 @@ struct btrfs_verity_descriptor_item {\n \t__u8 encryption;\n } __attribute__ ((__packed__));\n \n+/*\n+ * For a range identified by a BTRFS_REMAP_KEY item in the remap tree, gives\n+ * the address that the start of the range will get remapped to.  This\n+ * structure is also shared by BTRFS_REMAP_BACKREF_KEY.\n+ */\n+struct btrfs_remap_item {\n+\t__le64 address;\n+} __attribute__ ((__packed__));\n+\n #endif /* _BTRFS_CTREE_H_ */\n-- \n2.51.2\n\n\n\n---\n\nAdd a new METADATA_REMAP chunk type, which is a metadata chunk that holds the\nremap tree.\n\nThis is needed for bootstrapping purposes: the remap tree can't itself\nbe remapped, and must be relocated the existing way, by COWing every\nleaf. The remap tree can't go in the SYSTEM chunk as space there is\nlimited, because a copy of the chunk item gets placed in the superblock.\n\nThe changes in fs/btrfs/volumes.h are because we're adding a new block\ngroup type bit after the profile bits, and so can no longer rely on the\nconst_ilog2 trick.\n\nThe sizing to 32MB per chunk, matching the SYSTEM chunk, is an estimate\nhere, we can adjust it later if it proves to be too big or too small.\nThis works out to be ~500,000 remap items, which for a 4KB block size\ncovers ~2GB of remapped data in the worst case and ~500TB in the best case.\n\nSigned-off-by: Mark Harmstone <mark@harmstone.com>\nReviewed-by: Boris Burkov <boris@bur.io>\n---\n fs/btrfs/block-rsv.c            |  9 +++++++++\n fs/btrfs/block-rsv.h            |  1 +\n fs/btrfs/disk-io.c              |  1 +\n fs/btrfs/fs.h                   |  2 ++\n fs/btrfs/space-info.c           | 13 ++++++++++++-\n fs/btrfs/sysfs.c                |  2 ++\n fs/btrfs/tree-checker.c         | 13 +++++++++++--\n fs/btrfs/volumes.c              |  3 +++\n fs/btrfs/volumes.h              | 10 +++++++++-\n include/uapi/linux/btrfs_tree.h |  4 +++-\n 10 files changed, 53 insertions(+), 5 deletions(-)\n\ndiff --git a/fs/btrfs/block-rsv.c b/fs/btrfs/block-rsv.c\nindex 96cf7a162987..2781abf18f26 100644\n--- a/fs/btrfs/block-rsv.c\n+++ b/fs/btrfs/block-rsv.c\n@@ -419,6 +419,9 @@ void btrfs_init_root_block_rsv(struct btrfs_root *root)\n \tcase BTRFS_TREE_LOG_OBJECTID:\n \t\troot->block_rsv = &fs_info->treelog_rsv;\n \t\tbreak;\n+\tcase BTRFS_REMAP_TREE_OBJECTID:\n+\t\troot->block_rsv = &fs_info->remap_block_rsv;\n+\t\tbreak;\n \tdefault:\n \t\troot->block_rsv = NULL;\n \t\tbreak;\n@@ -432,6 +435,10 @@ void btrfs_init_global_block_rsv(struct btrfs_fs_info *fs_info)\n \tspace_info = btrfs_find_space_info(fs_info, BTRFS_BLOCK_GROUP_SYSTEM);\n \tfs_info->chunk_block_rsv.space_info = space_info;\n \n+\tspace_info = btrfs_find_space_info(fs_info,\n+\t\t\t\t\t   BTRFS_BLOCK_GROUP_METADATA_REMAP);\n+\tfs_info->remap_block_rsv.space_info = space_info;\n+\n \tspace_info = btrfs_find_space_info(fs_info, BTRFS_BLOCK_GROUP_METADATA);\n \tfs_info->global_block_rsv.space_info = space_info;\n \tfs_info->trans_block_rsv.space_info = space_info;\n@@ -458,6 +465,8 @@ void btrfs_release_global_block_rsv(struct btrfs_fs_info *fs_info)\n \tWARN_ON(fs_info->trans_block_rsv.reserved > 0);\n \tWARN_ON(fs_info->chunk_block_rsv.size > 0);\n \tWARN_ON(fs_info->chunk_block_rsv.reserved > 0);\n+\tWARN_ON(fs_info->remap_block_rsv.size > 0);\n+\tWARN_ON(fs_info->remap_block_rsv.reserved > 0);\n \tWARN_ON(fs_info->delayed_block_rsv.size > 0);\n \tWARN_ON(fs_info->delayed_block_rsv.reserved > 0);\n \tWARN_ON(fs_info->delayed_refs_rsv.reserved > 0);\ndiff --git a/fs/btrfs/block-rsv.h b/fs/btrfs/block-rsv.h\nindex 79ae9d05cd91..8359fb96bc3c 100644\n--- a/fs/btrfs/block-rsv.h\n+++ b/fs/btrfs/block-rsv.h\n@@ -22,6 +22,7 @@ enum btrfs_rsv_type {\n \tBTRFS_BLOCK_RSV_DELALLOC,\n \tBTRFS_BLOCK_RSV_TRANS,\n \tBTRFS_BLOCK_RSV_CHUNK,\n+\tBTRFS_BLOCK_RSV_REMAP,\n \tBTRFS_BLOCK_RSV_DELOPS,\n \tBTRFS_BLOCK_RSV_DELREFS,\n \tBTRFS_BLOCK_RSV_TREELOG,\ndiff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c\nindex cecb81d0f9e0..cbfb7127b528 100644\n--- a/fs/btrfs/disk-io.c\n+++ b/fs/btrfs/disk-io.c\n@@ -2773,6 +2773,7 @@ void btrfs_init_fs_info(struct btrfs_fs_info *fs_info)\n \t\t\t     BTRFS_BLOCK_RSV_GLOBAL);\n \tbtrfs_init_block_rsv(&fs_info->trans_block_rsv, BTRFS_BLOCK_RSV_TRANS);\n \tbtrfs_init_block_rsv(&fs_info->chunk_block_rsv, BTRFS_BLOCK_RSV_CHUNK);\n+\tbtrfs_init_block_rsv(&fs_info->remap_block_rsv, BTRFS_BLOCK_RSV_REMAP);\n \tbtrfs_init_block_rsv(&fs_info->treelog_rsv, BTRFS_BLOCK_RSV_TREELOG);\n \tbtrfs_init_block_rsv(&fs_info->empty_block_rsv, BTRFS_BLOCK_RSV_EMPTY);\n \tbtrfs_init_block_rsv(&fs_info->delayed_block_rsv,\ndiff --git a/fs/btrfs/fs.h b/fs/btrfs/fs.h\nindex 0dc851b9c51b..46c4f1dcec47 100644\n--- a/fs/btrfs/fs.h\n+++ b/fs/btrfs/fs.h\n@@ -501,6 +501,8 @@ struct btrfs_fs_info {\n \tstruct btrfs_block_rsv trans_block_rsv;\n \t/* Block reservation for chunk tree */\n \tstruct btrfs_block_rsv chunk_block_rsv;\n+\t/* Block reservation for remap tree. */\n+\tstruct btrfs_block_rsv remap_block_rsv;\n \t/* Block reservation for delayed operations */\n \tstruct btrfs_block_rsv delayed_block_rsv;\n \t/* Block reservation for delayed refs */\ndiff --git a/fs/btrfs/space-info.c b/fs/btrfs/space-info.c\nindex 7b7b7255f7d8..badebe6e0b34 100644\n--- a/fs/btrfs/space-info.c\n+++ b/fs/btrfs/space-info.c\n@@ -215,7 +215,7 @@ static u64 calc_chunk_size(const struct btrfs_fs_info *fs_info, u64 flags)\n \n \tif (flags & BTRFS_BLOCK_GROUP_DATA)\n \t\treturn BTRFS_MAX_DATA_CHUNK_SIZE;\n-\telse if (flags & BTRFS_BLOCK_GROUP_SYSTEM)\n+\telse if (flags & (BTRFS_BLOCK_GROUP_SYSTEM | BTRFS_BLOCK_GROUP_METADATA_REMAP))\n \t\treturn SZ_32M;\n \n \t/* Handle BTRFS_BLOCK_GROUP_METADATA */\n@@ -344,6 +344,8 @@ int btrfs_init_space_info(struct btrfs_fs_info *fs_info)\n \tif (mixed) {\n \t\tflags = BTRFS_BLOCK_GROUP_METADATA | BTRFS_BLOCK_GROUP_DATA;\n \t\tret = create_space_info(fs_info, flags);\n+\t\tif (ret)\n+\t\t\tgoto out;\n \t} else {\n \t\tflags = BTRFS_BLOCK_GROUP_METADATA;\n \t\tret = create_space_info(fs_info, flags);\n@@ -352,7 +354,15 @@ int btrfs_init_space_info(struct btrfs_fs_info *fs_info)\n \n \t\tflags = BTRFS_BLOCK_GROUP_DATA;\n \t\tret = create_space_info(fs_info, flags);\n+\t\tif (ret)\n+\t\t\tgoto out;\n+\t}\n+\n+\tif (features & BTRFS_FEATURE_INCOMPAT_REMAP_TREE) {\n+\t\tflags = BTRFS_BLOCK_GROUP_METADATA_REMAP;\n+\t\tret = create_space_info(fs_info, flags);\n \t}\n+\n out:\n \treturn ret;\n }\n@@ -607,6 +617,7 @@ static void dump_global_block_rsv(struct btrfs_fs_info *fs_info)\n \tDUMP_BLOCK_RSV(fs_info, global_block_rsv);\n \tDUMP_BLOCK_RSV(fs_info, trans_block_rsv);\n \tDUMP_BLOCK_RSV(fs_info, chunk_block_rsv);\n+\tDUMP_BLOCK_RSV(fs_info, remap_block_rsv);\n \tDUMP_BLOCK_RSV(fs_info, delayed_block_rsv);\n \tDUMP_BLOCK_RSV(fs_info, delayed_refs_rsv);\n }\ndiff --git a/fs/btrfs/sysfs.c b/fs/btrfs/sysfs.c\nindex 0e2ed8072443..0213a3c44628 100644\n--- a/fs/btrfs/sysfs.c\n+++ b/fs/btrfs/sysfs.c\n@@ -1972,6 +1972,8 @@ static const char *alloc_name(struct btrfs_space_info *space_info)\n \tcase BTRFS_BLOCK_GROUP_SYSTEM:\n \t\tASSERT(space_info->subgroup_id == BTRFS_SUB_GROUP_PRIMARY);\n \t\treturn \"system\";\n+\tcase BTRFS_BLOCK_GROUP_METADATA_REMAP:\n+\t\treturn \"metadata-remap\";\n \tdefault:\n \t\tWARN_ON(1);\n \t\treturn \"invalid-combination\";\ndiff --git a/fs/btrfs/tree-checker.c b/fs/btrfs/tree-checker.c\nindex aedc208a95b8..a6c158cd8fcd 100644\n--- a/fs/btrfs/tree-checker.c\n+++ b/fs/btrfs/tree-checker.c\n@@ -748,17 +748,26 @@ static int check_block_group_item(struct extent_buffer *leaf,\n \t\treturn -EUCLEAN;\n \t}\n \n+\tif (unlikely(flags & BTRFS_BLOCK_GROUP_METADATA_REMAP &&\n+\t\t     !btrfs_fs_incompat(fs_info, REMAP_TREE))) {\n+\t\tblock_group_err(leaf, slot,\n+\"invalid flags, have 0x%llx (METADATA_REMAP flag set) but no remap-tree incompat flag\",\n+\t\t\t\tflags);\n+\t\treturn -EUCLEAN;\n+\t}\n+\n \ttype = flags & BTRFS_BLOCK_GROUP_TYPE_MASK;\n \tif (unlikely(type != BTRFS_BLOCK_GROUP_DATA &&\n \t\t     type != BTRFS_BLOCK_GROUP_METADATA &&\n \t\t     type != BTRFS_BLOCK_GROUP_SYSTEM &&\n+\t\t     type != BTRFS_BLOCK_GROUP_METADATA_REMAP &&\n \t\t     type != (BTRFS_BLOCK_GROUP_METADATA |\n \t\t\t      BTRFS_BLOCK_GROUP_DATA))) {\n \t\tblock_group_err(leaf, slot,\n-\"invalid type, have 0x%llx (%lu bits set) expect either 0x%llx, 0x%llx, 0x%llx or 0x%llx\",\n+\"invalid type, have 0x%llx (%lu bits set) expect either 0x%llx, 0x%llx, 0x%llx, 0x%llx or 0x%llx\",\n \t\t\ttype, hweight64(type),\n \t\t\tBTRFS_BLOCK_GROUP_DATA, BTRFS_BLOCK_GROUP_METADATA,\n-\t\t\tBTRFS_BLOCK_GROUP_SYSTEM,\n+\t\t\tBTRFS_BLOCK_GROUP_SYSTEM, BTRFS_BLOCK_GROUP_METADATA_REMAP,\n \t\t\tBTRFS_BLOCK_GROUP_METADATA | BTRFS_BLOCK_GROUP_DATA);\n \t\treturn -EUCLEAN;\n \t}\ndiff --git a/fs/btrfs/volumes.c b/fs/btrfs/volumes.c\nindex 1134474926ff..07d42ba38d7d 100644\n--- a/fs/btrfs/volumes.c\n+++ b/fs/btrfs/volumes.c\n@@ -231,6 +231,9 @@ void btrfs_describe_block_groups(u64 bg_flags, char *buf, u32 size_buf)\n \tDESCRIBE_FLAG(BTRFS_BLOCK_GROUP_DATA, \"data\");\n \tDESCRIBE_FLAG(BTRFS_BLOCK_GROUP_SYSTEM, \"system\");\n \tDESCRIBE_FLAG(BTRFS_BLOCK_GROUP_METADATA, \"metadata\");\n+\t/* Block groups containing the remap tree. */\n+\tDESCRIBE_FLAG(BTRFS_BLOCK_GROUP_METADATA_REMAP, \"metadata-remap\");\n+\t/* Block group that has been remapped. */\n \tDESCRIBE_FLAG(BTRFS_BLOCK_GROUP_REMAPPED, \"remapped\");\n \n \tDESCRIBE_FLAG(BTRFS_AVAIL_ALLOC_BIT_SINGLE, \"single\");\ndiff --git a/fs/btrfs/volumes.h b/fs/btrfs/volumes.h\nindex 34b854c1a303..4117fabb248b 100644\n--- a/fs/btrfs/volumes.h\n+++ b/fs/btrfs/volumes.h\n@@ -58,7 +58,6 @@ static_assert(ilog2(BTRFS_STRIPE_LEN) == BTRFS_STRIPE_LEN_SHIFT);\n  */\n static_assert(const_ffs(BTRFS_BLOCK_GROUP_RAID0) <\n \t      const_ffs(BTRFS_BLOCK_GROUP_PROFILE_MASK & ~BTRFS_BLOCK_GROUP_RAID0));\n-static_assert(ilog2(BTRFS_BLOCK_GROUP_RAID0) > ilog2(BTRFS_BLOCK_GROUP_TYPE_MASK));\n \n /* ilog2() can handle both constants and variables */\n #define BTRFS_BG_FLAG_TO_INDEX(profile)\t\t\t\t\t\\\n@@ -80,6 +79,15 @@ enum btrfs_raid_types {\n \tBTRFS_NR_RAID_TYPES\n };\n \n+static_assert(BTRFS_RAID_RAID0 == 1);\n+static_assert(BTRFS_RAID_RAID1 == 2);\n+static_assert(BTRFS_RAID_DUP == 3);\n+static_assert(BTRFS_RAID_RAID10 == 4);\n+static_assert(BTRFS_RAID_RAID5 == 5);\n+static_assert(BTRFS_RAID_RAID6 == 6);\n+static_assert(BTRFS_RAID_RAID1C3 == 7);\n+static_assert(BTRFS_RAID_RAID1C4 == 8);\n+\n /*\n  * Use sequence counter to get consistent device stat data on\n  * 32-bit processors.\ndiff --git a/include/uapi/linux/btrfs_tree.h b/include/uapi/linux/btrfs_tree.h\nindex f011d34cb699..76578426671c 100644\n--- a/include/uapi/linux/btrfs_tree.h\n+++ b/include/uapi/linux/btrfs_tree.h\n@@ -1169,12 +1169,14 @@ struct btrfs_dev_replace_item {\n #define BTRFS_BLOCK_GROUP_RAID1C3       (1ULL << 9)\n #define BTRFS_BLOCK_GROUP_RAID1C4       (1ULL << 10)\n #define BTRFS_BLOCK_GROUP_REMAPPED      (1ULL << 11)\n+#define BTRFS_BLOCK_GROUP_METADATA_REMAP (1ULL << 12)\n #define BTRFS_BLOCK_GROUP_RESERVED\t(BTRFS_AVAIL_ALLOC_BIT_SINGLE | \\\n \t\t\t\t\t BTRFS_SPACE_INFO_GLOBAL_RSV)\n \n #define BTRFS_BLOCK_GROUP_TYPE_MASK\t(BTRFS_BLOCK_GROUP_DATA |    \\\n \t\t\t\t\t BTRFS_BLOCK_GROUP_SYSTEM |  \\\n-\t\t\t\t\t BTRFS_BLOCK_GROUP_METADATA)\n+\t\t\t\t\t BTRFS_BLOCK_GROUP_METADATA | \\\n+\t\t\t\t\t BTRFS_BLOCK_GROUP_METADATA_REMAP)\n \n #define BTRFS_BLOCK_GROUP_PROFILE_MASK\t(BTRFS_BLOCK_GROUP_RAID0 |   \\\n \t\t\t\t\t BTRFS_BLOCK_GROUP_RAID1 |   \\\n-- \n2.51.2\n\n\n\n---\n\nThis is version 8 of the patch series for the new logical remapping tree\nfeature - see the previous cover letters for more information including\nthe rationale:\n\n* RFC: https://lore.kernel.org/all/20250515163641.3449017-1-maharmstone@fb.com/\n* Version 1: https://lore.kernel.org/all/20250605162345.2561026-1-maharmstone@fb.com/\n* Version 2: https://lore.kernel.org/all/20250813143509.31073-1-mark@harmstone.com/\n* Version 3: https://lore.kernel.org/all/20251009112814.13942-1-mark@harmstone.com/\n* Version 4: https://lore.kernel.org/all/20251024181227.32228-1-mark@harmstone.com/\n* Version 5: https://lore.kernel.org/all/20251110171511.20900-1-mark@harmstone.com/\n* Version 6: https://lore.kernel.org/all/20251114184745.9304-1-mark@harmstone.com/\n* Version 7: https://lore.kernel.org/all/20251124185335.16556-1-mark@harmstone.com/\n\nChanges since version 7:\n* renamed struct btrfs_remap to struct btrfs_remap_item\n* renamed BTRFS_BLOCK_GROUP_FLAGS_REMAP to BTRFS_BLOCK_GROUP_FLAGS_METADATA_REMAP\n* added unlikelies\n* renamed new commit_* fields in struct btrfs_block_group to last_*, and added\n  new patch renaming existing commit_used to last_used to match\n* merged do_copy() into copy_remapped_data()\n* initialized on-stack struct btrfs_remap_items\n* fixed comments\n* added other minor changes as suggested by David Sterba\n\nMark Harmstone (17):\n  btrfs: add definitions and constants for remap-tree\n  btrfs: add METADATA_REMAP chunk type\n  btrfs: allow remapped chunks to have zero stripes\n  btrfs: remove remapped block groups from the free-space tree\n  btrfs: don't add metadata items for the remap tree to the extent tree\n  btrfs: rename struct btrfs_block_group field commit_used to last_used\n  btrfs: add extended version of struct block_group_item\n  btrfs: allow mounting filesystems with remap-tree incompat flag\n  btrfs: redirect I/O for remapped block groups\n  btrfs: handle deletions from remapped block group\n  btrfs: handle setting up relocation of block group with remap-tree\n  btrfs: move existing remaps before relocating block group\n  btrfs: replace identity remaps with actual remaps when doing\n    relocations\n  btrfs: add do_remap param to btrfs_discard_extent()\n  btrfs: allow balancing remap tree\n  btrfs: handle discarding fully-remapped block groups\n  btrfs: populate fully_remapped_bgs_list on mount\n\n fs/btrfs/Kconfig                |    2 +\n fs/btrfs/accessors.h            |   30 +\n fs/btrfs/bio.c                  |    3 +-\n fs/btrfs/bio.h                  |    3 +\n fs/btrfs/block-group.c          |  323 ++++--\n fs/btrfs/block-group.h          |   29 +-\n fs/btrfs/block-rsv.c            |    9 +\n fs/btrfs/block-rsv.h            |    1 +\n fs/btrfs/discard.c              |   57 +-\n fs/btrfs/disk-io.c              |  130 ++-\n fs/btrfs/extent-tree.c          |  151 ++-\n fs/btrfs/extent-tree.h          |    4 +-\n fs/btrfs/free-space-cache.c     |   59 +-\n fs/btrfs/free-space-cache.h     |    1 +\n fs/btrfs/free-space-tree.c      |    4 +-\n fs/btrfs/free-space-tree.h      |    5 +-\n fs/btrfs/fs.h                   |   10 +-\n fs/btrfs/inode.c                |    2 +-\n fs/btrfs/locking.c              |    1 +\n fs/btrfs/relocation.c           | 1885 +++++++++++++++++++++++++++++--\n fs/btrfs/relocation.h           |   18 +\n fs/btrfs/space-info.c           |   22 +-\n fs/btrfs/sysfs.c                |    4 +\n fs/btrfs/transaction.c          |    7 +\n fs/btrfs/tree-checker.c         |   94 +-\n fs/btrfs/tree-checker.h         |    5 +\n fs/btrfs/volumes.c              |  355 +++++-\n fs/btrfs/volumes.h              |   18 +-\n include/uapi/linux/btrfs.h      |    1 +\n include/uapi/linux/btrfs_tree.h |   34 +-\n 30 files changed, 2991 insertions(+), 276 deletions(-)\n\n-- \n2.51.2\n\n\n\n---\n\nWhen a chunk has been fully remapped, we are going to set its\nnum_stripes to 0, as it will no longer represent a physical location on\ndisk.\n\nChange tree-checker to allow for this, and fix read_one_chunk() to avoid\na divide by zero.\n\nSigned-off-by: Mark Harmstone <mark@harmstone.com>\nReviewed-by: Boris Burkov <boris@bur.io>\n---\n fs/btrfs/tree-checker.c | 65 ++++++++++++++++++++++++++++-------------\n fs/btrfs/volumes.c      |  7 ++++-\n 2 files changed, 51 insertions(+), 21 deletions(-)\n\ndiff --git a/fs/btrfs/tree-checker.c b/fs/btrfs/tree-checker.c\nindex a6c158cd8fcd..4e390d6517a3 100644\n--- a/fs/btrfs/tree-checker.c\n+++ b/fs/btrfs/tree-checker.c\n@@ -816,6 +816,41 @@ static void chunk_err(const struct btrfs_fs_info *fs_info,\n \tva_end(args);\n }\n \n+static bool valid_stripe_count(u64 profile, u16 num_stripes,\n+\t\t\t       u16 sub_stripes)\n+{\n+\tswitch (profile) {\n+\tcase BTRFS_BLOCK_GROUP_RAID0:\n+\t\treturn true;\n+\tcase BTRFS_BLOCK_GROUP_RAID10:\n+\t\treturn sub_stripes ==\n+\t\t\tbtrfs_raid_array[BTRFS_RAID_RAID10].sub_stripes;\n+\tcase BTRFS_BLOCK_GROUP_RAID1:\n+\t\treturn num_stripes ==\n+\t\t\tbtrfs_raid_array[BTRFS_RAID_RAID1].devs_min;\n+\tcase BTRFS_BLOCK_GROUP_RAID1C3:\n+\t\treturn num_stripes ==\n+\t\t\tbtrfs_raid_array[BTRFS_RAID_RAID1C3].devs_min;\n+\tcase BTRFS_BLOCK_GROUP_RAID1C4:\n+\t\treturn num_stripes ==\n+\t\t\tbtrfs_raid_array[BTRFS_RAID_RAID1C4].devs_min;\n+\tcase BTRFS_BLOCK_GROUP_RAID5:\n+\t\treturn num_stripes >=\n+\t\t\tbtrfs_raid_array[BTRFS_RAID_RAID5].devs_min;\n+\tcase BTRFS_BLOCK_GROUP_RAID6:\n+\t\treturn num_stripes >=\n+\t\t\tbtrfs_raid_array[BTRFS_RAID_RAID6].devs_min;\n+\tcase BTRFS_BLOCK_GROUP_DUP:\n+\t\treturn num_stripes ==\n+\t\t\tbtrfs_raid_array[BTRFS_RAID_DUP].dev_stripes;\n+\tcase 0: /* SINGLE */\n+\t\treturn num_stripes ==\n+\t\t\tbtrfs_raid_array[BTRFS_RAID_SINGLE].dev_stripes;\n+\tdefault:\n+\t\tBUG();\n+\t}\n+}\n+\n /*\n  * The common chunk check which could also work on super block sys chunk array.\n  *\n@@ -839,6 +874,7 @@ int btrfs_check_chunk_valid(const struct btrfs_fs_info *fs_info,\n \tu64 features;\n \tu32 chunk_sector_size;\n \tbool mixed = false;\n+\tbool remapped;\n \tint raid_index;\n \tint nparity;\n \tint ncopies;\n@@ -862,12 +898,14 @@ int btrfs_check_chunk_valid(const struct btrfs_fs_info *fs_info,\n \tncopies = btrfs_raid_array[raid_index].ncopies;\n \tnparity = btrfs_raid_array[raid_index].nparity;\n \n-\tif (unlikely(!num_stripes)) {\n+\tremapped = type & BTRFS_BLOCK_GROUP_REMAPPED;\n+\n+\tif (unlikely(!remapped && !num_stripes)) {\n \t\tchunk_err(fs_info, leaf, chunk, logical,\n \t\t\t  \"invalid chunk num_stripes, have %u\", num_stripes);\n \t\treturn -EUCLEAN;\n \t}\n-\tif (unlikely(num_stripes < ncopies)) {\n+\tif (unlikely(num_stripes != 0 && num_stripes < ncopies)) {\n \t\tchunk_err(fs_info, leaf, chunk, logical,\n \t\t\t  \"invalid chunk num_stripes < ncopies, have %u < %d\",\n \t\t\t  num_stripes, ncopies);\n@@ -965,22 +1003,9 @@ int btrfs_check_chunk_valid(const struct btrfs_fs_info *fs_info,\n \t\t}\n \t}\n \n-\tif (unlikely((type & BTRFS_BLOCK_GROUP_RAID10 &&\n-\t\t      sub_stripes != btrfs_raid_array[BTRFS_RAID_RAID10].sub_stripes) ||\n-\t\t     (type & BTRFS_BLOCK_GROUP_RAID1 &&\n-\t\t      num_stripes != btrfs_raid_array[BTRFS_RAID_RAID1].devs_min) ||\n-\t\t     (type & BTRFS_BLOCK_GROUP_RAID1C3 &&\n-\t\t      num_stripes != btrfs_raid_array[BTRFS_RAID_RAID1C3].devs_min) ||\n-\t\t     (type & BTRFS_BLOCK_GROUP_RAID1C4 &&\n-\t\t      num_stripes != btrfs_raid_array[BTRFS_RAID_RAID1C4].devs_min) ||\n-\t\t     (type & BTRFS_BLOCK_GROUP_RAID5 &&\n-\t\t      num_stripes < btrfs_raid_array[BTRFS_RAID_RAID5].devs_min) ||\n-\t\t     (type & BTRFS_BLOCK_GROUP_RAID6 &&\n-\t\t      num_stripes < btrfs_raid_array[BTRFS_RAID_RAID6].devs_min) ||\n-\t\t     (type & BTRFS_BLOCK_GROUP_DUP &&\n-\t\t      num_stripes != btrfs_raid_array[BTRFS_RAID_DUP].dev_stripes) ||\n-\t\t     ((type & BTRFS_BLOCK_GROUP_PROFILE_MASK) == 0 &&\n-\t\t      num_stripes != btrfs_raid_array[BTRFS_RAID_SINGLE].dev_stripes))) {\n+\tif (!remapped &&\n+\t    !valid_stripe_count(type & BTRFS_BLOCK_GROUP_PROFILE_MASK,\n+\t\t\t\tnum_stripes, sub_stripes)) {\n \t\tchunk_err(fs_info, leaf, chunk, logical,\n \t\t\t\"invalid num_stripes:sub_stripes %u:%u for profile %llu\",\n \t\t\tnum_stripes, sub_stripes,\n@@ -1004,11 +1029,11 @@ static int check_leaf_chunk_item(struct extent_buffer *leaf,\n \tstruct btrfs_fs_info *fs_info = leaf->fs_info;\n \tint num_stripes;\n \n-\tif (unlikely(btrfs_item_size(leaf, slot) < sizeof(struct btrfs_chunk))) {\n+\tif (unlikely(btrfs_item_size(leaf, slot) < offsetof(struct btrfs_chunk, stripe))) {\n \t\tchunk_err(fs_info, leaf, chunk, key->offset,\n \t\t\t\"invalid chunk item size: have %u expect [%zu, %u)\",\n \t\t\tbtrfs_item_size(leaf, slot),\n-\t\t\tsizeof(struct btrfs_chunk),\n+\t\t\toffsetof(struct btrfs_chunk, stripe),\n \t\t\tBTRFS_LEAF_DATA_SIZE(fs_info));\n \t\treturn -EUCLEAN;\n \t}\ndiff --git a/fs/btrfs/volumes.c b/fs/btrfs/volumes.c\nindex 07d42ba38d7d..070efac46a81 100644\n--- a/fs/btrfs/volumes.c\n+++ b/fs/btrfs/volumes.c\n@@ -7045,7 +7045,12 @@ static int read_one_chunk(struct btrfs_key *key, struct extent_buffer *leaf,\n \t */\n \tmap->sub_stripes = btrfs_raid_array[index].sub_stripes;\n \tmap->verified_stripes = 0;\n-\tmap->stripe_size = btrfs_calc_stripe_length(map);\n+\n+\tif (num_stripes > 0)\n+\t\tmap->stripe_size = btrfs_calc_stripe_length(map);\n+\telse\n+\t\tmap->stripe_size = 0;\n+\n \tfor (i = 0; i < num_stripes; i++) {\n \t\tmap->stripes[i].physical =\n \t\t\tbtrfs_stripe_offset_nr(leaf, chunk, i);\n-- \n2.51.2\n\n\n\n---\n\nAdd a struct btrfs_block_group_item_v2, which is used in the block group\ntree if the remap-tree incompat flag is set.\n\nThis adds two new fields to the block group item: `remap_bytes` and\n`identity_remap_count`.\n\n`remap_bytes` records the amount of data that's physically within this\nblock group, but nominally in another, remapped block group. This is\nnecessary because this data will need to be moved first if this block\ngroup is itself relocated. If `remap_bytes` > 0, this is an indicator to\nthe relocation thread that it will need to search the remap-tree for\nbackrefs. A block group must also have `remap_bytes` == 0 before it can\nbe dropped.\n\n`identity_remap_count` records how many identity remap items are located\nin the remap tree for this block group. When relocation is begun for\nthis block group, this is set to the number of holes in the free-space\ntree for this range. As identity remaps are converted into actual remaps\nby the relocation process, this number is decreased. Once it reaches 0,\neither because of relocation or because extents have been deleted, the\nblock group has been fully remapped and its chunk's device extents are\nremoved.\n\nSigned-off-by: Mark Harmstone <mark@harmstone.com>\nReviewed-by: Boris Burkov <boris@bur.io>\n---\n fs/btrfs/accessors.h            |  20 +++++++\n fs/btrfs/block-group.c          | 100 ++++++++++++++++++++++++--------\n fs/btrfs/block-group.h          |  14 ++++-\n fs/btrfs/discard.c              |   2 +-\n fs/btrfs/tree-checker.c         |  10 +++-\n include/uapi/linux/btrfs_tree.h |   8 +++\n 6 files changed, 126 insertions(+), 28 deletions(-)\n\ndiff --git a/fs/btrfs/accessors.h b/fs/btrfs/accessors.h\nindex 09cdd6bfddf5..9797f9e8d4e5 100644\n--- a/fs/btrfs/accessors.h\n+++ b/fs/btrfs/accessors.h\n@@ -240,6 +240,26 @@ BTRFS_SETGET_FUNCS(block_group_flags, struct btrfs_block_group_item, flags, 64);\n BTRFS_SETGET_STACK_FUNCS(stack_block_group_flags,\n \t\t\tstruct btrfs_block_group_item, flags, 64);\n \n+/* struct btrfs_block_group_item_v2 */\n+BTRFS_SETGET_STACK_FUNCS(stack_block_group_v2_used, struct btrfs_block_group_item_v2,\n+\t\t\t used, 64);\n+BTRFS_SETGET_FUNCS(block_group_v2_used, struct btrfs_block_group_item_v2, used, 64);\n+BTRFS_SETGET_STACK_FUNCS(stack_block_group_v2_chunk_objectid,\n+\t\t\t struct btrfs_block_group_item_v2, chunk_objectid, 64);\n+BTRFS_SETGET_FUNCS(block_group_v2_chunk_objectid,\n+\t\t   struct btrfs_block_group_item_v2, chunk_objectid, 64);\n+BTRFS_SETGET_STACK_FUNCS(stack_block_group_v2_flags,\n+\t\t\t struct btrfs_block_group_item_v2, flags, 64);\n+BTRFS_SETGET_FUNCS(block_group_v2_flags, struct btrfs_block_group_item_v2, flags, 64);\n+BTRFS_SETGET_STACK_FUNCS(stack_block_group_v2_remap_bytes,\n+\t\t\t struct btrfs_block_group_item_v2, remap_bytes, 64);\n+BTRFS_SETGET_FUNCS(block_group_v2_remap_bytes, struct btrfs_block_group_item_v2,\n+\t\t   remap_bytes, 64);\n+BTRFS_SETGET_STACK_FUNCS(stack_block_group_v2_identity_remap_count,\n+\t\t\t struct btrfs_block_group_item_v2, identity_remap_count, 32);\n+BTRFS_SETGET_FUNCS(block_group_v2_identity_remap_count, struct btrfs_block_group_item_v2,\n+\t\t   identity_remap_count, 32);\n+\n /* struct btrfs_free_space_info */\n BTRFS_SETGET_FUNCS(free_space_extent_count, struct btrfs_free_space_info,\n \t\t   extent_count, 32);\ndiff --git a/fs/btrfs/block-group.c b/fs/btrfs/block-group.c\nindex 822c5306a7a4..4962d17a175e 100644\n--- a/fs/btrfs/block-group.c\n+++ b/fs/btrfs/block-group.c\n@@ -2372,7 +2372,7 @@ static int check_chunk_block_group_mappings(struct btrfs_fs_info *fs_info)\n }\n \n static int read_one_block_group(struct btrfs_fs_info *info,\n-\t\t\t\tstruct btrfs_block_group_item *bgi,\n+\t\t\t\tstruct btrfs_block_group_item_v2 *bgi,\n \t\t\t\tconst struct btrfs_key *key,\n \t\t\t\tint need_clear)\n {\n@@ -2387,11 +2387,16 @@ static int read_one_block_group(struct btrfs_fs_info *info,\n \t\treturn -ENOMEM;\n \n \tcache->length = key->offset;\n-\tcache->used = btrfs_stack_block_group_used(bgi);\n+\tcache->used = btrfs_stack_block_group_v2_used(bgi);\n \tcache->last_used = cache->used;\n-\tcache->flags = btrfs_stack_block_group_flags(bgi);\n-\tcache->global_root_id = btrfs_stack_block_group_chunk_objectid(bgi);\n+\tcache->flags = btrfs_stack_block_group_v2_flags(bgi);\n+\tcache->global_root_id = btrfs_stack_block_group_v2_chunk_objectid(bgi);\n \tcache->space_info = btrfs_find_space_info(info, cache->flags);\n+\tcache->remap_bytes = btrfs_stack_block_group_v2_remap_bytes(bgi);\n+\tcache->last_remap_bytes = cache->remap_bytes;\n+\tcache->identity_remap_count =\n+\t\tbtrfs_stack_block_group_v2_identity_remap_count(bgi);\n+\tcache->last_identity_remap_count = cache->identity_remap_count;\n \n \tbtrfs_set_free_space_tree_thresholds(cache);\n \n@@ -2456,7 +2461,7 @@ static int read_one_block_group(struct btrfs_fs_info *info,\n \t} else if (cache->length == cache->used) {\n \t\tcache->cached = BTRFS_CACHE_FINISHED;\n \t\tbtrfs_free_excluded_extents(cache);\n-\t} else if (cache->used == 0) {\n+\t} else if (cache->used == 0 && cache->remap_bytes == 0) {\n \t\tcache->cached = BTRFS_CACHE_FINISHED;\n \t\tret = btrfs_add_new_free_space(cache, cache->start,\n \t\t\t\t\t       cache->start + cache->length, NULL);\n@@ -2476,7 +2481,7 @@ static int read_one_block_group(struct btrfs_fs_info *info,\n \n \tset_avail_alloc_bits(info, cache->flags);\n \tif (btrfs_chunk_writeable(info, cache->start)) {\n-\t\tif (cache->used == 0) {\n+\t\tif (cache->used == 0 && cache->remap_bytes == 0) {\n \t\t\tASSERT(list_empty(&cache->bg_list));\n \t\t\tif (btrfs_test_opt(info, DISCARD_ASYNC))\n \t\t\t\tbtrfs_discard_queue_work(&info->discard_ctl, cache);\n@@ -2580,9 +2585,10 @@ int btrfs_read_block_groups(struct btrfs_fs_info *info)\n \t\tneed_clear = 1;\n \n \twhile (1) {\n-\t\tstruct btrfs_block_group_item bgi;\n+\t\tstruct btrfs_block_group_item_v2 bgi;\n \t\tstruct extent_buffer *leaf;\n \t\tint slot;\n+\t\tsize_t size;\n \n \t\tret = find_first_block_group(info, path, &key);\n \t\tif (ret > 0)\n@@ -2593,8 +2599,16 @@ int btrfs_read_block_groups(struct btrfs_fs_info *info)\n \t\tleaf = path->nodes[0];\n \t\tslot = path->slots[0];\n \n+\t\tif (btrfs_fs_incompat(info, REMAP_TREE)) {\n+\t\t\tsize = sizeof(struct btrfs_block_group_item_v2);\n+\t\t} else {\n+\t\t\tsize = sizeof(struct btrfs_block_group_item);\n+\t\t\tbtrfs_set_stack_block_group_v2_remap_bytes(&bgi, 0);\n+\t\t\tbtrfs_set_stack_block_group_v2_identity_remap_count(&bgi, 0);\n+\t\t}\n+\n \t\tread_extent_buffer(leaf, &bgi, btrfs_item_ptr_offset(leaf, slot),\n-\t\t\t\t   sizeof(bgi));\n+\t\t\t\t   size);\n \n \t\tbtrfs_item_key_to_cpu(leaf, &key, slot);\n \t\tbtrfs_release_path(path);\n@@ -2664,25 +2678,38 @@ static int insert_block_group_item(struct btrfs_trans_handle *trans,\n \t\t\t\t   struct btrfs_block_group *block_group)\n {\n \tstruct btrfs_fs_info *fs_info = trans->fs_info;\n-\tstruct btrfs_block_group_item bgi;\n+\tstruct btrfs_block_group_item_v2 bgi;\n \tstruct btrfs_root *root = btrfs_block_group_root(fs_info);\n \tstruct btrfs_key key;\n \tu64 old_last_used;\n+\tsize_t size;\n \tint ret;\n \n \tspin_lock(&block_group->lock);\n-\tbtrfs_set_stack_block_group_used(&bgi, block_group->used);\n-\tbtrfs_set_stack_block_group_chunk_objectid(&bgi,\n-\t\t\t\t\t\t   block_group->global_root_id);\n-\tbtrfs_set_stack_block_group_flags(&bgi, block_group->flags);\n+\tbtrfs_set_stack_block_group_v2_used(&bgi, block_group->used);\n+\tbtrfs_set_stack_block_group_v2_chunk_objectid(&bgi,\n+\t\t\t\t\t\t      block_group->global_root_id);\n+\tbtrfs_set_stack_block_group_v2_flags(&bgi, block_group->flags);\n+\tbtrfs_set_stack_block_group_v2_remap_bytes(&bgi,\n+\t\t\t\t\t\t   block_group->remap_bytes);\n+\tbtrfs_set_stack_block_group_v2_identity_remap_count(&bgi,\n+\t\t\t\t\tblock_group->identity_remap_count);\n \told_last_used = block_group->last_used;\n \tblock_group->last_used = block_group->used;\n+\tblock_group->last_remap_bytes = block_group->remap_bytes;\n+\tblock_group->last_identity_remap_count =\n+\t\tblock_group->identity_remap_count;\n \tkey.objectid = block_group->start;\n \tkey.type = BTRFS_BLOCK_GROUP_ITEM_KEY;\n \tkey.offset = block_group->length;\n \tspin_unlock(&block_group->lock);\n \n-\tret = btrfs_insert_item(trans, root, &key, &bgi, sizeof(bgi));\n+\tif (btrfs_fs_incompat(fs_info, REMAP_TREE))\n+\t\tsize = sizeof(struct btrfs_block_group_item_v2);\n+\telse\n+\t\tsize = sizeof(struct btrfs_block_group_item);\n+\n+\tret = btrfs_insert_item(trans, root, &key, &bgi, size);\n \tif (ret < 0) {\n \t\tspin_lock(&block_group->lock);\n \t\tblock_group->last_used = old_last_used;\n@@ -3137,10 +3164,12 @@ static int update_block_group_item(struct btrfs_trans_handle *trans,\n \tstruct btrfs_root *root = btrfs_block_group_root(fs_info);\n \tunsigned long bi;\n \tstruct extent_buffer *leaf;\n-\tstruct btrfs_block_group_item bgi;\n+\tstruct btrfs_block_group_item_v2 bgi;\n \tstruct btrfs_key key;\n-\tu64 old_last_used;\n-\tu64 used;\n+\tu64 old_last_used, old_last_remap_bytes;\n+\tu32 old_last_identity_remap_count;\n+\tu64 used, remap_bytes;\n+\tu32 identity_remap_count;\n \n \t/*\n \t * Block group items update can be triggered out of commit transaction\n@@ -3150,13 +3179,21 @@ static int update_block_group_item(struct btrfs_trans_handle *trans,\n \t */\n \tspin_lock(&cache->lock);\n \told_last_used = cache->last_used;\n+\told_last_remap_bytes = cache->last_remap_bytes;\n+\told_last_identity_remap_count = cache->last_identity_remap_count;\n \tused = cache->used;\n-\t/* No change in used bytes, can safely skip it. */\n-\tif (cache->last_used == used) {\n+\tremap_bytes = cache->remap_bytes;\n+\tidentity_remap_count = cache->identity_remap_count;\n+\t/* No change in values, can safely skip it. */\n+\tif (cache->last_used == used &&\n+\t    cache->last_remap_bytes == remap_bytes &&\n+\t    cache->last_identity_remap_count == identity_remap_count) {\n \t\tspin_unlock(&cache->lock);\n \t\treturn 0;\n \t}\n \tcache->last_used = used;\n+\tcache->last_remap_bytes = remap_bytes;\n+\tcache->last_identity_remap_count = identity_remap_count;\n \tspin_unlock(&cache->lock);\n \n \tkey.objectid = cache->start;\n@@ -3172,11 +3209,23 @@ static int update_block_group_item(struct btrfs_trans_handle *trans,\n \n \tleaf = path->nodes[0];\n \tbi = btrfs_item_ptr_offset(leaf, path->slots[0]);\n-\tbtrfs_set_stack_block_group_used(&bgi, used);\n-\tbtrfs_set_stack_block_group_chunk_objectid(&bgi,\n-\t\t\t\t\t\t   cache->global_root_id);\n-\tbtrfs_set_stack_block_group_flags(&bgi, cache->flags);\n-\twrite_extent_buffer(leaf, &bgi, bi, sizeof(bgi));\n+\tbtrfs_set_stack_block_group_v2_used(&bgi, used);\n+\tbtrfs_set_stack_block_group_v2_chunk_objectid(&bgi,\n+\t\t\t\t\t\t      cache->global_root_id);\n+\tbtrfs_set_stack_block_group_v2_flags(&bgi, cache->flags);\n+\n+\tif (btrfs_fs_incompat(fs_info, REMAP_TREE)) {\n+\t\tbtrfs_set_stack_block_group_v2_remap_bytes(&bgi,\n+\t\t\t\t\t\t\t   cache->remap_bytes);\n+\t\tbtrfs_set_stack_block_group_v2_identity_remap_count(&bgi,\n+\t\t\t\t\t\tcache->identity_remap_count);\n+\t\twrite_extent_buffer(leaf, &bgi, bi,\n+\t\t\t\t    sizeof(struct btrfs_block_group_item_v2));\n+\t} else {\n+\t\twrite_extent_buffer(leaf, &bgi, bi,\n+\t\t\t\t    sizeof(struct btrfs_block_group_item));\n+\t}\n+\n fail:\n \tbtrfs_release_path(path);\n \t/*\n@@ -3191,6 +3240,9 @@ static int update_block_group_item(struct btrfs_trans_handle *trans,\n \tif (ret < 0 && ret != -ENOENT) {\n \t\tspin_lock(&cache->lock);\n \t\tcache->last_used = old_last_used;\n+\t\tcache->last_remap_bytes = old_last_remap_bytes;\n+\t\tcache->last_identity_remap_count =\n+\t\t\told_last_identity_remap_count;\n \t\tspin_unlock(&cache->lock);\n \t}\n \treturn ret;\ndiff --git a/fs/btrfs/block-group.h b/fs/btrfs/block-group.h\nindex 01401e9959c1..4cee3448ded3 100644\n--- a/fs/btrfs/block-group.h\n+++ b/fs/btrfs/block-group.h\n@@ -129,6 +129,8 @@ struct btrfs_block_group {\n \tu64 flags;\n \tu64 cache_generation;\n \tu64 global_root_id;\n+\tu64 remap_bytes;\n+\tu32 identity_remap_count;\n \n \t/*\n \t * The last committed used bytes of this block group, if the above @used\n@@ -136,6 +138,15 @@ struct btrfs_block_group {\n \t * group item of this block group.\n \t */\n \tu64 last_used;\n+\t/*\n+\t * The last committed remap_bytes value of this block group.\n+\t */\n+\tu64 last_remap_bytes;\n+\t/*\n+\t * The last commited identity_remap_count value of this block group.\n+\t */\n+\tu32 last_identity_remap_count;\n+\n \t/*\n \t * If the free space extent count exceeds this number, convert the block\n \t * group to bitmaps.\n@@ -282,7 +293,8 @@ static inline bool btrfs_is_block_group_used(const struct btrfs_block_group *bg)\n {\n \tlockdep_assert_held(&bg->lock);\n \n-\treturn (bg->used > 0 || bg->reserved > 0 || bg->pinned > 0);\n+\treturn (bg->used > 0 || bg->reserved > 0 || bg->pinned > 0 ||\n+\t\tbg->remap_bytes > 0);\n }\n \n static inline bool btrfs_is_block_group_data_only(const struct btrfs_block_group *block_group)\ndiff --git a/fs/btrfs/discard.c b/fs/btrfs/discard.c\nindex 89fe85778115..ee5f5b2788e1 100644\n--- a/fs/btrfs/discard.c\n+++ b/fs/btrfs/discard.c\n@@ -373,7 +373,7 @@ void btrfs_discard_queue_work(struct btrfs_discard_ctl *discard_ctl,\n \tif (!block_group || !btrfs_test_opt(block_group->fs_info, DISCARD_ASYNC))\n \t\treturn;\n \n-\tif (block_group->used == 0)\n+\tif (block_group->used == 0 && block_group->remap_bytes == 0)\n \t\tadd_to_discard_unused_list(discard_ctl, block_group);\n \telse\n \t\tadd_to_discard_list(discard_ctl, block_group);\ndiff --git a/fs/btrfs/tree-checker.c b/fs/btrfs/tree-checker.c\nindex 4e390d6517a3..d524fd4c3898 100644\n--- a/fs/btrfs/tree-checker.c\n+++ b/fs/btrfs/tree-checker.c\n@@ -688,6 +688,7 @@ static int check_block_group_item(struct extent_buffer *leaf,\n \tu64 chunk_objectid;\n \tu64 flags;\n \tu64 type;\n+\tsize_t exp_size;\n \n \t/*\n \t * Here we don't really care about alignment since extent allocator can\n@@ -699,10 +700,15 @@ static int check_block_group_item(struct extent_buffer *leaf,\n \t\treturn -EUCLEAN;\n \t}\n \n-\tif (unlikely(item_size != sizeof(bgi))) {\n+\tif (btrfs_fs_incompat(fs_info, REMAP_TREE))\n+\t\texp_size = sizeof(struct btrfs_block_group_item_v2);\n+\telse\n+\t\texp_size = sizeof(struct btrfs_block_group_item);\n+\n+\tif (unlikely(item_size != exp_size)) {\n \t\tblock_group_err(leaf, slot,\n \t\t\t\"invalid item size, have %u expect %zu\",\n-\t\t\t\titem_size, sizeof(bgi));\n+\t\t\t\titem_size, exp_size);\n \t\treturn -EUCLEAN;\n \t}\n \ndiff --git a/include/uapi/linux/btrfs_tree.h b/include/uapi/linux/btrfs_tree.h\nindex 76578426671c..86820a9644e8 100644\n--- a/include/uapi/linux/btrfs_tree.h\n+++ b/include/uapi/linux/btrfs_tree.h\n@@ -1229,6 +1229,14 @@ struct btrfs_block_group_item {\n \t__le64 flags;\n } __attribute__ ((__packed__));\n \n+struct btrfs_block_group_item_v2 {\n+\t__le64 used;\n+\t__le64 chunk_objectid;\n+\t__le64 flags;\n+\t__le64 remap_bytes;\n+\t__le32 identity_remap_count;\n+} __attribute__ ((__packed__));\n+\n struct btrfs_free_space_info {\n \t__le32 extent_count;\n \t__le32 flags;\n-- \n2.51.2\n\n\n\n---\n\nChange btrfs_map_block() so that if the block group has the REMAPPED\nflag set, we call btrfs_translate_remap() to obtain a new address.\n\nbtrfs_translate_remap() searches the remap tree for a range\ncorresponding to the logical address passed to btrfs_map_block(). If it\nis within an identity remap, this part of the block group hasn't yet\nbeen relocated, and so we use the existing address.\n\nIf it is within an actual remap, we subtract the start of the remap\nrange and add the address of its destination, contained in the item's\npayload.\n\nSigned-off-by: Mark Harmstone <mark@harmstone.com>\nReviewed-by: Boris Burkov <boris@bur.io>\n---\n fs/btrfs/relocation.c | 54 +++++++++++++++++++++++++++++++++++++++++++\n fs/btrfs/relocation.h |  2 ++\n fs/btrfs/volumes.c    | 19 +++++++++++++++\n 3 files changed, 75 insertions(+)\n\ndiff --git a/fs/btrfs/relocation.c b/fs/btrfs/relocation.c\nindex 310b7d817a27..525f45c668f6 100644\n--- a/fs/btrfs/relocation.c\n+++ b/fs/btrfs/relocation.c\n@@ -3859,6 +3859,60 @@ static const char *stage_to_string(enum reloc_stage stage)\n \treturn \"unknown\";\n }\n \n+int btrfs_translate_remap(struct btrfs_fs_info *fs_info, u64 *logical,\n+\t\t\t  u64 *length)\n+{\n+\tint ret;\n+\tstruct btrfs_key key, found_key;\n+\tstruct extent_buffer *leaf;\n+\tstruct btrfs_remap_item *remap;\n+\tBTRFS_PATH_AUTO_FREE(path);\n+\n+\tpath = btrfs_alloc_path();\n+\tif (!path)\n+\t\treturn -ENOMEM;\n+\n+\tkey.objectid = *logical;\n+\tkey.type = (u8)-1;\n+\tkey.offset = (u64)-1;\n+\n+\tret = btrfs_search_slot(NULL, fs_info->remap_root, &key, path,\n+\t\t\t\t0, 0);\n+\tif (ret < 0)\n+\t\treturn ret;\n+\n+\tleaf = path->nodes[0];\n+\n+\tif (path->slots[0] == 0)\n+\t\treturn -ENOENT;\n+\n+\tpath->slots[0]--;\n+\n+\tbtrfs_item_key_to_cpu(leaf, &found_key, path->slots[0]);\n+\n+\tif (found_key.type != BTRFS_REMAP_KEY &&\n+\t    found_key.type != BTRFS_IDENTITY_REMAP_KEY) {\n+\t\treturn -ENOENT;\n+\t}\n+\n+\tif (found_key.objectid > *logical ||\n+\t    found_key.objectid + found_key.offset <= *logical) {\n+\t\treturn -ENOENT;\n+\t}\n+\n+\tif (*logical + *length > found_key.objectid + found_key.offset)\n+\t\t*length = found_key.objectid + found_key.offset - *logical;\n+\n+\tif (found_key.type == BTRFS_IDENTITY_REMAP_KEY)\n+\t\treturn 0;\n+\n+\tremap = btrfs_item_ptr(leaf, path->slots[0], struct btrfs_remap_item);\n+\n+\t*logical += btrfs_remap_address(leaf, remap) - found_key.objectid;\n+\n+\treturn 0;\n+}\n+\n /*\n  * function to relocate all extents in a block group.\n  */\ndiff --git a/fs/btrfs/relocation.h b/fs/btrfs/relocation.h\nindex 5c36b3f84b57..b2ba83966650 100644\n--- a/fs/btrfs/relocation.h\n+++ b/fs/btrfs/relocation.h\n@@ -31,5 +31,7 @@ int btrfs_should_cancel_balance(const struct btrfs_fs_info *fs_info);\n struct btrfs_root *find_reloc_root(struct btrfs_fs_info *fs_info, u64 bytenr);\n bool btrfs_should_ignore_reloc_root(const struct btrfs_root *root);\n u64 btrfs_get_reloc_bg_bytenr(const struct btrfs_fs_info *fs_info);\n+int btrfs_translate_remap(struct btrfs_fs_info *fs_info, u64 *logical,\n+\t\t\t  u64 *length);\n \n #endif\ndiff --git a/fs/btrfs/volumes.c b/fs/btrfs/volumes.c\nindex d6060e0e2144..557ce56df800 100644\n--- a/fs/btrfs/volumes.c\n+++ b/fs/btrfs/volumes.c\n@@ -6584,6 +6584,25 @@ int btrfs_map_block(struct btrfs_fs_info *fs_info, enum btrfs_map_op op,\n \tif (IS_ERR(map))\n \t\treturn PTR_ERR(map);\n \n+\tif (map->type & BTRFS_BLOCK_GROUP_REMAPPED) {\n+\t\tu64 new_logical = logical;\n+\n+\t\tret = btrfs_translate_remap(fs_info, &new_logical, length);\n+\t\tif (ret)\n+\t\t\treturn ret;\n+\n+\t\tif (new_logical != logical) {\n+\t\t\tbtrfs_free_chunk_map(map);\n+\n+\t\t\tmap = btrfs_get_chunk_map(fs_info, new_logical,\n+\t\t\t\t\t\t  *length);\n+\t\t\tif (IS_ERR(map))\n+\t\t\t\treturn PTR_ERR(map);\n+\n+\t\t\tlogical = new_logical;\n+\t\t}\n+\t}\n+\n \tnum_copies = btrfs_chunk_map_num_copies(map);\n \tif (io_geom.mirror_num > num_copies)\n \t\treturn -EINVAL;\n-- \n2.51.2\n\n\n\n---\n\nIf we encounter a filesystem with the remap-tree incompat flag set,\nvaldiate its compatibility with the other flags, and load the remap tree\nusing the values that have been added to the superblock.\n\nThe remap-tree feature depends on the free space tere, but no-holes and\nblock-group-tree have been made dependencies to reduce the testing\nmatrix. Similarly I'm not aware of any reason why mixed-bg and zoned would be\nincompatible with remap-tree, but this is blocked for the time being\nuntil it can be fully tested.\n\nSigned-off-by: Mark Harmstone <mark@harmstone.com>\nReviewed-by: Boris Burkov <boris@bur.io>\n---\n fs/btrfs/Kconfig                |   2 +\n fs/btrfs/accessors.h            |   6 ++\n fs/btrfs/disk-io.c              | 111 ++++++++++++++++++++++++++++----\n fs/btrfs/extent-tree.c          |   2 +\n fs/btrfs/fs.h                   |   4 +-\n fs/btrfs/transaction.c          |   7 ++\n include/uapi/linux/btrfs_tree.h |   5 +-\n 7 files changed, 122 insertions(+), 15 deletions(-)\n\ndiff --git a/fs/btrfs/Kconfig b/fs/btrfs/Kconfig\nindex bf7feff2fe44..ee2fdcb49719 100644\n--- a/fs/btrfs/Kconfig\n+++ b/fs/btrfs/Kconfig\n@@ -115,4 +115,6 @@ config BTRFS_EXPERIMENTAL\n \n \t  - large folio support\n \n+\t  - remap-tree - logical address remapping tree\n+\n \t  If unsure, say N.\ndiff --git a/fs/btrfs/accessors.h b/fs/btrfs/accessors.h\nindex 9797f9e8d4e5..8938357fcb40 100644\n--- a/fs/btrfs/accessors.h\n+++ b/fs/btrfs/accessors.h\n@@ -883,6 +883,12 @@ BTRFS_SETGET_STACK_FUNCS(super_uuid_tree_generation, struct btrfs_super_block,\n \t\t\t uuid_tree_generation, 64);\n BTRFS_SETGET_STACK_FUNCS(super_nr_global_roots, struct btrfs_super_block,\n \t\t\t nr_global_roots, 64);\n+BTRFS_SETGET_STACK_FUNCS(super_remap_root, struct btrfs_super_block,\n+\t\t\t remap_root, 64);\n+BTRFS_SETGET_STACK_FUNCS(super_remap_root_generation, struct btrfs_super_block,\n+\t\t\t remap_root_generation, 64);\n+BTRFS_SETGET_STACK_FUNCS(super_remap_root_level, struct btrfs_super_block,\n+\t\t\t remap_root_level, 8);\n \n /* struct btrfs_file_extent_item */\n BTRFS_SETGET_STACK_FUNCS(stack_file_extent_type, struct btrfs_file_extent_item,\ndiff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c\nindex c36367f9017f..b03654ee91f5 100644\n--- a/fs/btrfs/disk-io.c\n+++ b/fs/btrfs/disk-io.c\n@@ -1158,6 +1158,8 @@ static struct btrfs_root *btrfs_get_global_root(struct btrfs_fs_info *fs_info,\n \t\treturn btrfs_grab_root(btrfs_global_root(fs_info, &key));\n \tcase BTRFS_RAID_STRIPE_TREE_OBJECTID:\n \t\treturn btrfs_grab_root(fs_info->stripe_root);\n+\tcase BTRFS_REMAP_TREE_OBJECTID:\n+\t\treturn btrfs_grab_root(fs_info->remap_root);\n \tdefault:\n \t\treturn NULL;\n \t}\n@@ -1248,6 +1250,7 @@ void btrfs_free_fs_info(struct btrfs_fs_info *fs_info)\n \tbtrfs_put_root(fs_info->data_reloc_root);\n \tbtrfs_put_root(fs_info->block_group_root);\n \tbtrfs_put_root(fs_info->stripe_root);\n+\tbtrfs_put_root(fs_info->remap_root);\n \tbtrfs_check_leaked_roots(fs_info);\n \tbtrfs_extent_buffer_leak_debug_check(fs_info);\n \tkfree(fs_info->super_copy);\n@@ -1800,6 +1803,7 @@ static void free_root_pointers(struct btrfs_fs_info *info, bool free_chunk_root)\n \tfree_root_extent_buffers(info->data_reloc_root);\n \tfree_root_extent_buffers(info->block_group_root);\n \tfree_root_extent_buffers(info->stripe_root);\n+\tfree_root_extent_buffers(info->remap_root);\n \tif (free_chunk_root)\n \t\tfree_root_extent_buffers(info->chunk_root);\n }\n@@ -2213,21 +2217,49 @@ static int btrfs_read_roots(struct btrfs_fs_info *fs_info)\n \tif (ret)\n \t\tgoto out;\n \n-\t/*\n-\t * This tree can share blocks with some other fs tree during relocation\n-\t * and we need a proper setup by btrfs_get_fs_root\n-\t */\n-\troot = btrfs_get_fs_root(tree_root->fs_info,\n-\t\t\t\t BTRFS_DATA_RELOC_TREE_OBJECTID, true);\n-\tif (IS_ERR(root)) {\n-\t\tif (!btrfs_test_opt(fs_info, IGNOREBADROOTS)) {\n-\t\t\tlocation.objectid = BTRFS_DATA_RELOC_TREE_OBJECTID;\n-\t\t\tret = PTR_ERR(root);\n-\t\t\tgoto out;\n+\tif (btrfs_fs_incompat(fs_info, REMAP_TREE)) {\n+\t\t/*\n+\t\t * The remap_root has already been loaded in\n+\t\t * load_important_roots().\n+\t\t */\n+\t\troot = fs_info->remap_root;\n+\n+\t\tset_bit(BTRFS_ROOT_TRACK_DIRTY, &root->state);\n+\n+\t\troot->root_key.objectid = BTRFS_REMAP_TREE_OBJECTID;\n+\t\troot->root_key.type = BTRFS_ROOT_ITEM_KEY;\n+\t\troot->root_key.offset = 0;\n+\n+\t\t/* Check that data reloc tree doesn't also exist. */\n+\t\tlocation.objectid = BTRFS_DATA_RELOC_TREE_OBJECTID;\n+\t\troot = btrfs_read_tree_root(fs_info->tree_root, &location);\n+\t\tif (!IS_ERR(root)) {\n+\t\t\tbtrfs_err(fs_info,\n+\t\t\t   \"data reloc tree exists when remap-tree enabled\");\n+\t\t\tbtrfs_put_root(root);\n+\t\t\treturn -EIO;\n+\t\t} else if (PTR_ERR(root) != -ENOENT) {\n+\t\t\tbtrfs_warn(fs_info,\n+\t\t\t   \"error %ld when checking for data reloc tree\",\n+\t\t\t\t   PTR_ERR(root));\n \t\t}\n \t} else {\n-\t\tset_bit(BTRFS_ROOT_TRACK_DIRTY, &root->state);\n-\t\tfs_info->data_reloc_root = root;\n+\t\t/*\n+\t\t * This tree can share blocks with some other fs tree during\n+\t\t * relocation and we need a proper setup by btrfs_get_fs_root().\n+\t\t */\n+\t\troot = btrfs_get_fs_root(tree_root->fs_info,\n+\t\t\t\t\t BTRFS_DATA_RELOC_TREE_OBJECTID, true);\n+\t\tif (IS_ERR(root)) {\n+\t\t\tif (!btrfs_test_opt(fs_info, IGNOREBADROOTS)) {\n+\t\t\t\tlocation.objectid = BTRFS_DATA_RELOC_TREE_OBJECTID;\n+\t\t\t\tret = PTR_ERR(root);\n+\t\t\t\tgoto out;\n+\t\t\t}\n+\t\t} else {\n+\t\t\tset_bit(BTRFS_ROOT_TRACK_DIRTY, &root->state);\n+\t\t\tfs_info->data_reloc_root = root;\n+\t\t}\n \t}\n \n \tlocation.objectid = BTRFS_QUOTA_TREE_OBJECTID;\n@@ -2467,6 +2499,36 @@ int btrfs_validate_super(const struct btrfs_fs_info *fs_info,\n \t\tret = -EINVAL;\n \t}\n \n+\tif (btrfs_fs_incompat(fs_info, REMAP_TREE)) {\n+\t\t/*\n+\t\t * Reduce test matrix for remap tree by requiring block-group-tree\n+\t\t * and no-holes. Free-space-tree is a hard requirement.\n+\t\t */\n+\t\tif (!btrfs_fs_compat_ro(fs_info, FREE_SPACE_TREE_VALID) ||\n+\t\t    !btrfs_fs_incompat(fs_info, NO_HOLES) ||\n+\t\t    !btrfs_fs_compat_ro(fs_info, BLOCK_GROUP_TREE)) {\n+\t\t\tbtrfs_err(fs_info,\n+\"remap-tree feature requires free-space-tree, no-holes, and block-group-tree\");\n+\t\t\tret = -EINVAL;\n+\t\t}\n+\n+\t\tif (btrfs_fs_incompat(fs_info, MIXED_GROUPS)) {\n+\t\t\tbtrfs_err(fs_info, \"remap-tree not supported with mixed-bg\");\n+\t\t\tret = -EINVAL;\n+\t\t}\n+\n+\t\tif (btrfs_fs_incompat(fs_info, ZONED)) {\n+\t\t\tbtrfs_err(fs_info, \"remap-tree not supported with zoned devices\");\n+\t\t\tret = -EINVAL;\n+\t\t}\n+\n+\t\tif (sectorsize > PAGE_SIZE) {\n+\t\t\tbtrfs_err(fs_info,\n+\t\t\t\t  \"remap-tree not supported when block size > page size\");\n+\t\t\tret = -EINVAL;\n+\t\t}\n+\t}\n+\n \t/*\n \t * Hint to catch really bogus numbers, bitflips or so, more exact checks are\n \t * done later\n@@ -2625,6 +2687,18 @@ static int load_important_roots(struct btrfs_fs_info *fs_info)\n \t\tbtrfs_warn(fs_info, \"couldn't read tree root\");\n \t\treturn ret;\n \t}\n+\n+\tif (btrfs_fs_incompat(fs_info, REMAP_TREE)) {\n+\t\tbytenr = btrfs_super_remap_root(sb);\n+\t\tgen = btrfs_super_remap_root_generation(sb);\n+\t\tlevel = btrfs_super_remap_root_level(sb);\n+\t\tret = load_super_root(fs_info->remap_root, bytenr, gen, level);\n+\t\tif (ret) {\n+\t\t\tbtrfs_warn(fs_info, \"couldn't read remap root\");\n+\t\t\treturn ret;\n+\t\t}\n+\t}\n+\n \treturn 0;\n }\n \n@@ -3245,6 +3319,7 @@ int __cold open_ctree(struct super_block *sb, struct btrfs_fs_devices *fs_device\n \tstruct btrfs_fs_info *fs_info = btrfs_sb(sb);\n \tstruct btrfs_root *tree_root;\n \tstruct btrfs_root *chunk_root;\n+\tstruct btrfs_root *remap_root;\n \tint ret;\n \tint level;\n \n@@ -3375,6 +3450,16 @@ int __cold open_ctree(struct super_block *sb, struct btrfs_fs_devices *fs_device\n \tif (ret < 0)\n \t\tgoto fail_alloc;\n \n+\tif (btrfs_super_incompat_flags(disk_super) & BTRFS_FEATURE_INCOMPAT_REMAP_TREE) {\n+\t\tremap_root = btrfs_alloc_root(fs_info, BTRFS_REMAP_TREE_OBJECTID,\n+\t\t\t\t\t      GFP_KERNEL);\n+\t\tfs_info->remap_root = remap_root;\n+\t\tif (!remap_root) {\n+\t\t\tret = -ENOMEM;\n+\t\t\tgoto fail_alloc;\n+\t\t}\n+\t}\n+\n \t/*\n \t * At this point our mount options are validated, if we set ->max_inline\n \t * to something non-standard make sure we truncate it to sectorsize.\ndiff --git a/fs/btrfs/extent-tree.c b/fs/btrfs/extent-tree.c\nindex 43473a6d91d7..3868a295be62 100644\n--- a/fs/btrfs/extent-tree.c\n+++ b/fs/btrfs/extent-tree.c\n@@ -2589,6 +2589,8 @@ static u64 get_alloc_profile_by_root(struct btrfs_root *root, int data)\n \t\tflags = BTRFS_BLOCK_GROUP_DATA;\n \telse if (root == fs_info->chunk_root)\n \t\tflags = BTRFS_BLOCK_GROUP_SYSTEM;\n+\telse if (root == fs_info->remap_root)\n+\t\tflags = BTRFS_BLOCK_GROUP_METADATA_REMAP;\n \telse\n \t\tflags = BTRFS_BLOCK_GROUP_METADATA;\n \ndiff --git a/fs/btrfs/fs.h b/fs/btrfs/fs.h\nindex 46c4f1dcec47..af11f2ce310a 100644\n--- a/fs/btrfs/fs.h\n+++ b/fs/btrfs/fs.h\n@@ -307,7 +307,8 @@ enum {\n #define BTRFS_FEATURE_INCOMPAT_SUPP\t\t\\\n \t(BTRFS_FEATURE_INCOMPAT_SUPP_STABLE |\t\\\n \t BTRFS_FEATURE_INCOMPAT_RAID_STRIPE_TREE | \\\n-\t BTRFS_FEATURE_INCOMPAT_EXTENT_TREE_V2)\n+\t BTRFS_FEATURE_INCOMPAT_EXTENT_TREE_V2 | \\\n+\t BTRFS_FEATURE_INCOMPAT_REMAP_TREE)\n \n #else\n \n@@ -467,6 +468,7 @@ struct btrfs_fs_info {\n \tstruct btrfs_root *data_reloc_root;\n \tstruct btrfs_root *block_group_root;\n \tstruct btrfs_root *stripe_root;\n+\tstruct btrfs_root *remap_root;\n \n \t/* The log root tree is a directory of all the other log roots */\n \tstruct btrfs_root *log_root_tree;\ndiff --git a/fs/btrfs/transaction.c b/fs/btrfs/transaction.c\nindex e2f993b1783f..f4cc9e1a1b93 100644\n--- a/fs/btrfs/transaction.c\n+++ b/fs/btrfs/transaction.c\n@@ -1967,6 +1967,13 @@ static void update_super_roots(struct btrfs_fs_info *fs_info)\n \t\tsuper->cache_generation = 0;\n \tif (test_bit(BTRFS_FS_UPDATE_UUID_TREE_GEN, &fs_info->flags))\n \t\tsuper->uuid_tree_generation = root_item->generation;\n+\n+\tif (btrfs_fs_incompat(fs_info, REMAP_TREE)) {\n+\t\troot_item = &fs_info->remap_root->root_item;\n+\t\tsuper->remap_root = root_item->bytenr;\n+\t\tsuper->remap_root_generation = root_item->generation;\n+\t\tsuper->remap_root_level = root_item->level;\n+\t}\n }\n \n int btrfs_transaction_blocked(struct btrfs_fs_info *info)\ndiff --git a/include/uapi/linux/btrfs_tree.h b/include/uapi/linux/btrfs_tree.h\nindex 86820a9644e8..f7843e6bb978 100644\n--- a/include/uapi/linux/btrfs_tree.h\n+++ b/include/uapi/linux/btrfs_tree.h\n@@ -721,9 +721,12 @@ struct btrfs_super_block {\n \t__u8 metadata_uuid[BTRFS_FSID_SIZE];\n \n \t__u64 nr_global_roots;\n+\t__le64 remap_root;\n+\t__le64 remap_root_generation;\n+\t__u8 remap_root_level;\n \n \t/* Future expansion */\n-\t__le64 reserved[27];\n+\t__u8 reserved[199];\n \t__u8 sys_chunk_array[BTRFS_SYSTEM_CHUNK_ARRAY_SIZE];\n \tstruct btrfs_root_backup super_roots[BTRFS_NUM_BACKUP_ROOTS];\n \n-- \n2.51.2\n\n\n\n---\n\nRename the field commit_used in struct btrfs_block_group to last_used,\nfor clarity and consistency with the similar fields we're about to add.\nIt's not obvious that commit_flags means \"flags as of the last commit\"\nrather than \"flags related to a commit\".\n\nSigned-off-by: Mark Harmstone <mark@harmstone.com>\n---\n fs/btrfs/block-group.c | 24 ++++++++++++------------\n fs/btrfs/block-group.h |  4 ++--\n 2 files changed, 14 insertions(+), 14 deletions(-)\n\ndiff --git a/fs/btrfs/block-group.c b/fs/btrfs/block-group.c\nindex 39e2db630bce..822c5306a7a4 100644\n--- a/fs/btrfs/block-group.c\n+++ b/fs/btrfs/block-group.c\n@@ -2388,7 +2388,7 @@ static int read_one_block_group(struct btrfs_fs_info *info,\n \n \tcache->length = key->offset;\n \tcache->used = btrfs_stack_block_group_used(bgi);\n-\tcache->commit_used = cache->used;\n+\tcache->last_used = cache->used;\n \tcache->flags = btrfs_stack_block_group_flags(bgi);\n \tcache->global_root_id = btrfs_stack_block_group_chunk_objectid(bgi);\n \tcache->space_info = btrfs_find_space_info(info, cache->flags);\n@@ -2667,7 +2667,7 @@ static int insert_block_group_item(struct btrfs_trans_handle *trans,\n \tstruct btrfs_block_group_item bgi;\n \tstruct btrfs_root *root = btrfs_block_group_root(fs_info);\n \tstruct btrfs_key key;\n-\tu64 old_commit_used;\n+\tu64 old_last_used;\n \tint ret;\n \n \tspin_lock(&block_group->lock);\n@@ -2675,8 +2675,8 @@ static int insert_block_group_item(struct btrfs_trans_handle *trans,\n \tbtrfs_set_stack_block_group_chunk_objectid(&bgi,\n \t\t\t\t\t\t   block_group->global_root_id);\n \tbtrfs_set_stack_block_group_flags(&bgi, block_group->flags);\n-\told_commit_used = block_group->commit_used;\n-\tblock_group->commit_used = block_group->used;\n+\told_last_used = block_group->last_used;\n+\tblock_group->last_used = block_group->used;\n \tkey.objectid = block_group->start;\n \tkey.type = BTRFS_BLOCK_GROUP_ITEM_KEY;\n \tkey.offset = block_group->length;\n@@ -2685,7 +2685,7 @@ static int insert_block_group_item(struct btrfs_trans_handle *trans,\n \tret = btrfs_insert_item(trans, root, &key, &bgi, sizeof(bgi));\n \tif (ret < 0) {\n \t\tspin_lock(&block_group->lock);\n-\t\tblock_group->commit_used = old_commit_used;\n+\t\tblock_group->last_used = old_last_used;\n \t\tspin_unlock(&block_group->lock);\n \t}\n \n@@ -3139,7 +3139,7 @@ static int update_block_group_item(struct btrfs_trans_handle *trans,\n \tstruct extent_buffer *leaf;\n \tstruct btrfs_block_group_item bgi;\n \tstruct btrfs_key key;\n-\tu64 old_commit_used;\n+\tu64 old_last_used;\n \tu64 used;\n \n \t/*\n@@ -3149,14 +3149,14 @@ static int update_block_group_item(struct btrfs_trans_handle *trans,\n \t * may be changed.\n \t */\n \tspin_lock(&cache->lock);\n-\told_commit_used = cache->commit_used;\n+\told_last_used = cache->last_used;\n \tused = cache->used;\n \t/* No change in used bytes, can safely skip it. */\n-\tif (cache->commit_used == used) {\n+\tif (cache->last_used == used) {\n \t\tspin_unlock(&cache->lock);\n \t\treturn 0;\n \t}\n-\tcache->commit_used = used;\n+\tcache->last_used = used;\n \tspin_unlock(&cache->lock);\n \n \tkey.objectid = cache->start;\n@@ -3180,17 +3180,17 @@ static int update_block_group_item(struct btrfs_trans_handle *trans,\n fail:\n \tbtrfs_release_path(path);\n \t/*\n-\t * We didn't update the block group item, need to revert commit_used\n+\t * We didn't update the block group item, need to revert last_used\n \t * unless the block group item didn't exist yet - this is to prevent a\n \t * race with a concurrent insertion of the block group item, with\n \t * insert_block_group_item(), that happened just after we attempted to\n-\t * update. In that case we would reset commit_used to 0 just after the\n+\t * update. In that case we would reset last_used to 0 just after the\n \t * insertion set it to a value greater than 0 - if the block group later\n \t * becomes with 0 used bytes, we would incorrectly skip its update.\n \t */\n \tif (ret < 0 && ret != -ENOENT) {\n \t\tspin_lock(&cache->lock);\n-\t\tcache->commit_used = old_commit_used;\n+\t\tcache->last_used = old_last_used;\n \t\tspin_unlock(&cache->lock);\n \t}\n \treturn ret;\ndiff --git a/fs/btrfs/block-group.h b/fs/btrfs/block-group.h\nindex 5f933455118c..01401e9959c1 100644\n--- a/fs/btrfs/block-group.h\n+++ b/fs/btrfs/block-group.h\n@@ -132,10 +132,10 @@ struct btrfs_block_group {\n \n \t/*\n \t * The last committed used bytes of this block group, if the above @used\n-\t * is still the same as @commit_used, we don't need to update block\n+\t * is still the same as @last_used, we don't need to update block\n \t * group item of this block group.\n \t */\n-\tu64 commit_used;\n+\tu64 last_used;\n \t/*\n \t * If the free space extent count exceeds this number, convert the block\n \t * group to bitmaps.\n-- \n2.51.2\n\n\n\n---\n\nbtrfs_discard_extent() can be called either when an extent is removed\nor from walking the free-space tree. With a remapped block group these\ntwo things are no longer equivalent: the extent's addresses are\nremapped, while the free-space tree exclusively uses underlying\naddresses.\n\nAdd a do_remap parameter to btrfs_discard_extent() and\nbtrfs_map_discard(), saying whether or not the address needs to be run\nthrough the remap tree first.\n\nSigned-off-by: Mark Harmstone <mark@harmstone.com>\nReviewed-by: Boris Burkov <boris@bur.io>\n---\n fs/btrfs/extent-tree.c      | 11 +++++++----\n fs/btrfs/extent-tree.h      |  2 +-\n fs/btrfs/free-space-cache.c |  2 +-\n fs/btrfs/inode.c            |  2 +-\n fs/btrfs/volumes.c          | 23 +++++++++++++++++++++--\n fs/btrfs/volumes.h          |  2 +-\n 6 files changed, 32 insertions(+), 10 deletions(-)\n\ndiff --git a/fs/btrfs/extent-tree.c b/fs/btrfs/extent-tree.c\nindex 70020ba8ef92..9d68f3fa4fa9 100644\n--- a/fs/btrfs/extent-tree.c\n+++ b/fs/btrfs/extent-tree.c\n@@ -1381,7 +1381,7 @@ static int do_discard_extent(struct btrfs_discard_stripe *stripe, u64 *bytes)\n }\n \n int btrfs_discard_extent(struct btrfs_fs_info *fs_info, u64 bytenr,\n-\t\t\t u64 num_bytes, u64 *actual_bytes)\n+\t\t\t u64 num_bytes, u64 *actual_bytes, bool do_remap)\n {\n \tint ret = 0;\n \tu64 discarded_bytes = 0;\n@@ -1399,7 +1399,8 @@ int btrfs_discard_extent(struct btrfs_fs_info *fs_info, u64 bytenr,\n \t\tint i;\n \n \t\tnum_bytes = end - cur;\n-\t\tstripes = btrfs_map_discard(fs_info, cur, &num_bytes, &num_stripes);\n+\t\tstripes = btrfs_map_discard(fs_info, cur, &num_bytes,\n+\t\t\t\t\t    &num_stripes, do_remap);\n \t\tif (IS_ERR(stripes)) {\n \t\t\tret = PTR_ERR(stripes);\n \t\t\tif (ret == -EOPNOTSUPP)\n@@ -2932,7 +2933,8 @@ int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans)\n \n \t\tif (btrfs_test_opt(fs_info, DISCARD_SYNC))\n \t\t\tret = btrfs_discard_extent(fs_info, start,\n-\t\t\t\t\t\t   end + 1 - start, NULL);\n+\t\t\t\t\t\t   end + 1 - start, NULL,\n+\t\t\t\t\t\t   true);\n \n \t\tnext_state = btrfs_next_extent_state(unpin, cached_state);\n \t\tbtrfs_clear_extent_dirty(unpin, start, end, &cached_state);\n@@ -2990,7 +2992,8 @@ int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans)\n \t\tret = -EROFS;\n \t\tif (!TRANS_ABORTED(trans))\n \t\t\tret = btrfs_discard_extent(fs_info, block_group->start,\n-\t\t\t\t\t\t   block_group->length, NULL);\n+\t\t\t\t\t\t   block_group->length, NULL,\n+\t\t\t\t\t\t   true);\n \n \t\t/*\n \t\t * Not strictly necessary to lock, as the block_group should be\ndiff --git a/fs/btrfs/extent-tree.h b/fs/btrfs/extent-tree.h\nindex d7b6aeb63656..ff330d4896d6 100644\n--- a/fs/btrfs/extent-tree.h\n+++ b/fs/btrfs/extent-tree.h\n@@ -161,7 +161,7 @@ int btrfs_drop_subtree(struct btrfs_trans_handle *trans,\n \t\t\tstruct extent_buffer *parent);\n void btrfs_error_unpin_extent_range(struct btrfs_fs_info *fs_info, u64 start, u64 end);\n int btrfs_discard_extent(struct btrfs_fs_info *fs_info, u64 bytenr,\n-\t\t\t u64 num_bytes, u64 *actual_bytes);\n+\t\t\t u64 num_bytes, u64 *actual_bytes, bool do_remap);\n int btrfs_trim_fs(struct btrfs_fs_info *fs_info, struct fstrim_range *range);\n void btrfs_handle_fully_remapped_bgs(struct btrfs_fs_info *fs_info);\n int btrfs_complete_bg_remapping(struct btrfs_block_group *bg);\ndiff --git a/fs/btrfs/free-space-cache.c b/fs/btrfs/free-space-cache.c\nindex 8d4db3d57cf7..17e79ee3e021 100644\n--- a/fs/btrfs/free-space-cache.c\n+++ b/fs/btrfs/free-space-cache.c\n@@ -3677,7 +3677,7 @@ static int do_trimming(struct btrfs_block_group *block_group,\n \t}\n \tspin_unlock(&space_info->lock);\n \n-\tret = btrfs_discard_extent(fs_info, start, bytes, &trimmed);\n+\tret = btrfs_discard_extent(fs_info, start, bytes, &trimmed, false);\n \tif (!ret) {\n \t\t*total_trimmed += trimmed;\n \t\ttrim_state = BTRFS_TRIM_STATE_TRIMMED;\ndiff --git a/fs/btrfs/inode.c b/fs/btrfs/inode.c\nindex 247b373bf5cf..3915e08d252c 100644\n--- a/fs/btrfs/inode.c\n+++ b/fs/btrfs/inode.c\n@@ -3370,7 +3370,7 @@ int btrfs_finish_one_ordered(struct btrfs_ordered_extent *ordered_extent)\n \t\t\t\tbtrfs_discard_extent(fs_info,\n \t\t\t\t\t\tordered_extent->disk_bytenr,\n \t\t\t\t\t\tordered_extent->disk_num_bytes,\n-\t\t\t\t\t\tNULL);\n+\t\t\t\t\t\tNULL, true);\n \t\t\tbtrfs_free_reserved_extent(fs_info,\n \t\t\t\t\tordered_extent->disk_bytenr,\n \t\t\t\t\tordered_extent->disk_num_bytes, true);\ndiff --git a/fs/btrfs/volumes.c b/fs/btrfs/volumes.c\nindex caffee6527b2..b0aef4d489e7 100644\n--- a/fs/btrfs/volumes.c\n+++ b/fs/btrfs/volumes.c\n@@ -3425,7 +3425,7 @@ static int btrfs_relocate_chunk_finish(struct btrfs_fs_info *fs_info,\n \t */\n \tif (btrfs_is_zoned(fs_info)) {\n \t\tret = btrfs_discard_extent(fs_info, bg->start, length,\n-\t\t\t\t\t   NULL);\n+\t\t\t\t\t   NULL, true);\n \t\tif (ret)\n \t\t\tbtrfs_info(fs_info,\n \t\t\t\t   \"failed to reset zone %llu after relocation\",\n@@ -6111,7 +6111,7 @@ void btrfs_put_bioc(struct btrfs_io_context *bioc)\n  */\n struct btrfs_discard_stripe *btrfs_map_discard(struct btrfs_fs_info *fs_info,\n \t\t\t\t\t       u64 logical, u64 *length_ret,\n-\t\t\t\t\t       u32 *num_stripes)\n+\t\t\t\t\t       u32 *num_stripes, bool do_remap)\n {\n \tstruct btrfs_chunk_map *map;\n \tstruct btrfs_discard_stripe *stripes;\n@@ -6135,6 +6135,25 @@ struct btrfs_discard_stripe *btrfs_map_discard(struct btrfs_fs_info *fs_info,\n \tif (IS_ERR(map))\n \t\treturn ERR_CAST(map);\n \n+\tif (do_remap && map->type & BTRFS_BLOCK_GROUP_REMAPPED) {\n+\t\tu64 new_logical = logical;\n+\n+\t\tret = btrfs_translate_remap(fs_info, &new_logical, &length);\n+\t\tif (ret)\n+\t\t\tgoto out_free_map;\n+\n+\t\tif (new_logical != logical) {\n+\t\t\tbtrfs_free_chunk_map(map);\n+\n+\t\t\tmap = btrfs_get_chunk_map(fs_info, new_logical,\n+\t\t\t\t\t\t  length);\n+\t\t\tif (IS_ERR(map))\n+\t\t\t\treturn ERR_CAST(map);\n+\n+\t\t\tlogical = new_logical;\n+\t\t}\n+\t}\n+\n \t/* we don't discard raid56 yet */\n \tif (map->type & BTRFS_BLOCK_GROUP_RAID56_MASK) {\n \t\tret = -EOPNOTSUPP;\ndiff --git a/fs/btrfs/volumes.h b/fs/btrfs/volumes.h\nindex ccf0a459180d..505a50689fb0 100644\n--- a/fs/btrfs/volumes.h\n+++ b/fs/btrfs/volumes.h\n@@ -732,7 +732,7 @@ int btrfs_map_repair_block(struct btrfs_fs_info *fs_info,\n \t\t\t   u32 length, int mirror_num);\n struct btrfs_discard_stripe *btrfs_map_discard(struct btrfs_fs_info *fs_info,\n \t\t\t\t\t       u64 logical, u64 *length_ret,\n-\t\t\t\t\t       u32 *num_stripes);\n+\t\t\t\t\t       u32 *num_stripes, bool do_remap);\n int btrfs_read_sys_array(struct btrfs_fs_info *fs_info);\n int btrfs_read_chunk_tree(struct btrfs_fs_info *fs_info);\n struct btrfs_block_group *btrfs_create_chunk(struct btrfs_trans_handle *trans,\n-- \n2.51.2\n\n\n\n---\n\nAdd a function do_remap_tree_reloc(), which does the actual work of\ndoing a relocation using the remap tree.\n\nIn a loop we call do_remap_reloc_trans(), which searches for the first\nidentity remap for the block group. We call btrfs_reserve_extent() to\nfind space elsewhere for it, and read the data into memory and write it\nto the new location. We then carve out the identity remap and replace it\nwith an actual remap, which points to the new location in which to look.\n\nOnce the last identity remap has been removed we call\nlast_identity_remap_gone(), which, as with deletions, removes the\nchunk's stripes and device extents.\n\nSigned-off-by: Mark Harmstone <mark@harmstone.com>\nReviewed-by: Boris Burkov <boris@bur.io>\n---\n fs/btrfs/relocation.c | 337 ++++++++++++++++++++++++++++++++++++++++++\n 1 file changed, 337 insertions(+)\n\ndiff --git a/fs/btrfs/relocation.c b/fs/btrfs/relocation.c\nindex 82f0e15f0f84..20cf0f7fd401 100644\n--- a/fs/btrfs/relocation.c\n+++ b/fs/btrfs/relocation.c\n@@ -4633,6 +4633,61 @@ static int create_remap_tree_entries(struct btrfs_trans_handle *trans,\n \treturn ret;\n }\n \n+static int find_next_identity_remap(struct btrfs_trans_handle *trans,\n+\t\t\t\t    struct btrfs_path *path, u64 bg_end,\n+\t\t\t\t    u64 last_start, u64 *start,\n+\t\t\t\t    u64 *length)\n+{\n+\tint ret;\n+\tstruct btrfs_key key, found_key;\n+\tstruct btrfs_root *remap_root = trans->fs_info->remap_root;\n+\tstruct extent_buffer *leaf;\n+\n+\tkey.objectid = last_start;\n+\tkey.type = BTRFS_IDENTITY_REMAP_KEY;\n+\tkey.offset = 0;\n+\n+\tret = btrfs_search_slot(trans, remap_root, &key, path, 0, 0);\n+\tif (ret < 0)\n+\t\tgoto out;\n+\n+\tleaf = path->nodes[0];\n+\twhile (true) {\n+\t\tif (path->slots[0] >= btrfs_header_nritems(leaf)) {\n+\t\t\tret = btrfs_next_leaf(remap_root, path);\n+\n+\t\t\tif (ret != 0) {\n+\t\t\t\tif (ret == 1)\n+\t\t\t\t\tret = -ENOENT;\n+\t\t\t\tgoto out;\n+\t\t\t}\n+\n+\t\t\tleaf = path->nodes[0];\n+\t\t}\n+\n+\t\tbtrfs_item_key_to_cpu(leaf, &found_key, path->slots[0]);\n+\n+\t\tif (found_key.objectid >= bg_end) {\n+\t\t\tret = -ENOENT;\n+\t\t\tgoto out;\n+\t\t}\n+\n+\t\tif (found_key.type == BTRFS_IDENTITY_REMAP_KEY) {\n+\t\t\t*start = found_key.objectid;\n+\t\t\t*length = found_key.offset;\n+\t\t\tret = 0;\n+\t\t\tgoto out;\n+\t\t}\n+\n+\t\tpath->slots[0]++;\n+\t}\n+\n+out:\n+\tbtrfs_release_path(path);\n+\n+\treturn ret;\n+}\n+\n static int remove_chunk_stripes(struct btrfs_trans_handle *trans,\n \t\t\t\tstruct btrfs_chunk_map *chunk_map,\n \t\t\t\tstruct btrfs_path *path)\n@@ -4779,6 +4834,96 @@ static void adjust_identity_remap_count(struct btrfs_trans_handle *trans,\n \t\tbtrfs_mark_bg_fully_remapped(bg, trans);\n }\n \n+static int add_remap_entry(struct btrfs_trans_handle *trans,\n+\t\t\t   struct btrfs_path *path,\n+\t\t\t   struct btrfs_block_group *src_bg, u64 old_addr,\n+\t\t\t   u64 new_addr, u64 length)\n+{\n+\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n+\tstruct btrfs_key key, new_key;\n+\tint ret;\n+\tint identity_count_delta = 0;\n+\n+\tkey.objectid = old_addr;\n+\tkey.type = (u8)-1;\n+\tkey.offset = (u64)-1;\n+\n+\tret = btrfs_search_slot(trans, fs_info->remap_root, &key, path, -1, 1);\n+\tif (ret < 0)\n+\t\tgoto end;\n+\n+\tif (path->slots[0] == 0) {\n+\t\tret = -ENOENT;\n+\t\tgoto end;\n+\t}\n+\n+\tpath->slots[0]--;\n+\n+\tbtrfs_item_key_to_cpu(path->nodes[0], &key, path->slots[0]);\n+\n+\tif (key.type != BTRFS_IDENTITY_REMAP_KEY ||\n+\t    key.objectid > old_addr ||\n+\t    key.objectid + key.offset <= old_addr) {\n+\t\tret = -ENOENT;\n+\t\tgoto end;\n+\t}\n+\n+\t/* Shorten or delete identity mapping entry. */\n+\n+\tif (key.objectid == old_addr) {\n+\t\tret = btrfs_del_item(trans, fs_info->remap_root, path);\n+\t\tif (ret)\n+\t\t\tgoto end;\n+\n+\t\tidentity_count_delta--;\n+\t} else {\n+\t\tnew_key.objectid = key.objectid;\n+\t\tnew_key.type = BTRFS_IDENTITY_REMAP_KEY;\n+\t\tnew_key.offset = old_addr - key.objectid;\n+\n+\t\tbtrfs_set_item_key_safe(trans, path, &new_key);\n+\t}\n+\n+\tbtrfs_release_path(path);\n+\n+\t/* Create new remap entry. */\n+\n+\tret = add_remap_item(trans, path, new_addr, length, old_addr);\n+\tif (ret)\n+\t\tgoto end;\n+\n+\t/* Add entry for remainder of identity mapping, if necessary. */\n+\n+\tif (key.objectid + key.offset != old_addr + length) {\n+\t\tnew_key.objectid = old_addr + length;\n+\t\tnew_key.type = BTRFS_IDENTITY_REMAP_KEY;\n+\t\tnew_key.offset = key.objectid + key.offset - old_addr - length;\n+\n+\t\tret = btrfs_insert_empty_item(trans, fs_info->remap_root,\n+\t\t\t\t\t      path, &new_key, 0);\n+\t\tif (ret)\n+\t\t\tgoto end;\n+\n+\t\tbtrfs_release_path(path);\n+\n+\t\tidentity_count_delta++;\n+\t}\n+\n+\t/* Add backref. */\n+\n+\tret = add_remap_backref_item(trans, path, new_addr, length, old_addr);\n+\tif (ret)\n+\t\tgoto end;\n+\n+\tif (identity_count_delta != 0)\n+\t\tadjust_identity_remap_count(trans, src_bg, identity_count_delta);\n+\n+end:\n+\tbtrfs_release_path(path);\n+\n+\treturn ret;\n+}\n+\n static int mark_chunk_remapped(struct btrfs_trans_handle *trans,\n \t\t\t       struct btrfs_path *path, uint64_t start)\n {\n@@ -4828,6 +4973,190 @@ static int mark_chunk_remapped(struct btrfs_trans_handle *trans,\n \treturn ret;\n }\n \n+static int do_remap_reloc_trans(struct btrfs_fs_info *fs_info,\n+\t\t\t\tstruct btrfs_block_group *src_bg,\n+\t\t\t\tstruct btrfs_path *path, u64 *last_start)\n+{\n+\tstruct btrfs_trans_handle *trans;\n+\tstruct btrfs_root *extent_root;\n+\tstruct btrfs_key ins;\n+\tstruct btrfs_block_group *dest_bg = NULL;\n+\tu64 start, remap_length, length, new_addr, min_size;\n+\tint ret;\n+\tbool no_more = false;\n+\tbool is_data = src_bg->flags & BTRFS_BLOCK_GROUP_DATA;\n+\tbool made_reservation = false, bg_needs_free_space;\n+\tstruct btrfs_space_info *sinfo = src_bg->space_info;\n+\n+\textent_root = btrfs_extent_root(fs_info, src_bg->start);\n+\n+\ttrans = btrfs_start_transaction(extent_root, 0);\n+\tif (IS_ERR(trans))\n+\t\treturn PTR_ERR(trans);\n+\n+\tmutex_lock(&fs_info->remap_mutex);\n+\n+\tret = find_next_identity_remap(trans, path, src_bg->start + src_bg->length,\n+\t\t\t\t       *last_start, &start, &remap_length);\n+\tif (ret == -ENOENT) {\n+\t\tno_more = true;\n+\t\tgoto next;\n+\t} else if (ret) {\n+\t\tmutex_unlock(&fs_info->remap_mutex);\n+\t\tbtrfs_end_transaction(trans);\n+\t\treturn ret;\n+\t}\n+\n+\t/* Try to reserve enough space for block. */\n+\n+\tspin_lock(&sinfo->lock);\n+\tbtrfs_space_info_update_bytes_may_use(sinfo, remap_length);\n+\tspin_unlock(&sinfo->lock);\n+\n+\tif (is_data)\n+\t\tmin_size = fs_info->sectorsize;\n+\telse\n+\t\tmin_size = fs_info->nodesize;\n+\n+\t/*\n+\t * We're using btrfs_reserve_extent() to allocate a contiguous\n+\t * logical address range, but this will become a remap item rather than\n+\t * an extent in the extent tree.\n+\t *\n+\t * Short allocations are fine: it means that we chop off the beginning\n+\t * of the identity remap that we're processing, and will tackle the\n+\t * rest of it the next time round.\n+\t */\n+\tret = btrfs_reserve_extent(fs_info->fs_root, remap_length,\n+\t\t\t\t   remap_length, min_size,\n+\t\t\t\t   0, 0, &ins, is_data, false);\n+\tif (ret) {\n+\t\tspin_lock(&sinfo->lock);\n+\t\tbtrfs_space_info_update_bytes_may_use(sinfo, -remap_length);\n+\t\tspin_unlock(&sinfo->lock);\n+\n+\t\tmutex_unlock(&fs_info->remap_mutex);\n+\t\tbtrfs_end_transaction(trans);\n+\t\treturn ret;\n+\t}\n+\n+\tmade_reservation = true;\n+\n+\tnew_addr = ins.objectid;\n+\tlength = ins.offset;\n+\n+\tif (!is_data && !IS_ALIGNED(length, fs_info->nodesize)) {\n+\t\tu64 new_length = ALIGN_DOWN(length, fs_info->nodesize);\n+\n+\t\tbtrfs_free_reserved_extent(fs_info, new_addr + new_length,\n+\t\t\t\t\t   length - new_length, 0);\n+\n+\t\tlength = new_length;\n+\t}\n+\n+\tdest_bg = btrfs_lookup_block_group(fs_info, new_addr);\n+\n+\tmutex_lock(&dest_bg->free_space_lock);\n+\tbg_needs_free_space = test_bit(BLOCK_GROUP_FLAG_NEEDS_FREE_SPACE,\n+\t\t\t\t       &dest_bg->runtime_flags);\n+\tmutex_unlock(&dest_bg->free_space_lock);\n+\n+\tif (bg_needs_free_space) {\n+\t\tret = btrfs_add_block_group_free_space(trans, dest_bg);\n+\t\tif (ret)\n+\t\t\tgoto fail;\n+\t}\n+\n+\tret = copy_remapped_data(fs_info, start, new_addr, length);\n+\tif (ret)\n+\t\tgoto fail;\n+\n+\tret = btrfs_remove_from_free_space_tree(trans, new_addr, length);\n+\tif (ret)\n+\t\tgoto fail;\n+\n+\tret = add_remap_entry(trans, path, src_bg, start, new_addr, length);\n+\tif (ret) {\n+\t\tbtrfs_add_to_free_space_tree(trans, new_addr, length);\n+\t\tgoto fail;\n+\t}\n+\n+\tadjust_block_group_remap_bytes(trans, dest_bg, length);\n+\tbtrfs_free_reserved_bytes(dest_bg, length, 0);\n+\n+\tspin_lock(&sinfo->lock);\n+\tsinfo->bytes_readonly += length;\n+\tspin_unlock(&sinfo->lock);\n+\n+next:\n+\tif (dest_bg)\n+\t\tbtrfs_put_block_group(dest_bg);\n+\n+\tif (made_reservation)\n+\t\tbtrfs_dec_block_group_reservations(fs_info, new_addr);\n+\n+\tmutex_unlock(&fs_info->remap_mutex);\n+\n+\tif (src_bg->identity_remap_count == 0) {\n+\t\tbool mark_fully_remapped = false;\n+\n+\t\tspin_lock(&src_bg->lock);\n+\n+\t\tif (!test_bit(BLOCK_GROUP_FLAG_FULLY_REMAPPED, &src_bg->runtime_flags)) {\n+\t\t\tmark_fully_remapped = true;\n+\t\t\tset_bit(BLOCK_GROUP_FLAG_FULLY_REMAPPED,\n+\t\t\t\t&src_bg->runtime_flags);\n+\t\t}\n+\n+\t\tspin_unlock(&src_bg->lock);\n+\n+\t\tif (mark_fully_remapped)\n+\t\t\tbtrfs_mark_bg_fully_remapped(src_bg, trans);\n+\t}\n+\n+\tret = btrfs_end_transaction(trans);\n+\tif (ret)\n+\t\treturn ret;\n+\n+\tif (no_more)\n+\t\treturn 1;\n+\n+\t*last_start = start;\n+\n+\treturn 0;\n+\n+fail:\n+\tif (dest_bg)\n+\t\tbtrfs_put_block_group(dest_bg);\n+\n+\tbtrfs_free_reserved_extent(fs_info, new_addr, length, 0);\n+\n+\tmutex_unlock(&fs_info->remap_mutex);\n+\tbtrfs_end_transaction(trans);\n+\n+\treturn ret;\n+}\n+\n+static int do_remap_reloc(struct btrfs_fs_info *fs_info,\n+\t\t\t  struct btrfs_path *path, struct btrfs_block_group *bg)\n+{\n+\tu64 last_start;\n+\tint ret;\n+\n+\tlast_start = bg->start;\n+\n+\twhile (true) {\n+\t\tret = do_remap_reloc_trans(fs_info, bg, path, &last_start);\n+\t\tif (ret) {\n+\t\t\tif (ret == 1)\n+\t\t\t\tret = 0;\n+\t\t\tbreak;\n+\t\t}\n+\t}\n+\n+\treturn ret;\n+}\n+\n int btrfs_translate_remap(struct btrfs_fs_info *fs_info, u64 *logical,\n \t\t\t  u64 *length)\n {\n@@ -5121,6 +5450,14 @@ int btrfs_relocate_block_group(struct btrfs_fs_info *fs_info, u64 group_start,\n \t\t}\n \n \t\tret = start_block_group_remapping(fs_info, path, bg);\n+\t\tif (ret)\n+\t\t\tgoto out;\n+\n+\t\tret = do_remap_reloc(fs_info, path, rc->block_group);\n+\t\tif (ret)\n+\t\t\tgoto out;\n+\n+\t\tbtrfs_delete_unused_bgs(fs_info);\n \t} else {\n \t\tret = do_nonremap_reloc(fs_info, verbose, rc);\n \t}\n-- \n2.51.2\n\n\n\n---\n\nThere is the following potential problem with the remap tree and delayed refs:\n\n* Remapped extent freed in a delayed ref, which removes an entry from the\n  remap tree\n* Remap tree now small enough to fit in a single leaf\n* Corruption as we now have a level-0 block with a level-1 metadata item\n  in the extent tree\n\nOne solution to this would be to rework the remap tree code so that it operates\nvia delayed refs. But as we're hoping to remove cow-only metadata items in the\nfuture anyway, change things so that the remap tree doesn't have any entries in\nthe extent tree. This also has the benefit of reducing write amplification.\n\nWe also make it so that the clear_cache mount option is a no-op, as with the\nextent tree v2, as the free-space tree can no longer be recreated from the\nextent tree.\n\nFinally disable relocating the remap tree itself, which is added back in\na later patch. As it is we would get corruption as the traditional\nrelocation method walks the extent tree, and we're removing its metadata\nitems.\n\nSigned-off-by: Mark Harmstone <mark@harmstone.com>\nReviewed-by: Boris Burkov <boris@bur.io>\n---\n fs/btrfs/disk-io.c     |  3 +++\n fs/btrfs/extent-tree.c | 31 ++++++++++++++++++++++++++++++-\n fs/btrfs/volumes.c     |  3 +++\n 3 files changed, 36 insertions(+), 1 deletion(-)\n\ndiff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c\nindex cbfb7127b528..c36367f9017f 100644\n--- a/fs/btrfs/disk-io.c\n+++ b/fs/btrfs/disk-io.c\n@@ -3007,6 +3007,9 @@ int btrfs_start_pre_rw_mount(struct btrfs_fs_info *fs_info)\n \t\tif (btrfs_fs_incompat(fs_info, EXTENT_TREE_V2))\n \t\t\tbtrfs_warn(fs_info,\n \t\t\t\t   \"'clear_cache' option is ignored with extent tree v2\");\n+\t\telse if (btrfs_fs_incompat(fs_info, REMAP_TREE))\n+\t\t\tbtrfs_warn(fs_info,\n+\t\t\t\t   \"'clear_cache' option is ignored with remap tree\");\n \t\telse\n \t\t\trebuild_free_space_tree = true;\n \t} else if (btrfs_fs_compat_ro(fs_info, FREE_SPACE_TREE) &&\ndiff --git a/fs/btrfs/extent-tree.c b/fs/btrfs/extent-tree.c\nindex 1dcd69fe97ed..43473a6d91d7 100644\n--- a/fs/btrfs/extent-tree.c\n+++ b/fs/btrfs/extent-tree.c\n@@ -1553,6 +1553,28 @@ static void free_head_ref_squota_rsv(struct btrfs_fs_info *fs_info,\n \t\t\t\t  BTRFS_QGROUP_RSV_DATA);\n }\n \n+static int drop_remap_tree_ref(struct btrfs_trans_handle *trans,\n+\t\t\t       const struct btrfs_delayed_ref_node *node)\n+{\n+\tu64 bytenr = node->bytenr;\n+\tu64 num_bytes = node->num_bytes;\n+\tint ret;\n+\n+\tret = btrfs_add_to_free_space_tree(trans, bytenr, num_bytes);\n+\tif (unlikely(ret)) {\n+\t\tbtrfs_abort_transaction(trans, ret);\n+\t\treturn ret;\n+\t}\n+\n+\tret = btrfs_update_block_group(trans, bytenr, num_bytes, false);\n+\tif (unlikely(ret)) {\n+\t\tbtrfs_abort_transaction(trans, ret);\n+\t\treturn ret;\n+\t}\n+\n+\treturn 0;\n+}\n+\n static int run_delayed_data_ref(struct btrfs_trans_handle *trans,\n \t\t\t\tstruct btrfs_delayed_ref_head *href,\n \t\t\t\tconst struct btrfs_delayed_ref_node *node,\n@@ -1747,7 +1769,10 @@ static int run_delayed_tree_ref(struct btrfs_trans_handle *trans,\n \t} else if (node->action == BTRFS_ADD_DELAYED_REF) {\n \t\tret = __btrfs_inc_extent_ref(trans, node, extent_op);\n \t} else if (node->action == BTRFS_DROP_DELAYED_REF) {\n-\t\tret = __btrfs_free_extent(trans, href, node, extent_op);\n+\t\tif (node->ref_root == BTRFS_REMAP_TREE_OBJECTID)\n+\t\t\tret = drop_remap_tree_ref(trans, node);\n+\t\telse\n+\t\t\tret = __btrfs_free_extent(trans, href, node, extent_op);\n \t} else {\n \t\tBUG();\n \t}\n@@ -4886,6 +4911,9 @@ static int alloc_reserved_tree_block(struct btrfs_trans_handle *trans,\n \tint level = btrfs_delayed_ref_owner(node);\n \tbool skinny_metadata = btrfs_fs_incompat(fs_info, SKINNY_METADATA);\n \n+\tif (unlikely(node->ref_root == BTRFS_REMAP_TREE_OBJECTID))\n+\t\tgoto skip;\n+\n \textent_key.objectid = node->bytenr;\n \tif (skinny_metadata) {\n \t\t/* The owner of a tree block is the level. */\n@@ -4938,6 +4966,7 @@ static int alloc_reserved_tree_block(struct btrfs_trans_handle *trans,\n \n \tbtrfs_free_path(path);\n \n+skip:\n \treturn alloc_reserved_extent(trans, node->bytenr, fs_info->nodesize);\n }\n \ndiff --git a/fs/btrfs/volumes.c b/fs/btrfs/volumes.c\nindex 070efac46a81..d6060e0e2144 100644\n--- a/fs/btrfs/volumes.c\n+++ b/fs/btrfs/volumes.c\n@@ -3970,6 +3970,9 @@ static bool should_balance_chunk(struct extent_buffer *leaf, struct btrfs_chunk\n \tstruct btrfs_balance_args *bargs = NULL;\n \tu64 chunk_type = btrfs_chunk_type(leaf, chunk);\n \n+\tif (chunk_type & BTRFS_BLOCK_GROUP_METADATA_REMAP)\n+\t\treturn false;\n+\n \t/* type filter */\n \tif (!((chunk_type & BTRFS_BLOCK_GROUP_TYPE_MASK) &\n \t      (bctl->flags & BTRFS_BALANCE_TYPE_MASK))) {\n-- \n2.51.2\n\n\n\n---\n\nHandle the case where we free an extent from a block group that has the\nREMAPPED flag set. Because the remap tree is orthogonal to the extent\ntree, for data this may be within any number of identity remaps or\nactual remaps. If we're freeing a metadata node, this will be wholly\ninside one or the other.\n\nbtrfs_remove_extent_from_remap_tree() searches the remap tree for the\nremaps that cover the range in question, then calls\nremove_range_from_remap_tree() for each one, to punch a hole in the\nremap and adjust the free-space tree.\n\nFor an identity remap, remove_range_from_remap_tree() will adjust the\nblock group's `identity_remap_count` if this changes. If it reaches\nzero we mark the block group as fully remapped.\n\nFor an identity remap, remove_range_from_remap_tree() will adjust the\nblock group's `identity_remap_count` if this changes. If it reaches\nzero we mark the block group as fully remapped.\n\nFully remapped block groups have their chunk stripes removed and their\ndevice extents freed, which makes the disk space available again to the\nchunk allocator. This happens asynchronously: in the cleaner thread for\nsync discard and nodiscard, and (in a later patch) in the discard worker\nfor async discard.\n\nSigned-off-by: Mark Harmstone <mark@harmstone.com>\nReviewed-by: Boris Burkov <boris@bur.io>\n---\n fs/btrfs/block-group.c |  98 ++++++---\n fs/btrfs/block-group.h |   4 +\n fs/btrfs/disk-io.c     |   6 +\n fs/btrfs/extent-tree.c |  98 ++++++++-\n fs/btrfs/extent-tree.h |   2 +\n fs/btrfs/fs.h          |   4 +-\n fs/btrfs/relocation.c  | 453 +++++++++++++++++++++++++++++++++++++++++\n fs/btrfs/relocation.h  |   5 +\n fs/btrfs/volumes.c     |  57 ++++--\n fs/btrfs/volumes.h     |   6 +\n 10 files changed, 678 insertions(+), 55 deletions(-)\n\ndiff --git a/fs/btrfs/block-group.c b/fs/btrfs/block-group.c\nindex 4962d17a175e..0143b0290a72 100644\n--- a/fs/btrfs/block-group.c\n+++ b/fs/btrfs/block-group.c\n@@ -1067,6 +1067,29 @@ static int remove_block_group_item(struct btrfs_trans_handle *trans,\n \treturn btrfs_del_item(trans, root, path);\n }\n \n+void btrfs_remove_bg_from_sinfo(struct btrfs_block_group *bg)\n+{\n+\tint factor = btrfs_bg_type_to_factor(bg->flags);\n+\n+\tspin_lock(&bg->space_info->lock);\n+\n+\tif (btrfs_test_opt(bg->fs_info, ENOSPC_DEBUG)) {\n+\t\tWARN_ON(bg->space_info->total_bytes < bg->length);\n+\t\tWARN_ON(bg->space_info->bytes_readonly\n+\t\t\t< bg->length - bg->zone_unusable);\n+\t\tWARN_ON(bg->space_info->bytes_zone_unusable\n+\t\t\t< bg->zone_unusable);\n+\t\tWARN_ON(bg->space_info->disk_total < bg->length * factor);\n+\t}\n+\tbg->space_info->total_bytes -= bg->length;\n+\tbg->space_info->bytes_readonly -= (bg->length - bg->zone_unusable);\n+\tbtrfs_space_info_update_bytes_zone_unusable(bg->space_info,\n+\t\t\t\t\t\t    -bg->zone_unusable);\n+\tbg->space_info->disk_total -= bg->length * factor;\n+\n+\tspin_unlock(&bg->space_info->lock);\n+}\n+\n int btrfs_remove_block_group(struct btrfs_trans_handle *trans,\n \t\t\t     struct btrfs_chunk_map *map)\n {\n@@ -1078,7 +1101,6 @@ int btrfs_remove_block_group(struct btrfs_trans_handle *trans,\n \tstruct kobject *kobj = NULL;\n \tint ret;\n \tint index;\n-\tint factor;\n \tstruct btrfs_caching_control *caching_ctl = NULL;\n \tbool remove_map;\n \tbool remove_rsv = false;\n@@ -1087,7 +1109,7 @@ int btrfs_remove_block_group(struct btrfs_trans_handle *trans,\n \tif (!block_group)\n \t\treturn -ENOENT;\n \n-\tBUG_ON(!block_group->ro);\n+\tBUG_ON(!block_group->ro && !(block_group->flags & BTRFS_BLOCK_GROUP_REMAPPED));\n \n \ttrace_btrfs_remove_block_group(block_group);\n \t/*\n@@ -1099,7 +1121,6 @@ int btrfs_remove_block_group(struct btrfs_trans_handle *trans,\n \t\t\t\t  block_group->length);\n \n \tindex = btrfs_bg_flags_to_raid_index(block_group->flags);\n-\tfactor = btrfs_bg_type_to_factor(block_group->flags);\n \n \t/* make sure this block group isn't part of an allocation cluster */\n \tcluster = &fs_info->data_alloc_cluster;\n@@ -1223,26 +1244,11 @@ int btrfs_remove_block_group(struct btrfs_trans_handle *trans,\n \n \tspin_lock(&block_group->space_info->lock);\n \tlist_del_init(&block_group->ro_list);\n-\n-\tif (btrfs_test_opt(fs_info, ENOSPC_DEBUG)) {\n-\t\tWARN_ON(block_group->space_info->total_bytes\n-\t\t\t< block_group->length);\n-\t\tWARN_ON(block_group->space_info->bytes_readonly\n-\t\t\t< block_group->length - block_group->zone_unusable);\n-\t\tWARN_ON(block_group->space_info->bytes_zone_unusable\n-\t\t\t< block_group->zone_unusable);\n-\t\tWARN_ON(block_group->space_info->disk_total\n-\t\t\t< block_group->length * factor);\n-\t}\n-\tblock_group->space_info->total_bytes -= block_group->length;\n-\tblock_group->space_info->bytes_readonly -=\n-\t\t(block_group->length - block_group->zone_unusable);\n-\tbtrfs_space_info_update_bytes_zone_unusable(block_group->space_info,\n-\t\t\t\t\t\t    -block_group->zone_unusable);\n-\tblock_group->space_info->disk_total -= block_group->length * factor;\n-\n \tspin_unlock(&block_group->space_info->lock);\n \n+\tif (!(block_group->flags & BTRFS_BLOCK_GROUP_REMAPPED))\n+\t\tbtrfs_remove_bg_from_sinfo(block_group);\n+\n \t/*\n \t * Remove the free space for the block group from the free space tree\n \t * and the block group's item from the extent tree before marking the\n@@ -1576,8 +1582,10 @@ void btrfs_delete_unused_bgs(struct btrfs_fs_info *fs_info)\n \n \t\tspin_lock(&space_info->lock);\n \t\tspin_lock(&block_group->lock);\n-\t\tif (btrfs_is_block_group_used(block_group) || block_group->ro ||\n-\t\t    list_is_singular(&block_group->list)) {\n+\t\tif (btrfs_is_block_group_used(block_group) ||\n+\t\t    (block_group->ro && !(block_group->flags & BTRFS_BLOCK_GROUP_REMAPPED)) ||\n+\t\t    list_is_singular(&block_group->list) ||\n+\t\t    test_bit(BLOCK_GROUP_FLAG_FULLY_REMAPPED, &block_group->runtime_flags)) {\n \t\t\t/*\n \t\t\t * We want to bail if we made new allocations or have\n \t\t\t * outstanding allocations in this block group.  We do\n@@ -1618,9 +1626,10 @@ void btrfs_delete_unused_bgs(struct btrfs_fs_info *fs_info)\n \t\t * needing to allocate extents from the block group.\n \t\t */\n \t\tused = btrfs_space_info_used(space_info, true);\n-\t\tif ((space_info->total_bytes - block_group->length < used &&\n-\t\t     block_group->zone_unusable < block_group->length) ||\n-\t\t    has_unwritten_metadata(block_group)) {\n+\t\tif (((space_info->total_bytes - block_group->length < used &&\n+\t\t      block_group->zone_unusable < block_group->length) ||\n+\t\t     has_unwritten_metadata(block_group)) &&\n+\t\t    !(block_group->flags & BTRFS_BLOCK_GROUP_REMAPPED)) {\n \t\t\t/*\n \t\t\t * Add a reference for the list, compensate for the ref\n \t\t\t * drop under the \"next\" label for the\n@@ -1785,6 +1794,12 @@ void btrfs_mark_bg_unused(struct btrfs_block_group *bg)\n \t\tbtrfs_get_block_group(bg);\n \t\ttrace_btrfs_add_unused_block_group(bg);\n \t\tlist_add_tail(&bg->bg_list, &fs_info->unused_bgs);\n+\t} else if (bg->flags & BTRFS_BLOCK_GROUP_REMAPPED &&\n+\t\t   bg->identity_remap_count == 0) {\n+\t\t/*\n+\t\t * Leave fully remapped block groups on the\n+\t\t * fully_remapped_bgs list.\n+\t\t */\n \t} else if (!test_bit(BLOCK_GROUP_FLAG_NEW, &bg->runtime_flags)) {\n \t\t/* Pull out the block group from the reclaim_bgs list. */\n \t\ttrace_btrfs_add_unused_block_group(bg);\n@@ -4594,6 +4609,14 @@ int btrfs_free_block_groups(struct btrfs_fs_info *info)\n \t\tlist_del_init(&block_group->bg_list);\n \t\tbtrfs_put_block_group(block_group);\n \t}\n+\n+\twhile (!list_empty(&info->fully_remapped_bgs)) {\n+\t\tblock_group = list_first_entry(&info->fully_remapped_bgs,\n+\t\t\t\t\t       struct btrfs_block_group,\n+\t\t\t\t\t       bg_list);\n+\t\tlist_del_init(&block_group->bg_list);\n+\t\tbtrfs_put_block_group(block_group);\n+\t}\n \tspin_unlock(&info->unused_bgs_lock);\n \n \tspin_lock(&info->zone_active_bgs_lock);\n@@ -4781,3 +4804,26 @@ bool btrfs_block_group_should_use_size_class(const struct btrfs_block_group *bg)\n \t\treturn false;\n \treturn true;\n }\n+\n+void btrfs_mark_bg_fully_remapped(struct btrfs_block_group *bg,\n+\t\t\t\t  struct btrfs_trans_handle *trans)\n+{\n+\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n+\n+\tspin_lock(&fs_info->unused_bgs_lock);\n+\n+\t/*\n+\t * The block group might already be on the unused_bgs list, remove it\n+\t * if it is. It'll get readded after the async discard worker finishes,\n+\t * or in btrfs_handle_fully_remapped_bgs() if we're not using async\n+\t * discard.\n+\t */\n+\tif (!list_empty(&bg->bg_list))\n+\t\tlist_del(&bg->bg_list);\n+\telse\n+\t\tbtrfs_get_block_group(bg);\n+\n+\tlist_add_tail(&bg->bg_list, &fs_info->fully_remapped_bgs);\n+\n+\tspin_unlock(&fs_info->unused_bgs_lock);\n+}\ndiff --git a/fs/btrfs/block-group.h b/fs/btrfs/block-group.h\nindex 4cee3448ded3..436d51a707a9 100644\n--- a/fs/btrfs/block-group.h\n+++ b/fs/btrfs/block-group.h\n@@ -92,6 +92,7 @@ enum btrfs_block_group_flags {\n \t * transaction.\n \t */\n \tBLOCK_GROUP_FLAG_NEW,\n+\tBLOCK_GROUP_FLAG_FULLY_REMAPPED,\n };\n \n enum btrfs_caching_type {\n@@ -336,6 +337,7 @@ int btrfs_add_new_free_space(struct btrfs_block_group *block_group,\n struct btrfs_trans_handle *btrfs_start_trans_remove_block_group(\n \t\t\t\tstruct btrfs_fs_info *fs_info,\n \t\t\t\tconst u64 chunk_offset);\n+void btrfs_remove_bg_from_sinfo(struct btrfs_block_group *bg);\n int btrfs_remove_block_group(struct btrfs_trans_handle *trans,\n \t\t\t     struct btrfs_chunk_map *map);\n void btrfs_delete_unused_bgs(struct btrfs_fs_info *fs_info);\n@@ -407,5 +409,7 @@ int btrfs_use_block_group_size_class(struct btrfs_block_group *bg,\n \t\t\t\t     enum btrfs_block_group_size_class size_class,\n \t\t\t\t     bool force_wrong_size_class);\n bool btrfs_block_group_should_use_size_class(const struct btrfs_block_group *bg);\n+void btrfs_mark_bg_fully_remapped(struct btrfs_block_group *bg,\n+\t\t\t\t  struct btrfs_trans_handle *trans);\n \n #endif /* BTRFS_BLOCK_GROUP_H */\ndiff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c\nindex b03654ee91f5..ba500e3bf0d8 100644\n--- a/fs/btrfs/disk-io.c\n+++ b/fs/btrfs/disk-io.c\n@@ -1495,6 +1495,10 @@ static int cleaner_kthread(void *arg)\n \t\t */\n \t\tbtrfs_run_defrag_inodes(fs_info);\n \n+\t\tif (btrfs_fs_incompat(fs_info, REMAP_TREE) &&\n+\t\t    !btrfs_test_opt(fs_info, DISCARD_ASYNC))\n+\t\t\tbtrfs_handle_fully_remapped_bgs(fs_info);\n+\n \t\t/*\n \t\t * Acquires fs_info->reclaim_bgs_lock to avoid racing\n \t\t * with relocation (btrfs_relocate_chunk) and relocation\n@@ -2835,6 +2839,7 @@ void btrfs_init_fs_info(struct btrfs_fs_info *fs_info)\n \tINIT_LIST_HEAD(&fs_info->tree_mod_seq_list);\n \tINIT_LIST_HEAD(&fs_info->unused_bgs);\n \tINIT_LIST_HEAD(&fs_info->reclaim_bgs);\n+\tINIT_LIST_HEAD(&fs_info->fully_remapped_bgs);\n \tINIT_LIST_HEAD(&fs_info->zone_active_bgs);\n #ifdef CONFIG_BTRFS_DEBUG\n \tINIT_LIST_HEAD(&fs_info->allocated_roots);\n@@ -2890,6 +2895,7 @@ void btrfs_init_fs_info(struct btrfs_fs_info *fs_info)\n \tmutex_init(&fs_info->chunk_mutex);\n \tmutex_init(&fs_info->transaction_kthread_mutex);\n \tmutex_init(&fs_info->cleaner_mutex);\n+\tmutex_init(&fs_info->remap_mutex);\n \tmutex_init(&fs_info->ro_block_group_mutex);\n \tinit_rwsem(&fs_info->commit_root_sem);\n \tinit_rwsem(&fs_info->cleanup_work_sem);\ndiff --git a/fs/btrfs/extent-tree.c b/fs/btrfs/extent-tree.c\nindex 3868a295be62..fef85ade017c 100644\n--- a/fs/btrfs/extent-tree.c\n+++ b/fs/btrfs/extent-tree.c\n@@ -41,6 +41,7 @@\n #include \"tree-checker.h\"\n #include \"raid-stripe-tree.h\"\n #include \"delayed-inode.h\"\n+#include \"relocation.h\"\n \n #undef SCRAMBLE_DELAYED_REFS\n \n@@ -2844,6 +2845,73 @@ static int unpin_extent_range(struct btrfs_fs_info *fs_info,\n \treturn 0;\n }\n \n+/*\n+ * Complete the remapping of a block group by removing its chunk stripes and\n+ * device extents, and adding it to the unused list if there's no longer any\n+ * extents nominally within it.\n+ */\n+int btrfs_complete_bg_remapping(struct btrfs_block_group *bg)\n+{\n+\tstruct btrfs_fs_info *fs_info = bg->fs_info;\n+\tstruct btrfs_chunk_map *map;\n+\tint ret;\n+\n+\tmap = btrfs_get_chunk_map(fs_info, bg->start, 1);\n+\tif (IS_ERR(map))\n+\t\treturn PTR_ERR(map);\n+\n+\tret = btrfs_last_identity_remap_gone(map, bg);\n+\tif (ret) {\n+\t\tbtrfs_free_chunk_map(map);\n+\t\treturn ret;\n+\t}\n+\n+\t/*\n+\t * Set num_stripes to 0, so that btrfs_remove_dev_extents()\n+\t * won't run a second time.\n+\t */\n+\tmap->num_stripes = 0;\n+\n+\tbtrfs_free_chunk_map(map);\n+\n+\tif (bg->used == 0) {\n+\t\tspin_lock(&fs_info->unused_bgs_lock);\n+\t\tif (!list_empty(&bg->bg_list)) {\n+\t\t\tlist_del_init(&bg->bg_list);\n+\t\t\tbtrfs_put_block_group(bg);\n+\t\t}\n+\t\tspin_unlock(&fs_info->unused_bgs_lock);\n+\n+\t\tbtrfs_mark_bg_unused(bg);\n+\t}\n+\n+\treturn 0;\n+}\n+\n+void btrfs_handle_fully_remapped_bgs(struct btrfs_fs_info *fs_info)\n+{\n+\tstruct btrfs_block_group *bg;\n+\tint ret;\n+\n+\tspin_lock(&fs_info->unused_bgs_lock);\n+\twhile (!list_empty(&fs_info->fully_remapped_bgs)) {\n+\t\tbg = list_first_entry(&fs_info->fully_remapped_bgs,\n+\t\t\t\t      struct btrfs_block_group, bg_list);\n+\t\tlist_del_init(&bg->bg_list);\n+\t\tspin_unlock(&fs_info->unused_bgs_lock);\n+\n+\t\tret = btrfs_complete_bg_remapping(bg);\n+\t\tif (ret) {\n+\t\t\tbtrfs_put_block_group(bg);\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tbtrfs_put_block_group(bg);\n+\t\tspin_lock(&fs_info->unused_bgs_lock);\n+\t}\n+\tspin_unlock(&fs_info->unused_bgs_lock);\n+}\n+\n int btrfs_finish_extent_commit(struct btrfs_trans_handle *trans)\n {\n \tstruct btrfs_fs_info *fs_info = trans->fs_info;\n@@ -2996,11 +3064,23 @@ u64 btrfs_get_extent_owner_root(struct btrfs_fs_info *fs_info,\n }\n \n static int do_free_extent_accounting(struct btrfs_trans_handle *trans,\n-\t\t\t\t     u64 bytenr, struct btrfs_squota_delta *delta)\n+\t\t\t\t     u64 bytenr, struct btrfs_squota_delta *delta,\n+\t\t\t\t     struct btrfs_path *path)\n {\n \tint ret;\n+\tbool remapped = false;\n \tu64 num_bytes = delta->num_bytes;\n \n+\t/* Returns 1 on success and 0 on no-op. */\n+\tret = btrfs_remove_extent_from_remap_tree(trans, path, bytenr,\n+\t\t\t\t\t\t  num_bytes);\n+\tif (unlikely(ret < 0)) {\n+\t\tbtrfs_abort_transaction(trans, ret);\n+\t\treturn ret;\n+\t} else if (ret == 1) {\n+\t\tremapped = true;\n+\t}\n+\n \tif (delta->is_data) {\n \t\tstruct btrfs_root *csum_root;\n \n@@ -3024,10 +3104,16 @@ static int do_free_extent_accounting(struct btrfs_trans_handle *trans,\n \t\treturn ret;\n \t}\n \n-\tret = btrfs_add_to_free_space_tree(trans, bytenr, num_bytes);\n-\tif (unlikely(ret)) {\n-\t\tbtrfs_abort_transaction(trans, ret);\n-\t\treturn ret;\n+\t/*\n+\t * If remapped, FST has already been taken care of in\n+\t * remove_range_from_remap_tree().\n+\t */\n+\tif (!remapped) {\n+\t\tret = btrfs_add_to_free_space_tree(trans, bytenr, num_bytes);\n+\t\tif (unlikely(ret)) {\n+\t\t\tbtrfs_abort_transaction(trans, ret);\n+\t\t\treturn ret;\n+\t\t}\n \t}\n \n \tret = btrfs_update_block_group(trans, bytenr, num_bytes, false);\n@@ -3386,7 +3472,7 @@ static int __btrfs_free_extent(struct btrfs_trans_handle *trans,\n \t\t}\n \t\tbtrfs_release_path(path);\n \n-\t\tret = do_free_extent_accounting(trans, bytenr, &delta);\n+\t\tret = do_free_extent_accounting(trans, bytenr, &delta, path);\n \t}\n \tbtrfs_release_path(path);\n \ndiff --git a/fs/btrfs/extent-tree.h b/fs/btrfs/extent-tree.h\nindex 71bb8109c969..d7b6aeb63656 100644\n--- a/fs/btrfs/extent-tree.h\n+++ b/fs/btrfs/extent-tree.h\n@@ -163,5 +163,7 @@ void btrfs_error_unpin_extent_range(struct btrfs_fs_info *fs_info, u64 start, u6\n int btrfs_discard_extent(struct btrfs_fs_info *fs_info, u64 bytenr,\n \t\t\t u64 num_bytes, u64 *actual_bytes);\n int btrfs_trim_fs(struct btrfs_fs_info *fs_info, struct fstrim_range *range);\n+void btrfs_handle_fully_remapped_bgs(struct btrfs_fs_info *fs_info);\n+int btrfs_complete_bg_remapping(struct btrfs_block_group *bg);\n \n #endif\ndiff --git a/fs/btrfs/fs.h b/fs/btrfs/fs.h\nindex af11f2ce310a..b59bda3f8e62 100644\n--- a/fs/btrfs/fs.h\n+++ b/fs/btrfs/fs.h\n@@ -579,6 +579,7 @@ struct btrfs_fs_info {\n \tstruct mutex transaction_kthread_mutex;\n \tstruct mutex cleaner_mutex;\n \tstruct mutex chunk_mutex;\n+\tstruct mutex remap_mutex;\n \n \t/*\n \t * This is taken to make sure we don't set block groups ro after the\n@@ -832,10 +833,11 @@ struct btrfs_fs_info {\n \tstruct list_head reclaim_bgs;\n \tint bg_reclaim_threshold;\n \n-\t/* Protects the lists unused_bgs and reclaim_bgs. */\n+\t/* Protects the lists unused_bgs, reclaim_bgs, and fully_remapped_bgs. */\n \tspinlock_t unused_bgs_lock;\n \t/* Protected by unused_bgs_lock. */\n \tstruct list_head unused_bgs;\n+\tstruct list_head fully_remapped_bgs;\n \tstruct mutex unused_bg_unpin_mutex;\n \t/* Protect block groups that are going to be deleted */\n \tstruct mutex reclaim_bgs_lock;\ndiff --git a/fs/btrfs/relocation.c b/fs/btrfs/relocation.c\nindex 525f45c668f6..e47234d5a156 100644\n--- a/fs/btrfs/relocation.c\n+++ b/fs/btrfs/relocation.c\n@@ -37,6 +37,7 @@\n #include \"super.h\"\n #include \"tree-checker.h\"\n #include \"raid-stripe-tree.h\"\n+#include \"free-space-tree.h\"\n \n /*\n  * Relocation overview\n@@ -3859,6 +3860,184 @@ static const char *stage_to_string(enum reloc_stage stage)\n \treturn \"unknown\";\n }\n \n+static void adjust_block_group_remap_bytes(struct btrfs_trans_handle *trans,\n+\t\t\t\t\t   struct btrfs_block_group *bg,\n+\t\t\t\t\t   s64 diff)\n+{\n+\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n+\tbool bg_already_dirty = true, mark_unused = false;\n+\n+\tspin_lock(&bg->lock);\n+\n+\tbg->remap_bytes += diff;\n+\n+\tif (bg->used == 0 && bg->remap_bytes == 0)\n+\t\tmark_unused = true;\n+\n+\tspin_unlock(&bg->lock);\n+\n+\tif (mark_unused)\n+\t\tbtrfs_mark_bg_unused(bg);\n+\n+\tspin_lock(&trans->transaction->dirty_bgs_lock);\n+\tif (list_empty(&bg->dirty_list)) {\n+\t\tlist_add_tail(&bg->dirty_list, &trans->transaction->dirty_bgs);\n+\t\tbg_already_dirty = false;\n+\t\tbtrfs_get_block_group(bg);\n+\t}\n+\tspin_unlock(&trans->transaction->dirty_bgs_lock);\n+\n+\t/* Modified block groups are accounted for in the delayed_refs_rsv. */\n+\tif (!bg_already_dirty)\n+\t\tbtrfs_inc_delayed_refs_rsv_bg_updates(fs_info);\n+}\n+\n+static int remove_chunk_stripes(struct btrfs_trans_handle *trans,\n+\t\t\t\tstruct btrfs_chunk_map *chunk_map,\n+\t\t\t\tstruct btrfs_path *path)\n+{\n+\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n+\tstruct btrfs_key key;\n+\tstruct extent_buffer *leaf;\n+\tstruct btrfs_chunk *chunk;\n+\tint ret;\n+\n+\tkey.objectid = BTRFS_FIRST_CHUNK_TREE_OBJECTID;\n+\tkey.type = BTRFS_CHUNK_ITEM_KEY;\n+\tkey.offset = chunk_map->start;\n+\n+\tbtrfs_reserve_chunk_metadata(trans, false);\n+\n+\tret = btrfs_search_slot(trans, fs_info->chunk_root, &key, path,\n+\t\t\t\t0, 1);\n+\tif (ret) {\n+\t\tif (ret == 1) {\n+\t\t\tbtrfs_release_path(path);\n+\t\t\tret = -ENOENT;\n+\t\t}\n+\t\tbtrfs_trans_release_chunk_metadata(trans);\n+\t\treturn ret;\n+\t}\n+\n+\tleaf = path->nodes[0];\n+\n+\tchunk = btrfs_item_ptr(leaf, path->slots[0], struct btrfs_chunk);\n+\tbtrfs_set_chunk_num_stripes(leaf, chunk, 0);\n+\tbtrfs_set_chunk_sub_stripes(leaf, chunk, 0);\n+\n+\tbtrfs_truncate_item(trans, path, offsetof(struct btrfs_chunk, stripe),\n+\t\t\t    1);\n+\n+\tbtrfs_mark_buffer_dirty(trans, leaf);\n+\n+\tbtrfs_release_path(path);\n+\tbtrfs_trans_release_chunk_metadata(trans);\n+\n+\treturn 0;\n+}\n+\n+int btrfs_last_identity_remap_gone(struct btrfs_chunk_map *chunk_map,\n+\t\t\t\t   struct btrfs_block_group *bg)\n+{\n+\tstruct btrfs_fs_info *fs_info = bg->fs_info;\n+\tstruct btrfs_trans_handle *trans;\n+\tint ret;\n+\tunsigned int num_items;\n+\tBTRFS_PATH_AUTO_FREE(path);\n+\n+\tpath = btrfs_alloc_path();\n+\tif (!path)\n+\t\treturn -ENOMEM;\n+\n+\t/*\n+\t * One item for each entry we're removing in the dev extents tree, and\n+\t * another for each device. DUP chunks are all on one device,\n+\t * everything else has one device per stripe.\n+\t */\n+\tif (bg->flags & BTRFS_BLOCK_GROUP_DUP)\n+\t\tnum_items = chunk_map->num_stripes + 1;\n+\telse\n+\t\tnum_items = 2 * chunk_map->num_stripes;\n+\n+\ttrans = btrfs_start_transaction_fallback_global_rsv(fs_info->tree_root,\n+\t\t\t\t\t\t\t    num_items);\n+\tif (IS_ERR(trans))\n+\t\treturn PTR_ERR(trans);\n+\n+\tret = btrfs_remove_dev_extents(trans, chunk_map);\n+\tif (unlikely(ret)) {\n+\t\tbtrfs_abort_transaction(trans, ret);\n+\t\treturn ret;\n+\t}\n+\n+\tmutex_lock(&trans->fs_info->chunk_mutex);\n+\n+\tfor (unsigned int i = 0; i < chunk_map->num_stripes; i++) {\n+\t\tret = btrfs_update_device(trans, chunk_map->stripes[i].dev);\n+\t\tif (unlikely(ret)) {\n+\t\t\tmutex_unlock(&trans->fs_info->chunk_mutex);\n+\t\t\tbtrfs_abort_transaction(trans, ret);\n+\t\t\treturn ret;\n+\t\t}\n+\t}\n+\n+\tmutex_unlock(&trans->fs_info->chunk_mutex);\n+\n+\twrite_lock(&trans->fs_info->mapping_tree_lock);\n+\tbtrfs_chunk_map_device_clear_bits(chunk_map, CHUNK_ALLOCATED);\n+\twrite_unlock(&trans->fs_info->mapping_tree_lock);\n+\n+\tbtrfs_remove_bg_from_sinfo(bg);\n+\n+\tret = remove_chunk_stripes(trans, chunk_map, path);\n+\tif (unlikely(ret)) {\n+\t\tbtrfs_abort_transaction(trans, ret);\n+\t\treturn ret;\n+\t}\n+\n+\tret = btrfs_commit_transaction(trans);\n+\tif (ret)\n+\t\treturn ret;\n+\n+\treturn 0;\n+}\n+\n+static void adjust_identity_remap_count(struct btrfs_trans_handle *trans,\n+\t\t\t\t        struct btrfs_block_group *bg, int delta)\n+{\n+\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n+\tbool bg_already_dirty = true, mark_fully_remapped = false;\n+\n+\tWARN_ON(delta < 0 && -delta > bg->identity_remap_count);\n+\n+\tspin_lock(&bg->lock);\n+\n+\tbg->identity_remap_count += delta;\n+\n+\tif (bg->identity_remap_count == 0 &&\n+\t    !test_bit(BLOCK_GROUP_FLAG_FULLY_REMAPPED, &bg->runtime_flags)) {\n+\t\tset_bit(BLOCK_GROUP_FLAG_FULLY_REMAPPED, &bg->runtime_flags);\n+\t\tmark_fully_remapped = true;\n+\t}\n+\n+\tspin_unlock(&bg->lock);\n+\n+\tspin_lock(&trans->transaction->dirty_bgs_lock);\n+\tif (list_empty(&bg->dirty_list)) {\n+\t\tlist_add_tail(&bg->dirty_list, &trans->transaction->dirty_bgs);\n+\t\tbg_already_dirty = false;\n+\t\tbtrfs_get_block_group(bg);\n+\t}\n+\tspin_unlock(&trans->transaction->dirty_bgs_lock);\n+\n+\t/* Modified block groups are accounted for in the delayed_refs_rsv. */\n+\tif (!bg_already_dirty)\n+\t\tbtrfs_inc_delayed_refs_rsv_bg_updates(fs_info);\n+\n+\tif (mark_fully_remapped)\n+\t\tbtrfs_mark_bg_fully_remapped(bg, trans);\n+}\n+\n int btrfs_translate_remap(struct btrfs_fs_info *fs_info, u64 *logical,\n \t\t\t  u64 *length)\n {\n@@ -4467,3 +4646,277 @@ u64 btrfs_get_reloc_bg_bytenr(const struct btrfs_fs_info *fs_info)\n \t\tlogical = fs_info->reloc_ctl->block_group->start;\n \treturn logical;\n }\n+\n+static int insert_remap_item(struct btrfs_trans_handle *trans,\n+\t\t\t     struct btrfs_path *path, u64 old_addr, u64 length,\n+\t\t\t     u64 new_addr)\n+{\n+\tint ret;\n+\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n+\tstruct btrfs_key key;\n+\tstruct btrfs_remap_item remap = { 0 };\n+\n+\tif (old_addr == new_addr) {\n+\t\t/* Add new identity remap item. */\n+\n+\t\tkey.objectid = old_addr;\n+\t\tkey.type = BTRFS_IDENTITY_REMAP_KEY;\n+\t\tkey.offset = length;\n+\n+\t\tret = btrfs_insert_empty_item(trans, fs_info->remap_root,\n+\t\t\t\t\t      path, &key, 0);\n+\t\tif (ret)\n+\t\t\treturn ret;\n+\t} else {\n+\t\t/* Add new remap item. */\n+\n+\t\tkey.objectid = old_addr;\n+\t\tkey.type = BTRFS_REMAP_KEY;\n+\t\tkey.offset = length;\n+\n+\t\tret = btrfs_insert_empty_item(trans, fs_info->remap_root,\n+\t\t\t\t\t      path, &key,\n+\t\t\t\t\t      sizeof(struct btrfs_remap_item));\n+\t\tif (ret)\n+\t\t\treturn ret;\n+\n+\t\tbtrfs_set_stack_remap_address(&remap, new_addr);\n+\n+\t\twrite_extent_buffer(path->nodes[0], &remap,\n+\t\t\tbtrfs_item_ptr_offset(path->nodes[0], path->slots[0]),\n+\t\t\tsizeof(struct btrfs_remap_item));\n+\n+\t\tbtrfs_release_path(path);\n+\n+\t\t/* Add new backref item. */\n+\n+\t\tkey.objectid = new_addr;\n+\t\tkey.type = BTRFS_REMAP_BACKREF_KEY;\n+\t\tkey.offset = length;\n+\n+\t\tret = btrfs_insert_empty_item(trans, fs_info->remap_root,\n+\t\t\t\t\t      path, &key,\n+\t\t\t\t\t      sizeof(struct btrfs_remap_item));\n+\t\tif (ret)\n+\t\t\treturn ret;\n+\n+\t\tbtrfs_set_stack_remap_address(&remap, old_addr);\n+\n+\t\twrite_extent_buffer(path->nodes[0], &remap,\n+\t\t\tbtrfs_item_ptr_offset(path->nodes[0], path->slots[0]),\n+\t\t\tsizeof(struct btrfs_remap_item));\n+\t}\n+\n+\tbtrfs_release_path(path);\n+\n+\treturn 0;\n+}\n+\n+/*\n+ * Punch a hole in the remap item or identity remap item pointed to by path,\n+ * for the range [hole_start, hole_start + hole_length).\n+ */\n+static int remove_range_from_remap_tree(struct btrfs_trans_handle *trans,\n+\t\t\t\t\tstruct btrfs_path *path,\n+\t\t\t\t\tstruct btrfs_block_group *bg,\n+\t\t\t\t\tu64 hole_start, u64 hole_length)\n+{\n+\tint ret;\n+\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n+\tstruct extent_buffer *leaf = path->nodes[0];\n+\tstruct btrfs_key key;\n+\tu64 hole_end, new_addr, remap_start, remap_length, remap_end;\n+\tu64 overlap_length;\n+\tbool is_identity_remap;\n+\tint identity_count_delta = 0;\n+\n+\thole_end = hole_start + hole_length;\n+\n+\tbtrfs_item_key_to_cpu(leaf, &key, path->slots[0]);\n+\n+\tis_identity_remap = key.type == BTRFS_IDENTITY_REMAP_KEY;\n+\n+\tremap_start = key.objectid;\n+\tremap_length = key.offset;\n+\n+\tremap_end = remap_start + remap_length;\n+\n+\tif (is_identity_remap) {\n+\t\tnew_addr = remap_start;\n+\t} else {\n+\t\tstruct btrfs_remap_item *remap_ptr;\n+\n+\t\tremap_ptr = btrfs_item_ptr(leaf, path->slots[0],\n+\t\t\t\t\t   struct btrfs_remap_item);\n+\t\tnew_addr = btrfs_remap_address(leaf, remap_ptr);\n+\t}\n+\n+\t/* Delete old item. */\n+\n+\tret = btrfs_del_item(trans, fs_info->remap_root, path);\n+\n+\tbtrfs_release_path(path);\n+\n+\tif (ret)\n+\t\treturn ret;\n+\n+\tif (is_identity_remap) {\n+\t\tidentity_count_delta = -1;\n+\t} else {\n+\t\t/* Remove backref. */\n+\n+\t\tkey.objectid = new_addr;\n+\t\tkey.type = BTRFS_REMAP_BACKREF_KEY;\n+\t\tkey.offset = remap_length;\n+\n+\t\tret = btrfs_search_slot(trans, fs_info->remap_root,\n+\t\t\t\t\t&key, path, -1, 1);\n+\t\tif (ret) {\n+\t\t\tif (ret == 1) {\n+\t\t\t\tbtrfs_release_path(path);\n+\t\t\t\tret = -ENOENT;\n+\t\t\t}\n+\t\t\treturn ret;\n+\t\t}\n+\n+\t\tret = btrfs_del_item(trans, fs_info->remap_root, path);\n+\n+\t\tbtrfs_release_path(path);\n+\n+\t\tif (ret)\n+\t\t\treturn ret;\n+\t}\n+\n+\t/* If hole_start > remap_start, re-add the start of the remap item. */\n+\tif (hole_start > remap_start) {\n+\t\tret = insert_remap_item(trans, path, remap_start,\n+\t\t\t\t\thole_start - remap_start, new_addr);\n+\t\tif (ret)\n+\t\t\treturn ret;\n+\n+\t\tif (is_identity_remap)\n+\t\t\tidentity_count_delta++;\n+\t}\n+\n+\t/* If hole_end < remap_end, re-add the end of the remap item. */\n+\tif (hole_end < remap_end) {\n+\t\tret = insert_remap_item(trans, path, hole_end,\n+\t\t\t\tremap_end - hole_end,\n+\t\t\t\thole_end - remap_start + new_addr);\n+\t\tif (ret)\n+\t\t\treturn ret;\n+\n+\t\tif (is_identity_remap)\n+\t\t\tidentity_count_delta++;\n+\t}\n+\n+\tif (identity_count_delta != 0)\n+\t\tadjust_identity_remap_count(trans, bg, identity_count_delta);\n+\n+\toverlap_length = min_t(u64, hole_end, remap_end) -\n+\t\t\t max_t(u64, hole_start, remap_start);\n+\n+\tif (!is_identity_remap) {\n+\t\tstruct btrfs_block_group *dest_bg;\n+\n+\t\tdest_bg = btrfs_lookup_block_group(fs_info, new_addr);\n+\n+\t\tadjust_block_group_remap_bytes(trans, dest_bg, -overlap_length);\n+\n+\t\tbtrfs_put_block_group(dest_bg);\n+\n+\t\tret = btrfs_add_to_free_space_tree(trans,\n+\t\t\t\t\t     hole_start - remap_start + new_addr,\n+\t\t\t\t\t     overlap_length);\n+\t\tif (ret)\n+\t\t\treturn ret;\n+\t}\n+\n+\tret = overlap_length;\n+\n+\treturn ret;\n+}\n+\n+/*\n+ * Returns 1 if remove_range_from_remap_tree() has been called successfully,\n+ * 0 if block group wasn't remapped, and a negative number on error.\n+ */\n+int btrfs_remove_extent_from_remap_tree(struct btrfs_trans_handle *trans,\n+\t\t\t\t\tstruct btrfs_path *path,\n+\t\t\t\t\tu64 bytenr, u64 num_bytes)\n+{\n+\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n+\tstruct btrfs_key key, found_key;\n+\tstruct extent_buffer *leaf;\n+\tstruct btrfs_block_group *bg;\n+\tint ret, length;\n+\n+\tif (!(btrfs_super_incompat_flags(fs_info->super_copy) &\n+\t      BTRFS_FEATURE_INCOMPAT_REMAP_TREE))\n+\t\treturn 0;\n+\n+\tbg = btrfs_lookup_block_group(fs_info, bytenr);\n+\tif (!bg)\n+\t\treturn 0;\n+\n+\tmutex_lock(&fs_info->remap_mutex);\n+\n+\tif (!(bg->flags & BTRFS_BLOCK_GROUP_REMAPPED)) {\n+\t\tmutex_unlock(&fs_info->remap_mutex);\n+\t\tbtrfs_put_block_group(bg);\n+\t\treturn 0;\n+\t}\n+\n+\tdo {\n+\t\tkey.objectid = bytenr;\n+\t\tkey.type = (u8)-1;\n+\t\tkey.offset = (u64)-1;\n+\n+\t\tret = btrfs_search_slot(trans, fs_info->remap_root, &key, path,\n+\t\t\t\t\t-1, 1);\n+\t\tif (ret < 0)\n+\t\t\tgoto end;\n+\n+\t\tleaf = path->nodes[0];\n+\n+\t\tif (path->slots[0] == 0) {\n+\t\t\tret = -ENOENT;\n+\t\t\tgoto end;\n+\t\t}\n+\n+\t\tpath->slots[0]--;\n+\n+\t\tbtrfs_item_key_to_cpu(leaf, &found_key, path->slots[0]);\n+\n+\t\tif (found_key.type != BTRFS_IDENTITY_REMAP_KEY &&\n+\t\t    found_key.type != BTRFS_REMAP_KEY) {\n+\t\t\tret = -ENOENT;\n+\t\t\tgoto end;\n+\t\t}\n+\n+\t\tif (bytenr < found_key.objectid ||\n+\t\t    bytenr >= found_key.objectid + found_key.offset) {\n+\t\t\tret = -ENOENT;\n+\t\t\tgoto end;\n+\t\t}\n+\n+\t\tlength = remove_range_from_remap_tree(trans, path, bg, bytenr,\n+\t\t\t\t\t\t      num_bytes);\n+\t\tif (length < 0) {\n+\t\t\tret = length;\n+\t\t\tgoto end;\n+\t\t}\n+\n+\t\tbytenr += length;\n+\t\tnum_bytes -= length;\n+\t} while (num_bytes > 0);\n+\n+\tret = 1;\n+\n+end:\n+\tmutex_unlock(&fs_info->remap_mutex);\n+\n+\tbtrfs_put_block_group(bg);\n+\tbtrfs_release_path(path);\n+\treturn ret;\n+}\ndiff --git a/fs/btrfs/relocation.h b/fs/btrfs/relocation.h\nindex b2ba83966650..0f4874f815db 100644\n--- a/fs/btrfs/relocation.h\n+++ b/fs/btrfs/relocation.h\n@@ -33,5 +33,10 @@ bool btrfs_should_ignore_reloc_root(const struct btrfs_root *root);\n u64 btrfs_get_reloc_bg_bytenr(const struct btrfs_fs_info *fs_info);\n int btrfs_translate_remap(struct btrfs_fs_info *fs_info, u64 *logical,\n \t\t\t  u64 *length);\n+int btrfs_remove_extent_from_remap_tree(struct btrfs_trans_handle *trans,\n+\t\t\t\t\tstruct btrfs_path *path,\n+\t\t\t\t\tu64 bytenr, u64 num_bytes);\n+int btrfs_last_identity_remap_gone(struct btrfs_chunk_map *chunk_map,\n+\t\t\t\t   struct btrfs_block_group *bg);\n \n #endif\ndiff --git a/fs/btrfs/volumes.c b/fs/btrfs/volumes.c\nindex 557ce56df800..46c5acc96725 100644\n--- a/fs/btrfs/volumes.c\n+++ b/fs/btrfs/volumes.c\n@@ -2923,8 +2923,8 @@ int btrfs_init_new_device(struct btrfs_fs_info *fs_info, const char *device_path\n \treturn ret;\n }\n \n-static noinline int btrfs_update_device(struct btrfs_trans_handle *trans,\n-\t\t\t\t\tstruct btrfs_device *device)\n+int btrfs_update_device(struct btrfs_trans_handle *trans,\n+\t\t\tstruct btrfs_device *device)\n {\n \tint ret;\n \tBTRFS_PATH_AUTO_FREE(path);\n@@ -3222,25 +3222,13 @@ static int remove_chunk_item(struct btrfs_trans_handle *trans,\n \treturn btrfs_free_chunk(trans, chunk_offset);\n }\n \n-int btrfs_remove_chunk(struct btrfs_trans_handle *trans, u64 chunk_offset)\n+int btrfs_remove_dev_extents(struct btrfs_trans_handle *trans,\n+\t\t\t     struct btrfs_chunk_map *map)\n {\n \tstruct btrfs_fs_info *fs_info = trans->fs_info;\n-\tstruct btrfs_chunk_map *map;\n+\tstruct btrfs_fs_devices *fs_devices = fs_info->fs_devices;\n \tu64 dev_extent_len = 0;\n \tint i, ret = 0;\n-\tstruct btrfs_fs_devices *fs_devices = fs_info->fs_devices;\n-\n-\tmap = btrfs_get_chunk_map(fs_info, chunk_offset, 1);\n-\tif (IS_ERR(map)) {\n-\t\t/*\n-\t\t * This is a logic error, but we don't want to just rely on the\n-\t\t * user having built with ASSERT enabled, so if ASSERT doesn't\n-\t\t * do anything we still error out.\n-\t\t */\n-\t\tDEBUG_WARN(\"errr %ld reading chunk map at offset %llu\",\n-\t\t\t   PTR_ERR(map), chunk_offset);\n-\t\treturn PTR_ERR(map);\n-\t}\n \n \t/*\n \t * First delete the device extent items from the devices btree.\n@@ -3261,7 +3249,7 @@ int btrfs_remove_chunk(struct btrfs_trans_handle *trans, u64 chunk_offset)\n \t\tif (unlikely(ret)) {\n \t\t\tmutex_unlock(&fs_devices->device_list_mutex);\n \t\t\tbtrfs_abort_transaction(trans, ret);\n-\t\t\tgoto out;\n+\t\t\treturn ret;\n \t\t}\n \n \t\tif (device->bytes_used > 0) {\n@@ -3281,6 +3269,31 @@ int btrfs_remove_chunk(struct btrfs_trans_handle *trans, u64 chunk_offset)\n \t}\n \tmutex_unlock(&fs_devices->device_list_mutex);\n \n+\treturn 0;\n+}\n+\n+int btrfs_remove_chunk(struct btrfs_trans_handle *trans, u64 chunk_offset)\n+{\n+\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n+\tstruct btrfs_chunk_map *map;\n+\tint ret;\n+\n+\tmap = btrfs_get_chunk_map(fs_info, chunk_offset, 1);\n+\tif (IS_ERR(map)) {\n+\t\t/*\n+\t\t * This is a logic error, but we don't want to just rely on the\n+\t\t * user having built with ASSERT enabled, so if ASSERT doesn't\n+\t\t * do anything we still error out.\n+\t\t */\n+\t\tDEBUG_WARN(\"errr %ld reading chunk map at offset %llu\",\n+\t\t\t   PTR_ERR(map), chunk_offset);\n+\t\treturn PTR_ERR(map);\n+\t}\n+\n+\tret = btrfs_remove_dev_extents(trans, map);\n+\tif (ret)\n+\t\tgoto out;\n+\n \t/*\n \t * We acquire fs_info->chunk_mutex for 2 reasons:\n \t *\n@@ -5417,7 +5430,7 @@ static void chunk_map_device_set_bits(struct btrfs_chunk_map *map, unsigned int\n \t}\n }\n \n-static void chunk_map_device_clear_bits(struct btrfs_chunk_map *map, unsigned int bits)\n+void btrfs_chunk_map_device_clear_bits(struct btrfs_chunk_map *map, unsigned int bits)\n {\n \tfor (int i = 0; i < map->num_stripes; i++) {\n \t\tstruct btrfs_io_stripe *stripe = &map->stripes[i];\n@@ -5434,7 +5447,7 @@ void btrfs_remove_chunk_map(struct btrfs_fs_info *fs_info, struct btrfs_chunk_ma\n \twrite_lock(&fs_info->mapping_tree_lock);\n \trb_erase_cached(&map->rb_node, &fs_info->mapping_tree);\n \tRB_CLEAR_NODE(&map->rb_node);\n-\tchunk_map_device_clear_bits(map, CHUNK_ALLOCATED);\n+\tbtrfs_chunk_map_device_clear_bits(map, CHUNK_ALLOCATED);\n \twrite_unlock(&fs_info->mapping_tree_lock);\n \n \t/* Once for the tree reference. */\n@@ -5470,7 +5483,7 @@ int btrfs_add_chunk_map(struct btrfs_fs_info *fs_info, struct btrfs_chunk_map *m\n \t\treturn -EEXIST;\n \t}\n \tchunk_map_device_set_bits(map, CHUNK_ALLOCATED);\n-\tchunk_map_device_clear_bits(map, CHUNK_TRIMMED);\n+\tbtrfs_chunk_map_device_clear_bits(map, CHUNK_TRIMMED);\n \twrite_unlock(&fs_info->mapping_tree_lock);\n \n \treturn 0;\n@@ -5826,7 +5839,7 @@ void btrfs_mapping_tree_free(struct btrfs_fs_info *fs_info)\n \t\tmap = rb_entry(node, struct btrfs_chunk_map, rb_node);\n \t\trb_erase_cached(&map->rb_node, &fs_info->mapping_tree);\n \t\tRB_CLEAR_NODE(&map->rb_node);\n-\t\tchunk_map_device_clear_bits(map, CHUNK_ALLOCATED);\n+\t\tbtrfs_chunk_map_device_clear_bits(map, CHUNK_ALLOCATED);\n \t\t/* Once for the tree ref. */\n \t\tbtrfs_free_chunk_map(map);\n \t\tcond_resched_rwlock_write(&fs_info->mapping_tree_lock);\ndiff --git a/fs/btrfs/volumes.h b/fs/btrfs/volumes.h\nindex 4117fabb248b..ccf0a459180d 100644\n--- a/fs/btrfs/volumes.h\n+++ b/fs/btrfs/volumes.h\n@@ -794,6 +794,8 @@ u64 btrfs_calc_stripe_length(const struct btrfs_chunk_map *map);\n int btrfs_nr_parity_stripes(u64 type);\n int btrfs_chunk_alloc_add_chunk_item(struct btrfs_trans_handle *trans,\n \t\t\t\t     struct btrfs_block_group *bg);\n+int btrfs_remove_dev_extents(struct btrfs_trans_handle *trans,\n+\t\t\t     struct btrfs_chunk_map *map);\n int btrfs_remove_chunk(struct btrfs_trans_handle *trans, u64 chunk_offset);\n \n #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS\n@@ -905,6 +907,10 @@ bool btrfs_repair_one_zone(struct btrfs_fs_info *fs_info, u64 logical);\n \n bool btrfs_pinned_by_swapfile(struct btrfs_fs_info *fs_info, void *ptr);\n const u8 *btrfs_sb_fsid_ptr(const struct btrfs_super_block *sb);\n+int btrfs_update_device(struct btrfs_trans_handle *trans,\n+\t\t\tstruct btrfs_device *device);\n+void btrfs_chunk_map_device_clear_bits(struct btrfs_chunk_map *map,\n+\t\t\t\t       unsigned int bits);\n \n #ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS\n struct btrfs_io_context *alloc_btrfs_io_context(struct btrfs_fs_info *fs_info,\n-- \n2.51.2\n\n\n\n---\n\nIf when relocating a block group we find that `remap_bytes` > 0 in its\nblock group item, that means that it has been the destination block\ngroup for another that has been remapped.\n\nWe need to seach the remap tree for any remap backrefs within this\nrange, and move the data to a third block group. This is because\notherwise btrfs_translate_remap() could end up following an unbounded\nchain of remaps, which would only get worse over time.\n\nWe only relocate one block group at a time, so `remap_bytes` will only\never go down while we are doing this. Once we're finished we set the\nREMAPPED flag on the block group, which will permanently prevent any\nother data from being moved to within it.\n\nSigned-off-by: Mark Harmstone <mark@harmstone.com>\nReviewed-by: Boris Burkov <boris@bur.io>\n---\n fs/btrfs/bio.c         |   3 +-\n fs/btrfs/bio.h         |   3 +\n fs/btrfs/extent-tree.c |   6 +-\n fs/btrfs/relocation.c  | 481 +++++++++++++++++++++++++++++++++++++++++\n 4 files changed, 490 insertions(+), 3 deletions(-)\n\ndiff --git a/fs/btrfs/bio.c b/fs/btrfs/bio.c\nindex a12446aa0fbf..1be042c0d521 100644\n--- a/fs/btrfs/bio.c\n+++ b/fs/btrfs/bio.c\n@@ -826,7 +826,8 @@ static bool btrfs_submit_chunk(struct btrfs_bio *bbio, int mirror_num)\n \t\t */\n \t\tif (!(inode->flags & BTRFS_INODE_NODATASUM) &&\n \t\t    !test_bit(BTRFS_FS_STATE_NO_DATA_CSUMS, &fs_info->fs_state) &&\n-\t\t    !btrfs_is_data_reloc_root(inode->root)) {\n+\t\t    !btrfs_is_data_reloc_root(inode->root) &&\n+\t\t    !bbio->is_remap) {\n \t\t\tif (should_async_write(bbio) &&\n \t\t\t    btrfs_wq_submit_bio(bbio, bioc, &smap, mirror_num))\n \t\t\t\tgoto done;\ndiff --git a/fs/btrfs/bio.h b/fs/btrfs/bio.h\nindex 157cdfa2f78a..303ed6c7103d 100644\n--- a/fs/btrfs/bio.h\n+++ b/fs/btrfs/bio.h\n@@ -90,6 +90,9 @@ struct btrfs_bio {\n \t */\n \tbool is_scrub:1;\n \n+\t/* Whether the bio is coming from copy_remapped_data_io(). */\n+\tbool is_remap:1;\n+\n \t/* Whether the csum generation for data write is async. */\n \tbool async_csum:1;\n \ndiff --git a/fs/btrfs/extent-tree.c b/fs/btrfs/extent-tree.c\nindex fef85ade017c..70020ba8ef92 100644\n--- a/fs/btrfs/extent-tree.c\n+++ b/fs/btrfs/extent-tree.c\n@@ -4557,7 +4557,8 @@ static noinline int find_free_extent(struct btrfs_root *root,\n \t\t    block_group->cached != BTRFS_CACHE_NO) {\n \t\t\tdown_read(&space_info->groups_sem);\n \t\t\tif (list_empty(&block_group->list) ||\n-\t\t\t    block_group->ro) {\n+\t\t\t    block_group->ro ||\n+\t\t\t    block_group->flags & BTRFS_BLOCK_GROUP_REMAPPED) {\n \t\t\t\t/*\n \t\t\t\t * someone is removing this block group,\n \t\t\t\t * we can't jump into the have_block_group\n@@ -4591,7 +4592,8 @@ static noinline int find_free_extent(struct btrfs_root *root,\n \n \t\tffe_ctl->hinted = false;\n \t\t/* If the block group is read-only, we can skip it entirely. */\n-\t\tif (unlikely(block_group->ro)) {\n+\t\tif (unlikely(block_group->ro ||\n+\t\t\t     block_group->flags & BTRFS_BLOCK_GROUP_REMAPPED)) {\n \t\t\tif (ffe_ctl->for_treelog)\n \t\t\t\tbtrfs_clear_treelog_bg(block_group);\n \t\t\tif (ffe_ctl->for_data_reloc)\ndiff --git a/fs/btrfs/relocation.c b/fs/btrfs/relocation.c\nindex 143eede52be0..82f0e15f0f84 100644\n--- a/fs/btrfs/relocation.c\n+++ b/fs/btrfs/relocation.c\n@@ -3976,6 +3976,481 @@ static void adjust_block_group_remap_bytes(struct btrfs_trans_handle *trans,\n \t\tbtrfs_inc_delayed_refs_rsv_bg_updates(fs_info);\n }\n \n+/* Private structure for I/O from copy_remapped_data().  */\n+struct reloc_io_private {\n+\tstruct completion done;\n+\trefcount_t pending_refs;\n+\tblk_status_t status;\n+};\n+\n+static void reloc_endio(struct btrfs_bio *bbio)\n+{\n+\tstruct reloc_io_private *priv = bbio->private;\n+\n+\tif (bbio->bio.bi_status)\n+\t\tWRITE_ONCE(priv->status, bbio->bio.bi_status);\n+\n+\tif (refcount_dec_and_test(&priv->pending_refs))\n+\t\tcomplete(&priv->done);\n+\n+\tbio_put(&bbio->bio);\n+}\n+\n+static int copy_remapped_data_io(struct btrfs_fs_info *fs_info,\n+\t\t\t\t struct reloc_io_private *priv,\n+\t\t\t\t struct page **pages, u64 addr, u64 length,\n+\t\t\t\t blk_opf_t op)\n+{\n+\tstruct btrfs_bio *bbio;\n+\tunsigned int i = 0;\n+\n+\tinit_completion(&priv->done);\n+\trefcount_set(&priv->pending_refs, 1);\n+\tpriv->status = 0;\n+\n+\tbbio = btrfs_bio_alloc(BIO_MAX_VECS, op, BTRFS_I(fs_info->btree_inode),\n+\t\t\t       addr, reloc_endio, priv);\n+\tbbio->bio.bi_iter.bi_sector = addr >> SECTOR_SHIFT;\n+\tbbio->is_remap = true;\n+\n+\tdo {\n+\t\tsize_t bytes = min_t(u64, length, PAGE_SIZE);\n+\n+\t\tif (bio_add_page(&bbio->bio, pages[i], bytes, 0) < bytes) {\n+\t\t\trefcount_inc(&priv->pending_refs);\n+\t\t\tbtrfs_submit_bbio(bbio, 0);\n+\n+\t\t\tbbio = btrfs_bio_alloc(BIO_MAX_VECS, op,\n+\t\t\t\t\t       BTRFS_I(fs_info->btree_inode),\n+\t\t\t\t\t       addr, reloc_endio, priv);\n+\t\t\tbbio->bio.bi_iter.bi_sector = addr >> SECTOR_SHIFT;\n+\t\t\tbbio->is_remap = true;\n+\t\t\tcontinue;\n+\t\t}\n+\n+\t\ti++;\n+\t\taddr += bytes;\n+\t\tlength -= bytes;\n+\t} while (length);\n+\n+\trefcount_inc(&priv->pending_refs);\n+\tbtrfs_submit_bbio(bbio, 0);\n+\n+\tif (!refcount_dec_and_test(&priv->pending_refs))\n+\t\twait_for_completion_io(&priv->done);\n+\n+\treturn blk_status_to_errno(READ_ONCE(priv->status));\n+}\n+\n+static int copy_remapped_data(struct btrfs_fs_info *fs_info, u64 old_addr,\n+\t\t\t      u64 new_addr, u64 length)\n+{\n+\tint ret;\n+\tu64 copy_len = min_t(u64, length, SZ_1M);\n+\tstruct page **pages;\n+\tstruct reloc_io_private priv;\n+\tunsigned int nr_pages = DIV_ROUND_UP(length, PAGE_SIZE);\n+\n+\tpages = kcalloc(nr_pages, sizeof(struct page *), GFP_NOFS);\n+\tif (!pages)\n+\t\treturn -ENOMEM;\n+\n+\tret = btrfs_alloc_page_array(nr_pages, pages, 0);\n+\tif (ret) {\n+\t\tret = -ENOMEM;\n+\t\tgoto end;\n+\t}\n+\n+\t/* Copy 1MB at a time, to avoid using too much memory. */\n+\n+\tdo {\n+\t\tu64 to_copy = min_t(u64, length, copy_len);\n+\n+\t\t/* Limit to one bio. */\n+\t\tto_copy = min_t(u64, to_copy, BIO_MAX_VECS << PAGE_SHIFT);\n+\n+\t\tret = copy_remapped_data_io(fs_info, &priv, pages, old_addr,\n+\t\t\t\t\t    to_copy, REQ_OP_READ);\n+\t\tif (ret)\n+\t\t\tgoto end;\n+\n+\t\tret = copy_remapped_data_io(fs_info, &priv, pages, new_addr,\n+\t\t\t\t\t    to_copy, REQ_OP_WRITE);\n+\t\tif (ret)\n+\t\t\tgoto end;\n+\n+\t\tif (to_copy == length)\n+\t\t\tbreak;\n+\n+\t\told_addr += to_copy;\n+\t\tnew_addr += to_copy;\n+\t\tlength -= to_copy;\n+\t} while (true);\n+\n+\tret = 0;\n+end:\n+\tfor (unsigned int i = 0; i < nr_pages; i++) {\n+\t\tif (pages[i])\n+\t\t\t__free_page(pages[i]);\n+\t}\n+\tkfree(pages);\n+\n+\treturn ret;\n+}\n+\n+static int add_remap_item(struct btrfs_trans_handle *trans,\n+\t\t\t  struct btrfs_path *path, u64 new_addr, u64 length,\n+\t\t\t  u64 old_addr)\n+{\n+\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n+\tstruct btrfs_remap_item remap = { 0 };\n+\tstruct btrfs_key key;\n+\tstruct extent_buffer *leaf;\n+\tint ret;\n+\n+\tkey.objectid = old_addr;\n+\tkey.type = BTRFS_REMAP_KEY;\n+\tkey.offset = length;\n+\n+\tret = btrfs_insert_empty_item(trans, fs_info->remap_root, path,\n+\t\t\t\t      &key, sizeof(struct btrfs_remap_item));\n+\tif (ret)\n+\t\treturn ret;\n+\n+\tleaf = path->nodes[0];\n+\n+\tbtrfs_set_stack_remap_address(&remap, new_addr);\n+\n+\twrite_extent_buffer(leaf, &remap,\n+\t\t\t    btrfs_item_ptr_offset(leaf, path->slots[0]),\n+\t\t\t    sizeof(struct btrfs_remap_item));\n+\n+\tbtrfs_release_path(path);\n+\n+\treturn 0;\n+}\n+\n+static int add_remap_backref_item(struct btrfs_trans_handle *trans,\n+\t\t\t\t  struct btrfs_path *path, u64 new_addr,\n+\t\t\t\t  u64 length, u64 old_addr)\n+{\n+\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n+\tstruct btrfs_remap_item remap = { 0 };\n+\tstruct btrfs_key key;\n+\tstruct extent_buffer *leaf;\n+\tint ret;\n+\n+\tkey.objectid = new_addr;\n+\tkey.type = BTRFS_REMAP_BACKREF_KEY;\n+\tkey.offset = length;\n+\n+\tret = btrfs_insert_empty_item(trans, fs_info->remap_root,\n+\t\t\t\t      path, &key,\n+\t\t\t\t      sizeof(struct btrfs_remap_item));\n+\tif (ret)\n+\t\treturn ret;\n+\n+\tleaf = path->nodes[0];\n+\n+\tbtrfs_set_stack_remap_address(&remap, old_addr);\n+\n+\twrite_extent_buffer(leaf, &remap,\n+\t\t\t    btrfs_item_ptr_offset(leaf, path->slots[0]),\n+\t\t\t    sizeof(struct btrfs_remap_item));\n+\n+\tbtrfs_release_path(path);\n+\n+\treturn 0;\n+}\n+\n+static int move_existing_remap(struct btrfs_fs_info *fs_info,\n+\t\t\t       struct btrfs_path *path,\n+\t\t\t       struct btrfs_block_group *bg, u64 new_addr,\n+\t\t\t       u64 length, u64 old_addr)\n+{\n+\tstruct btrfs_trans_handle *trans;\n+\tstruct extent_buffer *leaf;\n+\tstruct btrfs_remap_item *remap_ptr;\n+\tstruct btrfs_remap_item remap = { 0 };\n+\tstruct btrfs_key key, ins;\n+\tu64 dest_addr, dest_length, min_size;\n+\tstruct btrfs_block_group *dest_bg;\n+\tint ret;\n+\tconst bool is_data = bg->flags & BTRFS_BLOCK_GROUP_DATA;\n+\tstruct btrfs_space_info *sinfo = bg->space_info;\n+\tbool mutex_taken = false, bg_needs_free_space;\n+\n+\tspin_lock(&sinfo->lock);\n+\tbtrfs_space_info_update_bytes_may_use(sinfo, length);\n+\tspin_unlock(&sinfo->lock);\n+\n+\tif (is_data)\n+\t\tmin_size = fs_info->sectorsize;\n+\telse\n+\t\tmin_size = fs_info->nodesize;\n+\n+\tret = btrfs_reserve_extent(fs_info->fs_root, length, length, min_size,\n+\t\t\t\t   0, 0, &ins, is_data, false);\n+\tif (unlikely(ret)) {\n+\t\tspin_lock(&sinfo->lock);\n+\t\tbtrfs_space_info_update_bytes_may_use(sinfo, -length);\n+\t\tspin_unlock(&sinfo->lock);\n+\t\treturn ret;\n+\t}\n+\n+\tdest_addr = ins.objectid;\n+\tdest_length = ins.offset;\n+\n+\tif (!is_data && !IS_ALIGNED(dest_length, fs_info->nodesize)) {\n+\t\tu64 new_length = ALIGN_DOWN(dest_length, fs_info->nodesize);\n+\n+\t\tbtrfs_free_reserved_extent(fs_info, dest_addr + new_length,\n+\t\t\t\t\t   dest_length - new_length, 0);\n+\n+\t\tdest_length = new_length;\n+\t}\n+\n+\ttrans = btrfs_join_transaction(fs_info->remap_root);\n+\tif (IS_ERR(trans)) {\n+\t\tret = PTR_ERR(trans);\n+\t\ttrans = NULL;\n+\t\tgoto end;\n+\t}\n+\n+\tmutex_lock(&fs_info->remap_mutex);\n+\tmutex_taken = true;\n+\n+\t/* Find old remap entry. */\n+\n+\tkey.objectid = old_addr;\n+\tkey.type = BTRFS_REMAP_KEY;\n+\tkey.offset = length;\n+\n+\tret = btrfs_search_slot(trans, fs_info->remap_root, &key,\n+\t\t\t\tpath, 0, 1);\n+\tif (ret == 1) {\n+\t\t/*\n+\t\t * Not a problem if the remap entry wasn't found: that means\n+\t\t * that another transaction has deallocated the data.\n+\t\t * move_existing_remaps() loops until the BG contains no\n+\t\t * remaps, so we can just return 0 in this case.\n+\t\t */\n+\t\tbtrfs_release_path(path);\n+\t\tret = 0;\n+\t\tgoto end;\n+\t} else if (unlikely(ret)) {\n+\t\tgoto end;\n+\t}\n+\n+\tret = copy_remapped_data(fs_info, new_addr, dest_addr, dest_length);\n+\tif (unlikely(ret))\n+\t\tgoto end;\n+\n+\t/* Change data of old remap entry. */\n+\n+\tleaf = path->nodes[0];\n+\n+\tremap_ptr = btrfs_item_ptr(leaf, path->slots[0],\n+\t\t\t\t   struct btrfs_remap_item);\n+\tbtrfs_set_remap_address(leaf, remap_ptr, dest_addr);\n+\n+\tbtrfs_mark_buffer_dirty(trans, leaf);\n+\n+\tif (dest_length != length) {\n+\t\tkey.offset = dest_length;\n+\t\tbtrfs_set_item_key_safe(trans, path, &key);\n+\t}\n+\n+\tbtrfs_release_path(path);\n+\n+\tif (dest_length != length) {\n+\t\t/* Add remap item for remainder. */\n+\n+\t\tret = add_remap_item(trans, path, new_addr + dest_length,\n+\t\t\t\t     length - dest_length,\n+\t\t\t\t     old_addr + dest_length);\n+\t\tif (unlikely(ret))\n+\t\t\tgoto end;\n+\t}\n+\n+\t/* Change or remove old backref. */\n+\n+\tkey.objectid = new_addr;\n+\tkey.type = BTRFS_REMAP_BACKREF_KEY;\n+\tkey.offset = length;\n+\n+\tret = btrfs_search_slot(trans, fs_info->remap_root, &key,\n+\t\t\t\tpath, -1, 1);\n+\tif (unlikely(ret)) {\n+\t\tif (ret == 1) {\n+\t\t\tbtrfs_release_path(path);\n+\t\t\tret = -ENOENT;\n+\t\t}\n+\t\tgoto end;\n+\t}\n+\n+\tleaf = path->nodes[0];\n+\n+\tif (dest_length == length) {\n+\t\tret = btrfs_del_item(trans, fs_info->remap_root, path);\n+\t\tif (unlikely(ret)) {\n+\t\t\tbtrfs_release_path(path);\n+\t\t\tgoto end;\n+\t\t}\n+\t} else {\n+\t\tkey.objectid += dest_length;\n+\t\tkey.offset -= dest_length;\n+\t\tbtrfs_set_item_key_safe(trans, path, &key);\n+\n+\t\tbtrfs_set_stack_remap_address(&remap, old_addr + dest_length);\n+\n+\t\twrite_extent_buffer(leaf, &remap,\n+\t\t\t\t    btrfs_item_ptr_offset(leaf, path->slots[0]),\n+\t\t\t\t    sizeof(struct btrfs_remap_item));\n+\t}\n+\n+\tbtrfs_release_path(path);\n+\n+\t/* Add new backref. */\n+\n+\tret = add_remap_backref_item(trans, path, dest_addr, dest_length,\n+\t\t\t\t     old_addr);\n+\tif (unlikely(ret))\n+\t\tgoto end;\n+\n+\tadjust_block_group_remap_bytes(trans, bg, -dest_length);\n+\n+\tret = btrfs_add_to_free_space_tree(trans, new_addr, dest_length);\n+\tif (unlikely(ret))\n+\t\tgoto end;\n+\n+\tdest_bg = btrfs_lookup_block_group(fs_info, dest_addr);\n+\n+\tadjust_block_group_remap_bytes(trans, dest_bg, dest_length);\n+\n+\tmutex_lock(&dest_bg->free_space_lock);\n+\tbg_needs_free_space = test_bit(BLOCK_GROUP_FLAG_NEEDS_FREE_SPACE,\n+\t\t\t\t       &dest_bg->runtime_flags);\n+\tmutex_unlock(&dest_bg->free_space_lock);\n+\tbtrfs_put_block_group(dest_bg);\n+\n+\tif (bg_needs_free_space) {\n+\t\tret = btrfs_add_block_group_free_space(trans, dest_bg);\n+\t\tif (unlikely(ret))\n+\t\t\tgoto end;\n+\t}\n+\n+\tret = btrfs_remove_from_free_space_tree(trans, dest_addr, dest_length);\n+\tif (unlikely(ret)) {\n+\t\tbtrfs_remove_from_free_space_tree(trans, new_addr,\n+\t\t\t\t\t\t  dest_length);\n+\t\tgoto end;\n+\t}\n+\n+\tret = 0;\n+\n+end:\n+\tif (mutex_taken)\n+\t\tmutex_unlock(&fs_info->remap_mutex);\n+\n+\tbtrfs_dec_block_group_reservations(fs_info, dest_addr);\n+\n+\tif (unlikely(ret)) {\n+\t\tbtrfs_free_reserved_extent(fs_info, dest_addr, dest_length, 0);\n+\n+\t\tif (trans) {\n+\t\t\tbtrfs_abort_transaction(trans, ret);\n+\t\t\tbtrfs_end_transaction(trans);\n+\t\t}\n+\t} else {\n+\t\tdest_bg = btrfs_lookup_block_group(fs_info, dest_addr);\n+\t\tbtrfs_free_reserved_bytes(dest_bg, dest_length, 0);\n+\t\tbtrfs_put_block_group(dest_bg);\n+\n+\t\tret = btrfs_commit_transaction(trans);\n+\t}\n+\n+\treturn ret;\n+}\n+\n+static int move_existing_remaps(struct btrfs_fs_info *fs_info,\n+\t\t\t\tstruct btrfs_block_group *bg,\n+\t\t\t\tstruct btrfs_path *path)\n+{\n+\tint ret;\n+\tstruct btrfs_key key;\n+\tstruct extent_buffer *leaf;\n+\tstruct btrfs_remap_item *remap;\n+\tu64 old_addr;\n+\n+\t/* Look for backrefs in remap tree. */\n+\n+\twhile (bg->remap_bytes > 0) {\n+\t\tkey.objectid = bg->start;\n+\t\tkey.type = BTRFS_REMAP_BACKREF_KEY;\n+\t\tkey.offset = 0;\n+\n+\t\tret = btrfs_search_slot(NULL, fs_info->remap_root, &key, path,\n+\t\t\t\t\t0, 0);\n+\t\tif (ret < 0)\n+\t\t\treturn ret;\n+\n+\t\tleaf = path->nodes[0];\n+\n+\t\tif (path->slots[0] >= btrfs_header_nritems(leaf)) {\n+\t\t\tret = btrfs_next_leaf(fs_info->remap_root, path);\n+\t\t\tif (ret < 0) {\n+\t\t\t\tbtrfs_release_path(path);\n+\t\t\t\treturn ret;\n+\t\t\t}\n+\n+\t\t\tif (ret) {\n+\t\t\t\tbtrfs_release_path(path);\n+\t\t\t\tbreak;\n+\t\t\t}\n+\n+\t\t\tleaf = path->nodes[0];\n+\t\t}\n+\n+\t\tbtrfs_item_key_to_cpu(leaf, &key, path->slots[0]);\n+\n+\t\tif (key.type != BTRFS_REMAP_BACKREF_KEY) {\n+\t\t\tpath->slots[0]++;\n+\n+\t\t\tif (path->slots[0] >= btrfs_header_nritems(leaf)) {\n+\t\t\t\tret = btrfs_next_leaf(fs_info->remap_root, path);\n+\t\t\t\tif (ret < 0) {\n+\t\t\t\t\tbtrfs_release_path(path);\n+\t\t\t\t\treturn ret;\n+\t\t\t\t}\n+\n+\t\t\t\tif (ret) {\n+\t\t\t\t\tbtrfs_release_path(path);\n+\t\t\t\t\tbreak;\n+\t\t\t\t}\n+\n+\t\t\t\tleaf = path->nodes[0];\n+\t\t\t}\n+\t\t}\n+\n+\t\tremap = btrfs_item_ptr(leaf, path->slots[0],\n+\t\t\t\t       struct btrfs_remap_item);\n+\n+\t\told_addr = btrfs_remap_address(leaf, remap);\n+\n+\t\tbtrfs_release_path(path);\n+\n+\t\tret = move_existing_remap(fs_info, path, bg, key.objectid,\n+\t\t\t\t\t  key.offset, old_addr);\n+\t\tif (ret)\n+\t\t\treturn ret;\n+\t}\n+\n+\tASSERT(bg->remap_bytes == 0);\n+\n+\treturn 0;\n+}\n+\n static int create_remap_tree_entries(struct btrfs_trans_handle *trans,\n \t\t\t\t     struct btrfs_path *path,\n \t\t\t\t     struct btrfs_block_group *bg)\n@@ -4639,6 +5114,12 @@ int btrfs_relocate_block_group(struct btrfs_fs_info *fs_info, u64 group_start,\n \tWARN_ON(ret && ret != -EAGAIN);\n \n \tif (should_relocate_using_remap_tree(bg)) {\n+\t\tif (bg->remap_bytes != 0) {\n+\t\t\tret = move_existing_remaps(fs_info, bg, path);\n+\t\t\tif (ret)\n+\t\t\t\tgoto out;\n+\t\t}\n+\n \t\tret = start_block_group_remapping(fs_info, path, bg);\n \t} else {\n \t\tret = do_nonremap_reloc(fs_info, verbose, rc);\n-- \n2.51.2\n\n\n\n---\n\nHandle the preliminary work for relocating a block group in a filesystem\nwith the remap-tree flag set.\n\nIf the block group is SYSTEM btrfs_relocate_block_group() proceeds as it\ndoes already, as bootstrapping issues mean that these block groups have\nto be processed the existing way. Similarly with METADATA_REMAP blocks, which\nare dealt with in a later patch.\n\nOtherwise we walk the free-space tree for the block group in question,\nrecording any holes. These get converted into identity remaps and placed\nin the remap tree, and the block group's REMAPPED flag is set. From now\non no new allocations are possible within this block group, and any I/O\nto it will be funnelled through btrfs_translate_remap(). We store the\nnumber of identity remaps in `identity_remap_count`, so that we know\nwhen we've removed the last one and the block group is fully remapped.\n\nThe change in btrfs_read_roots() is because data relocations no longer\nrely on the data reloc tree as a hidden subvolume in which to do\nsnapshots.\n\n(Thanks to Sun YangKai for his suggestions.)\n\nSigned-off-by: Mark Harmstone <mark@harmstone.com>\nReviewed-by: Boris Burkov <boris@bur.io>\n---\n fs/btrfs/block-group.c     |   6 +-\n fs/btrfs/block-group.h     |   4 +\n fs/btrfs/free-space-tree.c |   4 +-\n fs/btrfs/free-space-tree.h |   5 +-\n fs/btrfs/relocation.c      | 516 +++++++++++++++++++++++++++++++++----\n fs/btrfs/relocation.h      |  11 +\n fs/btrfs/space-info.c      |   9 +-\n fs/btrfs/volumes.c         |  89 ++++---\n 8 files changed, 551 insertions(+), 93 deletions(-)\n\ndiff --git a/fs/btrfs/block-group.c b/fs/btrfs/block-group.c\nindex 0143b0290a72..2b3fd80a690f 100644\n--- a/fs/btrfs/block-group.c\n+++ b/fs/btrfs/block-group.c\n@@ -2405,6 +2405,7 @@ static int read_one_block_group(struct btrfs_fs_info *info,\n \tcache->used = btrfs_stack_block_group_v2_used(bgi);\n \tcache->last_used = cache->used;\n \tcache->flags = btrfs_stack_block_group_v2_flags(bgi);\n+\tcache->last_flags = cache->flags;\n \tcache->global_root_id = btrfs_stack_block_group_v2_chunk_objectid(bgi);\n \tcache->space_info = btrfs_find_space_info(info, cache->flags);\n \tcache->remap_bytes = btrfs_stack_block_group_v2_remap_bytes(bgi);\n@@ -2714,6 +2715,7 @@ static int insert_block_group_item(struct btrfs_trans_handle *trans,\n \tblock_group->last_remap_bytes = block_group->remap_bytes;\n \tblock_group->last_identity_remap_count =\n \t\tblock_group->identity_remap_count;\n+\tblock_group->last_flags = block_group->flags;\n \tkey.objectid = block_group->start;\n \tkey.type = BTRFS_BLOCK_GROUP_ITEM_KEY;\n \tkey.offset = block_group->length;\n@@ -3202,13 +3204,15 @@ static int update_block_group_item(struct btrfs_trans_handle *trans,\n \t/* No change in values, can safely skip it. */\n \tif (cache->last_used == used &&\n \t    cache->last_remap_bytes == remap_bytes &&\n-\t    cache->last_identity_remap_count == identity_remap_count) {\n+\t    cache->last_identity_remap_count == identity_remap_count &&\n+\t    cache->last_flags == cache->flags) {\n \t\tspin_unlock(&cache->lock);\n \t\treturn 0;\n \t}\n \tcache->last_used = used;\n \tcache->last_remap_bytes = remap_bytes;\n \tcache->last_identity_remap_count = identity_remap_count;\n+\tcache->last_flags = cache->flags;\n \tspin_unlock(&cache->lock);\n \n \tkey.objectid = cache->start;\ndiff --git a/fs/btrfs/block-group.h b/fs/btrfs/block-group.h\nindex 436d51a707a9..3e8c3d424481 100644\n--- a/fs/btrfs/block-group.h\n+++ b/fs/btrfs/block-group.h\n@@ -147,6 +147,10 @@ struct btrfs_block_group {\n \t * The last commited identity_remap_count value of this block group.\n \t */\n \tu32 last_identity_remap_count;\n+\t/*\n+\t * The last committed flags value for this block group.\n+\t */\n+\tu64 last_flags;\n \n \t/*\n \t * If the free space extent count exceeds this number, convert the block\ndiff --git a/fs/btrfs/free-space-tree.c b/fs/btrfs/free-space-tree.c\nindex ac092898130f..96d52c031977 100644\n--- a/fs/btrfs/free-space-tree.c\n+++ b/fs/btrfs/free-space-tree.c\n@@ -21,8 +21,7 @@ static int __add_block_group_free_space(struct btrfs_trans_handle *trans,\n \t\t\t\t\tstruct btrfs_block_group *block_group,\n \t\t\t\t\tstruct btrfs_path *path);\n \n-static struct btrfs_root *btrfs_free_space_root(\n-\t\t\t\tstruct btrfs_block_group *block_group)\n+struct btrfs_root *btrfs_free_space_root(struct btrfs_block_group *block_group)\n {\n \tstruct btrfs_key key = {\n \t\t.objectid = BTRFS_FREE_SPACE_TREE_OBJECTID,\n@@ -93,7 +92,6 @@ static int add_new_free_space_info(struct btrfs_trans_handle *trans,\n \treturn 0;\n }\n \n-EXPORT_FOR_TESTS\n struct btrfs_free_space_info *btrfs_search_free_space_info(\n \t\tstruct btrfs_trans_handle *trans,\n \t\tstruct btrfs_block_group *block_group,\ndiff --git a/fs/btrfs/free-space-tree.h b/fs/btrfs/free-space-tree.h\nindex ca04fc7cf29e..709730e36888 100644\n--- a/fs/btrfs/free-space-tree.h\n+++ b/fs/btrfs/free-space-tree.h\n@@ -36,12 +36,13 @@ int btrfs_add_to_free_space_tree(struct btrfs_trans_handle *trans,\n int btrfs_remove_from_free_space_tree(struct btrfs_trans_handle *trans,\n \t\t\t\t      u64 start, u64 size);\n int btrfs_delete_orphan_free_space_entries(struct btrfs_fs_info *fs_info);\n-\n-#ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS\n struct btrfs_free_space_info *\n btrfs_search_free_space_info(struct btrfs_trans_handle *trans,\n \t\t\t     struct btrfs_block_group *block_group,\n \t\t\t     struct btrfs_path *path, int cow);\n+struct btrfs_root *btrfs_free_space_root(struct btrfs_block_group *block_group);\n+\n+#ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS\n int __btrfs_add_to_free_space_tree(struct btrfs_trans_handle *trans,\n \t\t\t\t   struct btrfs_block_group *block_group,\n \t\t\t\t   struct btrfs_path *path, u64 start, u64 size);\ndiff --git a/fs/btrfs/relocation.c b/fs/btrfs/relocation.c\nindex e47234d5a156..143eede52be0 100644\n--- a/fs/btrfs/relocation.c\n+++ b/fs/btrfs/relocation.c\n@@ -3616,7 +3616,7 @@ static noinline_for_stack int relocate_block_group(struct reloc_control *rc)\n \t\tbtrfs_btree_balance_dirty(fs_info);\n \t}\n \n-\tif (!err) {\n+\tif (!err && !btrfs_fs_incompat(fs_info, REMAP_TREE)) {\n \t\tret = relocate_file_extent_cluster(rc);\n \t\tif (ret < 0)\n \t\t\terr = ret;\n@@ -3860,6 +3860,90 @@ static const char *stage_to_string(enum reloc_stage stage)\n \treturn \"unknown\";\n }\n \n+static int add_remap_tree_entries(struct btrfs_trans_handle *trans,\n+\t\t\t\t  struct btrfs_path *path,\n+\t\t\t\t  struct btrfs_key *entries,\n+\t\t\t\t  unsigned int num_entries)\n+{\n+\tint ret;\n+\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n+\tstruct btrfs_item_batch batch;\n+\tu32 *data_sizes;\n+\tu32 max_items;\n+\n+\tmax_items = BTRFS_LEAF_DATA_SIZE(trans->fs_info) / sizeof(struct btrfs_item);\n+\n+\tdata_sizes = kzalloc(sizeof(u32) * min_t(u32, num_entries, max_items),\n+\t\t\t     GFP_NOFS);\n+\tif (!data_sizes)\n+\t\treturn -ENOMEM;\n+\n+\twhile (true) {\n+\t\tbatch.keys = entries;\n+\t\tbatch.data_sizes = data_sizes;\n+\t\tbatch.total_data_size = 0;\n+\t\tbatch.nr = min_t(u32, num_entries, max_items);\n+\n+\t\tret = btrfs_insert_empty_items(trans, fs_info->remap_root, path,\n+\t\t\t\t\t       &batch);\n+\t\tbtrfs_release_path(path);\n+\n+\t\tif (num_entries <= max_items)\n+\t\t\tbreak;\n+\n+\t\tnum_entries -= max_items;\n+\t\tentries += max_items;\n+\t}\n+\n+\tkfree(data_sizes);\n+\n+\treturn ret;\n+}\n+\n+struct space_run {\n+\tu64 start;\n+\tu64 end;\n+};\n+\n+static void parse_bitmap(u64 block_size, const unsigned long *bitmap,\n+\t\t\t unsigned long size, u64 address,\n+\t\t\t struct space_run *space_runs,\n+\t\t\t unsigned int *num_space_runs)\n+{\n+\tunsigned long pos, end;\n+\tu64 run_start, run_length;\n+\n+\tpos = find_first_bit(bitmap, size);\n+\n+\tif (pos == size)\n+\t\treturn;\n+\n+\twhile (true) {\n+\t\tend = find_next_zero_bit(bitmap, size, pos);\n+\n+\t\trun_start = address + (pos * block_size);\n+\t\trun_length = (end - pos) * block_size;\n+\n+\t\tif (*num_space_runs != 0 &&\n+\t\t    space_runs[*num_space_runs - 1].end == run_start) {\n+\t\t\tspace_runs[*num_space_runs - 1].end += run_length;\n+\t\t} else {\n+\t\t\tspace_runs[*num_space_runs].start = run_start;\n+\t\t\tspace_runs[*num_space_runs].end = run_start + run_length;\n+\n+\t\t\t(*num_space_runs)++;\n+\t\t}\n+\n+\t\tif (end == size)\n+\t\t\tbreak;\n+\n+\t\tpos = find_next_bit(bitmap, size, end + 1);\n+\n+\t\tif (pos == size)\n+\t\t\tbreak;\n+\t}\n+}\n+\n static void adjust_block_group_remap_bytes(struct btrfs_trans_handle *trans,\n \t\t\t\t\t   struct btrfs_block_group *bg,\n \t\t\t\t\t   s64 diff)\n@@ -3892,6 +3976,188 @@ static void adjust_block_group_remap_bytes(struct btrfs_trans_handle *trans,\n \t\tbtrfs_inc_delayed_refs_rsv_bg_updates(fs_info);\n }\n \n+static int create_remap_tree_entries(struct btrfs_trans_handle *trans,\n+\t\t\t\t     struct btrfs_path *path,\n+\t\t\t\t     struct btrfs_block_group *bg)\n+{\n+\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n+\tstruct btrfs_free_space_info *fsi;\n+\tstruct btrfs_key key, found_key;\n+\tstruct extent_buffer *leaf;\n+\tstruct btrfs_root *space_root;\n+\tu32 extent_count;\n+\tstruct space_run *space_runs = NULL;\n+\tunsigned int num_space_runs = 0;\n+\tstruct btrfs_key *entries = NULL;\n+\tunsigned int max_entries, num_entries;\n+\tint ret;\n+\n+\tmutex_lock(&bg->free_space_lock);\n+\n+\tif (test_bit(BLOCK_GROUP_FLAG_NEEDS_FREE_SPACE, &bg->runtime_flags)) {\n+\t\tmutex_unlock(&bg->free_space_lock);\n+\n+\t\tret = btrfs_add_block_group_free_space(trans, bg);\n+\t\tif (ret)\n+\t\t\treturn ret;\n+\n+\t\tmutex_lock(&bg->free_space_lock);\n+\t}\n+\n+\tfsi = btrfs_search_free_space_info(trans, bg, path, 0);\n+\tif (IS_ERR(fsi)) {\n+\t\tmutex_unlock(&bg->free_space_lock);\n+\t\treturn PTR_ERR(fsi);\n+\t}\n+\n+\textent_count = btrfs_free_space_extent_count(path->nodes[0], fsi);\n+\n+\tbtrfs_release_path(path);\n+\n+\tspace_runs = kmalloc(sizeof(*space_runs) * extent_count, GFP_NOFS);\n+\tif (!space_runs) {\n+\t\tmutex_unlock(&bg->free_space_lock);\n+\t\treturn -ENOMEM;\n+\t}\n+\n+\tkey.objectid = bg->start;\n+\tkey.type = 0;\n+\tkey.offset = 0;\n+\n+\tspace_root = btrfs_free_space_root(bg);\n+\n+\tret = btrfs_search_slot(trans, space_root, &key, path, 0, 0);\n+\tif (ret < 0) {\n+\t\tmutex_unlock(&bg->free_space_lock);\n+\t\tgoto out;\n+\t}\n+\n+\tret = 0;\n+\n+\twhile (true) {\n+\t\tleaf = path->nodes[0];\n+\n+\t\tbtrfs_item_key_to_cpu(leaf, &found_key, path->slots[0]);\n+\n+\t\tif (found_key.objectid >= bg->start + bg->length)\n+\t\t\tbreak;\n+\n+\t\tif (found_key.type == BTRFS_FREE_SPACE_EXTENT_KEY) {\n+\t\t\tif (num_space_runs != 0 &&\n+\t\t\t    space_runs[num_space_runs - 1].end == found_key.objectid) {\n+\t\t\t\tspace_runs[num_space_runs - 1].end =\n+\t\t\t\t\tfound_key.objectid + found_key.offset;\n+\t\t\t} else {\n+\t\t\t\tASSERT(num_space_runs < extent_count);\n+\n+\t\t\t\tspace_runs[num_space_runs].start = found_key.objectid;\n+\t\t\t\tspace_runs[num_space_runs].end =\n+\t\t\t\t\tfound_key.objectid + found_key.offset;\n+\n+\t\t\t\tnum_space_runs++;\n+\t\t\t}\n+\t\t} else if (found_key.type == BTRFS_FREE_SPACE_BITMAP_KEY) {\n+\t\t\tvoid *bitmap;\n+\t\t\tunsigned long offset;\n+\t\t\tu32 data_size;\n+\n+\t\t\toffset = btrfs_item_ptr_offset(leaf, path->slots[0]);\n+\t\t\tdata_size = btrfs_item_size(leaf, path->slots[0]);\n+\n+\t\t\tif (data_size != 0) {\n+\t\t\t\tbitmap = kmalloc(data_size, GFP_NOFS);\n+\t\t\t\tif (!bitmap) {\n+\t\t\t\t\tmutex_unlock(&bg->free_space_lock);\n+\t\t\t\t\tret = -ENOMEM;\n+\t\t\t\t\tgoto out;\n+\t\t\t\t}\n+\n+\t\t\t\tread_extent_buffer(leaf, bitmap, offset,\n+\t\t\t\t\t\t   data_size);\n+\n+\t\t\t\tparse_bitmap(fs_info->sectorsize, bitmap,\n+\t\t\t\t\t     data_size * BITS_PER_BYTE,\n+\t\t\t\t\t     found_key.objectid, space_runs,\n+\t\t\t\t\t     &num_space_runs);\n+\n+\t\t\t\tASSERT(num_space_runs <= extent_count);\n+\n+\t\t\t\tkfree(bitmap);\n+\t\t\t}\n+\t\t}\n+\n+\t\tpath->slots[0]++;\n+\n+\t\tif (path->slots[0] >= btrfs_header_nritems(leaf)) {\n+\t\t\tret = btrfs_next_leaf(space_root, path);\n+\t\t\tif (ret != 0) {\n+\t\t\t\tif (ret == 1)\n+\t\t\t\t\tret = 0;\n+\t\t\t\tbreak;\n+\t\t\t}\n+\t\t\tleaf = path->nodes[0];\n+\t\t}\n+\t}\n+\n+\tbtrfs_release_path(path);\n+\n+\tmutex_unlock(&bg->free_space_lock);\n+\n+\tmax_entries = extent_count + 2;\n+\tentries = kmalloc(sizeof(*entries) * max_entries, GFP_NOFS);\n+\tif (!entries) {\n+\t\tret = -ENOMEM;\n+\t\tgoto out;\n+\t}\n+\n+\tnum_entries = 0;\n+\n+\tif (num_space_runs == 0) {\n+\t\tentries[num_entries].objectid = bg->start;\n+\t\tentries[num_entries].type = BTRFS_IDENTITY_REMAP_KEY;\n+\t\tentries[num_entries].offset = bg->length;\n+\t\tnum_entries++;\n+\t} else {\n+\t\tif (space_runs[0].start > bg->start) {\n+\t\t\tentries[num_entries].objectid = bg->start;\n+\t\t\tentries[num_entries].type = BTRFS_IDENTITY_REMAP_KEY;\n+\t\t\tentries[num_entries].offset =\n+\t\t\t\tspace_runs[0].start - bg->start;\n+\t\t\tnum_entries++;\n+\t\t}\n+\n+\t\tfor (unsigned int i = 1; i < num_space_runs; i++) {\n+\t\t\tentries[num_entries].objectid = space_runs[i - 1].end;\n+\t\t\tentries[num_entries].type = BTRFS_IDENTITY_REMAP_KEY;\n+\t\t\tentries[num_entries].offset =\n+\t\t\t\tspace_runs[i].start - space_runs[i - 1].end;\n+\t\t\tnum_entries++;\n+\t\t}\n+\n+\t\tif (space_runs[num_space_runs - 1].end < bg->start + bg->length) {\n+\t\t\tentries[num_entries].objectid =\n+\t\t\t\tspace_runs[num_space_runs - 1].end;\n+\t\t\tentries[num_entries].type = BTRFS_IDENTITY_REMAP_KEY;\n+\t\t\tentries[num_entries].offset =\n+\t\t\t\tbg->start + bg->length - space_runs[num_space_runs - 1].end;\n+\t\t\tnum_entries++;\n+\t\t}\n+\n+\t\tif (num_entries == 0)\n+\t\t\tgoto out;\n+\t}\n+\n+\tbg->identity_remap_count = num_entries;\n+\n+\tret = add_remap_tree_entries(trans, path, entries, num_entries);\n+\n+out:\n+\tkfree(entries);\n+\tkfree(space_runs);\n+\n+\treturn ret;\n+}\n+\n static int remove_chunk_stripes(struct btrfs_trans_handle *trans,\n \t\t\t\tstruct btrfs_chunk_map *chunk_map,\n \t\t\t\tstruct btrfs_path *path)\n@@ -4038,6 +4304,55 @@ static void adjust_identity_remap_count(struct btrfs_trans_handle *trans,\n \t\tbtrfs_mark_bg_fully_remapped(bg, trans);\n }\n \n+static int mark_chunk_remapped(struct btrfs_trans_handle *trans,\n+\t\t\t       struct btrfs_path *path, uint64_t start)\n+{\n+\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n+\tstruct btrfs_chunk_map *chunk_map;\n+\tstruct btrfs_key key;\n+\tu64 type;\n+\tint ret;\n+\tstruct extent_buffer *leaf;\n+\tstruct btrfs_chunk *chunk;\n+\n+\tread_lock(&fs_info->mapping_tree_lock);\n+\n+\tchunk_map = btrfs_find_chunk_map_nolock(fs_info, start, 1);\n+\tif (!chunk_map) {\n+\t\tread_unlock(&fs_info->mapping_tree_lock);\n+\t\treturn -ENOENT;\n+\t}\n+\n+\tchunk_map->type |= BTRFS_BLOCK_GROUP_REMAPPED;\n+\ttype = chunk_map->type;\n+\n+\tread_unlock(&fs_info->mapping_tree_lock);\n+\n+\tkey.objectid = BTRFS_FIRST_CHUNK_TREE_OBJECTID;\n+\tkey.type = BTRFS_CHUNK_ITEM_KEY;\n+\tkey.offset = start;\n+\n+\tret = btrfs_search_slot(trans, fs_info->chunk_root, &key, path,\n+\t\t\t\t0, 1);\n+\tif (ret == 1) {\n+\t\tret = -ENOENT;\n+\t\tgoto end;\n+\t} else if (ret < 0)\n+\t\tgoto end;\n+\n+\tleaf = path->nodes[0];\n+\n+\tchunk = btrfs_item_ptr(leaf, path->slots[0], struct btrfs_chunk);\n+\tbtrfs_set_chunk_type(leaf, chunk, type);\n+\tbtrfs_mark_buffer_dirty(trans, leaf);\n+\n+\tret = 0;\n+end:\n+\tbtrfs_free_chunk_map(chunk_map);\n+\tbtrfs_release_path(path);\n+\treturn ret;\n+}\n+\n int btrfs_translate_remap(struct btrfs_fs_info *fs_info, u64 *logical,\n \t\t\t  u64 *length)\n {\n@@ -4092,6 +4407,136 @@ int btrfs_translate_remap(struct btrfs_fs_info *fs_info, u64 *logical,\n \treturn 0;\n }\n \n+static int start_block_group_remapping(struct btrfs_fs_info *fs_info,\n+\t\t\t\t       struct btrfs_path *path,\n+\t\t\t\t       struct btrfs_block_group *bg)\n+{\n+\tstruct btrfs_trans_handle *trans;\n+\tbool bg_already_dirty = true;\n+\tint ret, ret2;\n+\n+\tret = btrfs_cache_block_group(bg, true);\n+\tif (ret)\n+\t\treturn ret;\n+\n+\ttrans = btrfs_start_transaction(fs_info->remap_root, 0);\n+\tif (IS_ERR(trans))\n+\t\treturn PTR_ERR(trans);\n+\n+\t/* We need to run delayed refs, to make sure FST is up to date. */\n+\tret = btrfs_run_delayed_refs(trans, U64_MAX);\n+\tif (ret) {\n+\t\tbtrfs_end_transaction(trans);\n+\t\treturn ret;\n+\t}\n+\n+\tmutex_lock(&fs_info->remap_mutex);\n+\n+\tif (bg->flags & BTRFS_BLOCK_GROUP_REMAPPED) {\n+\t\tret = 0;\n+\t\tgoto end;\n+\t}\n+\n+\tret = create_remap_tree_entries(trans, path, bg);\n+\tif (unlikely(ret)) {\n+\t\tbtrfs_abort_transaction(trans, ret);\n+\t\tgoto end;\n+\t}\n+\n+\tspin_lock(&bg->lock);\n+\tbg->flags |= BTRFS_BLOCK_GROUP_REMAPPED;\n+\tspin_unlock(&bg->lock);\n+\n+\tspin_lock(&trans->transaction->dirty_bgs_lock);\n+\tif (list_empty(&bg->dirty_list)) {\n+\t\tlist_add_tail(&bg->dirty_list,\n+\t\t\t      &trans->transaction->dirty_bgs);\n+\t\tbg_already_dirty = false;\n+\t\tbtrfs_get_block_group(bg);\n+\t}\n+\tspin_unlock(&trans->transaction->dirty_bgs_lock);\n+\n+\t/* Modified block groups are accounted for in the delayed_refs_rsv. */\n+\tif (!bg_already_dirty)\n+\t\tbtrfs_inc_delayed_refs_rsv_bg_updates(fs_info);\n+\n+\tret = mark_chunk_remapped(trans, path, bg->start);\n+\tif (unlikely(ret)) {\n+\t\tbtrfs_abort_transaction(trans, ret);\n+\t\tgoto end;\n+\t}\n+\n+\tret = btrfs_remove_block_group_free_space(trans, bg);\n+\tif (unlikely(ret)) {\n+\t\tbtrfs_abort_transaction(trans, ret);\n+\t\tgoto end;\n+\t}\n+\n+\tbtrfs_remove_free_space_cache(bg);\n+\n+end:\n+\tmutex_unlock(&fs_info->remap_mutex);\n+\n+\tret2 = btrfs_end_transaction(trans);\n+\tif (!ret)\n+\t\tret = ret2;\n+\n+\treturn ret;\n+}\n+\n+static int do_nonremap_reloc(struct btrfs_fs_info *fs_info, bool verbose,\n+\t\t\t     struct reloc_control *rc)\n+{\n+\tint ret;\n+\n+\twhile (1) {\n+\t\tenum reloc_stage finishes_stage;\n+\n+\t\tmutex_lock(&fs_info->cleaner_mutex);\n+\t\tret = relocate_block_group(rc);\n+\t\tmutex_unlock(&fs_info->cleaner_mutex);\n+\n+\t\tfinishes_stage = rc->stage;\n+\t\t/*\n+\t\t * We may have gotten ENOSPC after we already dirtied some\n+\t\t * extents.  If writeout happens while we're relocating a\n+\t\t * different block group we could end up hitting the\n+\t\t * BUG_ON(rc->stage == UPDATE_DATA_PTRS) in\n+\t\t * btrfs_reloc_cow_block.  Make sure we write everything out\n+\t\t * properly so we don't trip over this problem, and then break\n+\t\t * out of the loop if we hit an error.\n+\t\t */\n+\t\tif (rc->stage == MOVE_DATA_EXTENTS && rc->found_file_extent) {\n+\t\t\tint wb_ret;\n+\n+\t\t\twb_ret = btrfs_wait_ordered_range(BTRFS_I(rc->data_inode),\n+\t\t\t\t\t\t\t\t0, (u64)-1);\n+\t\t\tif (wb_ret && ret == 0)\n+\t\t\t\tret = wb_ret;\n+\t\t\tinvalidate_mapping_pages(rc->data_inode->i_mapping,\n+\t\t\t\t\t\t\t0, -1);\n+\t\t\trc->stage = UPDATE_DATA_PTRS;\n+\t\t}\n+\n+\t\tif (ret < 0)\n+\t\t\treturn ret;\n+\n+\t\tif (rc->extents_found == 0)\n+\t\t\tbreak;\n+\n+\t\tif (verbose)\n+\t\t\tbtrfs_info(fs_info, \"found %llu extents, stage: %s\",\n+\t\t\t\t   rc->extents_found,\n+\t\t\t\t   stage_to_string(finishes_stage));\n+\t}\n+\n+\tWARN_ON(rc->block_group->pinned > 0);\n+\tWARN_ON(rc->block_group->reserved > 0);\n+\tWARN_ON(rc->block_group->used > 0);\n+\n+\treturn 0;\n+}\n+\n /*\n  * function to relocate all extents in a block group.\n  */\n@@ -4102,7 +4547,7 @@ int btrfs_relocate_block_group(struct btrfs_fs_info *fs_info, u64 group_start,\n \tstruct btrfs_root *extent_root = btrfs_extent_root(fs_info, group_start);\n \tstruct reloc_control *rc;\n \tstruct inode *inode;\n-\tstruct btrfs_path *path;\n+\tstruct btrfs_path *path = NULL;\n \tint ret;\n \tbool bg_is_ro = false;\n \n@@ -4164,7 +4609,7 @@ int btrfs_relocate_block_group(struct btrfs_fs_info *fs_info, u64 group_start,\n \t}\n \n \tinode = lookup_free_space_inode(rc->block_group, path);\n-\tbtrfs_free_path(path);\n+\tbtrfs_release_path(path);\n \n \tif (!IS_ERR(inode))\n \t\tret = delete_block_group_cache(rc->block_group, inode, 0);\n@@ -4174,11 +4619,13 @@ int btrfs_relocate_block_group(struct btrfs_fs_info *fs_info, u64 group_start,\n \tif (ret && ret != -ENOENT)\n \t\tgoto out;\n \n-\trc->data_inode = create_reloc_inode(rc->block_group);\n-\tif (IS_ERR(rc->data_inode)) {\n-\t\tret = PTR_ERR(rc->data_inode);\n-\t\trc->data_inode = NULL;\n-\t\tgoto out;\n+\tif (!btrfs_fs_incompat(fs_info, REMAP_TREE)) {\n+\t\trc->data_inode = create_reloc_inode(rc->block_group);\n+\t\tif (IS_ERR(rc->data_inode)) {\n+\t\t\tret = PTR_ERR(rc->data_inode);\n+\t\t\trc->data_inode = NULL;\n+\t\t\tgoto out;\n+\t\t}\n \t}\n \n \tif (verbose)\n@@ -4191,54 +4638,17 @@ int btrfs_relocate_block_group(struct btrfs_fs_info *fs_info, u64 group_start,\n \tret = btrfs_zone_finish(rc->block_group);\n \tWARN_ON(ret && ret != -EAGAIN);\n \n-\twhile (1) {\n-\t\tenum reloc_stage finishes_stage;\n-\n-\t\tmutex_lock(&fs_info->cleaner_mutex);\n-\t\tret = relocate_block_group(rc);\n-\t\tmutex_unlock(&fs_info->cleaner_mutex);\n-\n-\t\tfinishes_stage = rc->stage;\n-\t\t/*\n-\t\t * We may have gotten ENOSPC after we already dirtied some\n-\t\t * extents.  If writeout happens while we're relocating a\n-\t\t * different block group we could end up hitting the\n-\t\t * BUG_ON(rc->stage == UPDATE_DATA_PTRS) in\n-\t\t * btrfs_reloc_cow_block.  Make sure we write everything out\n-\t\t * properly so we don't trip over this problem, and then break\n-\t\t * out of the loop if we hit an error.\n-\t\t */\n-\t\tif (rc->stage == MOVE_DATA_EXTENTS && rc->found_file_extent) {\n-\t\t\tint wb_ret;\n-\n-\t\t\twb_ret = btrfs_wait_ordered_range(BTRFS_I(rc->data_inode), 0,\n-\t\t\t\t\t\t\t  (u64)-1);\n-\t\t\tif (wb_ret && ret == 0)\n-\t\t\t\tret = wb_ret;\n-\t\t\tinvalidate_mapping_pages(rc->data_inode->i_mapping,\n-\t\t\t\t\t\t 0, -1);\n-\t\t\trc->stage = UPDATE_DATA_PTRS;\n-\t\t}\n-\n-\t\tif (ret < 0)\n-\t\t\tgoto out;\n-\n-\t\tif (rc->extents_found == 0)\n-\t\t\tbreak;\n-\n-\t\tif (verbose)\n-\t\t\tbtrfs_info(fs_info, \"found %llu extents, stage: %s\",\n-\t\t\t\t   rc->extents_found,\n-\t\t\t\t   stage_to_string(finishes_stage));\n+\tif (should_relocate_using_remap_tree(bg)) {\n+\t\tret = start_block_group_remapping(fs_info, path, bg);\n+\t} else {\n+\t\tret = do_nonremap_reloc(fs_info, verbose, rc);\n \t}\n-\n-\tWARN_ON(rc->block_group->pinned > 0);\n-\tWARN_ON(rc->block_group->reserved > 0);\n-\tWARN_ON(rc->block_group->used > 0);\n out:\n \tif (ret && bg_is_ro)\n \t\tbtrfs_dec_block_group_ro(rc->block_group);\n-\tiput(rc->data_inode);\n+\tif (!btrfs_fs_incompat(fs_info, REMAP_TREE))\n+\t\tiput(rc->data_inode);\n+\tbtrfs_free_path(path);\n \treloc_chunk_end(fs_info);\n out_put_bg:\n \tbtrfs_put_block_group(bg);\n@@ -4432,7 +4842,7 @@ int btrfs_recover_relocation(struct btrfs_fs_info *fs_info)\n \n \tbtrfs_free_path(path);\n \n-\tif (ret == 0) {\n+\tif (ret == 0 && !btrfs_fs_incompat(fs_info, REMAP_TREE)) {\n \t\t/* cleanup orphan inode in data relocation tree */\n \t\tfs_root = btrfs_grab_root(fs_info->data_reloc_root);\n \t\tASSERT(fs_root);\ndiff --git a/fs/btrfs/relocation.h b/fs/btrfs/relocation.h\nindex 0f4874f815db..40d0a67f6f07 100644\n--- a/fs/btrfs/relocation.h\n+++ b/fs/btrfs/relocation.h\n@@ -12,6 +12,17 @@ struct btrfs_trans_handle;\n struct btrfs_ordered_extent;\n struct btrfs_pending_snapshot;\n \n+static inline bool should_relocate_using_remap_tree(struct btrfs_block_group *bg)\n+{\n+\tif (!btrfs_fs_incompat(bg->fs_info, REMAP_TREE))\n+\t\treturn false;\n+\n+\tif (bg->flags & (BTRFS_BLOCK_GROUP_SYSTEM | BTRFS_BLOCK_GROUP_METADATA_REMAP))\n+\t\treturn false;\n+\n+\treturn true;\n+}\n+\n int btrfs_relocate_block_group(struct btrfs_fs_info *fs_info, u64 group_start,\n \t\t\t       bool verbose);\n int btrfs_init_reloc_root(struct btrfs_trans_handle *trans, struct btrfs_root *root);\ndiff --git a/fs/btrfs/space-info.c b/fs/btrfs/space-info.c\nindex badebe6e0b34..45c4815b3854 100644\n--- a/fs/btrfs/space-info.c\n+++ b/fs/btrfs/space-info.c\n@@ -376,8 +376,13 @@ void btrfs_add_bg_to_space_info(struct btrfs_fs_info *info,\n \tfactor = btrfs_bg_type_to_factor(block_group->flags);\n \n \tspin_lock(&space_info->lock);\n-\tspace_info->total_bytes += block_group->length;\n-\tspace_info->disk_total += block_group->length * factor;\n+\n+\tif (!(block_group->flags & BTRFS_BLOCK_GROUP_REMAPPED) ||\n+\t    block_group->identity_remap_count != 0) {\n+\t\tspace_info->total_bytes += block_group->length;\n+\t\tspace_info->disk_total += block_group->length * factor;\n+\t}\n+\n \tspace_info->bytes_used += block_group->used;\n \tspace_info->disk_used += block_group->used * factor;\n \tspace_info->bytes_readonly += block_group->bytes_super;\ndiff --git a/fs/btrfs/volumes.c b/fs/btrfs/volumes.c\nindex 46c5acc96725..caffee6527b2 100644\n--- a/fs/btrfs/volumes.c\n+++ b/fs/btrfs/volumes.c\n@@ -3405,15 +3405,55 @@ int btrfs_remove_chunk(struct btrfs_trans_handle *trans, u64 chunk_offset)\n \treturn ret;\n }\n \n-int btrfs_relocate_chunk(struct btrfs_fs_info *fs_info, u64 chunk_offset,\n-\t\t\t bool verbose)\n+static int btrfs_relocate_chunk_finish(struct btrfs_fs_info *fs_info,\n+\t\t\t\t       struct btrfs_block_group *bg)\n {\n \tstruct btrfs_root *root = fs_info->chunk_root;\n \tstruct btrfs_trans_handle *trans;\n-\tstruct btrfs_block_group *block_group;\n \tu64 length;\n \tint ret;\n \n+\tbtrfs_discard_cancel_work(&fs_info->discard_ctl, bg);\n+\tlength = bg->length;\n+\tbtrfs_put_block_group(bg);\n+\n+\t/*\n+\t * On a zoned file system, discard the whole block group, this will\n+\t * trigger a REQ_OP_ZONE_RESET operation on the device zone. If\n+\t * resetting the zone fails, don't treat it as a fatal problem from the\n+\t * filesystem's point of view.\n+\t */\n+\tif (btrfs_is_zoned(fs_info)) {\n+\t\tret = btrfs_discard_extent(fs_info, bg->start, length,\n+\t\t\t\t\t   NULL);\n+\t\tif (ret)\n+\t\t\tbtrfs_info(fs_info,\n+\t\t\t\t   \"failed to reset zone %llu after relocation\",\n+\t\t\t\t   bg->start);\n+\t}\n+\n+\ttrans = btrfs_start_trans_remove_block_group(root->fs_info, bg->start);\n+\tif (IS_ERR(trans)) {\n+\t\tret = PTR_ERR(trans);\n+\t\tbtrfs_handle_fs_error(root->fs_info, ret, NULL);\n+\t\treturn ret;\n+\t}\n+\n+\t/*\n+\t * Step two, delete the device extents and the chunk tree entries.\n+\t */\n+\tret = btrfs_remove_chunk(trans, bg->start);\n+\tbtrfs_end_transaction(trans);\n+\n+\treturn ret;\n+}\n+\n+int btrfs_relocate_chunk(struct btrfs_fs_info *fs_info, u64 chunk_offset,\n+\t\t\t bool verbose)\n+{\n+\tstruct btrfs_block_group *block_group;\n+\tint ret;\n+\n \tif (btrfs_fs_incompat(fs_info, EXTENT_TREE_V2)) {\n \t\tbtrfs_err(fs_info,\n \t\t\t  \"relocate: not supported on extent tree v2 yet\");\n@@ -3451,38 +3491,15 @@ int btrfs_relocate_chunk(struct btrfs_fs_info *fs_info, u64 chunk_offset,\n \tblock_group = btrfs_lookup_block_group(fs_info, chunk_offset);\n \tif (!block_group)\n \t\treturn -ENOENT;\n-\tbtrfs_discard_cancel_work(&fs_info->discard_ctl, block_group);\n-\tlength = block_group->length;\n-\tbtrfs_put_block_group(block_group);\n-\n-\t/*\n-\t * On a zoned file system, discard the whole block group, this will\n-\t * trigger a REQ_OP_ZONE_RESET operation on the device zone. If\n-\t * resetting the zone fails, don't treat it as a fatal problem from the\n-\t * filesystem's point of view.\n-\t */\n-\tif (btrfs_is_zoned(fs_info)) {\n-\t\tret = btrfs_discard_extent(fs_info, chunk_offset, length, NULL);\n-\t\tif (ret)\n-\t\t\tbtrfs_info(fs_info,\n-\t\t\t\t\"failed to reset zone %llu after relocation\",\n-\t\t\t\tchunk_offset);\n-\t}\n \n-\ttrans = btrfs_start_trans_remove_block_group(root->fs_info,\n-\t\t\t\t\t\t     chunk_offset);\n-\tif (IS_ERR(trans)) {\n-\t\tret = PTR_ERR(trans);\n-\t\tbtrfs_handle_fs_error(root->fs_info, ret, NULL);\n-\t\treturn ret;\n+\tif (should_relocate_using_remap_tree(block_group)) {\n+\t\t/* If we're relocating using the remap tree we're now done. */\n+\t\tbtrfs_put_block_group(block_group);\n+\t\tret = 0;\n+\t} else {\n+\t\tret = btrfs_relocate_chunk_finish(fs_info, block_group);\n \t}\n \n-\t/*\n-\t * step two, delete the device extents and the\n-\t * chunk tree entries\n-\t */\n-\tret = btrfs_remove_chunk(trans, chunk_offset);\n-\tbtrfs_end_transaction(trans);\n \treturn ret;\n }\n \n@@ -4155,6 +4172,14 @@ static int __btrfs_balance(struct btrfs_fs_info *fs_info)\n \t\tchunk = btrfs_item_ptr(leaf, slot, struct btrfs_chunk);\n \t\tchunk_type = btrfs_chunk_type(leaf, chunk);\n \n+\t\t/* Check if chunk has already been fully relocated. */\n+\t\tif (chunk_type & BTRFS_BLOCK_GROUP_REMAPPED &&\n+\t\t    btrfs_chunk_num_stripes(leaf, chunk) == 0) {\n+\t\t\tbtrfs_release_path(path);\n+\t\t\tmutex_unlock(&fs_info->reclaim_bgs_lock);\n+\t\t\tgoto loop;\n+\t\t}\n+\n \t\tif (!counting) {\n \t\t\tspin_lock(&fs_info->balance_lock);\n \t\t\tbctl->stat.considered++;\n-- \n2.51.2\n\n\n\n---\n\nAdd a function btrfs_populate_fully_remapped_bgs_list() which gets\ncalled on mount, which looks for fully remapped block groups\n(i.e. identity_remap_count == 0) which haven't yet had their chunk\nstripes and device extents removed.\n\nThis happens when a filesystem is unmounted while async discard has not\nyet finished, as otherwise the data range occupied by the chunk stripes\nwould be permanently unusable.\n\nSigned-off-by: Mark Harmstone <mark@harmstone.com>\nReviewed-by: Boris Burkov <boris@bur.io>\n---\n fs/btrfs/block-group.c      | 79 +++++++++++++++++++++++++++++++++++++\n fs/btrfs/block-group.h      |  2 +\n fs/btrfs/disk-io.c          |  9 +++++\n fs/btrfs/free-space-cache.c | 18 +++++++++\n fs/btrfs/relocation.c       |  4 ++\n 5 files changed, 112 insertions(+)\n\ndiff --git a/fs/btrfs/block-group.c b/fs/btrfs/block-group.c\nindex 47454c22d6f4..1f5101f40b8c 100644\n--- a/fs/btrfs/block-group.c\n+++ b/fs/btrfs/block-group.c\n@@ -4815,6 +4815,11 @@ void btrfs_mark_bg_fully_remapped(struct btrfs_block_group *bg,\n \tstruct btrfs_fs_info *fs_info = trans->fs_info;\n \n \tif (btrfs_test_opt(fs_info, DISCARD_ASYNC)) {\n+\t\tspin_lock(&bg->lock);\n+\t\tset_bit(BLOCK_GROUP_FLAG_STRIPE_REMOVAL_PENDING,\n+\t\t\t&bg->runtime_flags);\n+\t\tspin_unlock(&bg->lock);\n+\n \t\tbtrfs_discard_queue_work(&fs_info->discard_ctl, bg);\n \t} else {\n \t\tspin_lock(&fs_info->unused_bgs_lock);\n@@ -4834,3 +4839,77 @@ void btrfs_mark_bg_fully_remapped(struct btrfs_block_group *bg,\n \t\tspin_unlock(&fs_info->unused_bgs_lock);\n \t}\n }\n+\n+/*\n+ * Compare the block group and chunk trees, and find any fully-remapped block\n+ * groups which haven't yet had their chunk stripes and device extents removed,\n+ * and put them on the fully_remapped_bgs list so this gets done.\n+ *\n+ * This happens when a block group becomes fully remapped, i.e. its last\n+ * identity mapping is removed, and the volume is unmounted before async\n+ * discard has finished. It's important this gets done as until it is the\n+ * chunk's stripes are dead space.\n+ */\n+int btrfs_populate_fully_remapped_bgs_list(struct btrfs_fs_info *fs_info)\n+{\n+\tstruct rb_node *node_bg, *node_chunk;\n+\n+\tnode_bg = rb_first_cached(&fs_info->block_group_cache_tree);\n+\tnode_chunk = rb_first_cached(&fs_info->mapping_tree);\n+\n+\twhile (node_bg && node_chunk) {\n+\t\tstruct btrfs_block_group *bg;\n+\t\tstruct btrfs_chunk_map *map;\n+\n+\t\tbg = rb_entry(node_bg, struct btrfs_block_group, cache_node);\n+\t\tmap = rb_entry(node_chunk, struct btrfs_chunk_map, rb_node);\n+\n+\t\tASSERT(bg->start == map->start);\n+\n+\t\tif (!(bg->flags & BTRFS_BLOCK_GROUP_REMAPPED))\n+\t\t\tgoto next;\n+\n+\t\tif (bg->identity_remap_count != 0)\n+\t\t\tgoto next;\n+\n+\t\tif (map->num_stripes == 0)\n+\t\t\tgoto next;\n+\n+\t\tspin_lock(&fs_info->unused_bgs_lock);\n+\n+\t\tif (list_empty(&bg->bg_list)) {\n+\t\t\tbtrfs_get_block_group(bg);\n+\t\t\tlist_add_tail(&bg->bg_list,\n+\t\t\t\t      &fs_info->fully_remapped_bgs);\n+\t\t} else {\n+\t\t\tlist_move_tail(&bg->bg_list,\n+\t\t\t\t       &fs_info->fully_remapped_bgs);\n+\t\t}\n+\n+\t\tspin_unlock(&fs_info->unused_bgs_lock);\n+\n+\t\t/*\n+\t\t * Ideally we'd want to call btrfs_discard_queue_work() here,\n+\t\t * but it'd do nothing as the discard worker hasn't been\n+\t\t * started yet.\n+\t\t *\n+\t\t * The block group will get added to the discard list when\n+\t\t * btrfs_handle_fully_remapped_bgs() gets called, when we\n+\t\t * commit the first transaction.\n+\t\t */\n+\t\tif (btrfs_test_opt(fs_info, DISCARD_ASYNC)) {\n+\t\t\tspin_lock(&bg->lock);\n+\t\t\tset_bit(BLOCK_GROUP_FLAG_STRIPE_REMOVAL_PENDING,\n+\t\t\t\t&bg->runtime_flags);\n+\t\t\tspin_unlock(&bg->lock);\n+\t\t}\n+\n+next:\n+\t\tnode_bg = rb_next(node_bg);\n+\t\tnode_chunk = rb_next(node_chunk);\n+\t}\n+\n+\tASSERT(!node_bg && !node_chunk);\n+\n+\treturn 0;\n+}\ndiff --git a/fs/btrfs/block-group.h b/fs/btrfs/block-group.h\nindex 3117cebf02f5..ccca6ee517a9 100644\n--- a/fs/btrfs/block-group.h\n+++ b/fs/btrfs/block-group.h\n@@ -94,6 +94,7 @@ enum btrfs_block_group_flags {\n \t */\n \tBLOCK_GROUP_FLAG_NEW,\n \tBLOCK_GROUP_FLAG_FULLY_REMAPPED,\n+\tBLOCK_GROUP_FLAG_STRIPE_REMOVAL_PENDING,\n };\n \n enum btrfs_caching_type {\n@@ -416,5 +417,6 @@ int btrfs_use_block_group_size_class(struct btrfs_block_group *bg,\n bool btrfs_block_group_should_use_size_class(const struct btrfs_block_group *bg);\n void btrfs_mark_bg_fully_remapped(struct btrfs_block_group *bg,\n \t\t\t\t  struct btrfs_trans_handle *trans);\n+int btrfs_populate_fully_remapped_bgs_list(struct btrfs_fs_info *fs_info);\n \n #endif /* BTRFS_BLOCK_GROUP_H */\ndiff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c\nindex ba500e3bf0d8..0491b799148f 100644\n--- a/fs/btrfs/disk-io.c\n+++ b/fs/btrfs/disk-io.c\n@@ -3613,6 +3613,15 @@ int __cold open_ctree(struct super_block *sb, struct btrfs_fs_devices *fs_device\n \t\tgoto fail_sysfs;\n \t}\n \n+\tif (btrfs_fs_incompat(fs_info, REMAP_TREE)) {\n+\t\tret = btrfs_populate_fully_remapped_bgs_list(fs_info);\n+\t\tif (ret) {\n+\t\t\tbtrfs_err(fs_info,\n+\t\t\t\"failed to populate fully_remapped_bgs list: %d\", ret);\n+\t\t\tgoto fail_sysfs;\n+\t\t}\n+\t}\n+\n \tbtrfs_zoned_reserve_data_reloc_bg(fs_info);\n \tbtrfs_free_zone_cache(fs_info);\n \ndiff --git a/fs/btrfs/free-space-cache.c b/fs/btrfs/free-space-cache.c\nindex e15fa8567f7c..7f7744a78de2 100644\n--- a/fs/btrfs/free-space-cache.c\n+++ b/fs/btrfs/free-space-cache.c\n@@ -3068,6 +3068,7 @@ bool btrfs_is_free_space_trimmed(struct btrfs_block_group *block_group)\n \tbool ret = true;\n \n \tif (block_group->flags & BTRFS_BLOCK_GROUP_REMAPPED &&\n+\t    !test_bit(BLOCK_GROUP_FLAG_STRIPE_REMOVAL_PENDING, &block_group->runtime_flags) &&\n \t    block_group->identity_remap_count == 0) {\n \t\treturn true;\n \t}\n@@ -3849,6 +3850,23 @@ void btrfs_trim_fully_remapped_block_group(struct btrfs_block_group *bg)\n \tconst u64 max_discard_size = READ_ONCE(discard_ctl->max_discard_size);\n \tu64 end = btrfs_block_group_end(bg);\n \n+\tif (!test_bit(BLOCK_GROUP_FLAG_STRIPE_REMOVAL_PENDING, &bg->runtime_flags)) {\n+\t\tbg->discard_cursor = end;\n+\n+\t\tif (bg->used == 0) {\n+\t\t\tspin_lock(&fs_info->unused_bgs_lock);\n+\t\t\tif (!list_empty(&bg->bg_list)) {\n+\t\t\t\tlist_del_init(&bg->bg_list);\n+\t\t\t\tbtrfs_put_block_group(bg);\n+\t\t\t}\n+\t\t\tspin_unlock(&fs_info->unused_bgs_lock);\n+\n+\t\t\tbtrfs_mark_bg_unused(bg);\n+\t\t}\n+\n+\t\treturn;\n+\t}\n+\n \tbytes = end - bg->discard_cursor;\n \n \tif (max_discard_size &&\ndiff --git a/fs/btrfs/relocation.c b/fs/btrfs/relocation.c\nindex 20cf0f7fd401..c3f1b7828179 100644\n--- a/fs/btrfs/relocation.c\n+++ b/fs/btrfs/relocation.c\n@@ -4785,6 +4785,10 @@ int btrfs_last_identity_remap_gone(struct btrfs_chunk_map *chunk_map,\n \n \tbtrfs_remove_bg_from_sinfo(bg);\n \n+\tspin_lock(&bg->lock);\n+\tclear_bit(BLOCK_GROUP_FLAG_STRIPE_REMOVAL_PENDING, &bg->runtime_flags);\n+\tspin_unlock(&bg->lock);\n+\n \tret = remove_chunk_stripes(trans, chunk_map, path);\n \tif (unlikely(ret)) {\n \t\tbtrfs_abort_transaction(trans, ret);\n-- \n2.51.2\n\n\n\n---\n\nBalancing the METADATA_REMAP chunk, i.e. the chunk in which the remap tree\nlives, is a special case.\n\nWe can't use the remap tree itself for this, as then we'd have no way to\nboostrap it on mount. And we can't use the pre-remap tree code for this\nas it relies on walking the extent tree, and we're not creating backrefs\nfor METADATA_REMAP chunks.\n\nSo instead, if a balance would relocate any METADATA_REMAP block groups, mark\nthose block groups as readonly and COW every leaf of the remap tree.\n\nThere's more sophisticated ways of doing this, such as only COWing nodes\nwithin a block group that's to be relocated, but they're fiddly and with\nlots of edge cases. Plus it's not anticipated that a) the number of\nMETADATA_REMAP chunks is going to be particularly large, or b) that users will\nwant to only relocate some of these chunks - the main use case here is\nto unbreak RAID conversion and device removal.\n\nSigned-off-by: Mark Harmstone <mark@harmstone.com>\nReviewed-by: Boris Burkov <boris@bur.io>\n---\n fs/btrfs/volumes.c | 159 +++++++++++++++++++++++++++++++++++++++++++--\n 1 file changed, 155 insertions(+), 4 deletions(-)\n\ndiff --git a/fs/btrfs/volumes.c b/fs/btrfs/volumes.c\nindex b0aef4d489e7..96a3c0752f91 100644\n--- a/fs/btrfs/volumes.c\n+++ b/fs/btrfs/volumes.c\n@@ -4000,8 +4000,11 @@ static bool should_balance_chunk(struct extent_buffer *leaf, struct btrfs_chunk\n \tstruct btrfs_balance_args *bargs = NULL;\n \tu64 chunk_type = btrfs_chunk_type(leaf, chunk);\n \n-\tif (chunk_type & BTRFS_BLOCK_GROUP_METADATA_REMAP)\n-\t\treturn false;\n+\t/* Treat METADATA_REMAP chunks as METADATA. */\n+\tif (chunk_type & BTRFS_BLOCK_GROUP_METADATA_REMAP) {\n+\t\tchunk_type &= ~BTRFS_BLOCK_GROUP_METADATA_REMAP;\n+\t\tchunk_type |= BTRFS_BLOCK_GROUP_METADATA;\n+\t}\n \n \t/* type filter */\n \tif (!((chunk_type & BTRFS_BLOCK_GROUP_TYPE_MASK) &\n@@ -4084,6 +4087,113 @@ static bool should_balance_chunk(struct extent_buffer *leaf, struct btrfs_chunk\n \treturn true;\n }\n \n+struct remap_chunk_info {\n+\tstruct list_head list;\n+\tu64 offset;\n+\tstruct btrfs_block_group *bg;\n+\tbool made_ro;\n+};\n+\n+static int cow_remap_tree(struct btrfs_trans_handle *trans,\n+\t\t\t  struct btrfs_path *path)\n+{\n+\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n+\tstruct btrfs_key key = { 0 };\n+\tint ret;\n+\n+\tret = btrfs_search_slot(trans, fs_info->remap_root, &key, path, 0, 1);\n+\tif (ret < 0)\n+\t\treturn ret;\n+\n+\twhile (true) {\n+\t\tret = btrfs_next_leaf(fs_info->remap_root, path);\n+\t\tif (ret < 0) {\n+\t\t\treturn ret;\n+\t\t} else if (ret > 0) {\n+\t\t\tret = 0;\n+\t\t\tbreak;\n+\t\t}\n+\n+\t\tbtrfs_item_key_to_cpu(path->nodes[0], &key, path->slots[0]);\n+\n+\t\tbtrfs_release_path(path);\n+\n+\t\tret = btrfs_search_slot(trans, fs_info->remap_root, &key, path,\n+\t\t\t\t\t0, 1);\n+\t\tif (ret < 0)\n+\t\t\tbreak;\n+\t}\n+\n+\treturn ret;\n+}\n+\n+static int balance_remap_chunks(struct btrfs_fs_info *fs_info,\n+\t\t\t\tstruct btrfs_path *path,\n+\t\t\t\tstruct list_head *chunks)\n+{\n+\tstruct remap_chunk_info *rci, *tmp;\n+\tstruct btrfs_trans_handle *trans;\n+\tint ret;\n+\n+\tlist_for_each_entry_safe(rci, tmp, chunks, list) {\n+\t\trci->bg = btrfs_lookup_block_group(fs_info, rci->offset);\n+\t\tif (!rci->bg) {\n+\t\t\tlist_del(&rci->list);\n+\t\t\tkfree(rci);\n+\t\t\tcontinue;\n+\t\t}\n+\n+\t\tret = btrfs_inc_block_group_ro(rci->bg, false);\n+\t\tif (ret)\n+\t\t\tgoto end;\n+\n+\t\trci->made_ro = true;\n+\t}\n+\n+\tif (list_empty(chunks))\n+\t\treturn 0;\n+\n+\ttrans = btrfs_start_transaction(fs_info->remap_root, 0);\n+\tif (IS_ERR(trans)) {\n+\t\tret = PTR_ERR(trans);\n+\t\tgoto end;\n+\t}\n+\n+\tmutex_lock(&fs_info->remap_mutex);\n+\n+\tret = cow_remap_tree(trans, path);\n+\n+\tmutex_unlock(&fs_info->remap_mutex);\n+\n+\tbtrfs_release_path(path);\n+\n+\tbtrfs_commit_transaction(trans);\n+\n+end:\n+\twhile (!list_empty(chunks)) {\n+\t\tbool is_unused;\n+\n+\t\trci = list_first_entry(chunks, struct remap_chunk_info, list);\n+\n+\t\tspin_lock(&rci->bg->lock);\n+\t\tis_unused = !btrfs_is_block_group_used(rci->bg);\n+\t\tspin_unlock(&rci->bg->lock);\n+\n+\t\tif (is_unused)\n+\t\t\tbtrfs_mark_bg_unused(rci->bg);\n+\n+\t\tif (rci->made_ro)\n+\t\t\tbtrfs_dec_block_group_ro(rci->bg);\n+\n+\t\tbtrfs_put_block_group(rci->bg);\n+\n+\t\tlist_del(&rci->list);\n+\t\tkfree(rci);\n+\t}\n+\n+\treturn ret;\n+}\n+\n static int __btrfs_balance(struct btrfs_fs_info *fs_info)\n {\n \tstruct btrfs_balance_control *bctl = fs_info->balance_ctl;\n@@ -4106,6 +4216,9 @@ static int __btrfs_balance(struct btrfs_fs_info *fs_info)\n \tu32 count_meta = 0;\n \tu32 count_sys = 0;\n \tint chunk_reserved = 0;\n+\tstruct remap_chunk_info *rci;\n+\tunsigned int num_remap_chunks = 0;\n+\tLIST_HEAD(remap_chunks);\n \n \tpath = btrfs_alloc_path();\n \tif (!path) {\n@@ -4204,7 +4317,8 @@ static int __btrfs_balance(struct btrfs_fs_info *fs_info)\n \t\t\t\tcount_data++;\n \t\t\telse if (chunk_type & BTRFS_BLOCK_GROUP_SYSTEM)\n \t\t\t\tcount_sys++;\n-\t\t\telse if (chunk_type & BTRFS_BLOCK_GROUP_METADATA)\n+\t\t\telse if (chunk_type & (BTRFS_BLOCK_GROUP_METADATA |\n+\t\t\t\t\t       BTRFS_BLOCK_GROUP_METADATA_REMAP))\n \t\t\t\tcount_meta++;\n \n \t\t\tgoto loop;\n@@ -4224,6 +4338,30 @@ static int __btrfs_balance(struct btrfs_fs_info *fs_info)\n \t\t\tgoto loop;\n \t\t}\n \n+\t\t/*\n+\t\t * Balancing METADATA_REMAP chunks takes place separately - add\n+\t\t * the details to a list so it can be processed later.\n+\t\t */\n+\t\tif (chunk_type & BTRFS_BLOCK_GROUP_METADATA_REMAP) {\n+\t\t\tmutex_unlock(&fs_info->reclaim_bgs_lock);\n+\n+\t\t\trci = kmalloc(sizeof(struct remap_chunk_info),\n+\t\t\t\t      GFP_NOFS);\n+\t\t\tif (!rci) {\n+\t\t\t\tret = -ENOMEM;\n+\t\t\t\tgoto error;\n+\t\t\t}\n+\n+\t\t\trci->offset = found_key.offset;\n+\t\t\trci->bg = NULL;\n+\t\t\trci->made_ro = false;\n+\t\t\tlist_add_tail(&rci->list, &remap_chunks);\n+\n+\t\t\tnum_remap_chunks++;\n+\n+\t\t\tgoto loop;\n+\t\t}\n+\n \t\tif (!chunk_reserved) {\n \t\t\t/*\n \t\t\t * We may be relocating the only data chunk we have,\n@@ -4263,11 +4401,24 @@ static int __btrfs_balance(struct btrfs_fs_info *fs_info)\n \t\tkey.offset = found_key.offset - 1;\n \t}\n \n+\tbtrfs_release_path(path);\n+\n \tif (counting) {\n-\t\tbtrfs_release_path(path);\n \t\tcounting = false;\n \t\tgoto again;\n \t}\n+\n+\tif (!list_empty(&remap_chunks)) {\n+\t\tret = balance_remap_chunks(fs_info, path, &remap_chunks);\n+\t\tif (ret == -ENOSPC)\n+\t\t\tenospc_errors++;\n+\n+\t\tif (!ret) {\n+\t\t\tspin_lock(&fs_info->balance_lock);\n+\t\t\tbctl->stat.completed += num_remap_chunks;\n+\t\t\tspin_unlock(&fs_info->balance_lock);\n+\t\t}\n+\t}\n error:\n \tif (enospc_errors) {\n \t\tbtrfs_info(fs_info, \"%d enospc errors during balance\",\n-- \n2.51.2\n\n\n\n---\n\nDiscard normally works by iterating over the free-space entries of a\nblock group. This doesn't work for fully-remapped block groups, as we\nremoved their free-space entries when we started relocation.\n\nFor sync discard, call btrfs_discard_extent() when we commit the\ntransaction in which the last identity remap was removed.\n\nFor async discard, add a new function btrfs_trim_fully_remapped_block_group()\nto be called by the discard worker, which iterates over the block\ngroup's range using the normal async discard rules. Once we reach the\nend, remove the chunk's stripes and device extents to get back its free\nspace.\n\nSigned-off-by: Mark Harmstone <mark@harmstone.com>\nReviewed-by: Boris Burkov <boris@bur.io>\n---\n fs/btrfs/block-group.c      | 29 ++++++++++---------\n fs/btrfs/block-group.h      |  1 +\n fs/btrfs/discard.c          | 57 ++++++++++++++++++++++++++++++++-----\n fs/btrfs/extent-tree.c      |  3 ++\n fs/btrfs/free-space-cache.c | 36 +++++++++++++++++++++++\n fs/btrfs/free-space-cache.h |  1 +\n 6 files changed, 107 insertions(+), 20 deletions(-)\n\ndiff --git a/fs/btrfs/block-group.c b/fs/btrfs/block-group.c\nindex 2b3fd80a690f..47454c22d6f4 100644\n--- a/fs/btrfs/block-group.c\n+++ b/fs/btrfs/block-group.c\n@@ -4814,20 +4814,23 @@ void btrfs_mark_bg_fully_remapped(struct btrfs_block_group *bg,\n {\n \tstruct btrfs_fs_info *fs_info = trans->fs_info;\n \n-\tspin_lock(&fs_info->unused_bgs_lock);\n+\tif (btrfs_test_opt(fs_info, DISCARD_ASYNC)) {\n+\t\tbtrfs_discard_queue_work(&fs_info->discard_ctl, bg);\n+\t} else {\n+\t\tspin_lock(&fs_info->unused_bgs_lock);\n \n-\t/*\n-\t * The block group might already be on the unused_bgs list, remove it\n-\t * if it is. It'll get readded after the async discard worker finishes,\n-\t * or in btrfs_handle_fully_remapped_bgs() if we're not using async\n-\t * discard.\n-\t */\n-\tif (!list_empty(&bg->bg_list))\n-\t\tlist_del(&bg->bg_list);\n-\telse\n-\t\tbtrfs_get_block_group(bg);\n+\t\t/*\n+\t\t * The block group might already be on the unused_bgs list,\n+\t\t * remove it if it is. It'll get readded after\n+\t\t * btrfs_handle_fully_remapped_bgs() finishes.\n+\t\t */\n+\t\tif (!list_empty(&bg->bg_list))\n+\t\t\tlist_del(&bg->bg_list);\n+\t\telse\n+\t\t\tbtrfs_get_block_group(bg);\n \n-\tlist_add_tail(&bg->bg_list, &fs_info->fully_remapped_bgs);\n+\t\tlist_add_tail(&bg->bg_list, &fs_info->fully_remapped_bgs);\n \n-\tspin_unlock(&fs_info->unused_bgs_lock);\n+\t\tspin_unlock(&fs_info->unused_bgs_lock);\n+\t}\n }\ndiff --git a/fs/btrfs/block-group.h b/fs/btrfs/block-group.h\nindex 3e8c3d424481..3117cebf02f5 100644\n--- a/fs/btrfs/block-group.h\n+++ b/fs/btrfs/block-group.h\n@@ -49,6 +49,7 @@ enum btrfs_discard_state {\n \tBTRFS_DISCARD_EXTENTS,\n \tBTRFS_DISCARD_BITMAPS,\n \tBTRFS_DISCARD_RESET_CURSOR,\n+\tBTRFS_DISCARD_FULLY_REMAPPED,\n };\n \n /*\ndiff --git a/fs/btrfs/discard.c b/fs/btrfs/discard.c\nindex ee5f5b2788e1..a3d7b7752518 100644\n--- a/fs/btrfs/discard.c\n+++ b/fs/btrfs/discard.c\n@@ -215,6 +215,27 @@ static struct btrfs_block_group *find_next_block_group(\n \treturn ret_block_group;\n }\n \n+/*\n+ * Returns whether a block group is empty.\n+ *\n+ * @bg: block group of interest\n+ *\n+ * \"Empty\" here means that there are no extents physically located within the\n+ * device extents corresponding to this block group.\n+ *\n+ * For a remapped block group, this means that all of its identity remaps have\n+ * been removed. For a non-remapped block group, this means that no extents\n+ * have an address within its range, and that nothing has been remapped to be\n+ * within it.\n+ */\n+static bool block_group_is_empty(struct btrfs_block_group *bg)\n+{\n+\tif (bg->flags & BTRFS_BLOCK_GROUP_REMAPPED)\n+\t\treturn bg->identity_remap_count == 0;\n+\telse\n+\t\treturn bg->used == 0 && bg->remap_bytes == 0;\n+}\n+\n /*\n  * Look up next block group and set it for use.\n  *\n@@ -241,8 +262,10 @@ static struct btrfs_block_group *peek_discard_list(\n \tblock_group = find_next_block_group(discard_ctl, now);\n \n \tif (block_group && now >= block_group->discard_eligible_time) {\n+\t\tbool empty = block_group_is_empty(block_group);\n+\n \t\tif (block_group->discard_index == BTRFS_DISCARD_INDEX_UNUSED &&\n-\t\t    block_group->used != 0) {\n+\t\t    !empty) {\n \t\t\tif (btrfs_is_block_group_data_only(block_group)) {\n \t\t\t\t__add_to_discard_list(discard_ctl, block_group);\n \t\t\t\t/*\n@@ -267,7 +290,15 @@ static struct btrfs_block_group *peek_discard_list(\n \t\t}\n \t\tif (block_group->discard_state == BTRFS_DISCARD_RESET_CURSOR) {\n \t\t\tblock_group->discard_cursor = block_group->start;\n-\t\t\tblock_group->discard_state = BTRFS_DISCARD_EXTENTS;\n+\n+\t\t\tif (block_group->flags & BTRFS_BLOCK_GROUP_REMAPPED &&\n+\t\t\t    empty) {\n+\t\t\t\tblock_group->discard_state =\n+\t\t\t\t\tBTRFS_DISCARD_FULLY_REMAPPED;\n+\t\t\t} else {\n+\t\t\t\tblock_group->discard_state =\n+\t\t\t\t\tBTRFS_DISCARD_EXTENTS;\n+\t\t\t}\n \t\t}\n \t}\n \tif (block_group) {\n@@ -373,7 +404,7 @@ void btrfs_discard_queue_work(struct btrfs_discard_ctl *discard_ctl,\n \tif (!block_group || !btrfs_test_opt(block_group->fs_info, DISCARD_ASYNC))\n \t\treturn;\n \n-\tif (block_group->used == 0 && block_group->remap_bytes == 0)\n+\tif (block_group_is_empty(block_group))\n \t\tadd_to_discard_unused_list(discard_ctl, block_group);\n \telse\n \t\tadd_to_discard_list(discard_ctl, block_group);\n@@ -470,7 +501,7 @@ static void btrfs_finish_discard_pass(struct btrfs_discard_ctl *discard_ctl,\n {\n \tremove_from_discard_list(discard_ctl, block_group);\n \n-\tif (block_group->used == 0) {\n+\tif (block_group_is_empty(block_group)) {\n \t\tif (btrfs_is_free_space_trimmed(block_group))\n \t\t\tbtrfs_mark_bg_unused(block_group);\n \t\telse\n@@ -524,7 +555,8 @@ static void btrfs_discard_workfn(struct work_struct *work)\n \t/* Perform discarding */\n \tminlen = discard_minlen[discard_index];\n \n-\tif (discard_state == BTRFS_DISCARD_BITMAPS) {\n+\tswitch (discard_state) {\n+\tcase BTRFS_DISCARD_BITMAPS: {\n \t\tu64 maxlen = 0;\n \n \t\t/*\n@@ -541,17 +573,28 @@ static void btrfs_discard_workfn(struct work_struct *work)\n \t\t\t\t       btrfs_block_group_end(block_group),\n \t\t\t\t       minlen, maxlen, true);\n \t\tdiscard_ctl->discard_bitmap_bytes += trimmed;\n-\t} else {\n+\n+\t\tbreak;\n+\t}\n+\n+\tcase BTRFS_DISCARD_FULLY_REMAPPED:\n+\t\tbtrfs_trim_fully_remapped_block_group(block_group);\n+\t\tbreak;\n+\n+\tdefault:\n \t\tbtrfs_trim_block_group_extents(block_group, &trimmed,\n \t\t\t\t       block_group->discard_cursor,\n \t\t\t\t       btrfs_block_group_end(block_group),\n \t\t\t\t       minlen, true);\n \t\tdiscard_ctl->discard_extent_bytes += trimmed;\n+\n+\t\tbreak;\n \t}\n \n \t/* Determine next steps for a block_group */\n \tif (block_group->discard_cursor >= btrfs_block_group_end(block_group)) {\n-\t\tif (discard_state == BTRFS_DISCARD_BITMAPS) {\n+\t\tif (discard_state == BTRFS_DISCARD_BITMAPS ||\n+\t\t    discard_state == BTRFS_DISCARD_FULLY_REMAPPED) {\n \t\t\tbtrfs_finish_discard_pass(discard_ctl, block_group);\n \t\t} else {\n \t\t\tblock_group->discard_cursor = block_group->start;\ndiff --git a/fs/btrfs/extent-tree.c b/fs/btrfs/extent-tree.c\nindex 9d68f3fa4fa9..7d010d480f7c 100644\n--- a/fs/btrfs/extent-tree.c\n+++ b/fs/btrfs/extent-tree.c\n@@ -2901,6 +2901,9 @@ void btrfs_handle_fully_remapped_bgs(struct btrfs_fs_info *fs_info)\n \t\tlist_del_init(&bg->bg_list);\n \t\tspin_unlock(&fs_info->unused_bgs_lock);\n \n+\t\tbtrfs_discard_extent(fs_info, bg->start, bg->length,\n+\t\t\t\t     NULL, false);\n+\n \t\tret = btrfs_complete_bg_remapping(bg);\n \t\tif (ret) {\n \t\t\tbtrfs_put_block_group(bg);\ndiff --git a/fs/btrfs/free-space-cache.c b/fs/btrfs/free-space-cache.c\nindex 17e79ee3e021..e15fa8567f7c 100644\n--- a/fs/btrfs/free-space-cache.c\n+++ b/fs/btrfs/free-space-cache.c\n@@ -29,6 +29,7 @@\n #include \"file-item.h\"\n #include \"file.h\"\n #include \"super.h\"\n+#include \"relocation.h\"\n \n #define BITS_PER_BITMAP\t\t(PAGE_SIZE * 8UL)\n #define MAX_CACHE_BYTES_PER_GIG\tSZ_64K\n@@ -3066,6 +3067,11 @@ bool btrfs_is_free_space_trimmed(struct btrfs_block_group *block_group)\n \tstruct rb_node *node;\n \tbool ret = true;\n \n+\tif (block_group->flags & BTRFS_BLOCK_GROUP_REMAPPED &&\n+\t    block_group->identity_remap_count == 0) {\n+\t\treturn true;\n+\t}\n+\n \tspin_lock(&ctl->tree_lock);\n \tnode = rb_first(&ctl->free_space_offset);\n \n@@ -3834,6 +3840,36 @@ static int trim_no_bitmap(struct btrfs_block_group *block_group,\n \treturn ret;\n }\n \n+void btrfs_trim_fully_remapped_block_group(struct btrfs_block_group *bg)\n+{\n+\tstruct btrfs_fs_info *fs_info = bg->fs_info;\n+\tstruct btrfs_discard_ctl *discard_ctl = &fs_info->discard_ctl;\n+\tint ret = 0;\n+\tu64 bytes, trimmed;\n+\tconst u64 max_discard_size = READ_ONCE(discard_ctl->max_discard_size);\n+\tu64 end = btrfs_block_group_end(bg);\n+\n+\tbytes = end - bg->discard_cursor;\n+\n+\tif (max_discard_size &&\n+\t\tbytes >= (max_discard_size +\n+\t\t\tBTRFS_ASYNC_DISCARD_MIN_FILTER)) {\n+\t\tbytes = max_discard_size;\n+\t}\n+\n+\tret = btrfs_discard_extent(fs_info, bg->discard_cursor, bytes, &trimmed,\n+\t\t\t\t   false);\n+\tif (ret)\n+\t\treturn;\n+\n+\tbg->discard_cursor += trimmed;\n+\n+\tif (bg->discard_cursor < end)\n+\t\treturn;\n+\n+\tbtrfs_complete_bg_remapping(bg);\n+}\n+\n /*\n  * If we break out of trimming a bitmap prematurely, we should reset the\n  * trimming bit.  In a rather contrived case, it's possible to race here so\ndiff --git a/fs/btrfs/free-space-cache.h b/fs/btrfs/free-space-cache.h\nindex 9f1dbfdee8ca..33fc3b245648 100644\n--- a/fs/btrfs/free-space-cache.h\n+++ b/fs/btrfs/free-space-cache.h\n@@ -166,6 +166,7 @@ int btrfs_trim_block_group_extents(struct btrfs_block_group *block_group,\n int btrfs_trim_block_group_bitmaps(struct btrfs_block_group *block_group,\n \t\t\t\t   u64 *trimmed, u64 start, u64 end, u64 minlen,\n \t\t\t\t   u64 maxlen, bool async);\n+void btrfs_trim_fully_remapped_block_group(struct btrfs_block_group *bg);\n \n bool btrfs_free_space_cache_v1_active(struct btrfs_fs_info *fs_info);\n int btrfs_set_free_space_cache_v1_active(struct btrfs_fs_info *fs_info, bool active);\n-- \n2.51.2\n\n\n\n---\n\nOn 23/01/2026 10.04 am, Filipe Manana wrote:\n> On Wed, Jan 21, 2026 at 10:24\\u202fPM David Sterba <dsterba@suse.cz> wrote:\n>>\n>> On Wed, Jan 07, 2026 at 02:09:00PM +0000, Mark Harmstone wrote:\n>>> This is version 8 of the patch series for the new logical remapping tree\n>>> feature - see the previous cover letters for more information including\n>>> the rationale:\n>>>\n>>> * RFC: https://lore.kernel.org/all/20250515163641.3449017-1-maharmstone@fb.com/\n>>> * Version 1: https://lore.kernel.org/all/20250605162345.2561026-1-maharmstone@fb.com/\n>>> * Version 2: https://lore.kernel.org/all/20250813143509.31073-1-mark@harmstone.com/\n>>> * Version 3: https://lore.kernel.org/all/20251009112814.13942-1-mark@harmstone.com/\n>>> * Version 4: https://lore.kernel.org/all/20251024181227.32228-1-mark@harmstone.com/\n>>> * Version 5: https://lore.kernel.org/all/20251110171511.20900-1-mark@harmstone.com/\n>>> * Version 6: https://lore.kernel.org/all/20251114184745.9304-1-mark@harmstone.com/\n>>> * Version 7: https://lore.kernel.org/all/20251124185335.16556-1-mark@harmstone.com/\n>>>\n>>> Changes since version 7:\n>>> * renamed struct btrfs_remap to struct btrfs_remap_item\n>>> * renamed BTRFS_BLOCK_GROUP_FLAGS_REMAP to BTRFS_BLOCK_GROUP_FLAGS_METADATA_REMAP\n>>> * added unlikelies\n>>> * renamed new commit_* fields in struct btrfs_block_group to last_*, and added\n>>>    new patch renaming existing commit_used to last_used to match\n>>> * merged do_copy() into copy_remapped_data()\n>>> * initialized on-stack struct btrfs_remap_items\n>>> * fixed comments\n>>> * added other minor changes as suggested by David Sterba\n>>>\n>>> Mark Harmstone (17):\n>>>    btrfs: add definitions and constants for remap-tree\n>>>    btrfs: add METADATA_REMAP chunk type\n>>>    btrfs: allow remapped chunks to have zero stripes\n>>>    btrfs: remove remapped block groups from the free-space tree\n>>>    btrfs: don't add metadata items for the remap tree to the extent tree\n>>>    btrfs: rename struct btrfs_block_group field commit_used to last_used\n>>>    btrfs: add extended version of struct block_group_item\n>>>    btrfs: allow mounting filesystems with remap-tree incompat flag\n>>>    btrfs: redirect I/O for remapped block groups\n>>>    btrfs: handle deletions from remapped block group\n>>>    btrfs: handle setting up relocation of block group with remap-tree\n>>>    btrfs: move existing remaps before relocating block group\n>>>    btrfs: replace identity remaps with actual remaps when doing\n>>>      relocations\n>>>    btrfs: add do_remap param to btrfs_discard_extent()\n>>>    btrfs: allow balancing remap tree\n>>>    btrfs: handle discarding fully-remapped block groups\n>>>    btrfs: populate fully_remapped_bgs_list on mount\n>>\n>> Patches have been added to for-next. There were many coding style issues\n>> which I've tried to fix. As this is a lot of new code it'll get updated\n>> anyway, I realized that for this kind of initial batch the coding\n>> style is quite important as we'd have to stick with until some random\n>> change touches it. Please have a look for the differences. Thanks.\n\nThanks David.\n\n> This is a huge amount of code and quite critical.\n> Shouldn't we have test cases in fstests to exercise this feature?\n> I didn't see any test cases submitted.\n\nIt is, but it's a no-op if the incompat flag set isn't set.\n\nThere will be fstests for this before I propose taking it out of \nEXPERIMENTAL.\n\n\n---\n\nClaude's right, and I made this mistake because I was copying the \n\"return -EINVAL\" a few lines lower down, which also leaks. I'll patch \nthem both.\n\nOn 25/01/2026 12.57 pm, Chris Mason wrote:\n> Mark Harmstone <mark@harmstone.com> wrote:\n>> Change btrfs_map_block() so that if the block group has the REMAPPED\n>> flag set, we call btrfs_translate_remap() to obtain a new address.\n>>\n>> btrfs_translate_remap() searches the remap tree for a range\n>> corresponding to the logical address passed to btrfs_map_block(). If it\n>> is within an identity remap, this part of the block group hasn't yet\n>> been relocated, and so we use the existing address.\n>>\n>> If it is within an actual remap, we subtract the start of the remap\n>> range and add the address of its destination, contained in the item's\n>> payload.\n>>\n> \n> Hi everyone,\n> \n> Another AI review from linux-next runs:\n> \n>> diff --git a/fs/btrfs/volumes.c b/fs/btrfs/volumes.c\n>> --- a/fs/btrfs/volumes.c\n>> +++ b/fs/btrfs/volumes.c\n>> @@ -6586,6 +6586,24 @@ struct btrfs_io_geometry io_geom = { 0 };\n>> \tif (IS_ERR(map))\n>> \t\treturn PTR_ERR(map);\n>>\n>> +\tif (map->type & BTRFS_BLOCK_GROUP_REMAPPED) {\n>> +\t\tu64 new_logical = logical;\n>> +\n>> +\t\tret = btrfs_translate_remap(fs_info, &new_logical, length);\n>> +\t\tif (ret)\n>> +\t\t\treturn ret;\n>                          ^^^^^^^^^^\n> \n> When btrfs_translate_remap() returns an error, does this leak the chunk\n> map? The map was obtained via btrfs_get_chunk_map() which increments a\n> refcount, and btrfs_get_chunk_map() documents that callers are\n> responsible for dropping the reference. The other error paths in this\n> function use goto out, which calls btrfs_free_chunk_map(map).\n> \n>> +\n>> +\t\tif (new_logical != logical) {\n>> +\t\t\tbtrfs_free_chunk_map(map);\n>> +\n>> +\t\t\tmap = btrfs_get_chunk_map(fs_info, new_logical, *length);\n>> +\t\t\tif (IS_ERR(map))\n>> +\t\t\t\treturn PTR_ERR(map);\n>> +\n>> +\t\t\tlogical = new_logical;\n>> +\t\t}\n>> +\t}\n> \n> [ ... ]\n\n\n",
          "reply_to": "",
          "message_date": ""
        }
      ],
      "analysis_source": "llm"
    },
    "2026-01-23": {
      "report_file": "2026-02-18_ollama_llama3.1-8b.html",
      "developer": "Mark Harmstone",
      "reviews": [
        {
          "author": "Filipe Manana",
          "summary": "Reviewer Filipe Manana raised concerns about the lack of test cases for the remap tree feature, suggesting that fstests should be updated to exercise this functionality.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes",
            "test cases"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "On Wed, Jan 21, 2026 at 10:24PM David Sterba <dsterba@suse.cz> wrote:\n>\n> On Wed, Jan 07, 2026 at 02:09:00PM +0000, Mark Harmstone wrote:\n> > This is version 8 of the patch series for the new logical remapping tree\n> > feature - see the previous cover letters for more information including\n> > the rationale:\n> >\n> > * RFC: https://lore.kernel.org/all/20250515163641.3449017-1-maharmstone@fb.com/\n> > * Version 1: https://lore.kernel.org/all/20250605162345.2561026-1-maharmstone@fb.com/\n> > * Version 2: https://lore.kernel.org/all/20250813143509.31073-1-mark@harmstone.com/\n> > * Version 3: https://lore.kernel.org/all/20251009112814.13942-1-mark@harmstone.com/\n> > * Version 4: https://lore.kernel.org/all/20251024181227.32228-1-mark@harmstone.com/\n> > * Version 5: https://lore.kernel.org/all/20251110171511.20900-1-mark@harmstone.com/\n> > * Version 6: https://lore.kernel.org/all/20251114184745.9304-1-mark@harmstone.com/\n> > * Version 7: https://lore.kernel.org/all/20251124185335.16556-1-mark@harmstone.com/\n> >\n> > Changes since version 7:\n> > * renamed struct btrfs_remap to struct btrfs_remap_item\n> > * renamed BTRFS_BLOCK_GROUP_FLAGS_REMAP to BTRFS_BLOCK_GROUP_FLAGS_METADATA_REMAP\n> > * added unlikelies\n> > * renamed new commit_* fields in struct btrfs_block_group to last_*, and added\n> >   new patch renaming existing commit_used to last_used to match\n> > * merged do_copy() into copy_remapped_data()\n> > * initialized on-stack struct btrfs_remap_items\n> > * fixed comments\n> > * added other minor changes as suggested by David Sterba\n> >\n> > Mark Harmstone (17):\n> >   btrfs: add definitions and constants for remap-tree\n> >   btrfs: add METADATA_REMAP chunk type\n> >   btrfs: allow remapped chunks to have zero stripes\n> >   btrfs: remove remapped block groups from the free-space tree\n> >   btrfs: don't add metadata items for the remap tree to the extent tree\n> >   btrfs: rename struct btrfs_block_group field commit_used to last_used\n> >   btrfs: add extended version of struct block_group_item\n> >   btrfs: allow mounting filesystems with remap-tree incompat flag\n> >   btrfs: redirect I/O for remapped block groups\n> >   btrfs: handle deletions from remapped block group\n> >   btrfs: handle setting up relocation of block group with remap-tree\n> >   btrfs: move existing remaps before relocating block group\n> >   btrfs: replace identity remaps with actual remaps when doing\n> >     relocations\n> >   btrfs: add do_remap param to btrfs_discard_extent()\n> >   btrfs: allow balancing remap tree\n> >   btrfs: handle discarding fully-remapped block groups\n> >   btrfs: populate fully_remapped_bgs_list on mount\n>\n> Patches have been added to for-next. There were many coding style issues\n> which I've tried to fix. As this is a lot of new code it'll get updated\n> anyway, I realized that for this kind of initial batch the coding\n> style is quite important as we'd have to stick with until some random\n> change touches it. Please have a look for the differences. Thanks.\n\nThis is a huge amount of code and quite critical.\nShouldn't we have test cases in fstests to exercise this feature?\nI didn't see any test cases submitted.\n\n>\n",
          "reply_to": "",
          "message_date": "2026-01-23"
        }
      ],
      "analysis_source": "llm"
    },
    "2026-01-25": {
      "report_file": "2026-02-18_ollama_llama3.1-8b.html",
      "developer": "Mark Harmstone",
      "reviews": [
        {
          "author": "Chris Mason",
          "summary": "Chris Mason raised several technical concerns about potential bugs and leaks in the patch, specifically regarding NULL pointer dereferences, transaction handle leaks, and missing error handling.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "potential bug",
            "leak"
          ],
          "has_inline_review": true,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Mark Harmstone <mark@harmstone.com> wrote:\n> Balancing the METADATA_REMAP chunk, i.e. the chunk in which the remap tree\n> lives, is a special case.\n> \n> We can't use the remap tree itself for this, as then we'd have no way to\n> boostrap it on mount. And we can't use the pre-remap tree code for this\n> as it relies on walking the extent tree, and we're not creating backrefs\n> for METADATA_REMAP chunks.\n> \n> So instead, if a balance would relocate any METADATA_REMAP block groups, mark\n> those block groups as readonly and COW every leaf of the remap tree.\n\nHi everyone,\n\nI ran my AI patch review prompts on linux-next, and this one was flagged.   As\nwe add more btrfs specifics we'll probably find some other fun, but this one\nseems right to me:\n\n>\n> diff --git a/fs/btrfs/volumes.c b/fs/btrfs/volumes.c\n> --- a/fs/btrfs/volumes.c\n> +++ b/fs/btrfs/volumes.c\n\n[ ... ]\n\n> +static int balance_remap_chunks(struct btrfs_fs_info *fs_info, struct btrfs_path *path,\n> +\t\t\t\tstruct list_head *chunks)\n> +{\n> +\tstruct remap_chunk_info *rci, *tmp;\n> +\tstruct btrfs_trans_handle *trans;\n> +\tint ret;\n> +\n> +\tlist_for_each_entry_safe(rci, tmp, chunks, list) {\n> +\t\trci->bg = btrfs_lookup_block_group(fs_info, rci->offset);\n> +\t\tif (!rci->bg) {\n> +\t\t\tlist_del(&rci->list);\n> +\t\t\tkfree(rci);\n> +\t\t\tcontinue;\n> +\t\t}\n> +\n> +\t\tret = btrfs_inc_block_group_ro(rci->bg, false);\n> +\t\tif (ret)\n> +\t\t\tgoto end;\n\nIf btrfs_inc_block_group_ro() fails here, the remaining entries in the\nlist still have rci->bg set to NULL (from the initialization in\n__btrfs_balance()). The goto jumps to the cleanup loop below.\n\n> +\n> +\t\trci->made_ro = true;\n> +\t}\n\n[ ... ]\n\n> +end:\n> +\twhile (!list_empty(chunks)) {\n> +\t\tbool is_unused;\n> +\n> +\t\trci = list_first_entry(chunks, struct remap_chunk_info, list);\n> +\n> +\t\tspin_lock(&rci->bg->lock);\n                         ^^^^^^^^\n\nCan this dereference a NULL pointer? When the loop above exits early\nvia goto end, the remaining rci entries in the list have rci->bg == NULL.\nThe cleanup loop then calls spin_lock(&rci->bg->lock) on these entries,\nwhich would crash the kernel.\n\n> +\t\tis_unused = !btrfs_is_block_group_used(rci->bg);\n> +\t\tspin_unlock(&rci->bg->lock);\n> +\n> +\t\tif (is_unused)\n> +\t\t\tbtrfs_mark_bg_unused(rci->bg);\n> +\n> +\t\tif (rci->made_ro)\n> +\t\t\tbtrfs_dec_block_group_ro(rci->bg);\n> +\n> +\t\tbtrfs_put_block_group(rci->bg);\n> +\n> +\t\tlist_del(&rci->list);\n> +\t\tkfree(rci);\n> +\t}\n> +\n> +\treturn ret;\n> +}\n\n[ ... ]\n\n> +\t\t\trci->offset = found_key.offset;\n> +\t\t\trci->bg = NULL;\n                                  ^^^^\n\nThis is where rci->bg is initialized to NULL. If balance_remap_chunks()\nfails partway through processing the list, these unprocessed entries\nstill have bg == NULL when the cleanup loop runs.\n\n[ ... ]\n\n\n\n---\n\nMark Harmstone <mark@harmstone.com> wrote:\n> If when relocating a block group we find that `remap_bytes` > 0 in its\n> block group item, that means that it has been the destination block\n> group for another that has been remapped.\n> \n> We need to seach the remap tree for any remap backrefs within this\n> range, and move the data to a third block group. This is because\n> otherwise btrfs_translate_remap() could end up following an unbounded\n> chain of remaps, which would only get worse over time.\n> \n> We only relocate one block group at a time, so `remap_bytes` will only\n> ever go down while we are doing this. Once we're finished we set the\n> REMAPPED flag on the block group, which will permanently prevent any\n> other data from being moved to within it.\n\nHi everyone,\n\nOne more AI review from linux-next, this looks valid to me:\n\n> diff --git a/fs/btrfs/relocation.c b/fs/btrfs/relocation.c\n> --- a/fs/btrfs/relocation.c\n> +++ b/fs/btrfs/relocation.c\n\n[ ... ]\n\n> +static int move_existing_remap(struct btrfs_fs_info *fs_info,\n> +\t\t\t       struct btrfs_path *path,\n> +\t\t\t       struct btrfs_block_group *bg, u64 new_addr,\n> +\t\t\t       u64 length, u64 old_addr)\n> +{\n\n[ ... ]\n\n> +\tdest_bg = btrfs_lookup_block_group(fs_info, dest_addr);\n> +\n> +\tadjust_block_group_remap_bytes(trans, dest_bg, dest_length);\n> +\n> +\tmutex_lock(&dest_bg->free_space_lock);\n> +\tbg_needs_free_space = test_bit(BLOCK_GROUP_FLAG_NEEDS_FREE_SPACE,\n> +\t\t\t\t       &dest_bg->runtime_flags);\n> +\tmutex_unlock(&dest_bg->free_space_lock);\n> +\tbtrfs_put_block_group(dest_bg);\n> +\n> +\tif (bg_needs_free_space) {\n> +\t\tret = btrfs_add_block_group_free_space(trans, dest_bg);\n                                                         ^^^^^^^\n\nIs there a use-after-free here? btrfs_put_block_group() is called above,\nwhich can free the block group if the refcount drops to zero. Then\nbtrfs_add_block_group_free_space() dereferences dest_bg by calling\nmutex_lock(&block_group->free_space_lock).\n\nPerhaps the btrfs_put_block_group() call should be moved after the\nconditional block that uses dest_bg?\n\n> +\t\tif (unlikely(ret))\n> +\t\t\tgoto end;\n> +\t}\n\n[ ... ]\n\n> +static int move_existing_remaps(struct btrfs_fs_info *fs_info,\n> +\t\t\t\tstruct btrfs_block_group *bg,\n> +\t\t\t\tstruct btrfs_path *path)\n> +{\n> +\tint ret;\n> +\tstruct btrfs_key key;\n> +\tstruct extent_buffer *leaf;\n> +\tstruct btrfs_remap_item *remap;\n> +\tu64 old_addr;\n> +\n> +\t/* Look for backrefs in remap tree. */\n> +\twhile (bg->remap_bytes > 0) {\n> +\t\tkey.objectid = bg->start;\n> +\t\tkey.type = BTRFS_REMAP_BACKREF_KEY;\n> +\t\tkey.offset = 0;\n> +\n> +\t\tret = btrfs_search_slot(NULL, fs_info->remap_root, &key, path, 0, 0);\n> +\t\tif (ret < 0)\n> +\t\t\treturn ret;\n> +\n> +\t\tleaf = path->nodes[0];\n> +\n> +\t\tif (path->slots[0] >= btrfs_header_nritems(leaf)) {\n> +\t\t\tret = btrfs_next_leaf(fs_info->remap_root, path);\n\n[ ... ]\n\n> +\t\t\tleaf = path->nodes[0];\n> +\t\t}\n> +\n> +\t\tbtrfs_item_key_to_cpu(leaf, &key, path->slots[0]);\n> +\n> +\t\tif (key.type != BTRFS_REMAP_BACKREF_KEY) {\n> +\t\t\tpath->slots[0]++;\n\nWhen the slot is incremented here because the key type does not match,\nshould the key be re-read from the new slot? The code below reads\nthe remap item from path->slots[0] (the incremented slot), but then\npasses key.objectid and key.offset (from the old slot) to\nmove_existing_remap().\n\nIf the key at the new slot has different objectid/offset values than\nthe previous slot, this would pass mismatched address and length values\nto move_existing_remap().\n\n> +\n> +\t\t\tif (path->slots[0] >= btrfs_header_nritems(leaf)) {\n> +\t\t\t\tret = btrfs_next_leaf(fs_info->remap_root, path);\n\n[ ... ]\n\n> +\t\t\t\tleaf = path->nodes[0];\n> +\t\t\t}\n> +\t\t}\n> +\n> +\t\tremap = btrfs_item_ptr(leaf, path->slots[0], struct btrfs_remap_item);\n> +\t\told_addr = btrfs_remap_address(leaf, remap);\n> +\n> +\t\tbtrfs_release_path(path);\n> +\n> +\t\tret = move_existing_remap(fs_info, path, bg, key.objectid,\n> +\t\t\t\t\t  key.offset, old_addr);\n\n[ ... ]\n\n\n\n---\n\nMark Harmstone <mark@harmstone.com> wrote:\n> Handle the case where we free an extent from a block group that has the\n> REMAPPED flag set. Because the remap tree is orthogonal to the extent\n> tree, for data this may be within any number of identity remaps or\n> actual remaps. If we're freeing a metadata node, this will be wholly\n> inside one or the other.\n> \n> btrfs_remove_extent_from_remap_tree() searches the remap tree for the\n> remaps that cover the range in question, then calls\n> remove_range_from_remap_tree() for each one, to punch a hole in the\n> remap and adjust the free-space tree.\n> \n> For an identity remap, remove_range_from_remap_tree() will adjust the\n> block group's `identity_remap_count` if this changes. If it reaches\n> zero we mark the block group as fully remapped.\n> \n> For an identity remap, remove_range_from_remap_tree() will adjust the\n> block group's `identity_remap_count` if this changes. If it reaches\n> zero we mark the block group as fully remapped.\n> \n> Fully remapped block groups have their chunk stripes removed and their\n> device extents freed, which makes the disk space available again to the\n> chunk allocator. This happens asynchronously: in the cleaner thread for\n> sync discard and nodiscard, and (in a later patch) in the discard worker\n> for async discard.\n\nHi everyone,\n\nAnother AI review from my recent linux-next run:\n\n> diff --git a/fs/btrfs/relocation.c b/fs/btrfs/relocation.c\n> --- a/fs/btrfs/relocation.c\n> +++ b/fs/btrfs/relocation.c\n\n[ ... ]\n\n> +int btrfs_last_identity_remap_gone(struct btrfs_chunk_map *chunk_map,\n> +\t\t\t\t   struct btrfs_block_group *bg)\n> +{\n> +\tstruct btrfs_fs_info *fs_info = bg->fs_info;\n> +\tstruct btrfs_trans_handle *trans;\n> +\tint ret;\n> +\tunsigned int num_items;\n> +\tBTRFS_PATH_AUTO_FREE(path);\n> +\n> +\tpath = btrfs_alloc_path();\n> +\tif (!path)\n> +\t\treturn -ENOMEM;\n> +\n> +\t/*\n> +\t * One item for each entry we're removing in the dev extents tree, and\n> +\t * another for each device. DUP chunks are all on one device,\n> +\t * everything else has one device per stripe.\n> +\t */\n> +\tif (bg->flags & BTRFS_BLOCK_GROUP_DUP)\n> +\t\tnum_items = chunk_map->num_stripes + 1;\n> +\telse\n> +\t\tnum_items = 2 * chunk_map->num_stripes;\n> +\n> +\ttrans = btrfs_start_transaction_fallback_global_rsv(fs_info->tree_root, num_items);\n> +\tif (IS_ERR(trans))\n> +\t\treturn PTR_ERR(trans);\n> +\n> +\tret = btrfs_remove_dev_extents(trans, chunk_map);\n> +\tif (unlikely(ret)) {\n> +\t\tbtrfs_abort_transaction(trans, ret);\n> +\t\treturn ret;\n> +\t}\n\nCan this leak the transaction handle? btrfs_abort_transaction() marks\nthe transaction as aborted but does not end it. __btrfs_abort_transaction()\nhas a comment explaining cleanup happens in btrfs_end_transaction().\n\n> +\n> +\tmutex_lock(&trans->fs_info->chunk_mutex);\n> +\tfor (unsigned int i = 0; i < chunk_map->num_stripes; i++) {\n> +\t\tret = btrfs_update_device(trans, chunk_map->stripes[i].dev);\n> +\t\tif (unlikely(ret)) {\n> +\t\t\tmutex_unlock(&trans->fs_info->chunk_mutex);\n> +\t\t\tbtrfs_abort_transaction(trans, ret);\n> +\t\t\treturn ret;\n> +\t\t}\n\nSame question here about leaking the transaction handle.\n\n> +\t}\n> +\tmutex_unlock(&trans->fs_info->chunk_mutex);\n> +\n> +\twrite_lock(&trans->fs_info->mapping_tree_lock);\n> +\tbtrfs_chunk_map_device_clear_bits(chunk_map, CHUNK_ALLOCATED);\n> +\twrite_unlock(&trans->fs_info->mapping_tree_lock);\n> +\n> +\tbtrfs_remove_bg_from_sinfo(bg);\n> +\n> +\tret = remove_chunk_stripes(trans, chunk_map, path);\n> +\tif (unlikely(ret)) {\n> +\t\tbtrfs_abort_transaction(trans, ret);\n> +\t\treturn ret;\n> +\t}\n\nAnd here as well - does this return path need btrfs_end_transaction()?\n\n> +\n> +\tret = btrfs_commit_transaction(trans);\n> +\tif (ret)\n> +\t\treturn ret;\n> +\n> +\treturn 0;\n> +}\n\n[ ... ]\n\n> +static int remove_range_from_remap_tree(struct btrfs_trans_handle *trans,\n> +\t\t\t\t\tstruct btrfs_path *path,\n> +\t\t\t\t\tstruct btrfs_block_group *bg,\n> +\t\t\t\t\tu64 hole_start, u64 hole_length)\n> +{\n\n[ ... ]\n\n> +\tif (!is_identity_remap) {\n> +\t\tstruct btrfs_block_group *dest_bg;\n> +\n> +\t\tdest_bg = btrfs_lookup_block_group(fs_info, new_addr);\n> +\t\tadjust_block_group_remap_bytes(trans, dest_bg, -overlap_length);\n> +\t\tbtrfs_put_block_group(dest_bg);\n\nbtrfs_lookup_block_group() can return NULL if no block group is found\nfor the address. Every other caller checks for NULL before using the\nresult. Is a NULL check needed here before passing dest_bg to\nadjust_block_group_remap_bytes()? That function does spin_lock(&bg->lock)\nwhich would crash on a NULL pointer.\n\n> +\t\tret = btrfs_add_to_free_space_tree(trans,\n> +\t\t\t\t\t\t   hole_start - remap_start + new_addr,\n> +\t\t\t\t\t\t   overlap_length);\n> +\t\tif (ret)\n> +\t\t\treturn ret;\n> +\t}\n\n[ ... ]\n\nThis is not a bug, but the commit message appears to have a duplicated\nparagraph about identity remaps:\n\n    For an identity remap, remove_range_from_remap_tree() will adjust the\n    block group's `identity_remap_count` if this changes. If it reaches\n    zero we mark the block group as fully remapped.\n\n    For an identity remap, remove_range_from_remap_tree() will adjust the\n    block group's `identity_remap_count` if this changes. If it reaches\n    zero we mark the block group as fully remapped.\n\n\n\n---\n\nMark Harmstone <mark@harmstone.com> wrote:\n> Change btrfs_map_block() so that if the block group has the REMAPPED\n> flag set, we call btrfs_translate_remap() to obtain a new address.\n> \n> btrfs_translate_remap() searches the remap tree for a range\n> corresponding to the logical address passed to btrfs_map_block(). If it\n> is within an identity remap, this part of the block group hasn't yet\n> been relocated, and so we use the existing address.\n> \n> If it is within an actual remap, we subtract the start of the remap\n> range and add the address of its destination, contained in the item's\n> payload.\n> \n\nHi everyone,\n\nAnother AI review from linux-next runs:\n\n> diff --git a/fs/btrfs/volumes.c b/fs/btrfs/volumes.c\n> --- a/fs/btrfs/volumes.c\n> +++ b/fs/btrfs/volumes.c\n> @@ -6586,6 +6586,24 @@ struct btrfs_io_geometry io_geom = { 0 };\n> \tif (IS_ERR(map))\n> \t\treturn PTR_ERR(map);\n>\n> +\tif (map->type & BTRFS_BLOCK_GROUP_REMAPPED) {\n> +\t\tu64 new_logical = logical;\n> +\n> +\t\tret = btrfs_translate_remap(fs_info, &new_logical, length);\n> +\t\tif (ret)\n> +\t\t\treturn ret;\n                        ^^^^^^^^^^\n\nWhen btrfs_translate_remap() returns an error, does this leak the chunk\nmap? The map was obtained via btrfs_get_chunk_map() which increments a\nrefcount, and btrfs_get_chunk_map() documents that callers are\nresponsible for dropping the reference. The other error paths in this\nfunction use goto out, which calls btrfs_free_chunk_map(map).\n\n> +\n> +\t\tif (new_logical != logical) {\n> +\t\t\tbtrfs_free_chunk_map(map);\n> +\n> +\t\t\tmap = btrfs_get_chunk_map(fs_info, new_logical, *length);\n> +\t\t\tif (IS_ERR(map))\n> +\t\t\t\treturn PTR_ERR(map);\n> +\n> +\t\t\tlogical = new_logical;\n> +\t\t}\n> +\t}\n\n[ ... ]\n",
          "reply_to": "",
          "message_date": "2026-01-25"
        }
      ],
      "analysis_source": "llm"
    }
  }
}