<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Review Comments: Re: [PATCH v23 10/22] cxl: Export function for unwinding cxl by accelerators</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
                         "Helvetica Neue", Arial, sans-serif;
            background: #f5f5f5;
            color: #333;
            line-height: 1.6;
            padding: 20px;
            max-width: 900px;
            margin: 0 auto;
        }
        .home-link { margin-bottom: 12px; display: block; }
        .home-link a { color: #0366d6; text-decoration: none; font-size: 0.9em; }
        .home-link a:hover { text-decoration: underline; }

        h1 { font-size: 1.3em; margin-bottom: 2px; color: #1a1a1a; line-height: 1.3; }

        .lore-link { font-size: 0.85em; margin: 4px 0 6px; display: block; }
        .lore-link a { color: #0366d6; text-decoration: none; }
        .lore-link a:hover { text-decoration: underline; }

        .date-range {
            font-size: 0.8em;
            color: #888;
            margin-bottom: 16px;
        }
        .date-range a { color: #0366d6; text-decoration: none; }
        .date-range a:hover { text-decoration: underline; }

        /* thread-node scroll margin so the card isn't clipped at the top */
        .thread-node { scroll-margin-top: 8px; }

        /* ── Patch summary ──────────────────────────────────────────── */
        .patch-summary-block {
            background: #fff;
            border-radius: 8px;
            padding: 12px 16px;
            margin-bottom: 20px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.08);
            border-left: 3px solid #4a90d9;
        }
        .patch-summary-label {
            font-size: 0.72em;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 0.06em;
            color: #4a90d9;
            margin-bottom: 4px;
        }
        .patch-summary-text {
            font-size: 0.88em;
            color: #444;
            line-height: 1.55;
        }

        /* ── Thread tree ────────────────────────────────────────────── */
        .thread-tree {
            display: flex;
            flex-direction: column;
            gap: 6px;
        }

        /* Depth indentation via left border */
        .thread-node { position: relative; }
        .thread-children {
            margin-left: 20px;
            padding-left: 12px;
            border-left: 2px solid #e0e0e0;
            margin-top: 6px;
            display: flex;
            flex-direction: column;
            gap: 6px;
        }

        /* ── Review comment card ────────────────────────────────────── */
        .review-comment {
            background: #fff;
            border-radius: 6px;
            padding: 10px 14px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.08);
            font-size: 0.88em;
        }
        .review-comment-header {
            display: flex;
            flex-wrap: wrap;
            align-items: center;
            gap: 6px;
            margin-bottom: 5px;
        }
        .review-author {
            font-weight: 700;
            color: #1a1a1a;
            font-size: 0.95em;
        }

        /* Date chip — links back to the daily report */
        .date-chip {
            font-size: 0.75em;
            color: #777;
            background: #f0f0f0;
            border-radius: 10px;
            padding: 1px 7px;
            text-decoration: none;
            white-space: nowrap;
        }
        a.date-chip:hover { background: #e0e8f5; color: #0366d6; }

        .badge {
            display: inline-block;
            padding: 1px 8px;
            border-radius: 10px;
            font-size: 0.75em;
            font-weight: 600;
        }
        .inline-review-badge {
            display: inline-block;
            padding: 0 6px;
            border-radius: 8px;
            font-size: 0.78em;
            font-weight: 500;
            background: #e3f2fd;
            color: #1565c0;
        }
        .review-tag-badge {
            display: inline-block;
            padding: 0 6px;
            border-radius: 8px;
            font-size: 0.78em;
            font-weight: 500;
            background: #e8f5e9;
            color: #2e7d32;
        }
        .analysis-source-badge {
            display: inline-block;
            padding: 1px 7px;
            border-radius: 10px;
            font-size: 0.72em;
            font-weight: 600;
            border: 1px solid rgba(0,0,0,0.1);
        }

        .review-comment-text {
            color: #444;
            line-height: 1.55;
            margin-bottom: 4px;
        }
        .review-comment-signals {
            margin-top: 3px;
            font-size: 0.85em;
            color: #aaa;
            font-style: italic;
        }

        /* ── Collapsible raw body ───────────────────────────────────── */
        .raw-body-toggle {
            margin-top: 5px;
            font-size: 0.85em;
        }
        .raw-body-toggle summary {
            cursor: pointer;
            color: #888;
            padding: 2px 0;
            font-weight: 500;
            font-size: 0.9em;
            list-style: none;
        }
        .raw-body-toggle summary::-webkit-details-marker { display: none; }
        .raw-body-toggle summary::before { content: "▶ "; font-size: 0.7em; }
        .raw-body-toggle[open] summary::before { content: "▼ "; }
        .raw-body-toggle summary:hover { color: #555; }
        .raw-body-text {
            white-space: pre-wrap;
            font-size: 0.95em;
            background: #f8f8f8;
            padding: 8px 10px;
            border-radius: 4px;
            max-height: 360px;
            overflow-y: auto;
            margin-top: 4px;
            line-height: 1.5;
            color: #444;
            border: 1px solid #e8e8e8;
        }

        .no-reviews {
            color: #aaa;
            font-size: 0.85em;
            font-style: italic;
            padding: 8px 0;
        }

        footer {
            text-align: center;
            color: #bbb;
            font-size: 0.78em;
            margin-top: 36px;
            padding: 16px;
        }
    </style>
</head>
<body>
    <div class="home-link"><a href="../">&larr; Back to reports</a></div>
    <h1>Re: [PATCH v23 10/22] cxl: Export function for unwinding cxl by accelerators</h1>
    <div class="lore-link"><a href="https://lore.kernel.org/all/aZk5CVRELS2qo92c@gourry-fedora-PF4VCD3F/" target="_blank">View on lore.kernel.org &rarr;</a></div>
    <div class="date-range">Active on: <a href="#2026-02-21">2026-02-21</a> &bull; <a href="#2026-02-20">2026-02-20</a> &bull; <a href="#2026-02-19">2026-02-19</a> &bull; <a href="#2026-02-16">2026-02-16</a> &bull; <a href="#2026-02-13">2026-02-13</a> &bull; <a href="#2026-02-12">2026-02-12</a> &bull; <a href="#2026-02-11">2026-02-11</a> &bull; <a href="#2026-02-01">2026-02-01</a></div>
    
    <div class="thread-tree">
<div class="thread-node depth-0" id="2026-02-01">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">alejandro.lucero-palau (author)</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-01">2026-02-01</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The author addressed a concern about differentiating between CXL memory expanders and device accelerators, explaining that they will add a new function for initializing cxl_dev_state and a macro to help accel drivers embed it in their private structs.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">From: Alejandro Lucero &lt;alucerop@amd.com&gt;

Differentiate CXL memory expanders (type 3) from CXL device accelerators
(type 2) with a new function for initializing cxl_dev_state and a macro
for helping accel drivers to embed cxl_dev_state inside a private
struct.

Move structs to include/cxl as the size of the accel driver private
struct embedding cxl_dev_state needs to know the size of this struct.

Use same new initialization with the type3 pci driver.

Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
Reviewed-by: Alison Schofield &lt;alison.schofield@intel.com&gt;
Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
---
 drivers/cxl/core/mbox.c      |  12 +-
 drivers/cxl/core/memdev.c    |  32 +++++
 drivers/cxl/cxl.h            |  97 +--------------
 drivers/cxl/cxlmem.h         |  86 +------------
 drivers/cxl/pci.c            |  14 +--
 include/cxl/cxl.h            | 226 +++++++++++++++++++++++++++++++++++
 tools/testing/cxl/test/mem.c |   3 +-
 7 files changed, 274 insertions(+), 196 deletions(-)
 create mode 100644 include/cxl/cxl.h

diff --git a/drivers/cxl/core/mbox.c b/drivers/cxl/core/mbox.c
index fa6dd0c94656..bee84d0101d1 100644
--- a/drivers/cxl/core/mbox.c
+++ b/drivers/cxl/core/mbox.c
@@ -1514,23 +1514,21 @@ int cxl_mailbox_init(struct cxl_mailbox *cxl_mbox, struct device *host)
 }
 EXPORT_SYMBOL_NS_GPL(cxl_mailbox_init, &quot;CXL&quot;);
 
-struct cxl_memdev_state *cxl_memdev_state_create(struct device *dev)
+struct cxl_memdev_state *cxl_memdev_state_create(struct device *dev, u64 serial,
+						 u16 dvsec)
 {
 	struct cxl_memdev_state *mds;
 	int rc;
 
-	mds = devm_kzalloc(dev, sizeof(*mds), GFP_KERNEL);
+	mds = devm_cxl_dev_state_create(dev, CXL_DEVTYPE_CLASSMEM, serial,
+					dvsec, struct cxl_memdev_state, cxlds,
+					true);
 	if (!mds) {
 		dev_err(dev, &quot;No memory available\n&quot;);
 		return ERR_PTR(-ENOMEM);
 	}
 
 	mutex_init(&amp;mds-&gt;event.log_lock);
-	mds-&gt;cxlds.dev = dev;
-	mds-&gt;cxlds.reg_map.host = dev;
-	mds-&gt;cxlds.cxl_mbox.host = dev;
-	mds-&gt;cxlds.reg_map.resource = CXL_RESOURCE_NONE;
-	mds-&gt;cxlds.type = CXL_DEVTYPE_CLASSMEM;
 
 	rc = devm_cxl_register_mce_notifier(dev, &amp;mds-&gt;mce_notifier);
 	if (rc == -EOPNOTSUPP)
diff --git a/drivers/cxl/core/memdev.c b/drivers/cxl/core/memdev.c
index af3d0cc65138..22d156f25305 100644
--- a/drivers/cxl/core/memdev.c
+++ b/drivers/cxl/core/memdev.c
@@ -656,6 +656,38 @@ static void detach_memdev(struct work_struct *work)
 
 static struct lock_class_key cxl_memdev_key;
 
+static void cxl_dev_state_init(struct cxl_dev_state *cxlds, struct device *dev,
+			       enum cxl_devtype type, u64 serial, u16 dvsec,
+			       bool has_mbox)
+{
+	*cxlds = (struct cxl_dev_state) {
+		.dev = dev,
+		.type = type,
+		.serial = serial,
+		.cxl_dvsec = dvsec,
+		.reg_map.host = dev,
+		.reg_map.resource = CXL_RESOURCE_NONE,
+	};
+
+	if (has_mbox)
+		cxlds-&gt;cxl_mbox.host = dev;
+}
+
+struct cxl_dev_state *_devm_cxl_dev_state_create(struct device *dev,
+						 enum cxl_devtype type,
+						 u64 serial, u16 dvsec,
+						 size_t size, bool has_mbox)
+{
+	struct cxl_dev_state *cxlds = devm_kzalloc(dev, size, GFP_KERNEL);
+
+	if (!cxlds)
+		return NULL;
+
+	cxl_dev_state_init(cxlds, dev, type, serial, dvsec, has_mbox);
+	return cxlds;
+}
+EXPORT_SYMBOL_NS_GPL(_devm_cxl_dev_state_create, &quot;CXL&quot;);
+
 static struct cxl_memdev *cxl_memdev_alloc(struct cxl_dev_state *cxlds,
 					   const struct file_operations *fops,
 					   const struct cxl_memdev_attach *attach)
diff --git a/drivers/cxl/cxl.h b/drivers/cxl/cxl.h
index e1d47062e1d3..3eaa353e430b 100644
--- a/drivers/cxl/cxl.h
+++ b/drivers/cxl/cxl.h
@@ -12,6 +12,7 @@
 #include &lt;linux/node.h&gt;
 #include &lt;linux/io.h&gt;
 #include &lt;linux/range.h&gt;
+#include &lt;cxl/cxl.h&gt;
 
 extern const struct nvdimm_security_ops *cxl_security_ops;
 
@@ -201,97 +202,6 @@ static inline int ways_to_eiw(unsigned int ways, u8 *eiw)
 #define   CXLDEV_MBOX_BG_CMD_COMMAND_VENDOR_MASK GENMASK_ULL(63, 48)
 #define CXLDEV_MBOX_PAYLOAD_OFFSET 0x20
 
-/*
- * Using struct_group() allows for per register-block-type helper routines,
- * without requiring block-type agnostic code to include the prefix.
- */
-struct cxl_regs {
-	/*
-	 * Common set of CXL Component register block base pointers
-	 * @hdm_decoder: CXL 2.0 8.2.5.12 CXL HDM Decoder Capability Structure
-	 * @ras: CXL 2.0 8.2.5.9 CXL RAS Capability Structure
-	 */
-	struct_group_tagged(cxl_component_regs, component,
-		void __iomem *hdm_decoder;
-		void __iomem *ras;
-	);
-	/*
-	 * Common set of CXL Device register block base pointers
-	 * @status: CXL 2.0 8.2.8.3 Device Status Registers
-	 * @mbox: CXL 2.0 8.2.8.4 Mailbox Registers
-	 * @memdev: CXL 2.0 8.2.8.5 Memory Device Registers
-	 */
-	struct_group_tagged(cxl_device_regs, device_regs,
-		void __iomem *status, *mbox, *memdev;
-	);
-
-	struct_group_tagged(cxl_pmu_regs, pmu_regs,
-		void __iomem *pmu;
-	);
-
-	/*
-	 * RCH downstream port specific RAS register
-	 * @aer: CXL 3.0 8.2.1.1 RCH Downstream Port RCRB
-	 */
-	struct_group_tagged(cxl_rch_regs, rch_regs,
-		void __iomem *dport_aer;
-	);
-
-	/*
-	 * RCD upstream port specific PCIe cap register
-	 * @pcie_cap: CXL 3.0 8.2.1.2 RCD Upstream Port RCRB
-	 */
-	struct_group_tagged(cxl_rcd_regs, rcd_regs,
-		void __iomem *rcd_pcie_cap;
-	);
-};
-
-struct cxl_reg_map {
-	bool valid;
-	int id;
-	unsigned long offset;
-	unsigned long size;
-};
-
-struct cxl_component_reg_map {
-	struct cxl_reg_map hdm_decoder;
-	struct cxl_reg_map ras;
-};
-
-struct cxl_device_reg_map {
-	struct cxl_reg_map status;
-	struct cxl_reg_map mbox;
-	struct cxl_reg_map memdev;
-};
-
-struct cxl_pmu_reg_map {
-	struct cxl_reg_map pmu;
-};
-
-/**
- * struct cxl_register_map - DVSEC harvested register block mapping parameters
- * @host: device for devm operations and logging
- * @base: virtual base of the register-block-BAR + @block_offset
- * @resource: physical resource base of the register block
- * @max_size: maximum mapping size to perform register search
- * @reg_type: see enum cxl_regloc_type
- * @component_map: cxl_reg_map for component registers
- * @device_map: cxl_reg_maps for device registers
- * @pmu_map: cxl_reg_maps for CXL Performance Monitoring Units
- */
-struct cxl_register_map {
-	struct device *host;
-	void __iomem *base;
-	resource_size_t resource;
-	resource_size_t max_size;
-	u8 reg_type;
-	union {
-		struct cxl_component_reg_map component_map;
-		struct cxl_device_reg_map device_map;
-		struct cxl_pmu_reg_map pmu_map;
-	};
-};
-
 void cxl_probe_component_regs(struct device *dev, void __iomem *base,
 			      struct cxl_component_reg_map *map);
 void cxl_probe_device_regs(struct device *dev, void __iomem *base,
@@ -497,11 +407,6 @@ struct cxl_region_params {
 	resource_size_t cache_size;
 };
 
-enum cxl_partition_mode {
-	CXL_PARTMODE_RAM,
-	CXL_PARTMODE_PMEM,
-};
-
 /*
  * Indicate whether this region has been assembled by autodetection or
  * userspace assembly. Prevent endpoint decoders outside of automatic
diff --git a/drivers/cxl/cxlmem.h b/drivers/cxl/cxlmem.h
index ef202b34e5ea..281546de426e 100644
--- a/drivers/cxl/cxlmem.h
+++ b/drivers/cxl/cxlmem.h
@@ -113,8 +113,6 @@ int devm_cxl_dpa_reserve(struct cxl_endpoint_decoder *cxled,
 			 resource_size_t base, resource_size_t len,
 			 resource_size_t skipped);
 
-#define CXL_NR_PARTITIONS_MAX 2
-
 struct cxl_dpa_info {
 	u64 size;
 	struct cxl_dpa_part_info {
@@ -373,87 +371,6 @@ struct cxl_security_state {
 	struct kernfs_node *sanitize_node;
 };
 
-/*
- * enum cxl_devtype - delineate type-2 from a generic type-3 device
- * @CXL_DEVTYPE_DEVMEM - Vendor specific CXL Type-2 device implementing HDM-D or
- *			 HDM-DB, no requirement that this device implements a
- *			 mailbox, or other memory-device-standard manageability
- *			 flows.
- * @CXL_DEVTYPE_CLASSMEM - Common class definition of a CXL Type-3 device with
- *			   HDM-H and class-mandatory memory device registers
- */
-enum cxl_devtype {
-	CXL_DEVTYPE_DEVMEM,
-	CXL_DEVTYPE_CLASSMEM,
-};
-
-/**
- * struct cxl_dpa_perf - DPA performance property entry
- * @dpa_range: range for DPA address
- * @coord: QoS performance data (i.e. latency, bandwidth)
- * @cdat_coord: raw QoS performance data from CDAT
- * @qos_class: QoS Class cookies
- */
-struct cxl_dpa_perf {
-	struct range dpa_range;
-	struct access_coordinate coord[ACCESS_COORDINATE_MAX];
-	struct access_coordinate cdat_coord[ACCESS_COORDINATE_MAX];
-	int qos_class;
-};
-
-/**
- * struct cxl_dpa_partition - DPA partition descriptor
- * @res: shortcut to the partition in the DPA resource tree (cxlds-&gt;dpa_res)
- * @perf: performance attributes of the partition from CDAT
- * @mode: operation mode for the DPA capacity, e.g. ram, pmem, dynamic...
- */
-struct cxl_dpa_partition {
-	struct resource res;
-	struct cxl_dpa_perf perf;
-	enum cxl_partition_mode mode;
-};
-
-/**
- * struct cxl_dev_state - The driver device state
- *
- * cxl_dev_state represents the CXL driver/device state.  It provides an
- * interface to mailbox commands as well as some cached data about the device.
- * Currently only memory devices are represented.
- *
- * @dev: The device associated with this CXL state
- * @cxlmd: The device representing the CXL.mem capabilities of @dev
- * @reg_map: component and ras register mapping parameters
- * @regs: Parsed register blocks
- * @cxl_dvsec: Offset to the PCIe device DVSEC
- * @rcd: operating in RCD mode (CXL 3.0 9.11.8 CXL Devices Attached to an RCH)
- * @media_ready: Indicate whether the device media is usable
- * @dpa_res: Overall DPA resource tree for the device
- * @part: DPA partition array
- * @nr_partitions: Number of DPA partitions
- * @serial: PCIe Device Serial Number
- * @type: Generic Memory Class device or Vendor Specific Memory device
- * @cxl_mbox: CXL mailbox context
- * @cxlfs: CXL features context
- */
-struct cxl_dev_state {
-	struct device *dev;
-	struct cxl_memdev *cxlmd;
-	struct cxl_register_map reg_map;
-	struct cxl_regs regs;
-	int cxl_dvsec;
-	bool rcd;
-	bool media_ready;
-	struct resource dpa_res;
-	struct cxl_dpa_partition part[CXL_NR_PARTITIONS_MAX];
-	unsigned int nr_partitions;
-	u64 serial;
-	enum cxl_devtype type;
-	struct cxl_mailbox cxl_mbox;
-#ifdef CONFIG_CXL_FEATURES
-	struct cxl_features_state *cxlfs;
-#endif
-};
-
 static inline resource_size_t cxl_pmem_size(struct cxl_dev_state *cxlds)
 {
 	/*
@@ -858,7 +775,8 @@ int cxl_dev_state_identify(struct cxl_memdev_state *mds);
 int cxl_await_media_ready(struct cxl_dev_state *cxlds);
 int cxl_enumerate_cmds(struct cxl_memdev_state *mds);
 int cxl_mem_dpa_fetch(struct cxl_memdev_state *mds, struct cxl_dpa_info *info);
-struct cxl_memdev_state *cxl_memdev_state_create(struct device *dev);
+struct cxl_memdev_state *cxl_memdev_state_create(struct device *dev, u64 serial,
+						 u16 dvsec);
 void set_exclusive_cxl_commands(struct cxl_memdev_state *mds,
 				unsigned long *cmds);
 void clear_exclusive_cxl_commands(struct cxl_memdev_state *mds,
diff --git a/drivers/cxl/pci.c b/drivers/cxl/pci.c
index 1cf232220873..24179cc702bf 100644
--- a/drivers/cxl/pci.c
+++ b/drivers/cxl/pci.c
@@ -911,25 +911,25 @@ static int cxl_pci_probe(struct pci_dev *pdev, const struct pci_device_id *id)
 	int rc, pmu_count;
 	unsigned int i;
 	bool irq_avail;
+	u16 dvsec;
 
 	rc = pcim_enable_device(pdev);
 	if (rc)
 		return rc;
 	pci_set_master(pdev);
 
-	mds = cxl_memdev_state_create(&amp;pdev-&gt;dev);
+	dvsec = pci_find_dvsec_capability(pdev, PCI_VENDOR_ID_CXL,
+					  PCI_DVSEC_CXL_DEVICE);
+	if (!dvsec)
+		pci_warn(pdev, &quot;Device DVSEC not present, skip CXL.mem init\n&quot;);
+
+	mds = cxl_memdev_state_create(&amp;pdev-&gt;dev, pci_get_dsn(pdev), dvsec);
 	if (IS_ERR(mds))
 		return PTR_ERR(mds);
 	cxlds = &amp;mds-&gt;cxlds;
 	pci_set_drvdata(pdev, cxlds);
 
 	cxlds-&gt;rcd = is_cxl_restricted(pdev);
-	cxlds-&gt;serial = pci_get_dsn(pdev);
-	cxlds-&gt;cxl_dvsec = pci_find_dvsec_capability(
-		pdev, PCI_VENDOR_ID_CXL, PCI_DVSEC_CXL_DEVICE);
-	if (!cxlds-&gt;cxl_dvsec)
-		dev_warn(&amp;pdev-&gt;dev,
-			 &quot;Device DVSEC not present, skip CXL.mem init\n&quot;);
 
 	rc = cxl_pci_setup_regs(pdev, CXL_REGLOC_RBI_MEMDEV, &amp;map);
 	if (rc)
diff --git a/include/cxl/cxl.h b/include/cxl/cxl.h
new file mode 100644
index 000000000000..13d448686189
--- /dev/null
+++ b/include/cxl/cxl.h
@@ -0,0 +1,226 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/* Copyright(c) 2020 Intel Corporation. */
+/* Copyright(c) 2025 Advanced Micro Devices, Inc. */
+
+#ifndef __CXL_CXL_H__
+#define __CXL_CXL_H__
+
+#include &lt;linux/node.h&gt;
+#include &lt;linux/ioport.h&gt;
+#include &lt;cxl/mailbox.h&gt;
+
+/**
+ * enum cxl_devtype - delineate type-2 from a generic type-3 device
+ * @CXL_DEVTYPE_DEVMEM: Vendor specific CXL Type-2 device implementing HDM-D or
+ *			 HDM-DB, no requirement that this device implements a
+ *			 mailbox, or other memory-device-standard manageability
+ *			 flows.
+ * @CXL_DEVTYPE_CLASSMEM: Common class definition of a CXL Type-3 device with
+ *			   HDM-H and class-mandatory memory device registers
+ */
+enum cxl_devtype {
+	CXL_DEVTYPE_DEVMEM,
+	CXL_DEVTYPE_CLASSMEM,
+};
+
+struct device;
+
+/*
+ * Using struct_group() allows for per register-block-type helper routines,
+ * without requiring block-type agnostic code to include the prefix.
+ */
+struct cxl_regs {
+	/*
+	 * Common set of CXL Component register block base pointers
+	 * @hdm_decoder: CXL 2.0 8.2.5.12 CXL HDM Decoder Capability Structure
+	 * @ras: CXL 2.0 8.2.5.9 CXL RAS Capability Structure
+	 */
+	struct_group_tagged(cxl_component_regs, component,
+		void __iomem *hdm_decoder;
+		void __iomem *ras;
+	);
+	/*
+	 * Common set of CXL Device register block base pointers
+	 * @status: CXL 2.0 8.2.8.3 Device Status Registers
+	 * @mbox: CXL 2.0 8.2.8.4 Mailbox Registers
+	 * @memdev: CXL 2.0 8.2.8.5 Memory Device Registers
+	 */
+	struct_group_tagged(cxl_device_regs, device_regs,
+		void __iomem *status, *mbox, *memdev;
+	);
+
+	struct_group_tagged(cxl_pmu_regs, pmu_regs,
+		void __iomem *pmu;
+	);
+
+	/*
+	 * RCH downstream port specific RAS register
+	 * @aer: CXL 3.0 8.2.1.1 RCH Downstream Port RCRB
+	 */
+	struct_group_tagged(cxl_rch_regs, rch_regs,
+		void __iomem *dport_aer;
+	);
+
+	/*
+	 * RCD upstream port specific PCIe cap register
+	 * @pcie_cap: CXL 3.0 8.2.1.2 RCD Upstream Port RCRB
+	 */
+	struct_group_tagged(cxl_rcd_regs, rcd_regs,
+		void __iomem *rcd_pcie_cap;
+	);
+};
+
+struct cxl_reg_map {
+	bool valid;
+	int id;
+	unsigned long offset;
+	unsigned long size;
+};
+
+struct cxl_component_reg_map {
+	struct cxl_reg_map hdm_decoder;
+	struct cxl_reg_map ras;
+};
+
+struct cxl_device_reg_map {
+	struct cxl_reg_map status;
+	struct cxl_reg_map mbox;
+	struct cxl_reg_map memdev;
+};
+
+struct cxl_pmu_reg_map {
+	struct cxl_reg_map pmu;
+};
+
+/**
+ * struct cxl_register_map - DVSEC harvested register block mapping parameters
+ * @host: device for devm operations and logging
+ * @base: virtual base of the register-block-BAR + @block_offset
+ * @resource: physical resource base of the register block
+ * @max_size: maximum mapping size to perform register search
+ * @reg_type: see enum cxl_regloc_type
+ * @component_map: cxl_reg_map for component registers
+ * @device_map: cxl_reg_maps for device registers
+ * @pmu_map: cxl_reg_maps for CXL Performance Monitoring Units
+ */
+struct cxl_register_map {
+	struct device *host;
+	void __iomem *base;
+	resource_size_t resource;
+	resource_size_t max_size;
+	u8 reg_type;
+	union {
+		struct cxl_component_reg_map component_map;
+		struct cxl_device_reg_map device_map;
+		struct cxl_pmu_reg_map pmu_map;
+	};
+};
+
+/**
+ * struct cxl_dpa_perf - DPA performance property entry
+ * @dpa_range: range for DPA address
+ * @coord: QoS performance data (i.e. latency, bandwidth)
+ * @cdat_coord: raw QoS performance data from CDAT
+ * @qos_class: QoS Class cookies
+ */
+struct cxl_dpa_perf {
+	struct range dpa_range;
+	struct access_coordinate coord[ACCESS_COORDINATE_MAX];
+	struct access_coordinate cdat_coord[ACCESS_COORDINATE_MAX];
+	int qos_class;
+};
+
+enum cxl_partition_mode {
+	CXL_PARTMODE_RAM,
+	CXL_PARTMODE_PMEM,
+};
+
+/**
+ * struct cxl_dpa_partition - DPA partition descriptor
+ * @res: shortcut to the partition in the DPA resource tree (cxlds-&gt;dpa_res)
+ * @perf: performance attributes of the partition from CDAT
+ * @mode: operation mode for the DPA capacity, e.g. ram, pmem, dynamic...
+ */
+struct cxl_dpa_partition {
+	struct resource res;
+	struct cxl_dpa_perf perf;
+	enum cxl_partition_mode mode;
+};
+
+#define CXL_NR_PARTITIONS_MAX 2
+
+/**
+ * struct cxl_dev_state - The driver device state
+ *
+ * cxl_dev_state represents the CXL driver/device state.  It provides an
+ * interface to mailbox commands as well as some cached data about the device.
+ * Currently only memory devices are represented.
+ *
+ * @dev: The device associated with this CXL state
+ * @cxlmd: The device representing the CXL.mem capabilities of @dev
+ * @reg_map: component and ras register mapping parameters
+ * @regs: Parsed register blocks
+ * @cxl_dvsec: Offset to the PCIe device DVSEC
+ * @rcd: operating in RCD mode (CXL 3.0 9.11.8 CXL Devices Attached to an RCH)
+ * @media_ready: Indicate whether the device media is usable
+ * @dpa_res: Overall DPA resource tree for the device
+ * @part: DPA partition array
+ * @nr_partitions: Number of DPA partitions
+ * @serial: PCIe Device Serial Number
+ * @type: Generic Memory Class device or Vendor Specific Memory device
+ * @cxl_mbox: CXL mailbox context
+ * @cxlfs: CXL features context
+ */
+struct cxl_dev_state {
+	/* public for Type2 drivers */
+	struct device *dev;
+	struct cxl_memdev *cxlmd;
+
+	/* private for Type2 drivers */
+	struct cxl_register_map reg_map;
+	struct cxl_regs regs;
+	int cxl_dvsec;
+	bool rcd;
+	bool media_ready;
+	struct resource dpa_res;
+	struct cxl_dpa_partition part[CXL_NR_PARTITIONS_MAX];
+	unsigned int nr_partitions;
+	u64 serial;
+	enum cxl_devtype type;
+	struct cxl_mailbox cxl_mbox;
+#ifdef CONFIG_CXL_FEATURES
+	struct cxl_features_state *cxlfs;
+#endif
+};
+
+struct cxl_dev_state *_devm_cxl_dev_state_create(struct device *dev,
+						 enum cxl_devtype type,
+						 u64 serial, u16 dvsec,
+						 size_t size, bool has_mbox);
+
+/**
+ * cxl_dev_state_create - safely create and cast a cxl dev state embedded in a
+ * driver specific struct.
+ *
+ * @parent: device behind the request
+ * @type: CXL device type
+ * @serial: device identification
+ * @dvsec: dvsec capability offset
+ * @drv_struct: driver struct embedding a cxl_dev_state struct
+ * @member: drv_struct member as cxl_dev_state
+ * @mbox: true if mailbox supported
+ *
+ * Returns a pointer to the drv_struct allocated and embedding a cxl_dev_state
+ * struct initialized.
+ *
+ * Introduced for Type2 driver support.
+ */
+#define devm_cxl_dev_state_create(parent, type, serial, dvsec, drv_struct, member, mbox)	\
+	({										\
+		static_assert(__same_type(struct cxl_dev_state,				\
+			      ((drv_struct *)NULL)-&gt;member));				\
+		static_assert(offsetof(drv_struct, member) == 0);			\
+		(drv_struct *)_devm_cxl_dev_state_create(parent, type, serial, dvsec,	\
+						      sizeof(drv_struct), mbox);	\
+	})
+#endif /* __CXL_CXL_H__ */
diff --git a/tools/testing/cxl/test/mem.c b/tools/testing/cxl/test/mem.c
index cb87e8c0e63c..79f42f4474d4 100644
--- a/tools/testing/cxl/test/mem.c
+++ b/tools/testing/cxl/test/mem.c
@@ -1716,7 +1716,7 @@ static int cxl_mock_mem_probe(struct platform_device *pdev)
 	if (rc)
 		return rc;
 
-	mds = cxl_memdev_state_create(dev);
+	mds = cxl_memdev_state_create(dev, pdev-&gt;id + 1, 0);
 	if (IS_ERR(mds))
 		return PTR_ERR(mds);
 
@@ -1732,7 +1732,6 @@ static int cxl_mock_mem_probe(struct platform_device *pdev)
 	mds-&gt;event.buf = (struct cxl_get_event_payload *) mdata-&gt;event_buf;
 	INIT_DELAYED_WORK(&amp;mds-&gt;security.poll_dwork, cxl_mockmem_sanitize_work);
 
-	cxlds-&gt;serial = pdev-&gt;id + 1;
 	if (is_rcd(pdev))
 		cxlds-&gt;rcd = true;
 
-- 
2.34.1</pre>
</details>
<div class="review-comment-signals">Signals: clarification, explanation</div>
</div>
<div class="thread-children">
<div class="thread-node depth-1" id="2026-02-11">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Cheatham, Benjamin</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-11">2026-02-11</a>
<span class="inline-review-badge">Inline Review</span>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Cheatham suggested moving the function call to be the first thing in the function, which would avoid acquiring a lock in cxl_region_can_probe() above.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Minor nit: Should probably move this to be the first thing in the function. It would save
having to acquire a lock in cxl_region_can_probe() above. Keep my reviewed-by either way,
it&#x27;s really just a minor optimization.</pre>
</details>
<div class="review-comment-signals">Signals: minor optimization</div>
</div>
<div class="thread-children">
<div class="thread-node depth-2" id="2026-02-12">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Alejandro Palau</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-12">2026-02-12</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer noted that the error inside sfc should not be fatal for cxl sfc initialization and suggested fallback to another cxl initialization possibility; also raised questions about handling multiple HDMs</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Hi Ben,


Yes, I think you are right. This works in my tests and it is safe 
because I check the region does exist before using it. But the error 
inside sfc should then not be fatal for cxl sfc initialization and 
fallback to the other cxl initialization possibility.


If I add the check for the decoder state, I guess I can keep the 
function names. If I rely on the region being there, I should change 
them. I will think about it.


This also brings the question of what is more than one hdm present. This 
is not needed in my use case and likely this is also true for other 
coming Type2 devices, but it does also require further thinking.


Thank you!</pre>
</details>
<div class="review-comment-signals">Signals: requested changes</div>
</div>
<div class="thread-children">
<div class="thread-node depth-3">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Cheatham, Benjamin</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-19">2026-02-19</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer questioned the use of unsigned int for interleave granularity/ways, suggesting it&#x27;s because negative values wouldn&#x27;t make sense, but agreed that using a smaller type is reasonable.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">If I had to guess unsigned int was used because a negative interleave granularity/ways makes no sense. I think your suggestion is fine though since no one
in their right mind would give anything but a (relatively) small and positive value for these.

Thanks,
Ben</pre>
</details>
<div class="review-comment-signals">Signals: NEEDS_WORK</div>
</div>
</div>
<div class="thread-node depth-3">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Cheatham, Benjamin</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-19">2026-02-19</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer suggested modifying the patch to address a previously noted issue by adding a small addition to enable CXL support, and requested that the decoder position be fixed in a separate patch (19/22). Additionally, he pointed out that the interleave_ways parameter in cxl_get_hpa_freespace() is currently unused.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">I&#x27;m fine with that, but I would at least do the fix with the decoder position in 19/22 and make a note that the
interleave_ways parameter in cxl_get_hpa_freespace() below is currently unused (unless I&#x27;m misunderstanding
the endpoint-&gt;host_bridge member).

That way, the support is mostly there and just requires a small, previously noted, addition to enable. If you&#x27;re
fine with that then feel free to add my Reviewed-by after implementing in v24.

Thanks,
Ben</pre>
</details>
<div class="review-comment-signals">Signals: requested changes</div>
</div>
</div>
</div>
</div>
<div class="thread-node depth-2" id="2026-02-19">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Alejandro Palau</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-19">2026-02-19</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Alejandro Palau expressed confusion about the original implementation of cxl support and requested changes for version 24.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Hi Ben,


I do not remember why this was done this way. Maybe some initial need 
which disappeared later.

I can not see a reason now, so I will do so in v24.


Thank you!</pre>
</details>
<div class="review-comment-signals">Signals: confusion, requested changes</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Alejandro Palau</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-19">2026-02-19</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer pointed out that the cxl_accel_unwind() function is not properly handling the case where the accelerator is already being reset, and suggested adding a check to ensure that the function only unwinds the accelerator if it&#x27;s not currently being reset.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Sure.

Thanks!</pre>
</details>
<div class="review-comment-signals">Signals: requested changes</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Alejandro Palau</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-19">2026-02-19</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Alejandro Palau expressed concern that the code does not support interleaving for Type2 accelerators, despite being trivial to implement, due to previous discussions and potential future use cases.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Hi Ben,


I do remember this one.


Dan&#x27;s original patches had this support for interleaving, then I removed 
it as the case for Type2 and interleaving is quite unlikely, at least 
right now and likely in the near future. But I was told why do not 
support it as it was trivial to do so. FWIW, If I think only about the 
use case coming with the patchset, I agree with you, but because those 
previous discussions, I think I have to leave it.


Thank you</pre>
</details>
<div class="review-comment-signals">Signals: previous discussions, potential future use cases</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Alejandro Palau</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-19">2026-02-19</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer noted that CXL initialization fails, leading to an earlier release of the modified struct, and requested further investigation.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">No, I do not think that is necessary. The CXL initialization fails, and 
the result is the modified struct will be released sooner or later.</pre>
</details>
<div class="review-comment-signals">Signals: failure, earlier release</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Alejandro Palau</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-19">2026-02-19</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer suggested replacing kstrtouint with kstrtoint to obtain values for cxl_region_params fields defined as int, considering the simplicity of this approach over modifying other places and structs.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Good catch. I wonder if I should just change the way the value is 
obtained, using kstrtoint instead of kstrtouint, as those values are 
used for cxl_region_params fields defined as int. In other words, it 
seems doing that simpler than changing all the other places you mention 
and the structs involved. I can not see a reason for using unsigned int 
so I think I will follow that approach. Tell me if you think otherwise.


Thank you</pre>
</details>
<div class="review-comment-signals">Signals: requested changes</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Alejandro Palau</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-19">2026-02-19</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Alejandro Palau acknowledged the issue and agreed to make the necessary corrections.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">That&#x27;s true. I will fix it.


Thank you!</pre>
</details>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Alejandro Palau</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-19">2026-02-19</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Alejandro Palau agreed to implement the requested change, indicating that they understand its purpose.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">It makes sense. I&#x27;ll do it.

Thanks</pre>
</details>
</div>
</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Cheatham, Benjamin</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-11">2026-02-11</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Cheatham questioned the complexity of the code and suggested simplification by removing the outer loop in cxl_get_hpa_freespace() since ctx-&gt;host_bridges is only set to one host bridge at that point, and also proposed changing ctx-&gt;host_bridges to a struct device * const.

The reviewer noted that interleave_ways is hardcoded to 1 and suggested removing this portion of the function or adding a doc comment explaining its current unused state.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">This may be over complicated. I&#x27;m not quite sure how it works (I&#x27;m just slow today I guess), but I understand
what the intention is based on the debug print below. My issue is that ctx-&gt;host_bridges is only set to 1 host
bridge (endpoint-&gt;host_bridge) in cxl_get_hpa_freespace(), which is the only caller of this function. At that
point, why have the outer loop at all? At that point, you could also simplify ctx-&gt;host_bridges to only
be a struct device * const.

Maybe this gets called elsewhere later on in the series? I haven&#x27;t looked at the rest yet. If I&#x27;m wrong, then
I&#x27;d probably add a comment saying what the cxlsd-&gt;target[] entries are supposed to be pointing at.

---

Mentioned earlier, interleave_ways is effectively hardcoded to 1 (unless I&#x27;m misunderstanding
something). I think what you want here is to go to the CXL root and pass in the children (i.e. host bridges)?
I&#x27;m not sure of what the fix is to get the intended behavior.

It may be worth getting rid of the interleave_ways portion of this function and
add it later when someone needs it. You could also explain it&#x27;s hard coded to 1/unused
in the doc comment if you know of an immediate need for it.</pre>
</details>
<div class="review-comment-signals">Signals: complexity, simplification, requested changes</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Cheatham, Benjamin</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-11">2026-02-11</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#155724;background:#d4edda">Positive</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Gave Reviewed-by</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; By definition a type2 cxl device will use the host managed memory for
&gt; specific functionality, therefore it should not be available to other
&gt; uses.
&gt; 
&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
&gt; Reviewed-by: Davidlohr Bueso &lt;daves@stgolabs.net&gt;
&gt; Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
&gt; Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
&gt; ---
&gt;  drivers/cxl/core/region.c | 7 +++++++
&gt;  1 file changed, 7 insertions(+)
&gt; 
&gt; diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
&gt; index 293e63dfef22..12df717cc881 100644
&gt; --- a/drivers/cxl/core/region.c
&gt; +++ b/drivers/cxl/core/region.c
&gt; @@ -4441,6 +4441,13 @@ static int cxl_region_probe(struct device *dev)
&gt;  	if (rc)
&gt;  		return rc;
&gt;  
&gt; +	/*
&gt; +	 * HDM-D[B] (device-memory) regions have accelerator specific usage.
&gt; +	 * Skip device-dax registration.
&gt; +	 */
&gt; +	if (cxlr-&gt;type == CXL_DECODER_DEVMEM)
&gt; +		return 0;

Minor nit: Should probably move this to be the first thing in the function. It would save
having to acquire a lock in cxl_region_can_probe() above. Keep my reviewed-by either way,
it&#x27;s really just a minor optimization.
&gt; +
&gt;  	/*
&gt;  	 * From this point on any path that changes the region&#x27;s state away from
&gt;  	 * CXL_CONFIG_COMMIT is also responsible for releasing the driver.



---

On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; CXL region creation involves allocating capacity from Device Physical
&gt; Address (DPA) and assigning it to decode a given Host Physical Address
&gt; (HPA). Before determining how much DPA to allocate the amount of available
&gt; HPA must be determined. Also, not all HPA is created equal, some HPA
&gt; targets RAM, some targets PMEM, some is prepared for device-memory flows
&gt; like HDM-D and HDM-DB, and some is HDM-H (host-only).
&gt; 
&gt; In order to support Type2 CXL devices, wrap all of those concerns into
&gt; an API that retrieves a root decoder (platform CXL window) that fits the
&gt; specified constraints and the capacity available for a new region.
&gt; 
&gt; Add a complementary function for releasing the reference to such root
&gt; decoder.
&gt; 
&gt; Based on https://lore.kernel.org/linux-cxl/168592159290.1948938.13522227102445462976.stgit@dwillia2-xfh.jf.intel.com/
&gt; 
&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
&gt; ---
&gt;  drivers/cxl/core/region.c | 164 ++++++++++++++++++++++++++++++++++++++
&gt;  drivers/cxl/cxl.h         |   3 +
&gt;  include/cxl/cxl.h         |   6 ++
&gt;  3 files changed, 173 insertions(+)
&gt; 
&gt; diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
&gt; index 954b8fcdbac6..bdefd088f5f1 100644
&gt; --- a/drivers/cxl/core/region.c
&gt; +++ b/drivers/cxl/core/region.c
&gt; @@ -705,6 +705,170 @@ static int free_hpa(struct cxl_region *cxlr)
&gt;  	return 0;
&gt;  }
&gt;  
&gt; +struct cxlrd_max_context {
&gt; +	struct device * const *host_bridges;
&gt; +	int interleave_ways;
&gt; +	unsigned long flags;
&gt; +	resource_size_t max_hpa;
&gt; +	struct cxl_root_decoder *cxlrd;
&gt; +};
&gt; +
&gt; +static int find_max_hpa(struct device *dev, void *data)
&gt; +{
&gt; +	struct cxlrd_max_context *ctx = data;
&gt; +	struct cxl_switch_decoder *cxlsd;
&gt; +	struct cxl_root_decoder *cxlrd;
&gt; +	struct resource *res, *prev;
&gt; +	struct cxl_decoder *cxld;
&gt; +	resource_size_t free = 0;
&gt; +	resource_size_t max;
&gt; +	int found = 0;
&gt; +
&gt; +	if (!is_root_decoder(dev))
&gt; +		return 0;
&gt; +
&gt; +	cxlrd = to_cxl_root_decoder(dev);
&gt; +	cxlsd = &amp;cxlrd-&gt;cxlsd;
&gt; +	cxld = &amp;cxlsd-&gt;cxld;
&gt; +
&gt; +	if ((cxld-&gt;flags &amp; ctx-&gt;flags) != ctx-&gt;flags) {
&gt; +		dev_dbg(dev, &quot;flags not matching: %08lx vs %08lx\n&quot;,
&gt; +			cxld-&gt;flags, ctx-&gt;flags);
&gt; +		return 0;
&gt; +	}
&gt; +
&gt; +	for (int i = 0; i &lt; ctx-&gt;interleave_ways; i++) {
&gt; +		for (int j = 0; j &lt; ctx-&gt;interleave_ways; j++) {
&gt; +			if (ctx-&gt;host_bridges[i] == cxlsd-&gt;target[j]-&gt;dport_dev) {
&gt; +				found++;
&gt; +				break;
&gt; +			}
&gt; +		}
&gt; +	}

This may be over complicated. I&#x27;m not quite sure how it works (I&#x27;m just slow today I guess), but I understand
what the intention is based on the debug print below. My issue is that ctx-&gt;host_bridges is only set to 1 host
bridge (endpoint-&gt;host_bridge) in cxl_get_hpa_freespace(), which is the only caller of this function. At that
point, why have the outer loop at all? At that point, you could also simplify ctx-&gt;host_bridges to only
be a struct device * const.

Maybe this gets called elsewhere later on in the series? I haven&#x27;t looked at the rest yet. If I&#x27;m wrong, then
I&#x27;d probably add a comment saying what the cxlsd-&gt;target[] entries are supposed to be pointing at.
&gt; +
&gt; +	if (found != ctx-&gt;interleave_ways) {
&gt; +		dev_dbg(dev,
&gt; +			&quot;Not enough host bridges. Found %d for %d interleave ways requested\n&quot;,
&gt; +			found, ctx-&gt;interleave_ways);
&gt; +		return 0;
&gt; +	}
&gt; +
&gt; +	/*
&gt; +	 * Walk the root decoder resource range relying on cxl_rwsem.region to
&gt; +	 * preclude sibling arrival/departure and find the largest free space
&gt; +	 * gap.
&gt; +	 */
&gt; +	lockdep_assert_held_read(&amp;cxl_rwsem.region);
&gt; +	res = cxlrd-&gt;res-&gt;child;
&gt; +
&gt; +	/* With no resource child the whole parent resource is available */
&gt; +	if (!res)
&gt; +		max = resource_size(cxlrd-&gt;res);
&gt; +	else
&gt; +		max = 0;
&gt; +
&gt; +	for (prev = NULL; res; prev = res, res = res-&gt;sibling) {
&gt; +		if (!prev &amp;&amp; res-&gt;start == cxlrd-&gt;res-&gt;start &amp;&amp;
&gt; +		    res-&gt;end == cxlrd-&gt;res-&gt;end) {
&gt; +			max = resource_size(cxlrd-&gt;res);
&gt; +			break;
&gt; +		}
&gt; +		/*
&gt; +		 * Sanity check for preventing arithmetic problems below as a
&gt; +		 * resource with size 0 could imply using the end field below
&gt; +		 * when set to unsigned zero - 1 or all f in hex.
&gt; +		 */
&gt; +		if (prev &amp;&amp; !resource_size(prev))
&gt; +			continue;
&gt; +
&gt; +		if (!prev &amp;&amp; res-&gt;start &gt; cxlrd-&gt;res-&gt;start) {
&gt; +			free = res-&gt;start - cxlrd-&gt;res-&gt;start;
&gt; +			max = max(free, max);
&gt; +		}
&gt; +		if (prev &amp;&amp; res-&gt;start &gt; prev-&gt;end + 1) {
&gt; +			free = res-&gt;start - prev-&gt;end + 1;
&gt; +			max = max(free, max);
&gt; +		}
&gt; +	}
&gt; +
&gt; +	if (prev &amp;&amp; prev-&gt;end + 1 &lt; cxlrd-&gt;res-&gt;end + 1) {
&gt; +		free = cxlrd-&gt;res-&gt;end + 1 - prev-&gt;end + 1;
&gt; +		max = max(free, max);
&gt; +	}
&gt; +
&gt; +	dev_dbg(cxlrd_dev(cxlrd), &quot;found %pa bytes of free space\n&quot;, &amp;max);
&gt; +	if (max &gt; ctx-&gt;max_hpa) {
&gt; +		if (ctx-&gt;cxlrd)
&gt; +			put_device(cxlrd_dev(ctx-&gt;cxlrd));
&gt; +		get_device(cxlrd_dev(cxlrd));
&gt; +		ctx-&gt;cxlrd = cxlrd;
&gt; +		ctx-&gt;max_hpa = max;
&gt; +	}
&gt; +	return 0;
&gt; +}
&gt; +
&gt; +/**
&gt; + * cxl_get_hpa_freespace - find a root decoder with free capacity per constraints
&gt; + * @cxlmd: the mem device requiring the HPA
&gt; + * @interleave_ways: number of entries in @host_bridges
&gt; + * @flags: CXL_DECODER_F flags for selecting RAM vs PMEM, and Type2 device
&gt; + * @max_avail_contig: output parameter of max contiguous bytes available in the
&gt; + *		      returned decoder
&gt; + *
&gt; + * Returns a pointer to a struct cxl_root_decoder
&gt; + *
&gt; + * The return tuple of a &#x27;struct cxl_root_decoder&#x27; and &#x27;bytes available given
&gt; + * in (@max_avail_contig))&#x27; is a point in time snapshot. If by the time the
&gt; + * caller goes to use this decoder and its capacity is reduced then caller needs
&gt; + * to loop and retry.
&gt; + *
&gt; + * The returned root decoder has an elevated reference count that needs to be
&gt; + * put with cxl_put_root_decoder(cxlrd).
&gt; + */
&gt; +struct cxl_root_decoder *cxl_get_hpa_freespace(struct cxl_memdev *cxlmd,
&gt; +					       int interleave_ways,
&gt; +					       unsigned long flags,
&gt; +					       resource_size_t *max_avail_contig)
&gt; +{
&gt; +	struct cxlrd_max_context ctx = {
&gt; +		.flags = flags,
&gt; +		.interleave_ways = interleave_ways,
&gt; +	};
&gt; +	struct cxl_port *root_port;
&gt; +	struct cxl_port *endpoint;
&gt; +
&gt; +	endpoint = cxlmd-&gt;endpoint;
&gt; +	if (!endpoint) {
&gt; +		dev_dbg(&amp;cxlmd-&gt;dev, &quot;endpoint not linked to memdev\n&quot;);
&gt; +		return ERR_PTR(-ENXIO);
&gt; +	}
&gt; +
&gt; +	ctx.host_bridges = &amp;endpoint-&gt;host_bridge;

Mentioned earlier, interleave_ways is effectively hardcoded to 1 (unless I&#x27;m misunderstanding
something). I think what you want here is to go to the CXL root and pass in the children (i.e. host bridges)?
I&#x27;m not sure of what the fix is to get the intended behavior.

It may be worth getting rid of the interleave_ways portion of this function and
add it later when someone needs it. You could also explain it&#x27;s hard coded to 1/unused
in the doc comment if you know of an immediate need for it.

&gt; +
&gt; +	struct cxl_root *root __free(put_cxl_root) = find_cxl_root(endpoint);
&gt; +	if (!root) {
&gt; +		dev_dbg(&amp;endpoint-&gt;dev, &quot;endpoint is not related to a root port\n&quot;);
&gt; +		return ERR_PTR(-ENXIO);
&gt; +	}
&gt; +
&gt; +	root_port = &amp;root-&gt;port;
&gt; +	scoped_guard(rwsem_read, &amp;cxl_rwsem.region)
&gt; +		device_for_each_child(&amp;root_port-&gt;dev, &amp;ctx, find_max_hpa);

Can just use a guard() here.

&gt; +
&gt; +	if (!ctx.cxlrd)
&gt; +		return ERR_PTR(-ENOMEM);
&gt; +
&gt; +	*max_avail_contig = ctx.max_hpa;
&gt; +	return ctx.cxlrd;
&gt; +}
&gt; +EXPORT_SYMBOL_NS_GPL(cxl_get_hpa_freespace, &quot;CXL&quot;);
&gt; +
&gt; +void cxl_put_root_decoder(struct cxl_root_decoder *cxlrd)
&gt; +{
&gt; +	put_device(cxlrd_dev(cxlrd));
&gt; +}
&gt; +EXPORT_SYMBOL_NS_GPL(cxl_put_root_decoder, &quot;CXL&quot;);
&gt; +
&gt;  static ssize_t size_store(struct device *dev, struct device_attribute *attr,
&gt;  			  const char *buf, size_t len)
&gt;  {
&gt; diff --git a/drivers/cxl/cxl.h b/drivers/cxl/cxl.h
&gt; index 944c5d1ccceb..c7d9b2c2908f 100644
&gt; --- a/drivers/cxl/cxl.h
&gt; +++ b/drivers/cxl/cxl.h
&gt; @@ -706,6 +706,9 @@ struct cxl_root_decoder *to_cxl_root_decoder(struct device *dev);
&gt;  struct cxl_switch_decoder *to_cxl_switch_decoder(struct device *dev);
&gt;  struct cxl_endpoint_decoder *to_cxl_endpoint_decoder(struct device *dev);
&gt;  bool is_root_decoder(struct device *dev);
&gt; +
&gt; +#define cxlrd_dev(cxlrd) (&amp;(cxlrd)-&gt;cxlsd.cxld.dev)
&gt; +
&gt;  bool is_switch_decoder(struct device *dev);
&gt;  bool is_endpoint_decoder(struct device *dev);
&gt;  struct cxl_root_decoder *cxl_root_decoder_alloc(struct cxl_port *port,
&gt; diff --git a/include/cxl/cxl.h b/include/cxl/cxl.h
&gt; index 92880c26b2d5..834dc7e78934 100644
&gt; --- a/include/cxl/cxl.h
&gt; +++ b/include/cxl/cxl.h
&gt; @@ -255,4 +255,10 @@ struct cxl_endpoint_decoder *cxl_get_committed_decoder(struct cxl_memdev *cxlmd,
&gt;  struct range;
&gt;  int cxl_get_region_range(struct cxl_region *region, struct range *range);
&gt;  void cxl_unregister_region(struct cxl_region *cxlr);
&gt; +struct cxl_port;
&gt; +struct cxl_root_decoder *cxl_get_hpa_freespace(struct cxl_memdev *cxlmd,
&gt; +					       int interleave_ways,
&gt; +					       unsigned long flags,
&gt; +					       resource_size_t *max);
&gt; +void cxl_put_root_decoder(struct cxl_root_decoder *cxlrd);
&gt;  #endif /* __CXL_CXL_H__ */



---

On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; Check if device HDM is already committed during firmware/BIOS
&gt; initialization.
&gt; 
&gt; A CXL region should exist if so after memdev allocation/initialization.
&gt; Get HPA from region and map it.
&gt; 
&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; ---
&gt;  drivers/net/ethernet/sfc/efx_cxl.c | 28 +++++++++++++++++++++++++++-
&gt;  1 file changed, 27 insertions(+), 1 deletion(-)
&gt; 
&gt; diff --git a/drivers/net/ethernet/sfc/efx_cxl.c b/drivers/net/ethernet/sfc/efx_cxl.c
&gt; index a77ef4783fcb..3536eccf1b2a 100644
&gt; --- a/drivers/net/ethernet/sfc/efx_cxl.c
&gt; +++ b/drivers/net/ethernet/sfc/efx_cxl.c
&gt; @@ -19,6 +19,7 @@ int efx_cxl_init(struct efx_probe_data *probe_data)
&gt;  	struct efx_nic *efx = &amp;probe_data-&gt;efx;
&gt;  	struct pci_dev *pci_dev = efx-&gt;pci_dev;
&gt;  	struct efx_cxl *cxl;
&gt; +	struct range range;
&gt;  	u16 dvsec;
&gt;  	int rc;
&gt;  
&gt; @@ -90,13 +91,38 @@ int efx_cxl_init(struct efx_probe_data *probe_data)
&gt;  		return PTR_ERR(cxl-&gt;cxlmd);
&gt;  	}
&gt;  
&gt; -	probe_data-&gt;cxl = cxl;
&gt; +	cxl-&gt;cxled = cxl_get_committed_decoder(cxl-&gt;cxlmd, &amp;cxl-&gt;efx_region);
&gt; +	if (cxl-&gt;cxled) {
&gt; +		if (!cxl-&gt;efx_region) {
&gt; +			pci_err(pci_dev, &quot;CXL found committed decoder without a region&quot;);
&gt; +			return -ENODEV;
&gt; +		}
&gt; +		rc = cxl_get_region_range(cxl-&gt;efx_region, &amp;range);

Missing an empty line above.

&gt; +		if (rc) {
&gt; +			pci_err(pci_dev,
&gt; +				&quot;CXL getting regions params from a committed decoder failed&quot;);
&gt; +			return rc;
&gt; +		}
&gt; +
&gt; +		cxl-&gt;ctpio_cxl = ioremap(range.start, range.end - range.start + 1);

Maybe use range_len() instead for the second parameter?

&gt; +		if (!cxl-&gt;ctpio_cxl) {
&gt; +			pci_err(pci_dev, &quot;CXL ioremap region (%pra) failed&quot;, &amp;range);
&gt; +			return -ENOMEM;
&gt; +		}
&gt; +
&gt; +		probe_data-&gt;cxl = cxl;
&gt; +	}
&gt;  
&gt;  	return 0;
&gt;  }
&gt;  
&gt;  void efx_cxl_exit(struct efx_probe_data *probe_data)
&gt;  {
&gt; +	if (!probe_data-&gt;cxl)
&gt; +		return;
&gt; +
&gt; +	iounmap(probe_data-&gt;cxl-&gt;ctpio_cxl);
&gt; +	cxl_unregister_region(probe_data-&gt;cxl-&gt;efx_region);
&gt;  }
&gt;  
&gt;  MODULE_IMPORT_NS(&quot;CXL&quot;);



---

On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; Region creation involves finding available DPA (device-physical-address)
&gt; capacity to map into HPA (host-physical-address) space.
&gt; 
&gt; In order to support CXL Type2 devices, define an API, cxl_request_dpa(),
&gt; that tries to allocate the DPA memory the driver requires to operate.The
&gt; memory requested should not be bigger than the max available HPA obtained
&gt; previously with cxl_get_hpa_freespace().
&gt; 
&gt; Based on https://lore.kernel.org/linux-cxl/168592158743.1948938.7622563891193802610.stgit@dwillia2-xfh.jf.intel.com/
&gt; 
&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
&gt; Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
&gt; ---
&gt;  drivers/cxl/core/hdm.c | 84 ++++++++++++++++++++++++++++++++++++++++++
&gt;  drivers/cxl/cxl.h      |  1 +
&gt;  include/cxl/cxl.h      |  5 +++
&gt;  3 files changed, 90 insertions(+)
&gt; 
&gt; diff --git a/drivers/cxl/core/hdm.c b/drivers/cxl/core/hdm.c
&gt; index a172ce4e9b19..d60a697f12cc 100644
&gt; --- a/drivers/cxl/core/hdm.c
&gt; +++ b/drivers/cxl/core/hdm.c
&gt; @@ -3,6 +3,7 @@
&gt;  #include &lt;linux/seq_file.h&gt;
&gt;  #include &lt;linux/device.h&gt;
&gt;  #include &lt;linux/delay.h&gt;
&gt; +#include &lt;cxl/cxl.h&gt;
&gt;  
&gt;  #include &quot;cxlmem.h&quot;
&gt;  #include &quot;core.h&quot;
&gt; @@ -546,6 +547,12 @@ bool cxl_resource_contains_addr(const struct resource *res, const resource_size_
&gt;  	return resource_contains(res, &amp;_addr);
&gt;  }
&gt;  
&gt; +/**
&gt; + * cxl_dpa_free - release DPA (Device Physical Address)
&gt; + * @cxled: endpoint decoder linked to the DPA
&gt; + *
&gt; + * Returns 0 or error.
&gt; + */
&gt;  int cxl_dpa_free(struct cxl_endpoint_decoder *cxled)
&gt;  {
&gt;  	struct cxl_port *port = cxled_to_port(cxled);
&gt; @@ -572,6 +579,7 @@ int cxl_dpa_free(struct cxl_endpoint_decoder *cxled)
&gt;  	devm_cxl_dpa_release(cxled);
&gt;  	return 0;
&gt;  }
&gt; +EXPORT_SYMBOL_NS_GPL(cxl_dpa_free, &quot;CXL&quot;);
&gt;  
&gt;  int cxl_dpa_set_part(struct cxl_endpoint_decoder *cxled,
&gt;  		     enum cxl_partition_mode mode)
&gt; @@ -603,6 +611,82 @@ int cxl_dpa_set_part(struct cxl_endpoint_decoder *cxled,
&gt;  	return 0;
&gt;  }
&gt;  
&gt; +static int find_free_decoder(struct device *dev, const void *data)
&gt; +{
&gt; +	struct cxl_endpoint_decoder *cxled;
&gt; +	struct cxl_port *port;
&gt; +
&gt; +	if (!is_endpoint_decoder(dev))
&gt; +		return 0;
&gt; +
&gt; +	cxled = to_cxl_endpoint_decoder(dev);
&gt; +	port = cxled_to_port(cxled);
&gt; +
&gt; +	return cxled-&gt;cxld.id == (port-&gt;hdm_end + 1);
&gt; +}
&gt; +
&gt; +static struct cxl_endpoint_decoder *
&gt; +cxl_find_free_decoder(struct cxl_memdev *cxlmd)
&gt; +{
&gt; +	struct cxl_port *endpoint = cxlmd-&gt;endpoint;
&gt; +	struct device *dev;
&gt; +
&gt; +	guard(rwsem_read)(&amp;cxl_rwsem.dpa);
&gt; +	dev = device_find_child(&amp;endpoint-&gt;dev, NULL,
&gt; +				find_free_decoder);
&gt; +	if (!dev)
&gt; +		return NULL;
&gt; +
&gt; +	return to_cxl_endpoint_decoder(dev);
&gt; +}
&gt; +
&gt; +/**
&gt; + * cxl_request_dpa - search and reserve DPA given input constraints
&gt; + * @cxlmd: memdev with an endpoint port with available decoders
&gt; + * @mode: CXL partition mode (ram vs pmem)
&gt; + * @alloc: dpa size required
&gt; + *
&gt; + * Returns a pointer to a &#x27;struct cxl_endpoint_decoder&#x27; on success or
&gt; + * an errno encoded pointer on failure.
&gt; + *
&gt; + * Given that a region needs to allocate from limited HPA capacity it
&gt; + * may be the case that a device has more mappable DPA capacity than
&gt; + * available HPA. The expectation is that @alloc is a driver known
&gt; + * value based on the device capacity but which could not be fully
&gt; + * available due to HPA constraints.
&gt; + *
&gt; + * Returns a pinned cxl_decoder with at least @alloc bytes of capacity
&gt; + * reserved, or an error pointer. The caller is also expected to own the
&gt; + * lifetime of the memdev registration associated with the endpoint to
&gt; + * pin the decoder registered as well.
&gt; + */
&gt; +struct cxl_endpoint_decoder *cxl_request_dpa(struct cxl_memdev *cxlmd,
&gt; +					     enum cxl_partition_mode mode,
&gt; +					     resource_size_t alloc)
&gt; +{
&gt; +	int rc;
&gt; +
&gt; +	if (!IS_ALIGNED(alloc, SZ_256M))
&gt; +		return ERR_PTR(-EINVAL);
&gt; +
&gt; +	struct cxl_endpoint_decoder *cxled __free(put_cxled) =
&gt; +		cxl_find_free_decoder(cxlmd);
&gt; +
&gt; +	if (!cxled)
&gt; +		return ERR_PTR(-ENODEV);
&gt; +
&gt; +	rc = cxl_dpa_set_part(cxled, mode);
&gt; +	if (rc)
&gt; +		return ERR_PTR(rc);
&gt; +
&gt; +	rc = cxl_dpa_alloc(cxled, alloc);
&gt; +	if (rc)
&gt; +		return ERR_PTR(rc);

Should cxl_dpa_set_part() be unwound here, or does it not matter? If it doesn&#x27;t matter:
Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
&gt; +
&gt; +	return no_free_ptr(cxled);
&gt; +}
&gt; +EXPORT_SYMBOL_NS_GPL(cxl_request_dpa, &quot;CXL&quot;);
&gt; +
&gt;  static int __cxl_dpa_alloc(struct cxl_endpoint_decoder *cxled, u64 size)
&gt;  {
&gt;  	struct cxl_memdev *cxlmd = cxled_to_memdev(cxled);
&gt; diff --git a/drivers/cxl/cxl.h b/drivers/cxl/cxl.h
&gt; index d1b010e5e1d0..2b1f7d687a0e 100644
&gt; --- a/drivers/cxl/cxl.h
&gt; +++ b/drivers/cxl/cxl.h
&gt; @@ -667,6 +667,7 @@ struct cxl_root *find_cxl_root(struct cxl_port *port);
&gt;  
&gt;  DEFINE_FREE(put_cxl_root, struct cxl_root *, if (_T) put_device(&amp;_T-&gt;port.dev))
&gt;  DEFINE_FREE(put_cxl_port, struct cxl_port *, if (!IS_ERR_OR_NULL(_T)) put_device(&amp;_T-&gt;dev))
&gt; +DEFINE_FREE(put_cxled, struct cxl_endpoint_decoder *, if (!IS_ERR_OR_NULL(_T)) put_device(&amp;_T-&gt;cxld.dev))
&gt;  DEFINE_FREE(put_cxl_root_decoder, struct cxl_root_decoder *, if (!IS_ERR_OR_NULL(_T)) put_device(&amp;_T-&gt;cxlsd.cxld.dev))
&gt;  DEFINE_FREE(put_cxl_region, struct cxl_region *, if (!IS_ERR_OR_NULL(_T)) put_device(&amp;_T-&gt;dev))
&gt;  
&gt; diff --git a/include/cxl/cxl.h b/include/cxl/cxl.h
&gt; index 783ad570a6eb..4802371db00e 100644
&gt; --- a/include/cxl/cxl.h
&gt; +++ b/include/cxl/cxl.h
&gt; @@ -7,6 +7,7 @@
&gt;  
&gt;  #include &lt;linux/node.h&gt;
&gt;  #include &lt;linux/ioport.h&gt;
&gt; +#include &lt;linux/range.h&gt;
&gt;  #include &lt;cxl/mailbox.h&gt;
&gt;  
&gt;  /**
&gt; @@ -276,4 +277,8 @@ struct cxl_root_decoder *cxl_get_hpa_freespace(struct cxl_memdev *cxlmd,
&gt;  					       unsigned long flags,
&gt;  					       resource_size_t *max);
&gt;  void cxl_put_root_decoder(struct cxl_root_decoder *cxlrd);
&gt; +struct cxl_endpoint_decoder *cxl_request_dpa(struct cxl_memdev *cxlmd,
&gt; +					     enum cxl_partition_mode mode,
&gt; +					     resource_size_t alloc);
&gt; +int cxl_dpa_free(struct cxl_endpoint_decoder *cxled);
&gt;  #endif /* __CXL_CXL_H__ */



---

On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; Current code is expecting Type3 or CXL_DECODER_HOSTONLYMEM devices only.
&gt; Support for Type2 implies region type needs to be based on the endpoint
&gt; type HDM-D[B] instead.
&gt; 
&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; Reviewed-by: Zhi Wang &lt;zhiw@nvidia.com&gt;
&gt; Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
&gt; Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
&gt; Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
&gt; Reviewed-by: Alison Schofield &lt;alison.schofield@intel.com&gt;
&gt; Reviewed-by: Davidlohr Bueso &lt;daves@stgolabs.net&gt;
&gt; ---
&gt;  drivers/cxl/core/region.c | 10 ++++++----
&gt;  1 file changed, 6 insertions(+), 4 deletions(-)
&gt; 
&gt; diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
&gt; index bdefd088f5f1..f53b2e9fd9e6 100644
&gt; --- a/drivers/cxl/core/region.c
&gt; +++ b/drivers/cxl/core/region.c
&gt; @@ -2833,7 +2833,8 @@ static ssize_t create_ram_region_show(struct device *dev,
&gt;  }
&gt;  
&gt;  static struct cxl_region *__create_region(struct cxl_root_decoder *cxlrd,
&gt; -					  enum cxl_partition_mode mode, int id)
&gt; +					  enum cxl_partition_mode mode, int id,
&gt; +					  enum cxl_decoder_type target_type)
&gt;  {
&gt;  	int rc;
&gt;  
&gt; @@ -2855,7 +2856,7 @@ static struct cxl_region *__create_region(struct cxl_root_decoder *cxlrd,
&gt;  		return ERR_PTR(-EBUSY);
&gt;  	}
&gt;  
&gt; -	return devm_cxl_add_region(cxlrd, id, mode, CXL_DECODER_HOSTONLYMEM);
&gt; +	return devm_cxl_add_region(cxlrd, id, mode, target_type);
&gt;  }
&gt;  
&gt;  static ssize_t create_region_store(struct device *dev, const char *buf,
&gt; @@ -2869,7 +2870,7 @@ static ssize_t create_region_store(struct device *dev, const char *buf,
&gt;  	if (rc != 1)
&gt;  		return -EINVAL;
&gt;  
&gt; -	cxlr = __create_region(cxlrd, mode, id);
&gt; +	cxlr = __create_region(cxlrd, mode, id, CXL_DECODER_HOSTONLYMEM);

I haven&#x27;t read the ABI docs, but would it be worthwhile to update the documentation for this attribute
to mention it only makes type 3 regions? I&#x27;m flip-flopping on whether it&#x27;s worth the trouble but thought
I should mention it.

Either way:
Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;

&gt;  	if (IS_ERR(cxlr))
&gt;  		return PTR_ERR(cxlr);
&gt;  
&gt; @@ -4036,7 +4037,8 @@ static struct cxl_region *construct_region(struct cxl_root_decoder *cxlrd,
&gt;  
&gt;  	do {
&gt;  		cxlr = __create_region(cxlrd, cxlds-&gt;part[part].mode,
&gt; -				       atomic_read(&amp;cxlrd-&gt;region_id));
&gt; +				       atomic_read(&amp;cxlrd-&gt;region_id),
&gt; +				       cxled-&gt;cxld.target_type);
&gt;  	} while (IS_ERR(cxlr) &amp;&amp; PTR_ERR(cxlr) == -EBUSY);
&gt;  
&gt;  	if (IS_ERR(cxlr)) {



---

On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; Region creation based on Type3 devices is triggered from user space
&gt; allowing memory combination through interleaving.
&gt; 
&gt; In preparation for kernel driven region creation, that is Type2 drivers
&gt; triggering region creation backed with its advertised CXL memory, factor
&gt; out a common helper from the user-sysfs region setup for interleave ways.
&gt; 
&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; Reviewed-by: Zhi Wang &lt;zhiw@nvidia.com&gt;
&gt; Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
&gt; Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
&gt; Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
&gt; Reviewed-by: Alison Schofield &lt;alison.schofield@intel.com&gt;
&gt; ---
&gt;  drivers/cxl/core/region.c | 43 ++++++++++++++++++++++++---------------
&gt;  1 file changed, 27 insertions(+), 16 deletions(-)
&gt; 
&gt; diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
&gt; index f53b2e9fd9e6..ece1d3df7cf1 100644
&gt; --- a/drivers/cxl/core/region.c
&gt; +++ b/drivers/cxl/core/region.c
&gt; @@ -485,22 +485,14 @@ static ssize_t interleave_ways_show(struct device *dev,
&gt;  
&gt;  static const struct attribute_group *get_cxl_region_target_group(void);
&gt;  
&gt; -static ssize_t interleave_ways_store(struct device *dev,
&gt; -				     struct device_attribute *attr,
&gt; -				     const char *buf, size_t len)
&gt; +static int set_interleave_ways(struct cxl_region *cxlr, int val)

@val should probably stay an unsigned int. You pass an unsigned int in the sysfs function, and the
function was originally coded with that in mind (same with @save below). With that cleaned up:
Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;

&gt;  {
&gt; -	struct cxl_root_decoder *cxlrd = to_cxl_root_decoder(dev-&gt;parent);
&gt; +	struct cxl_root_decoder *cxlrd = to_cxl_root_decoder(cxlr-&gt;dev.parent);
&gt;  	struct cxl_decoder *cxld = &amp;cxlrd-&gt;cxlsd.cxld;
&gt; -	struct cxl_region *cxlr = to_cxl_region(dev);
&gt;  	struct cxl_region_params *p = &amp;cxlr-&gt;params;
&gt; -	unsigned int val, save;
&gt; -	int rc;
&gt; +	int save, rc;
&gt;  	u8 iw;
&gt;  
&gt; -	rc = kstrtouint(buf, 0, &amp;val);
&gt; -	if (rc)
&gt; -		return rc;
&gt; -
&gt;  	rc = ways_to_eiw(val, &amp;iw);
&gt;  	if (rc)
&gt;  		return rc;
&gt; @@ -515,9 +507,7 @@ static ssize_t interleave_ways_store(struct device *dev,
&gt;  		return -EINVAL;
&gt;  	}
&gt;  
&gt; -	ACQUIRE(rwsem_write_kill, rwsem)(&amp;cxl_rwsem.region);
&gt; -	if ((rc = ACQUIRE_ERR(rwsem_write_kill, &amp;rwsem)))
&gt; -		return rc;
&gt; +	lockdep_assert_held_write(&amp;cxl_rwsem.region);
&gt;  
&gt;  	if (p-&gt;state &gt;= CXL_CONFIG_INTERLEAVE_ACTIVE)
&gt;  		return -EBUSY;
&gt; @@ -525,10 +515,31 @@ static ssize_t interleave_ways_store(struct device *dev,
&gt;  	save = p-&gt;interleave_ways;
&gt;  	p-&gt;interleave_ways = val;
&gt;  	rc = sysfs_update_group(&amp;cxlr-&gt;dev.kobj, get_cxl_region_target_group());
&gt; -	if (rc) {
&gt; +	if (rc)
&gt;  		p-&gt;interleave_ways = save;
&gt; +
&gt; +	return rc;
&gt; +}
&gt; +
&gt; +static ssize_t interleave_ways_store(struct device *dev,
&gt; +				     struct device_attribute *attr,
&gt; +				     const char *buf, size_t len)
&gt; +{
&gt; +	struct cxl_region *cxlr = to_cxl_region(dev);
&gt; +	unsigned int val;
&gt; +	int rc;
&gt; +
&gt; +	rc = kstrtouint(buf, 0, &amp;val);
&gt; +	if (rc)
&gt; +		return rc;
&gt; +
&gt; +	ACQUIRE(rwsem_write_kill, rwsem)(&amp;cxl_rwsem.region);
&gt; +	if ((rc = ACQUIRE_ERR(rwsem_write_kill, &amp;rwsem)))
&gt; +		return rc;
&gt; +
&gt; +	rc = set_interleave_ways(cxlr, val);
&gt; +	if (rc)
&gt;  		return rc;
&gt; -	}
&gt;  
&gt;  	return len;
&gt;  }



---

On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; Region creation based on Type3 devices is triggered from user space
&gt; allowing memory combination through interleaving.
&gt; 
&gt; In preparation for kernel driven region creation, that is Type2 drivers
&gt; triggering region creation backed with its advertised CXL memory, factor
&gt; out a common helper from the user-sysfs region setup forinterleave
&gt; granularity.
&gt; 
&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; Reviewed-by: Zhi Wang &lt;zhiw@nvidia.com&gt;
&gt; Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
&gt; Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
&gt; Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
&gt; Reviewed-by: Alison Schofield &lt;alison.schofield@intel.com&gt;
&gt; ---
&gt;  drivers/cxl/core/region.c | 39 +++++++++++++++++++++++++--------------
&gt;  1 file changed, 25 insertions(+), 14 deletions(-)
&gt; 
&gt; diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
&gt; index ece1d3df7cf1..63c2aeb2ee1f 100644
&gt; --- a/drivers/cxl/core/region.c
&gt; +++ b/drivers/cxl/core/region.c
&gt; @@ -559,21 +559,14 @@ static ssize_t interleave_granularity_show(struct device *dev,
&gt;  	return sysfs_emit(buf, &quot;%d\n&quot;, p-&gt;interleave_granularity);
&gt;  }
&gt;  
&gt; -static ssize_t interleave_granularity_store(struct device *dev,
&gt; -					    struct device_attribute *attr,
&gt; -					    const char *buf, size_t len)
&gt; +static int set_interleave_granularity(struct cxl_region *cxlr, int val)

Same thing as last patch. Assuming it&#x27;s fixed:
Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
&gt;  {
&gt; -	struct cxl_root_decoder *cxlrd = to_cxl_root_decoder(dev-&gt;parent);
&gt; +	struct cxl_root_decoder *cxlrd = to_cxl_root_decoder(cxlr-&gt;dev.parent);
&gt;  	struct cxl_decoder *cxld = &amp;cxlrd-&gt;cxlsd.cxld;
&gt; -	struct cxl_region *cxlr = to_cxl_region(dev);
&gt;  	struct cxl_region_params *p = &amp;cxlr-&gt;params;
&gt; -	int rc, val;
&gt; +	int rc;
&gt;  	u16 ig;
&gt;  
&gt; -	rc = kstrtoint(buf, 0, &amp;val);
&gt; -	if (rc)
&gt; -		return rc;
&gt; -
&gt;  	rc = granularity_to_eig(val, &amp;ig);
&gt;  	if (rc)
&gt;  		return rc;
&gt; @@ -589,14 +582,32 @@ static ssize_t interleave_granularity_store(struct device *dev,
&gt;  	if (cxld-&gt;interleave_ways &gt; 1 &amp;&amp; val != cxld-&gt;interleave_granularity)
&gt;  		return -EINVAL;
&gt;  
&gt; -	ACQUIRE(rwsem_write_kill, rwsem)(&amp;cxl_rwsem.region);
&gt; -	if ((rc = ACQUIRE_ERR(rwsem_write_kill, &amp;rwsem)))
&gt; -		return rc;
&gt; -
&gt; +	lockdep_assert_held_write(&amp;cxl_rwsem.region);
&gt;  	if (p-&gt;state &gt;= CXL_CONFIG_INTERLEAVE_ACTIVE)
&gt;  		return -EBUSY;
&gt;  
&gt;  	p-&gt;interleave_granularity = val;
&gt; +	return 0;
&gt; +}
&gt; +
&gt; +static ssize_t interleave_granularity_store(struct device *dev,
&gt; +					    struct device_attribute *attr,
&gt; +					    const char *buf, size_t len)
&gt; +{
&gt; +	struct cxl_region *cxlr = to_cxl_region(dev);
&gt; +	int rc, val;
&gt; +
&gt; +	rc = kstrtoint(buf, 0, &amp;val);
&gt; +	if (rc)
&gt; +		return rc;
&gt; +
&gt; +	ACQUIRE(rwsem_write_kill, rwsem)(&amp;cxl_rwsem.region);
&gt; +	if ((rc = ACQUIRE_ERR(rwsem_write_kill, &amp;rwsem)))
&gt; +		return rc;
&gt; +
&gt; +	rc = set_interleave_granularity(cxlr, val);
&gt; +	if (rc)
&gt; +		return rc;
&gt;  
&gt;  	return len;
&gt;  }



---

On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; Creating a CXL region requires userspace intervention through the cxl
&gt; sysfs files. Type2 support should allow accelerator drivers to create
&gt; such cxl region from kernel code.
&gt; 
&gt; Adding that functionality and integrating it with current support for
&gt; memory expanders.
&gt; 
&gt; Based on https://lore.kernel.org/linux-cxl/168592159835.1948938.1647215579839222774.stgit@dwillia2-xfh.jf.intel.com/
&gt; 
&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
&gt; Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
&gt; ---
&gt;  drivers/cxl/core/region.c | 131 ++++++++++++++++++++++++++++++++++++--
&gt;  include/cxl/cxl.h         |   3 +
&gt;  2 files changed, 127 insertions(+), 7 deletions(-)
&gt; 
&gt; diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
&gt; index 63c2aeb2ee1f..293e63dfef22 100644
&gt; --- a/drivers/cxl/core/region.c
&gt; +++ b/drivers/cxl/core/region.c
&gt; @@ -2944,6 +2944,14 @@ cxl_find_region_by_name(struct cxl_root_decoder *cxlrd, const char *name)
&gt;  	return to_cxl_region(region_dev);
&gt;  }
&gt;  
&gt; +static void drop_region(struct cxl_region *cxlr)
&gt; +{
&gt; +	struct cxl_root_decoder *cxlrd = to_cxl_root_decoder(cxlr-&gt;dev.parent);
&gt; +	struct cxl_port *port = cxlrd_to_port(cxlrd);
&gt; +
&gt; +	devm_release_action(port-&gt;uport_dev, __unregister_region, cxlr);
&gt; +}
&gt; +
&gt;  static ssize_t delete_region_store(struct device *dev,
&gt;  				   struct device_attribute *attr,
&gt;  				   const char *buf, size_t len)
&gt; @@ -4047,14 +4055,12 @@ static int __construct_region(struct cxl_region *cxlr,
&gt;  	return 0;
&gt;  }
&gt;  
&gt; -/* Establish an empty region covering the given HPA range */
&gt; -static struct cxl_region *construct_region(struct cxl_root_decoder *cxlrd,
&gt; -					   struct cxl_endpoint_decoder *cxled)
&gt; +static struct cxl_region *construct_region_begin(struct cxl_root_decoder *cxlrd,
&gt; +						 struct cxl_endpoint_decoder *cxled)
&gt;  {
&gt;  	struct cxl_memdev *cxlmd = cxled_to_memdev(cxled);
&gt; -	struct cxl_port *port = cxlrd_to_port(cxlrd);
&gt;  	struct cxl_dev_state *cxlds = cxlmd-&gt;cxlds;
&gt; -	int rc, part = READ_ONCE(cxled-&gt;part);
&gt; +	int part = READ_ONCE(cxled-&gt;part);
&gt;  	struct cxl_region *cxlr;
&gt;  
&gt;  	do {
&gt; @@ -4063,13 +4069,26 @@ static struct cxl_region *construct_region(struct cxl_root_decoder *cxlrd,
&gt;  				       cxled-&gt;cxld.target_type);
&gt;  	} while (IS_ERR(cxlr) &amp;&amp; PTR_ERR(cxlr) == -EBUSY);
&gt;  
&gt; -	if (IS_ERR(cxlr)) {
&gt; +	if (IS_ERR(cxlr))
&gt;  		dev_err(cxlmd-&gt;dev.parent,
&gt;  			&quot;%s:%s: %s failed assign region: %ld\n&quot;,
&gt;  			dev_name(&amp;cxlmd-&gt;dev), dev_name(&amp;cxled-&gt;cxld.dev),
&gt;  			__func__, PTR_ERR(cxlr));
&gt; +
&gt; +	return cxlr;
&gt; +}
&gt; +
&gt; +/* Establish an empty region covering the given HPA range */
&gt; +static struct cxl_region *construct_region(struct cxl_root_decoder *cxlrd,
&gt; +					   struct cxl_endpoint_decoder *cxled)
&gt; +{
&gt; +	struct cxl_port *port = cxlrd_to_port(cxlrd);
&gt; +	struct cxl_region *cxlr;
&gt; +	int rc;
&gt; +
&gt; +	cxlr = construct_region_begin(cxlrd, cxled);
&gt; +	if (IS_ERR(cxlr))
&gt;  		return cxlr;
&gt; -	}
&gt;  
&gt;  	rc = __construct_region(cxlr, cxlrd, cxled);
&gt;  	if (rc) {
&gt; @@ -4080,6 +4099,104 @@ static struct cxl_region *construct_region(struct cxl_root_decoder *cxlrd,
&gt;  	return cxlr;
&gt;  }
&gt;  
&gt; +DEFINE_FREE(cxl_region_drop, struct cxl_region *, if (_T) drop_region(_T))

This needs to be &quot;if (!IS_ERR_OR_NULL(_T) drop_region(_T)&quot;. If construct_region_begin() returns an
error pointer, drop_region() will be called with it as of now leading to a garbage pointer deref.

&gt; +
&gt; +static struct cxl_region *
&gt; +__construct_new_region(struct cxl_root_decoder *cxlrd,
&gt; +		       struct cxl_endpoint_decoder **cxled, int ways)
&gt; +{
&gt; +	struct cxl_memdev *cxlmd = cxled_to_memdev(cxled[0]);
&gt; +	struct cxl_decoder *cxld = &amp;cxlrd-&gt;cxlsd.cxld;
&gt; +	struct cxl_region_params *p;
&gt; +	resource_size_t size = 0;
&gt; +	int rc, i;
&gt; +
&gt; +	struct cxl_region *cxlr __free(cxl_region_drop) =
&gt; +		construct_region_begin(cxlrd, cxled[0]);
&gt; +	if (IS_ERR(cxlr))
&gt; +		return cxlr;
&gt; +
&gt; +	guard(rwsem_write)(&amp;cxl_rwsem.region);
&gt; +
&gt; +	/*
&gt; +	 * Sanity check. This should not happen with an accel driver handling
&gt; +	 * the region creation.
&gt; +	 */
&gt; +	p = &amp;cxlr-&gt;params;
&gt; +	if (p-&gt;state &gt;= CXL_CONFIG_INTERLEAVE_ACTIVE) {
&gt; +		dev_err(cxlmd-&gt;dev.parent,
&gt; +			&quot;%s:%s: %s  unexpected region state\n&quot;,
&gt; +			dev_name(&amp;cxlmd-&gt;dev), dev_name(&amp;cxled[0]-&gt;cxld.dev),
&gt; +			__func__);
&gt; +		return ERR_PTR(-EBUSY);
&gt; +	}
&gt; +
&gt; +	rc = set_interleave_ways(cxlr, ways);
&gt; +	if (rc)
&gt; +		return ERR_PTR(rc);
&gt; +
&gt; +	rc = set_interleave_granularity(cxlr, cxld-&gt;interleave_granularity);
&gt; +	if (rc)
&gt; +		return ERR_PTR(rc);
&gt; +
&gt; +	scoped_guard(rwsem_read, &amp;cxl_rwsem.dpa) {
&gt; +		for (i = 0; i &lt; ways; i++) {
&gt; +			if (!cxled[i]-&gt;dpa_res)
&gt; +				return ERR_PTR(-EINVAL);
&gt; +			size += resource_size(cxled[i]-&gt;dpa_res);
&gt; +		}
&gt; +
&gt; +		rc = alloc_hpa(cxlr, size);
&gt; +		if (rc)
&gt; +			return ERR_PTR(rc);
&gt; +
&gt; +		for (i = 0; i &lt; ways; i++) {
&gt; +			rc = cxl_region_attach(cxlr, cxled[i], 0);

Position parameter is hardcoded to 0. It should be set to i, right? This kind of goes back to my
issues in patch 12/22; the interleaving functionality is there but it looks unused.

&gt; +			if (rc)
&gt; +				return ERR_PTR(rc);
&gt; +		}
&gt; +	}
&gt; +
&gt; +	rc = cxl_region_decode_commit(cxlr);
&gt; +	if (rc)
&gt; +		return ERR_PTR(rc);
&gt; +
&gt; +	p-&gt;state = CXL_CONFIG_COMMIT;
&gt; +
&gt; +	return no_free_ptr(cxlr);
&gt; +}
&gt; +
&gt; +/**
&gt; + * cxl_create_region - Establish a region given an endpoint decoder
&gt; + * @cxlrd: root decoder to allocate HPA
&gt; + * @cxled: endpoint decoders with reserved DPA capacity
&gt; + * @ways: interleave ways required
&gt; + *
&gt; + * Returns a fully formed region in the commit state and attached to the
&gt; + * cxl_region driver.
&gt; + */
&gt; +struct cxl_region *cxl_create_region(struct cxl_root_decoder *cxlrd,
&gt; +				     struct cxl_endpoint_decoder **cxled,
&gt; +				     int ways)
&gt; +{
&gt; +	struct cxl_region *cxlr;
&gt; +
&gt; +	mutex_lock(&amp;cxlrd-&gt;range_lock);
&gt; +	cxlr = __construct_new_region(cxlrd, cxled, ways);
&gt; +	mutex_unlock(&amp;cxlrd-&gt;range_lock);
&gt; +	if (IS_ERR(cxlr))
&gt; +		return cxlr;
&gt; +
&gt; +	if (device_attach(&amp;cxlr-&gt;dev) &lt;= 0) {
&gt; +		dev_err(&amp;cxlr-&gt;dev, &quot;failed to create region\n&quot;);
&gt; +		drop_region(cxlr);
&gt; +		return ERR_PTR(-ENODEV);
&gt; +	}
&gt; +
&gt; +	return cxlr;
&gt; +}
&gt; +EXPORT_SYMBOL_NS_GPL(cxl_create_region, &quot;CXL&quot;);
&gt; +
&gt;  static struct cxl_region *
&gt;  cxl_find_region_by_range(struct cxl_root_decoder *cxlrd, struct range *hpa)
&gt;  {
&gt; diff --git a/include/cxl/cxl.h b/include/cxl/cxl.h
&gt; index 4802371db00e..50acbd13bcf8 100644
&gt; --- a/include/cxl/cxl.h
&gt; +++ b/include/cxl/cxl.h
&gt; @@ -281,4 +281,7 @@ struct cxl_endpoint_decoder *cxl_request_dpa(struct cxl_memdev *cxlmd,
&gt;  					     enum cxl_partition_mode mode,
&gt;  					     resource_size_t alloc);
&gt;  int cxl_dpa_free(struct cxl_endpoint_decoder *cxled);
&gt; +struct cxl_region *cxl_create_region(struct cxl_root_decoder *cxlrd,
&gt; +				     struct cxl_endpoint_decoder **cxled,
&gt; +				     int ways);
&gt;  #endif /* __CXL_CXL_H__ */



---

On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; Differentiate CXL memory expanders (type 3) from CXL device accelerators
&gt; (type 2) with a new function for initializing cxl_dev_state and a macro
&gt; for helping accel drivers to embed cxl_dev_state inside a private
&gt; struct.
&gt; 
&gt; Move structs to include/cxl as the size of the accel driver private
&gt; struct embedding cxl_dev_state needs to know the size of this struct.
&gt; 
&gt; Use same new initialization with the type3 pci driver.
&gt; 
&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
&gt; Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
&gt; Reviewed-by: Alison Schofield &lt;alison.schofield@intel.com&gt;
&gt; Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
&gt; ---
&gt;  drivers/cxl/core/mbox.c      |  12 +-
&gt;  drivers/cxl/core/memdev.c    |  32 +++++
&gt;  drivers/cxl/cxl.h            |  97 +--------------
&gt;  drivers/cxl/cxlmem.h         |  86 +------------
&gt;  drivers/cxl/pci.c            |  14 +--
&gt;  include/cxl/cxl.h            | 226 +++++++++++++++++++++++++++++++++++
&gt;  tools/testing/cxl/test/mem.c |   3 +-
&gt;  7 files changed, 274 insertions(+), 196 deletions(-)
&gt;  create mode 100644 include/cxl/cxl.h
&gt; 
&gt; diff --git a/drivers/cxl/core/mbox.c b/drivers/cxl/core/mbox.c
&gt; index fa6dd0c94656..bee84d0101d1 100644
&gt; --- a/drivers/cxl/core/mbox.c
&gt; +++ b/drivers/cxl/core/mbox.c
&gt; @@ -1514,23 +1514,21 @@ int cxl_mailbox_init(struct cxl_mailbox *cxl_mbox, struct device *host)
&gt;  }
&gt;  EXPORT_SYMBOL_NS_GPL(cxl_mailbox_init, &quot;CXL&quot;);
&gt;  
&gt; -struct cxl_memdev_state *cxl_memdev_state_create(struct device *dev)
&gt; +struct cxl_memdev_state *cxl_memdev_state_create(struct device *dev, u64 serial,
&gt; +						 u16 dvsec)
&gt;  {
&gt;  	struct cxl_memdev_state *mds;
&gt;  	int rc;
&gt;  
&gt; -	mds = devm_kzalloc(dev, sizeof(*mds), GFP_KERNEL);
&gt; +	mds = devm_cxl_dev_state_create(dev, CXL_DEVTYPE_CLASSMEM, serial,
&gt; +					dvsec, struct cxl_memdev_state, cxlds,
&gt; +					true);
&gt;  	if (!mds) {
&gt;  		dev_err(dev, &quot;No memory available\n&quot;);
&gt;  		return ERR_PTR(-ENOMEM);
&gt;  	}
&gt;  
&gt;  	mutex_init(&amp;mds-&gt;event.log_lock);
&gt; -	mds-&gt;cxlds.dev = dev;
&gt; -	mds-&gt;cxlds.reg_map.host = dev;
&gt; -	mds-&gt;cxlds.cxl_mbox.host = dev;
&gt; -	mds-&gt;cxlds.reg_map.resource = CXL_RESOURCE_NONE;
&gt; -	mds-&gt;cxlds.type = CXL_DEVTYPE_CLASSMEM;
&gt;  
&gt;  	rc = devm_cxl_register_mce_notifier(dev, &amp;mds-&gt;mce_notifier);
&gt;  	if (rc == -EOPNOTSUPP)
&gt; diff --git a/drivers/cxl/core/memdev.c b/drivers/cxl/core/memdev.c
&gt; index af3d0cc65138..22d156f25305 100644
&gt; --- a/drivers/cxl/core/memdev.c
&gt; +++ b/drivers/cxl/core/memdev.c
&gt; @@ -656,6 +656,38 @@ static void detach_memdev(struct work_struct *work)
&gt;  
&gt;  static struct lock_class_key cxl_memdev_key;
&gt;  
&gt; +static void cxl_dev_state_init(struct cxl_dev_state *cxlds, struct device *dev,
&gt; +			       enum cxl_devtype type, u64 serial, u16 dvsec,
&gt; +			       bool has_mbox)
&gt; +{
&gt; +	*cxlds = (struct cxl_dev_state) {
&gt; +		.dev = dev,
&gt; +		.type = type,
&gt; +		.serial = serial,
&gt; +		.cxl_dvsec = dvsec,
&gt; +		.reg_map.host = dev,
&gt; +		.reg_map.resource = CXL_RESOURCE_NONE,
&gt; +	};
&gt; +
&gt; +	if (has_mbox)
&gt; +		cxlds-&gt;cxl_mbox.host = dev;
&gt; +}
&gt; +
&gt; +struct cxl_dev_state *_devm_cxl_dev_state_create(struct device *dev,
&gt; +						 enum cxl_devtype type,
&gt; +						 u64 serial, u16 dvsec,
&gt; +						 size_t size, bool has_mbox)
&gt; +{
&gt; +	struct cxl_dev_state *cxlds = devm_kzalloc(dev, size, GFP_KERNEL);
&gt; +
&gt; +	if (!cxlds)
&gt; +		return NULL;
&gt; +
&gt; +	cxl_dev_state_init(cxlds, dev, type, serial, dvsec, has_mbox);

Nit: Having a second function to do the init seems overkill here, especially since cxl_dev_state_init() isn&#x27;t called outside this
function. I&#x27;d fold it into this function instead, but I&#x27;m fine with it either way (especially if you were told otherwise before).

Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
&gt; +	return cxlds;
&gt; +}
&gt; +EXPORT_SYMBOL_NS_GPL(_devm_cxl_dev_state_create, &quot;CXL&quot;);
&gt; +
&gt;  static struct cxl_memdev *cxl_memdev_alloc(struct cxl_dev_state *cxlds,
&gt;  					   const struct file_operations *fops,
&gt;  					   const struct cxl_memdev_attach *attach)
&gt; diff --git a/drivers/cxl/cxl.h b/drivers/cxl/cxl.h
&gt; index e1d47062e1d3..3eaa353e430b 100644
&gt; --- a/drivers/cxl/cxl.h
&gt; +++ b/drivers/cxl/cxl.h
&gt; @@ -12,6 +12,7 @@
&gt;  #include &lt;linux/node.h&gt;
&gt;  #include &lt;linux/io.h&gt;
&gt;  #include &lt;linux/range.h&gt;
&gt; +#include &lt;cxl/cxl.h&gt;
&gt;  
&gt;  extern const struct nvdimm_security_ops *cxl_security_ops;
&gt;  
&gt; @@ -201,97 +202,6 @@ static inline int ways_to_eiw(unsigned int ways, u8 *eiw)
&gt;  #define   CXLDEV_MBOX_BG_CMD_COMMAND_VENDOR_MASK GENMASK_ULL(63, 48)
&gt;  #define CXLDEV_MBOX_PAYLOAD_OFFSET 0x20
&gt;  
&gt; -/*
&gt; - * Using struct_group() allows for per register-block-type helper routines,
&gt; - * without requiring block-type agnostic code to include the prefix.
&gt; - */
&gt; -struct cxl_regs {
&gt; -	/*
&gt; -	 * Common set of CXL Component register block base pointers
&gt; -	 * @hdm_decoder: CXL 2.0 8.2.5.12 CXL HDM Decoder Capability Structure
&gt; -	 * @ras: CXL 2.0 8.2.5.9 CXL RAS Capability Structure
&gt; -	 */
&gt; -	struct_group_tagged(cxl_component_regs, component,
&gt; -		void __iomem *hdm_decoder;
&gt; -		void __iomem *ras;
&gt; -	);
&gt; -	/*
&gt; -	 * Common set of CXL Device register block base pointers
&gt; -	 * @status: CXL 2.0 8.2.8.3 Device Status Registers
&gt; -	 * @mbox: CXL 2.0 8.2.8.4 Mailbox Registers
&gt; -	 * @memdev: CXL 2.0 8.2.8.5 Memory Device Registers
&gt; -	 */
&gt; -	struct_group_tagged(cxl_device_regs, device_regs,
&gt; -		void __iomem *status, *mbox, *memdev;
&gt; -	);
&gt; -
&gt; -	struct_group_tagged(cxl_pmu_regs, pmu_regs,
&gt; -		void __iomem *pmu;
&gt; -	);
&gt; -
&gt; -	/*
&gt; -	 * RCH downstream port specific RAS register
&gt; -	 * @aer: CXL 3.0 8.2.1.1 RCH Downstream Port RCRB
&gt; -	 */
&gt; -	struct_group_tagged(cxl_rch_regs, rch_regs,
&gt; -		void __iomem *dport_aer;
&gt; -	);
&gt; -
&gt; -	/*
&gt; -	 * RCD upstream port specific PCIe cap register
&gt; -	 * @pcie_cap: CXL 3.0 8.2.1.2 RCD Upstream Port RCRB
&gt; -	 */
&gt; -	struct_group_tagged(cxl_rcd_regs, rcd_regs,
&gt; -		void __iomem *rcd_pcie_cap;
&gt; -	);
&gt; -};
&gt; -
&gt; -struct cxl_reg_map {
&gt; -	bool valid;
&gt; -	int id;
&gt; -	unsigned long offset;
&gt; -	unsigned long size;
&gt; -};
&gt; -
&gt; -struct cxl_component_reg_map {
&gt; -	struct cxl_reg_map hdm_decoder;
&gt; -	struct cxl_reg_map ras;
&gt; -};
&gt; -
&gt; -struct cxl_device_reg_map {
&gt; -	struct cxl_reg_map status;
&gt; -	struct cxl_reg_map mbox;
&gt; -	struct cxl_reg_map memdev;
&gt; -};
&gt; -
&gt; -struct cxl_pmu_reg_map {
&gt; -	struct cxl_reg_map pmu;
&gt; -};
&gt; -
&gt; -/**
&gt; - * struct cxl_register_map - DVSEC harvested register block mapping parameters
&gt; - * @host: device for devm operations and logging
&gt; - * @base: virtual base of the register-block-BAR + @block_offset
&gt; - * @resource: physical resource base of the register block
&gt; - * @max_size: maximum mapping size to perform register search
&gt; - * @reg_type: see enum cxl_regloc_type
&gt; - * @component_map: cxl_reg_map for component registers
&gt; - * @device_map: cxl_reg_maps for device registers
&gt; - * @pmu_map: cxl_reg_maps for CXL Performance Monitoring Units
&gt; - */
&gt; -struct cxl_register_map {
&gt; -	struct device *host;
&gt; -	void __iomem *base;
&gt; -	resource_size_t resource;
&gt; -	resource_size_t max_size;
&gt; -	u8 reg_type;
&gt; -	union {
&gt; -		struct cxl_component_reg_map component_map;
&gt; -		struct cxl_device_reg_map device_map;
&gt; -		struct cxl_pmu_reg_map pmu_map;
&gt; -	};
&gt; -};
&gt; -
&gt;  void cxl_probe_component_regs(struct device *dev, void __iomem *base,
&gt;  			      struct cxl_component_reg_map *map);
&gt;  void cxl_probe_device_regs(struct device *dev, void __iomem *base,
&gt; @@ -497,11 +407,6 @@ struct cxl_region_params {
&gt;  	resource_size_t cache_size;
&gt;  };
&gt;  
&gt; -enum cxl_partition_mode {
&gt; -	CXL_PARTMODE_RAM,
&gt; -	CXL_PARTMODE_PMEM,
&gt; -};
&gt; -
&gt;  /*
&gt;   * Indicate whether this region has been assembled by autodetection or
&gt;   * userspace assembly. Prevent endpoint decoders outside of automatic
&gt; diff --git a/drivers/cxl/cxlmem.h b/drivers/cxl/cxlmem.h
&gt; index ef202b34e5ea..281546de426e 100644
&gt; --- a/drivers/cxl/cxlmem.h
&gt; +++ b/drivers/cxl/cxlmem.h
&gt; @@ -113,8 +113,6 @@ int devm_cxl_dpa_reserve(struct cxl_endpoint_decoder *cxled,
&gt;  			 resource_size_t base, resource_size_t len,
&gt;  			 resource_size_t skipped);
&gt;  
&gt; -#define CXL_NR_PARTITIONS_MAX 2
&gt; -
&gt;  struct cxl_dpa_info {
&gt;  	u64 size;
&gt;  	struct cxl_dpa_part_info {
&gt; @@ -373,87 +371,6 @@ struct cxl_security_state {
&gt;  	struct kernfs_node *sanitize_node;
&gt;  };
&gt;  
&gt; -/*
&gt; - * enum cxl_devtype - delineate type-2 from a generic type-3 device
&gt; - * @CXL_DEVTYPE_DEVMEM - Vendor specific CXL Type-2 device implementing HDM-D or
&gt; - *			 HDM-DB, no requirement that this device implements a
&gt; - *			 mailbox, or other memory-device-standard manageability
&gt; - *			 flows.
&gt; - * @CXL_DEVTYPE_CLASSMEM - Common class definition of a CXL Type-3 device with
&gt; - *			   HDM-H and class-mandatory memory device registers
&gt; - */
&gt; -enum cxl_devtype {
&gt; -	CXL_DEVTYPE_DEVMEM,
&gt; -	CXL_DEVTYPE_CLASSMEM,
&gt; -};
&gt; -
&gt; -/**
&gt; - * struct cxl_dpa_perf - DPA performance property entry
&gt; - * @dpa_range: range for DPA address
&gt; - * @coord: QoS performance data (i.e. latency, bandwidth)
&gt; - * @cdat_coord: raw QoS performance data from CDAT
&gt; - * @qos_class: QoS Class cookies
&gt; - */
&gt; -struct cxl_dpa_perf {
&gt; -	struct range dpa_range;
&gt; -	struct access_coordinate coord[ACCESS_COORDINATE_MAX];
&gt; -	struct access_coordinate cdat_coord[ACCESS_COORDINATE_MAX];
&gt; -	int qos_class;
&gt; -};
&gt; -
&gt; -/**
&gt; - * struct cxl_dpa_partition - DPA partition descriptor
&gt; - * @res: shortcut to the partition in the DPA resource tree (cxlds-&gt;dpa_res)
&gt; - * @perf: performance attributes of the partition from CDAT
&gt; - * @mode: operation mode for the DPA capacity, e.g. ram, pmem, dynamic...
&gt; - */
&gt; -struct cxl_dpa_partition {
&gt; -	struct resource res;
&gt; -	struct cxl_dpa_perf perf;
&gt; -	enum cxl_partition_mode mode;
&gt; -};
&gt; -
&gt; -/**
&gt; - * struct cxl_dev_state - The driver device state
&gt; - *
&gt; - * cxl_dev_state represents the CXL driver/device state.  It provides an
&gt; - * interface to mailbox commands as well as some cached data about the device.
&gt; - * Currently only memory devices are represented.
&gt; - *
&gt; - * @dev: The device associated with this CXL state
&gt; - * @cxlmd: The device representing the CXL.mem capabilities of @dev
&gt; - * @reg_map: component and ras register mapping parameters
&gt; - * @regs: Parsed register blocks
&gt; - * @cxl_dvsec: Offset to the PCIe device DVSEC
&gt; - * @rcd: operating in RCD mode (CXL 3.0 9.11.8 CXL Devices Attached to an RCH)
&gt; - * @media_ready: Indicate whether the device media is usable
&gt; - * @dpa_res: Overall DPA resource tree for the device
&gt; - * @part: DPA partition array
&gt; - * @nr_partitions: Number of DPA partitions
&gt; - * @serial: PCIe Device Serial Number
&gt; - * @type: Generic Memory Class device or Vendor Specific Memory device
&gt; - * @cxl_mbox: CXL mailbox context
&gt; - * @cxlfs: CXL features context
&gt; - */
&gt; -struct cxl_dev_state {
&gt; -	struct device *dev;
&gt; -	struct cxl_memdev *cxlmd;
&gt; -	struct cxl_register_map reg_map;
&gt; -	struct cxl_regs regs;
&gt; -	int cxl_dvsec;
&gt; -	bool rcd;
&gt; -	bool media_ready;
&gt; -	struct resource dpa_res;
&gt; -	struct cxl_dpa_partition part[CXL_NR_PARTITIONS_MAX];
&gt; -	unsigned int nr_partitions;
&gt; -	u64 serial;
&gt; -	enum cxl_devtype type;
&gt; -	struct cxl_mailbox cxl_mbox;
&gt; -#ifdef CONFIG_CXL_FEATURES
&gt; -	struct cxl_features_state *cxlfs;
&gt; -#endif
&gt; -};
&gt; -
&gt;  static inline resource_size_t cxl_pmem_size(struct cxl_dev_state *cxlds)
&gt;  {
&gt;  	/*
&gt; @@ -858,7 +775,8 @@ int cxl_dev_state_identify(struct cxl_memdev_state *mds);
&gt;  int cxl_await_media_ready(struct cxl_dev_state *cxlds);
&gt;  int cxl_enumerate_cmds(struct cxl_memdev_state *mds);
&gt;  int cxl_mem_dpa_fetch(struct cxl_memdev_state *mds, struct cxl_dpa_info *info);
&gt; -struct cxl_memdev_state *cxl_memdev_state_create(struct device *dev);
&gt; +struct cxl_memdev_state *cxl_memdev_state_create(struct device *dev, u64 serial,
&gt; +						 u16 dvsec);
&gt;  void set_exclusive_cxl_commands(struct cxl_memdev_state *mds,
&gt;  				unsigned long *cmds);
&gt;  void clear_exclusive_cxl_commands(struct cxl_memdev_state *mds,
&gt; diff --git a/drivers/cxl/pci.c b/drivers/cxl/pci.c
&gt; index 1cf232220873..24179cc702bf 100644
&gt; --- a/drivers/cxl/pci.c
&gt; +++ b/drivers/cxl/pci.c
&gt; @@ -911,25 +911,25 @@ static int cxl_pci_probe(struct pci_dev *pdev, const struct pci_device_id *id)
&gt;  	int rc, pmu_count;
&gt;  	unsigned int i;
&gt;  	bool irq_avail;
&gt; +	u16 dvsec;
&gt;  
&gt;  	rc = pcim_enable_device(pdev);
&gt;  	if (rc)
&gt;  		return rc;
&gt;  	pci_set_master(pdev);
&gt;  
&gt; -	mds = cxl_memdev_state_create(&amp;pdev-&gt;dev);
&gt; +	dvsec = pci_find_dvsec_capability(pdev, PCI_VENDOR_ID_CXL,
&gt; +					  PCI_DVSEC_CXL_DEVICE);
&gt; +	if (!dvsec)
&gt; +		pci_warn(pdev, &quot;Device DVSEC not present, skip CXL.mem init\n&quot;);
&gt; +
&gt; +	mds = cxl_memdev_state_create(&amp;pdev-&gt;dev, pci_get_dsn(pdev), dvsec);
&gt;  	if (IS_ERR(mds))
&gt;  		return PTR_ERR(mds);
&gt;  	cxlds = &amp;mds-&gt;cxlds;
&gt;  	pci_set_drvdata(pdev, cxlds);
&gt;  
&gt;  	cxlds-&gt;rcd = is_cxl_restricted(pdev);
&gt; -	cxlds-&gt;serial = pci_get_dsn(pdev);
&gt; -	cxlds-&gt;cxl_dvsec = pci_find_dvsec_capability(
&gt; -		pdev, PCI_VENDOR_ID_CXL, PCI_DVSEC_CXL_DEVICE);
&gt; -	if (!cxlds-&gt;cxl_dvsec)
&gt; -		dev_warn(&amp;pdev-&gt;dev,
&gt; -			 &quot;Device DVSEC not present, skip CXL.mem init\n&quot;);
&gt;  
&gt;  	rc = cxl_pci_setup_regs(pdev, CXL_REGLOC_RBI_MEMDEV, &amp;map);
&gt;  	if (rc)
&gt; diff --git a/include/cxl/cxl.h b/include/cxl/cxl.h
&gt; new file mode 100644
&gt; index 000000000000..13d448686189
&gt; --- /dev/null
&gt; +++ b/include/cxl/cxl.h
&gt; @@ -0,0 +1,226 @@
&gt; +/* SPDX-License-Identifier: GPL-2.0 */
&gt; +/* Copyright(c) 2020 Intel Corporation. */
&gt; +/* Copyright(c) 2025 Advanced Micro Devices, Inc. */
&gt; +
&gt; +#ifndef __CXL_CXL_H__
&gt; +#define __CXL_CXL_H__
&gt; +
&gt; +#include &lt;linux/node.h&gt;
&gt; +#include &lt;linux/ioport.h&gt;
&gt; +#include &lt;cxl/mailbox.h&gt;
&gt; +
&gt; +/**
&gt; + * enum cxl_devtype - delineate type-2 from a generic type-3 device
&gt; + * @CXL_DEVTYPE_DEVMEM: Vendor specific CXL Type-2 device implementing HDM-D or
&gt; + *			 HDM-DB, no requirement that this device implements a
&gt; + *			 mailbox, or other memory-device-standard manageability
&gt; + *			 flows.
&gt; + * @CXL_DEVTYPE_CLASSMEM: Common class definition of a CXL Type-3 device with
&gt; + *			   HDM-H and class-mandatory memory device registers
&gt; + */
&gt; +enum cxl_devtype {
&gt; +	CXL_DEVTYPE_DEVMEM,
&gt; +	CXL_DEVTYPE_CLASSMEM,
&gt; +};
&gt; +
&gt; +struct device;
&gt; +
&gt; +/*
&gt; + * Using struct_group() allows for per register-block-type helper routines,
&gt; + * without requiring block-type agnostic code to include the prefix.
&gt; + */
&gt; +struct cxl_regs {
&gt; +	/*
&gt; +	 * Common set of CXL Component register block base pointers
&gt; +	 * @hdm_decoder: CXL 2.0 8.2.5.12 CXL HDM Decoder Capability Structure
&gt; +	 * @ras: CXL 2.0 8.2.5.9 CXL RAS Capability Structure
&gt; +	 */
&gt; +	struct_group_tagged(cxl_component_regs, component,
&gt; +		void __iomem *hdm_decoder;
&gt; +		void __iomem *ras;
&gt; +	);
&gt; +	/*
&gt; +	 * Common set of CXL Device register block base pointers
&gt; +	 * @status: CXL 2.0 8.2.8.3 Device Status Registers
&gt; +	 * @mbox: CXL 2.0 8.2.8.4 Mailbox Registers
&gt; +	 * @memdev: CXL 2.0 8.2.8.5 Memory Device Registers
&gt; +	 */
&gt; +	struct_group_tagged(cxl_device_regs, device_regs,
&gt; +		void __iomem *status, *mbox, *memdev;
&gt; +	);
&gt; +
&gt; +	struct_group_tagged(cxl_pmu_regs, pmu_regs,
&gt; +		void __iomem *pmu;
&gt; +	);
&gt; +
&gt; +	/*
&gt; +	 * RCH downstream port specific RAS register
&gt; +	 * @aer: CXL 3.0 8.2.1.1 RCH Downstream Port RCRB
&gt; +	 */
&gt; +	struct_group_tagged(cxl_rch_regs, rch_regs,
&gt; +		void __iomem *dport_aer;
&gt; +	);
&gt; +
&gt; +	/*
&gt; +	 * RCD upstream port specific PCIe cap register
&gt; +	 * @pcie_cap: CXL 3.0 8.2.1.2 RCD Upstream Port RCRB
&gt; +	 */
&gt; +	struct_group_tagged(cxl_rcd_regs, rcd_regs,
&gt; +		void __iomem *rcd_pcie_cap;
&gt; +	);
&gt; +};
&gt; +
&gt; +struct cxl_reg_map {
&gt; +	bool valid;
&gt; +	int id;
&gt; +	unsigned long offset;
&gt; +	unsigned long size;
&gt; +};
&gt; +
&gt; +struct cxl_component_reg_map {
&gt; +	struct cxl_reg_map hdm_decoder;
&gt; +	struct cxl_reg_map ras;
&gt; +};
&gt; +
&gt; +struct cxl_device_reg_map {
&gt; +	struct cxl_reg_map status;
&gt; +	struct cxl_reg_map mbox;
&gt; +	struct cxl_reg_map memdev;
&gt; +};
&gt; +
&gt; +struct cxl_pmu_reg_map {
&gt; +	struct cxl_reg_map pmu;
&gt; +};
&gt; +
&gt; +/**
&gt; + * struct cxl_register_map - DVSEC harvested register block mapping parameters
&gt; + * @host: device for devm operations and logging
&gt; + * @base: virtual base of the register-block-BAR + @block_offset
&gt; + * @resource: physical resource base of the register block
&gt; + * @max_size: maximum mapping size to perform register search
&gt; + * @reg_type: see enum cxl_regloc_type
&gt; + * @component_map: cxl_reg_map for component registers
&gt; + * @device_map: cxl_reg_maps for device registers
&gt; + * @pmu_map: cxl_reg_maps for CXL Performance Monitoring Units
&gt; + */
&gt; +struct cxl_register_map {
&gt; +	struct device *host;
&gt; +	void __iomem *base;
&gt; +	resource_size_t resource;
&gt; +	resource_size_t max_size;
&gt; +	u8 reg_type;
&gt; +	union {
&gt; +		struct cxl_component_reg_map component_map;
&gt; +		struct cxl_device_reg_map device_map;
&gt; +		struct cxl_pmu_reg_map pmu_map;
&gt; +	};
&gt; +};
&gt; +
&gt; +/**
&gt; + * struct cxl_dpa_perf - DPA performance property entry
&gt; + * @dpa_range: range for DPA address
&gt; + * @coord: QoS performance data (i.e. latency, bandwidth)
&gt; + * @cdat_coord: raw QoS performance data from CDAT
&gt; + * @qos_class: QoS Class cookies
&gt; + */
&gt; +struct cxl_dpa_perf {
&gt; +	struct range dpa_range;
&gt; +	struct access_coordinate coord[ACCESS_COORDINATE_MAX];
&gt; +	struct access_coordinate cdat_coord[ACCESS_COORDINATE_MAX];
&gt; +	int qos_class;
&gt; +};
&gt; +
&gt; +enum cxl_partition_mode {
&gt; +	CXL_PARTMODE_RAM,
&gt; +	CXL_PARTMODE_PMEM,
&gt; +};
&gt; +
&gt; +/**
&gt; + * struct cxl_dpa_partition - DPA partition descriptor
&gt; + * @res: shortcut to the partition in the DPA resource tree (cxlds-&gt;dpa_res)
&gt; + * @perf: performance attributes of the partition from CDAT
&gt; + * @mode: operation mode for the DPA capacity, e.g. ram, pmem, dynamic...
&gt; + */
&gt; +struct cxl_dpa_partition {
&gt; +	struct resource res;
&gt; +	struct cxl_dpa_perf perf;
&gt; +	enum cxl_partition_mode mode;
&gt; +};
&gt; +
&gt; +#define CXL_NR_PARTITIONS_MAX 2
&gt; +
&gt; +/**
&gt; + * struct cxl_dev_state - The driver device state
&gt; + *
&gt; + * cxl_dev_state represents the CXL driver/device state.  It provides an
&gt; + * interface to mailbox commands as well as some cached data about the device.
&gt; + * Currently only memory devices are represented.
&gt; + *
&gt; + * @dev: The device associated with this CXL state
&gt; + * @cxlmd: The device representing the CXL.mem capabilities of @dev
&gt; + * @reg_map: component and ras register mapping parameters
&gt; + * @regs: Parsed register blocks
&gt; + * @cxl_dvsec: Offset to the PCIe device DVSEC
&gt; + * @rcd: operating in RCD mode (CXL 3.0 9.11.8 CXL Devices Attached to an RCH)
&gt; + * @media_ready: Indicate whether the device media is usable
&gt; + * @dpa_res: Overall DPA resource tree for the device
&gt; + * @part: DPA partition array
&gt; + * @nr_partitions: Number of DPA partitions
&gt; + * @serial: PCIe Device Serial Number
&gt; + * @type: Generic Memory Class device or Vendor Specific Memory device
&gt; + * @cxl_mbox: CXL mailbox context
&gt; + * @cxlfs: CXL features context
&gt; + */
&gt; +struct cxl_dev_state {
&gt; +	/* public for Type2 drivers */
&gt; +	struct device *dev;
&gt; +	struct cxl_memdev *cxlmd;
&gt; +
&gt; +	/* private for Type2 drivers */
&gt; +	struct cxl_register_map reg_map;
&gt; +	struct cxl_regs regs;
&gt; +	int cxl_dvsec;
&gt; +	bool rcd;
&gt; +	bool media_ready;
&gt; +	struct resource dpa_res;
&gt; +	struct cxl_dpa_partition part[CXL_NR_PARTITIONS_MAX];
&gt; +	unsigned int nr_partitions;
&gt; +	u64 serial;
&gt; +	enum cxl_devtype type;
&gt; +	struct cxl_mailbox cxl_mbox;
&gt; +#ifdef CONFIG_CXL_FEATURES
&gt; +	struct cxl_features_state *cxlfs;
&gt; +#endif
&gt; +};
&gt; +
&gt; +struct cxl_dev_state *_devm_cxl_dev_state_create(struct device *dev,
&gt; +						 enum cxl_devtype type,
&gt; +						 u64 serial, u16 dvsec,
&gt; +						 size_t size, bool has_mbox);
&gt; +
&gt; +/**
&gt; + * cxl_dev_state_create - safely create and cast a cxl dev state embedded in a
&gt; + * driver specific struct.
&gt; + *
&gt; + * @parent: device behind the request
&gt; + * @type: CXL device type
&gt; + * @serial: device identification
&gt; + * @dvsec: dvsec capability offset
&gt; + * @drv_struct: driver struct embedding a cxl_dev_state struct
&gt; + * @member: drv_struct member as cxl_dev_state
&gt; + * @mbox: true if mailbox supported
&gt; + *
&gt; + * Returns a pointer to the drv_struct allocated and embedding a cxl_dev_state
&gt; + * struct initialized.
&gt; + *
&gt; + * Introduced for Type2 driver support.
&gt; + */
&gt; +#define devm_cxl_dev_state_create(parent, type, serial, dvsec, drv_struct, member, mbox)	\
&gt; +	({										\
&gt; +		static_assert(__same_type(struct cxl_dev_state,				\
&gt; +			      ((drv_struct *)NULL)-&gt;member));				\
&gt; +		static_assert(offsetof(drv_struct, member) == 0);			\
&gt; +		(drv_struct *)_devm_cxl_dev_state_create(parent, type, serial, dvsec,	\
&gt; +						      sizeof(drv_struct), mbox);	\
&gt; +	})
&gt; +#endif /* __CXL_CXL_H__ */
&gt; diff --git a/tools/testing/cxl/test/mem.c b/tools/testing/cxl/test/mem.c
&gt; index cb87e8c0e63c..79f42f4474d4 100644
&gt; --- a/tools/testing/cxl/test/mem.c
&gt; +++ b/tools/testing/cxl/test/mem.c
&gt; @@ -1716,7 +1716,7 @@ static int cxl_mock_mem_probe(struct platform_device *pdev)
&gt;  	if (rc)
&gt;  		return rc;
&gt;  
&gt; -	mds = cxl_memdev_state_create(dev);
&gt; +	mds = cxl_memdev_state_create(dev, pdev-&gt;id + 1, 0);
&gt;  	if (IS_ERR(mds))
&gt;  		return PTR_ERR(mds);
&gt;  
&gt; @@ -1732,7 +1732,6 @@ static int cxl_mock_mem_probe(struct platform_device *pdev)
&gt;  	mds-&gt;event.buf = (struct cxl_get_event_payload *) mdata-&gt;event_buf;
&gt;  	INIT_DELAYED_WORK(&amp;mds-&gt;security.poll_dwork, cxl_mockmem_sanitize_work);
&gt;  
&gt; -	cxlds-&gt;serial = pdev-&gt;id + 1;
&gt;  	if (is_rcd(pdev))
&gt;  		cxlds-&gt;rcd = true;
&gt;  



---

On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; A Type2 device configured by the BIOS can already have its HDM
&gt; committed. Add a cxl_get_committed_decoder() function for cheking
&gt; so after memdev creation. A CXL region should have been created
&gt; during memdev initialization, therefore a Type2 driver can ask for
&gt; such a region for working with the HPA. If the HDM is not committed,
&gt; a Type2 driver will create the region after obtaining proper HPA
&gt; and DPA space.
&gt; 
&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; ---
&gt;  drivers/cxl/core/hdm.c | 39 +++++++++++++++++++++++++++++++++++++++
&gt;  include/cxl/cxl.h      |  3 +++
&gt;  2 files changed, 42 insertions(+)
&gt; 
&gt; diff --git a/drivers/cxl/core/hdm.c b/drivers/cxl/core/hdm.c
&gt; index 6e516c69b2d2..a172ce4e9b19 100644
&gt; --- a/drivers/cxl/core/hdm.c
&gt; +++ b/drivers/cxl/core/hdm.c
&gt; @@ -686,6 +686,45 @@ int cxl_dpa_alloc(struct cxl_endpoint_decoder *cxled, u64 size)
&gt;  	return devm_add_action_or_reset(&amp;port-&gt;dev, cxl_dpa_release, cxled);
&gt;  }
&gt;  
&gt; +static int find_committed_endpoint_decoder(struct device *dev, const void *data)
&gt; +{
&gt; +	struct cxl_endpoint_decoder *cxled;
&gt; +	struct cxl_port *port;
&gt; +
&gt; +	if (!is_endpoint_decoder(dev))
&gt; +		return 0;
&gt; +
&gt; +	cxled = to_cxl_endpoint_decoder(dev);
&gt; +	port = cxled_to_port(cxled);
&gt; +
&gt; +	return cxled-&gt;cxld.id == port-&gt;hdm_end;

Is this the way you&#x27;re supposed to check if a decoder is committed? The doc comment for @hdm_end in
struct cxl_port says it&#x27;s just the last allocated decoder. If allocated decoders are always committed then
I&#x27;m fine with this, otherwise I think you&#x27;d want to a register read or something to find the commit state.
&gt; +}
&gt; +
&gt; +struct cxl_endpoint_decoder *cxl_get_committed_decoder(struct cxl_memdev *cxlmd,
&gt; +						       struct cxl_region **cxlr)
&gt; +{
&gt; +	struct cxl_port *endpoint = cxlmd-&gt;endpoint;
&gt; +	struct cxl_endpoint_decoder *cxled;
&gt; +	struct device *cxled_dev;
&gt; +
&gt; +	if (!endpoint)
&gt; +		return NULL;
&gt; +
&gt; +	guard(rwsem_read)(&amp;cxl_rwsem.dpa);
&gt; +	cxled_dev = device_find_child(&amp;endpoint-&gt;dev, NULL,
&gt; +				      find_committed_endpoint_decoder);
&gt; +
&gt; +	if (!cxled_dev)
&gt; +		return NULL;
&gt; +
&gt; +	cxled = to_cxl_endpoint_decoder(cxled_dev);
&gt; +	*cxlr = cxled-&gt;cxld.region;
&gt; +
&gt; +	put_device(cxled_dev);
&gt; +	return cxled;
&gt; +}
&gt; +EXPORT_SYMBOL_NS_GPL(cxl_get_committed_decoder, &quot;CXL&quot;);
&gt; +
&gt;  static void cxld_set_interleave(struct cxl_decoder *cxld, u32 *ctrl)
&gt;  {
&gt;  	u16 eig;
&gt; diff --git a/include/cxl/cxl.h b/include/cxl/cxl.h
&gt; index 6f8d365067af..928276dba952 100644
&gt; --- a/include/cxl/cxl.h
&gt; +++ b/include/cxl/cxl.h
&gt; @@ -249,4 +249,7 @@ int cxl_map_component_regs(const struct cxl_register_map *map,
&gt;  int cxl_set_capacity(struct cxl_dev_state *cxlds, u64 capacity);
&gt;  struct cxl_memdev *devm_cxl_add_memdev(struct cxl_dev_state *cxlds,
&gt;  				       const struct cxl_memdev_attach *attach);
&gt; +struct cxl_region;
&gt; +struct cxl_endpoint_decoder *cxl_get_committed_decoder(struct cxl_memdev *cxlmd,
&gt; +						       struct cxl_region **cxlr);
&gt;  #endif /* __CXL_CXL_H__ */



---

On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; This patchset should be applied on the cxl next branch using the base
&gt; specified at the end of this cover letter.
&gt; 
&gt; Dependencies on Dan&#x27;s work has gone and also on Terry&#x27;s as the only
&gt; patch required is now in next. The other dependency is on Smita patchset
&gt; but it does not exist such a dependency as that work will not avoid the
&gt; problem with Type2 and DAX/hmem if soft reserved memory. This needs to
&gt; be solved by the BIOS and Type2 UEFI driver for populating the CXL.mem
&gt; range as EFI_RESERVED_TYPE instead of default EFI_CONVENTIONAL_MEMORY
&gt; with the EFI_MEMORY_SP attribute. There exists though a dependency on
&gt; one Smita&#x27;s patches:
&gt; 
&gt; [PATCH v5 3/7] cxl/region: Skip decoder reset on detach for autodiscovered regions
&gt; 
&gt; This is needed for the default behaviour with current BIOS configuration
&gt; where the HDM Type2 decoders will be kept unreset when driver unloads.
&gt; This is the main change introduced in v23: committed decoders will not
&gt; be reset. Previous v22 functionality supported first driver load finding
&gt; committed decoders but resetting them at unload and supporting
&gt; uncommitted decoders in next driver loads. This will be suported in
&gt; follow-up works.
&gt; 
&gt; v23 changes:
&gt; 
&gt;   patch 11: fixing minor issues and droping change in
&gt; 	    should_emulate_decoders (Jonathan Cameron)
&gt; 
&gt;   patch13: refactoring unregister_region for safety type in Type2 API
&gt; 
&gt;   sfc changes: slight modifications to error path
&gt; 

This cover letter is really long, I&#x27;d remove the change logs for anything more
than 3 revisions back (assuming a v24 is needed). After that you could leave
a lore link for older revisions if you want, but it&#x27;s not needed imo.
Also, feel free to add my Reviewed-by for anything I didn&#x27;t leave a comment on
(felt I should cut down on the mail).

Thanks,
Ben


---

On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; Region creation involves finding available DPA (device-physical-address)
&gt; capacity to map into HPA (host-physical-address) space.
&gt; 
&gt; In order to support CXL Type2 devices, define an API, cxl_request_dpa(),
&gt; that tries to allocate the DPA memory the driver requires to operate.The
&gt; memory requested should not be bigger than the max available HPA obtained
&gt; previously with cxl_get_hpa_freespace().
&gt; 
&gt; Based on https://lore.kernel.org/linux-cxl/168592158743.1948938.7622563891193802610.stgit@dwillia2-xfh.jf.intel.com/
&gt; 
&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
&gt; Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
&gt; ---
&gt;  drivers/cxl/core/hdm.c | 84 ++++++++++++++++++++++++++++++++++++++++++
&gt;  drivers/cxl/cxl.h      |  1 +
&gt;  include/cxl/cxl.h      |  5 +++
&gt;  3 files changed, 90 insertions(+)
&gt; 
&gt; diff --git a/drivers/cxl/core/hdm.c b/drivers/cxl/core/hdm.c
&gt; index a172ce4e9b19..d60a697f12cc 100644
&gt; --- a/drivers/cxl/core/hdm.c
&gt; +++ b/drivers/cxl/core/hdm.c
&gt; @@ -3,6 +3,7 @@
&gt;  #include &lt;linux/seq_file.h&gt;
&gt;  #include &lt;linux/device.h&gt;
&gt;  #include &lt;linux/delay.h&gt;
&gt; +#include &lt;cxl/cxl.h&gt;
&gt;  
&gt;  #include &quot;cxlmem.h&quot;
&gt;  #include &quot;core.h&quot;
&gt; @@ -546,6 +547,12 @@ bool cxl_resource_contains_addr(const struct resource *res, const resource_size_
&gt;  	return resource_contains(res, &amp;_addr);
&gt;  }
&gt;  
&gt; +/**
&gt; + * cxl_dpa_free - release DPA (Device Physical Address)
&gt; + * @cxled: endpoint decoder linked to the DPA
&gt; + *
&gt; + * Returns 0 or error.
&gt; + */
&gt;  int cxl_dpa_free(struct cxl_endpoint_decoder *cxled)
&gt;  {
&gt;  	struct cxl_port *port = cxled_to_port(cxled);
&gt; @@ -572,6 +579,7 @@ int cxl_dpa_free(struct cxl_endpoint_decoder *cxled)
&gt;  	devm_cxl_dpa_release(cxled);
&gt;  	return 0;
&gt;  }
&gt; +EXPORT_SYMBOL_NS_GPL(cxl_dpa_free, &quot;CXL&quot;);
&gt;  
&gt;  int cxl_dpa_set_part(struct cxl_endpoint_decoder *cxled,
&gt;  		     enum cxl_partition_mode mode)
&gt; @@ -603,6 +611,82 @@ int cxl_dpa_set_part(struct cxl_endpoint_decoder *cxled,
&gt;  	return 0;
&gt;  }
&gt;  
&gt; +static int find_free_decoder(struct device *dev, const void *data)
&gt; +{
&gt; +	struct cxl_endpoint_decoder *cxled;
&gt; +	struct cxl_port *port;
&gt; +
&gt; +	if (!is_endpoint_decoder(dev))
&gt; +		return 0;
&gt; +
&gt; +	cxled = to_cxl_endpoint_decoder(dev);
&gt; +	port = cxled_to_port(cxled);
&gt; +
&gt; +	return cxled-&gt;cxld.id == (port-&gt;hdm_end + 1);
&gt; +}
&gt; +
&gt; +static struct cxl_endpoint_decoder *
&gt; +cxl_find_free_decoder(struct cxl_memdev *cxlmd)
&gt; +{
&gt; +	struct cxl_port *endpoint = cxlmd-&gt;endpoint;
&gt; +	struct device *dev;
&gt; +
&gt; +	guard(rwsem_read)(&amp;cxl_rwsem.dpa);
&gt; +	dev = device_find_child(&amp;endpoint-&gt;dev, NULL,
&gt; +				find_free_decoder);
&gt; +	if (!dev)
&gt; +		return NULL;
&gt; +
&gt; +	return to_cxl_endpoint_decoder(dev);
&gt; +}
&gt; +
&gt; +/**
&gt; + * cxl_request_dpa - search and reserve DPA given input constraints
&gt; + * @cxlmd: memdev with an endpoint port with available decoders
&gt; + * @mode: CXL partition mode (ram vs pmem)
&gt; + * @alloc: dpa size required
&gt; + *
&gt; + * Returns a pointer to a &#x27;struct cxl_endpoint_decoder&#x27; on success or
&gt; + * an errno encoded pointer on failure.
&gt; + *
&gt; + * Given that a region needs to allocate from limited HPA capacity it
&gt; + * may be the case that a device has more mappable DPA capacity than
&gt; + * available HPA. The expectation is that @alloc is a driver known
&gt; + * value based on the device capacity but which could not be fully
&gt; + * available due to HPA constraints.
&gt; + *
&gt; + * Returns a pinned cxl_decoder with at least @alloc bytes of capacity
&gt; + * reserved, or an error pointer. The caller is also expected to own the
&gt; + * lifetime of the memdev registration associated with the endpoint to
&gt; + * pin the decoder registered as well.
&gt; + */
&gt; +struct cxl_endpoint_decoder *cxl_request_dpa(struct cxl_memdev *cxlmd,
&gt; +					     enum cxl_partition_mode mode,
&gt; +					     resource_size_t alloc)
&gt; +{
&gt; +	int rc;
&gt; +
&gt; +	if (!IS_ALIGNED(alloc, SZ_256M))
&gt; +		return ERR_PTR(-EINVAL);
&gt; +
&gt; +	struct cxl_endpoint_decoder *cxled __free(put_cxled) =
&gt; +		cxl_find_free_decoder(cxlmd);
&gt; +
&gt; +	if (!cxled)
&gt; +		return ERR_PTR(-ENODEV);
&gt; +
&gt; +	rc = cxl_dpa_set_part(cxled, mode);
&gt; +	if (rc)
&gt; +		return ERR_PTR(rc);
&gt; +
&gt; +	rc = cxl_dpa_alloc(cxled, alloc);
&gt; +	if (rc)
&gt; +		return ERR_PTR(rc);

Should cxl_dpa_set_part() be unwound here, or does it not matter? If it doesn&#x27;t matter:
Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
&gt; +
&gt; +	return no_free_ptr(cxled);
&gt; +}
&gt; +EXPORT_SYMBOL_NS_GPL(cxl_request_dpa, &quot;CXL&quot;);
&gt; +
&gt;  static int __cxl_dpa_alloc(struct cxl_endpoint_decoder *cxled, u64 size)
&gt;  {
&gt;  	struct cxl_memdev *cxlmd = cxled_to_memdev(cxled);
&gt; diff --git a/drivers/cxl/cxl.h b/drivers/cxl/cxl.h
&gt; index d1b010e5e1d0..2b1f7d687a0e 100644
&gt; --- a/drivers/cxl/cxl.h
&gt; +++ b/drivers/cxl/cxl.h
&gt; @@ -667,6 +667,7 @@ struct cxl_root *find_cxl_root(struct cxl_port *port);
&gt;  
&gt;  DEFINE_FREE(put_cxl_root, struct cxl_root *, if (_T) put_device(&amp;_T-&gt;port.dev))
&gt;  DEFINE_FREE(put_cxl_port, struct cxl_port *, if (!IS_ERR_OR_NULL(_T)) put_device(&amp;_T-&gt;dev))
&gt; +DEFINE_FREE(put_cxled, struct cxl_endpoint_decoder *, if (!IS_ERR_OR_NULL(_T)) put_device(&amp;_T-&gt;cxld.dev))
&gt;  DEFINE_FREE(put_cxl_root_decoder, struct cxl_root_decoder *, if (!IS_ERR_OR_NULL(_T)) put_device(&amp;_T-&gt;cxlsd.cxld.dev))
&gt;  DEFINE_FREE(put_cxl_region, struct cxl_region *, if (!IS_ERR_OR_NULL(_T)) put_device(&amp;_T-&gt;dev))
&gt;  
&gt; diff --git a/include/cxl/cxl.h b/include/cxl/cxl.h
&gt; index 783ad570a6eb..4802371db00e 100644
&gt; --- a/include/cxl/cxl.h
&gt; +++ b/include/cxl/cxl.h
&gt; @@ -7,6 +7,7 @@
&gt;  
&gt;  #include &lt;linux/node.h&gt;
&gt;  #include &lt;linux/ioport.h&gt;
&gt; +#include &lt;linux/range.h&gt;
&gt;  #include &lt;cxl/mailbox.h&gt;
&gt;  
&gt;  /**
&gt; @@ -276,4 +277,8 @@ struct cxl_root_decoder *cxl_get_hpa_freespace(struct cxl_memdev *cxlmd,
&gt;  					       unsigned long flags,
&gt;  					       resource_size_t *max);
&gt;  void cxl_put_root_decoder(struct cxl_root_decoder *cxlrd);
&gt; +struct cxl_endpoint_decoder *cxl_request_dpa(struct cxl_memdev *cxlmd,
&gt; +					     enum cxl_partition_mode mode,
&gt; +					     resource_size_t alloc);
&gt; +int cxl_dpa_free(struct cxl_endpoint_decoder *cxled);
&gt;  #endif /* __CXL_CXL_H__ */



---



On 2/19/2026 4:40 AM, Alejandro Lucero Palau wrote:
&gt; 
&gt; On 2/11/26 22:11, Cheatham, Benjamin wrote:
&gt;&gt; On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt;&gt;&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; Region creation based on Type3 devices is triggered from user space
&gt;&gt;&gt; allowing memory combination through interleaving.
&gt;&gt;&gt;
&gt;&gt;&gt; In preparation for kernel driven region creation, that is Type2 drivers
&gt;&gt;&gt; triggering region creation backed with its advertised CXL memory, factor
&gt;&gt;&gt; out a common helper from the user-sysfs region setup for interleave ways.
&gt;&gt;&gt;
&gt;&gt;&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt;&gt;&gt; Reviewed-by: Zhi Wang &lt;zhiw@nvidia.com&gt;
&gt;&gt;&gt; Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
&gt;&gt;&gt; Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
&gt;&gt;&gt; Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
&gt;&gt;&gt; Reviewed-by: Alison Schofield &lt;alison.schofield@intel.com&gt;
&gt;&gt;&gt; ---
&gt;&gt;&gt;  drivers/cxl/core/region.c | 43 ++++++++++++++++++++++++---------------
&gt;&gt;&gt;  1 file changed, 27 insertions(+), 16 deletions(-)
&gt;&gt;&gt;
&gt;&gt;&gt; diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
&gt;&gt;&gt; index f53b2e9fd9e6..ece1d3df7cf1 100644
&gt;&gt;&gt; --- a/drivers/cxl/core/region.c
&gt;&gt;&gt; +++ b/drivers/cxl/core/region.c
&gt;&gt;&gt; @@ -485,22 +485,14 @@ static ssize_t interleave_ways_show(struct device *dev,
&gt;&gt;&gt;   static const struct attribute_group *get_cxl_region_target_group(void);
&gt;&gt;&gt;  -static ssize_t interleave_ways_store(struct device *dev,
&gt;&gt;&gt; - struct device_attribute *attr,
&gt;&gt;&gt; - const char *buf, size_t len)
&gt;&gt;&gt; +static int set_interleave_ways(struct cxl_region *cxlr, int val)
&gt;&gt; @val should probably stay an unsigned int. You pass an unsigned int in the sysfs function, and the
&gt;&gt; function was originally coded with that in mind (same with @save below).
&gt; 
&gt; Good catch. I wonder if I should just change the way the value is obtained, using kstrtoint instead of kstrtouint, as those values are used for cxl_region_params fields defined as int. In other words, it seems doing that simpler than changing all the other places you mention and the structs involved. I can not see a reason for using unsigned int so I think I will follow that approach. Tell me if you think otherwise.
&gt; 

If I had to guess unsigned int was used because a negative interleave granularity/ways makes no sense. I think your suggestion is fine though since no one
in their right mind would give anything but a (relatively) small and positive value for these.

Thanks,
Ben

&gt; 
&gt; Thank you
&gt; 
&gt; 
&gt;&gt; With that cleaned up:
&gt;&gt; Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
&gt;&gt;
&gt;&gt;&gt;  {
&gt;&gt;&gt; - struct cxl_root_decoder *cxlrd = to_cxl_root_decoder(dev-&gt;parent);
&gt;&gt;&gt; + struct cxl_root_decoder *cxlrd = to_cxl_root_decoder(cxlr-&gt;dev.parent);
&gt;&gt;&gt;  struct cxl_decoder *cxld = &amp;cxlrd-&gt;cxlsd.cxld;
&gt;&gt;&gt; - struct cxl_region *cxlr = to_cxl_region(dev);
&gt;&gt;&gt;  struct cxl_region_params *p = &amp;cxlr-&gt;params;
&gt;&gt;&gt; - unsigned int val, save;
&gt;&gt;&gt; - int rc;
&gt;&gt;&gt; + int save, rc;
&gt;&gt;&gt;  u8 iw;
&gt;&gt;&gt;  - rc = kstrtouint(buf, 0, &amp;val);
&gt;&gt;&gt; - if (rc)
&gt;&gt;&gt; - return rc;
&gt;&gt;&gt; -
&gt;&gt;&gt;  rc = ways_to_eiw(val, &amp;iw);
&gt;&gt;&gt;  if (rc)
&gt;&gt;&gt;  return rc;
&gt;&gt;&gt; @@ -515,9 +507,7 @@ static ssize_t interleave_ways_store(struct device *dev,
&gt;&gt;&gt;  return -EINVAL;
&gt;&gt;&gt;  }
&gt;&gt;&gt;  - ACQUIRE(rwsem_write_kill, rwsem)(&amp;cxl_rwsem.region);
&gt;&gt;&gt; - if ((rc = ACQUIRE_ERR(rwsem_write_kill, &amp;rwsem)))
&gt;&gt;&gt; - return rc;
&gt;&gt;&gt; + lockdep_assert_held_write(&amp;cxl_rwsem.region);
&gt;&gt;&gt;   if (p-&gt;state &gt;= CXL_CONFIG_INTERLEAVE_ACTIVE)
&gt;&gt;&gt;  return -EBUSY;
&gt;&gt;&gt; @@ -525,10 +515,31 @@ static ssize_t interleave_ways_store(struct device *dev,
&gt;&gt;&gt;  save = p-&gt;interleave_ways;
&gt;&gt;&gt;  p-&gt;interleave_ways = val;
&gt;&gt;&gt;  rc = sysfs_update_group(&amp;cxlr-&gt;dev.kobj, get_cxl_region_target_group());
&gt;&gt;&gt; - if (rc) {
&gt;&gt;&gt; + if (rc)
&gt;&gt;&gt;  p-&gt;interleave_ways = save;
&gt;&gt;&gt; +
&gt;&gt;&gt; + return rc;
&gt;&gt;&gt; +}
&gt;&gt;&gt; +
&gt;&gt;&gt; +static ssize_t interleave_ways_store(struct device *dev,
&gt;&gt;&gt; + struct device_attribute *attr,
&gt;&gt;&gt; + const char *buf, size_t len)
&gt;&gt;&gt; +{
&gt;&gt;&gt; + struct cxl_region *cxlr = to_cxl_region(dev);
&gt;&gt;&gt; + unsigned int val;
&gt;&gt;&gt; + int rc;
&gt;&gt;&gt; +
&gt;&gt;&gt; + rc = kstrtouint(buf, 0, &amp;val);
&gt;&gt;&gt; + if (rc)
&gt;&gt;&gt; + return rc;
&gt;&gt;&gt; +
&gt;&gt;&gt; + ACQUIRE(rwsem_write_kill, rwsem)(&amp;cxl_rwsem.region);
&gt;&gt;&gt; + if ((rc = ACQUIRE_ERR(rwsem_write_kill, &amp;rwsem)))
&gt;&gt;&gt; + return rc;
&gt;&gt;&gt; +
&gt;&gt;&gt; + rc = set_interleave_ways(cxlr, val);
&gt;&gt;&gt; + if (rc)
&gt;&gt;&gt;  return rc;
&gt;&gt;&gt; - }
&gt;&gt;&gt;   return len;
&gt;&gt;&gt;  }



---

On 2/19/2026 3:58 AM, Alejandro Lucero Palau wrote:
&gt; 
&gt; On 2/11/26 22:10, Cheatham, Benjamin wrote:
&gt;&gt; On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt;&gt;&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; CXL region creation involves allocating capacity from Device Physical
&gt;&gt;&gt; Address (DPA) and assigning it to decode a given Host Physical Address
&gt;&gt;&gt; (HPA). Before determining how much DPA to allocate the amount of available
&gt;&gt;&gt; HPA must be determined. Also, not all HPA is created equal, some HPA
&gt;&gt;&gt; targets RAM, some targets PMEM, some is prepared for device-memory flows
&gt;&gt;&gt; like HDM-D and HDM-DB, and some is HDM-H (host-only).
&gt;&gt;&gt;
&gt;&gt;&gt; In order to support Type2 CXL devices, wrap all of those concerns into
&gt;&gt;&gt; an API that retrieves a root decoder (platform CXL window) that fits the
&gt;&gt;&gt; specified constraints and the capacity available for a new region.
&gt;&gt;&gt;
&gt;&gt;&gt; Add a complementary function for releasing the reference to such root
&gt;&gt;&gt; decoder.
&gt;&gt;&gt;
&gt;&gt;&gt; Based on https://lore.kernel.org/linux-cxl/168592159290.1948938.13522227102445462976.stgit@dwillia2-xfh.jf.intel.com/
&gt;&gt;&gt;
&gt;&gt;&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt;&gt;&gt; Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
&gt;&gt;&gt; ---
&gt;&gt;&gt;  drivers/cxl/core/region.c | 164 ++++++++++++++++++++++++++++++++++++++
&gt;&gt;&gt;  drivers/cxl/cxl.h | 3 +
&gt;&gt;&gt;  include/cxl/cxl.h | 6 ++
&gt;&gt;&gt;  3 files changed, 173 insertions(+)
&gt;&gt;&gt;
&gt;&gt;&gt; diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
&gt;&gt;&gt; index 954b8fcdbac6..bdefd088f5f1 100644
&gt;&gt;&gt; --- a/drivers/cxl/core/region.c
&gt;&gt;&gt; +++ b/drivers/cxl/core/region.c
&gt;&gt;&gt; @@ -705,6 +705,170 @@ static int free_hpa(struct cxl_region *cxlr)
&gt;&gt;&gt;  return 0;
&gt;&gt;&gt;  }
&gt;&gt;&gt;  +struct cxlrd_max_context {
&gt;&gt;&gt; + struct device * const *host_bridges;
&gt;&gt;&gt; + int interleave_ways;
&gt;&gt;&gt; + unsigned long flags;
&gt;&gt;&gt; + resource_size_t max_hpa;
&gt;&gt;&gt; + struct cxl_root_decoder *cxlrd;
&gt;&gt;&gt; +};
&gt;&gt;&gt; +
&gt;&gt;&gt; +static int find_max_hpa(struct device *dev, void *data)
&gt;&gt;&gt; +{
&gt;&gt;&gt; + struct cxlrd_max_context *ctx = data;
&gt;&gt;&gt; + struct cxl_switch_decoder *cxlsd;
&gt;&gt;&gt; + struct cxl_root_decoder *cxlrd;
&gt;&gt;&gt; + struct resource *res, *prev;
&gt;&gt;&gt; + struct cxl_decoder *cxld;
&gt;&gt;&gt; + resource_size_t free = 0;
&gt;&gt;&gt; + resource_size_t max;
&gt;&gt;&gt; + int found = 0;
&gt;&gt;&gt; +
&gt;&gt;&gt; + if (!is_root_decoder(dev))
&gt;&gt;&gt; + return 0;
&gt;&gt;&gt; +
&gt;&gt;&gt; + cxlrd = to_cxl_root_decoder(dev);
&gt;&gt;&gt; + cxlsd = &amp;cxlrd-&gt;cxlsd;
&gt;&gt;&gt; + cxld = &amp;cxlsd-&gt;cxld;
&gt;&gt;&gt; +
&gt;&gt;&gt; + if ((cxld-&gt;flags &amp; ctx-&gt;flags) != ctx-&gt;flags) {
&gt;&gt;&gt; + dev_dbg(dev, &quot;flags not matching: %08lx vs %08lx\n&quot;,
&gt;&gt;&gt; + cxld-&gt;flags, ctx-&gt;flags);
&gt;&gt;&gt; + return 0;
&gt;&gt;&gt; + }
&gt;&gt;&gt; +
&gt;&gt;&gt; + for (int i = 0; i &lt; ctx-&gt;interleave_ways; i++) {
&gt;&gt;&gt; + for (int j = 0; j &lt; ctx-&gt;interleave_ways; j++) {
&gt;&gt;&gt; + if (ctx-&gt;host_bridges[i] == cxlsd-&gt;target[j]-&gt;dport_dev) {
&gt;&gt;&gt; + found++;
&gt;&gt;&gt; + break;
&gt;&gt;&gt; + }
&gt;&gt;&gt; + }
&gt;&gt;&gt; + }
&gt;&gt; This may be over complicated. I&#x27;m not quite sure how it works (I&#x27;m just slow today I guess), but I understand
&gt;&gt; what the intention is based on the debug print below. My issue is that ctx-&gt;host_bridges is only set to 1 host
&gt;&gt; bridge (endpoint-&gt;host_bridge) in cxl_get_hpa_freespace(), which is the only caller of this function. At that
&gt;&gt; point, why have the outer loop at all? At that point, you could also simplify ctx-&gt;host_bridges to only
&gt;&gt; be a struct device * const.
&gt;&gt;
&gt;&gt; Maybe this gets called elsewhere later on in the series? I haven&#x27;t looked at the rest yet. If I&#x27;m wrong, then
&gt;&gt; I&#x27;d probably add a comment saying what the cxlsd-&gt;target[] entries are supposed to be pointing at.
&gt; 
&gt; 
&gt; Hi Ben,
&gt; 
&gt; 
&gt; I do remember this one.
&gt; 
&gt; 
&gt; Dan&#x27;s original patches had this support for interleaving, then I removed it as the case for Type2 and interleaving is quite unlikely, at least right now and likely in the near future. But I was told why do not support it as it was trivial to do so. FWIW, If I think only about the use case coming with the patchset, I agree with you, but because those previous discussions, I think I have to leave it.
&gt; 

I&#x27;m fine with that, but I would at least do the fix with the decoder position in 19/22 and make a note that the
interleave_ways parameter in cxl_get_hpa_freespace() below is currently unused (unless I&#x27;m misunderstanding
the endpoint-&gt;host_bridge member).

That way, the support is mostly there and just requires a small, previously noted, addition to enable. If you&#x27;re
fine with that then feel free to add my Reviewed-by after implementing in v24.

Thanks,
Ben

&gt; 
&gt; Thank you
&gt; 
&gt; 
&gt;&gt;&gt; +
&gt;&gt;&gt; + if (found != ctx-&gt;interleave_ways) {
&gt;&gt;&gt; + dev_dbg(dev,
&gt;&gt;&gt; + &quot;Not enough host bridges. Found %d for %d interleave ways requested\n&quot;,
&gt;&gt;&gt; + found, ctx-&gt;interleave_ways);
&gt;&gt;&gt; + return 0;
&gt;&gt;&gt; + }
&gt;&gt;&gt; +
&gt;&gt;&gt; + /*
&gt;&gt;&gt; + * Walk the root decoder resource range relying on cxl_rwsem.region to
&gt;&gt;&gt; + * preclude sibling arrival/departure and find the largest free space
&gt;&gt;&gt; + * gap.
&gt;&gt;&gt; + */
&gt;&gt;&gt; + lockdep_assert_held_read(&amp;cxl_rwsem.region);
&gt;&gt;&gt; + res = cxlrd-&gt;res-&gt;child;
&gt;&gt;&gt; +
&gt;&gt;&gt; + /* With no resource child the whole parent resource is available */
&gt;&gt;&gt; + if (!res)
&gt;&gt;&gt; + max = resource_size(cxlrd-&gt;res);
&gt;&gt;&gt; + else
&gt;&gt;&gt; + max = 0;
&gt;&gt;&gt; +
&gt;&gt;&gt; + for (prev = NULL; res; prev = res, res = res-&gt;sibling) {
&gt;&gt;&gt; + if (!prev &amp;&amp; res-&gt;start == cxlrd-&gt;res-&gt;start &amp;&amp;
&gt;&gt;&gt; + res-&gt;end == cxlrd-&gt;res-&gt;end) {
&gt;&gt;&gt; + max = resource_size(cxlrd-&gt;res);
&gt;&gt;&gt; + break;
&gt;&gt;&gt; + }
&gt;&gt;&gt; + /*
&gt;&gt;&gt; + * Sanity check for preventing arithmetic problems below as a
&gt;&gt;&gt; + * resource with size 0 could imply using the end field below
&gt;&gt;&gt; + * when set to unsigned zero - 1 or all f in hex.
&gt;&gt;&gt; + */
&gt;&gt;&gt; + if (prev &amp;&amp; !resource_size(prev))
&gt;&gt;&gt; + continue;
&gt;&gt;&gt; +
&gt;&gt;&gt; + if (!prev &amp;&amp; res-&gt;start &gt; cxlrd-&gt;res-&gt;start) {
&gt;&gt;&gt; + free = res-&gt;start - cxlrd-&gt;res-&gt;start;
&gt;&gt;&gt; + max = max(free, max);
&gt;&gt;&gt; + }
&gt;&gt;&gt; + if (prev &amp;&amp; res-&gt;start &gt; prev-&gt;end + 1) {
&gt;&gt;&gt; + free = res-&gt;start - prev-&gt;end + 1;
&gt;&gt;&gt; + max = max(free, max);
&gt;&gt;&gt; + }
&gt;&gt;&gt; + }
&gt;&gt;&gt; +
&gt;&gt;&gt; + if (prev &amp;&amp; prev-&gt;end + 1 &lt; cxlrd-&gt;res-&gt;end + 1) {
&gt;&gt;&gt; + free = cxlrd-&gt;res-&gt;end + 1 - prev-&gt;end + 1;
&gt;&gt;&gt; + max = max(free, max);
&gt;&gt;&gt; + }
&gt;&gt;&gt; +
&gt;&gt;&gt; + dev_dbg(cxlrd_dev(cxlrd), &quot;found %pa bytes of free space\n&quot;, &amp;max);
&gt;&gt;&gt; + if (max &gt; ctx-&gt;max_hpa) {
&gt;&gt;&gt; + if (ctx-&gt;cxlrd)
&gt;&gt;&gt; + put_device(cxlrd_dev(ctx-&gt;cxlrd));
&gt;&gt;&gt; + get_device(cxlrd_dev(cxlrd));
&gt;&gt;&gt; + ctx-&gt;cxlrd = cxlrd;
&gt;&gt;&gt; + ctx-&gt;max_hpa = max;
&gt;&gt;&gt; + }
&gt;&gt;&gt; + return 0;
&gt;&gt;&gt; +}
&gt;&gt;&gt; +
&gt;&gt;&gt; +/**
&gt;&gt;&gt; + * cxl_get_hpa_freespace - find a root decoder with free capacity per constraints
&gt;&gt;&gt; + * @cxlmd: the mem device requiring the HPA
&gt;&gt;&gt; + * @interleave_ways: number of entries in @host_bridges
&gt;&gt;&gt; + * @flags: CXL_DECODER_F flags for selecting RAM vs PMEM, and Type2 device
&gt;&gt;&gt; + * @max_avail_contig: output parameter of max contiguous bytes available in the
&gt;&gt;&gt; + * returned decoder
&gt;&gt;&gt; + *
&gt;&gt;&gt; + * Returns a pointer to a struct cxl_root_decoder
&gt;&gt;&gt; + *
&gt;&gt;&gt; + * The return tuple of a &#x27;struct cxl_root_decoder&#x27; and &#x27;bytes available given
&gt;&gt;&gt; + * in (@max_avail_contig))&#x27; is a point in time snapshot. If by the time the
&gt;&gt;&gt; + * caller goes to use this decoder and its capacity is reduced then caller needs
&gt;&gt;&gt; + * to loop and retry.
&gt;&gt;&gt; + *
&gt;&gt;&gt; + * The returned root decoder has an elevated reference count that needs to be
&gt;&gt;&gt; + * put with cxl_put_root_decoder(cxlrd).
&gt;&gt;&gt; + */
&gt;&gt;&gt; +struct cxl_root_decoder *cxl_get_hpa_freespace(struct cxl_memdev *cxlmd,
&gt;&gt;&gt; + int interleave_ways,
&gt;&gt;&gt; + unsigned long flags,
&gt;&gt;&gt; + resource_size_t *max_avail_contig)
&gt;&gt;&gt; +{
&gt;&gt;&gt; + struct cxlrd_max_context ctx = {
&gt;&gt;&gt; + .flags = flags,
&gt;&gt;&gt; + .interleave_ways = interleave_ways,
&gt;&gt;&gt; + };
&gt;&gt;&gt; + struct cxl_port *root_port;
&gt;&gt;&gt; + struct cxl_port *endpoint;
&gt;&gt;&gt; +
&gt;&gt;&gt; + endpoint = cxlmd-&gt;endpoint;
&gt;&gt;&gt; + if (!endpoint) {
&gt;&gt;&gt; + dev_dbg(&amp;cxlmd-&gt;dev, &quot;endpoint not linked to memdev\n&quot;);
&gt;&gt;&gt; + return ERR_PTR(-ENXIO);
&gt;&gt;&gt; + }
&gt;&gt;&gt; +
&gt;&gt;&gt; + ctx.host_bridges = &amp;endpoint-&gt;host_bridge;
&gt;&gt; Mentioned earlier, interleave_ways is effectively hardcoded to 1 (unless I&#x27;m misunderstanding
&gt;&gt; something). I think what you want here is to go to the CXL root and pass in the children (i.e. host bridges)?
&gt;&gt; I&#x27;m not sure of what the fix is to get the intended behavior.
&gt;&gt;
&gt;&gt; It may be worth getting rid of the interleave_ways portion of this function and
&gt;&gt; add it later when someone needs it. You could also explain it&#x27;s hard coded to 1/unused
&gt;&gt; in the doc comment if you know of an immediate need for it.
&gt;&gt;
&gt;&gt;&gt; +
&gt;&gt;&gt; + struct cxl_root *root __free(put_cxl_root) = find_cxl_root(endpoint);
&gt;&gt;&gt; + if (!root) {
&gt;&gt;&gt; + dev_dbg(&amp;endpoint-&gt;dev, &quot;endpoint is not related to a root port\n&quot;);
&gt;&gt;&gt; + return ERR_PTR(-ENXIO);
&gt;&gt;&gt; + }
&gt;&gt;&gt; +
&gt;&gt;&gt; + root_port = &amp;root-&gt;port;
&gt;&gt;&gt; + scoped_guard(rwsem_read, &amp;cxl_rwsem.region)
&gt;&gt;&gt; + device_for_each_child(&amp;root_port-&gt;dev, &amp;ctx, find_max_hpa);
&gt;&gt; Can just use a guard() here.
&gt;&gt;
&gt;&gt;&gt; +
&gt;&gt;&gt; + if (!ctx.cxlrd)
&gt;&gt;&gt; + return ERR_PTR(-ENOMEM);
&gt;&gt;&gt; +
&gt;&gt;&gt; + *max_avail_contig = ctx.max_hpa;
&gt;&gt;&gt; + return ctx.cxlrd;
&gt;&gt;&gt; +}
&gt;&gt;&gt; +EXPORT_SYMBOL_NS_GPL(cxl_get_hpa_freespace, &quot;CXL&quot;);
&gt;&gt;&gt; +
&gt;&gt;&gt; +void cxl_put_root_decoder(struct cxl_root_decoder *cxlrd)
&gt;&gt;&gt; +{
&gt;&gt;&gt; + put_device(cxlrd_dev(cxlrd));
&gt;&gt;&gt; +}
&gt;&gt;&gt; +EXPORT_SYMBOL_NS_GPL(cxl_put_root_decoder, &quot;CXL&quot;);
&gt;&gt;&gt; +
&gt;&gt;&gt;  static ssize_t size_store(struct device *dev, struct device_attribute *attr,
&gt;&gt;&gt;  const char *buf, size_t len)
&gt;&gt;&gt;  {
&gt;&gt;&gt; diff --git a/drivers/cxl/cxl.h b/drivers/cxl/cxl.h
&gt;&gt;&gt; index 944c5d1ccceb..c7d9b2c2908f 100644
&gt;&gt;&gt; --- a/drivers/cxl/cxl.h
&gt;&gt;&gt; +++ b/drivers/cxl/cxl.h
&gt;&gt;&gt; @@ -706,6 +706,9 @@ struct cxl_root_decoder *to_cxl_root_decoder(struct device *dev);
&gt;&gt;&gt;  struct cxl_switch_decoder *to_cxl_switch_decoder(struct device *dev);
&gt;&gt;&gt;  struct cxl_endpoint_decoder *to_cxl_endpoint_decoder(struct device *dev);
&gt;&gt;&gt;  bool is_root_decoder(struct device *dev);
&gt;&gt;&gt; +
&gt;&gt;&gt; +#define cxlrd_dev(cxlrd) (&amp;(cxlrd)-&gt;cxlsd.cxld.dev)
&gt;&gt;&gt; +
&gt;&gt;&gt;  bool is_switch_decoder(struct device *dev);
&gt;&gt;&gt;  bool is_endpoint_decoder(struct device *dev);
&gt;&gt;&gt;  struct cxl_root_decoder *cxl_root_decoder_alloc(struct cxl_port *port,
&gt;&gt;&gt; diff --git a/include/cxl/cxl.h b/include/cxl/cxl.h
&gt;&gt;&gt; index 92880c26b2d5..834dc7e78934 100644
&gt;&gt;&gt; --- a/include/cxl/cxl.h
&gt;&gt;&gt; +++ b/include/cxl/cxl.h
&gt;&gt;&gt; @@ -255,4 +255,10 @@ struct cxl_endpoint_decoder *cxl_get_committed_decoder(struct cxl_memdev *cxlmd,
&gt;&gt;&gt;  struct range;
&gt;&gt;&gt;  int cxl_get_region_range(struct cxl_region *region, struct range *range);
&gt;&gt;&gt;  void cxl_unregister_region(struct cxl_region *cxlr);
&gt;&gt;&gt; +struct cxl_port;
&gt;&gt;&gt; +struct cxl_root_decoder *cxl_get_hpa_freespace(struct cxl_memdev *cxlmd,
&gt;&gt;&gt; + int interleave_ways,
&gt;&gt;&gt; + unsigned long flags,
&gt;&gt;&gt; + resource_size_t *max);
&gt;&gt;&gt; +void cxl_put_root_decoder(struct cxl_root_decoder *cxlrd);
&gt;&gt;&gt;  #endif /* __CXL_CXL_H__ */

</pre>
</details>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Cheatham, Benjamin</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-11">2026-02-11</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer suggested updating ABI documentation to explicitly state that this attribute only applies to type 3 regions, and offered a Reviewed-by tag.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">I haven&#x27;t read the ABI docs, but would it be worthwhile to update the documentation for this attribute
to mention it only makes type 3 regions? I&#x27;m flip-flopping on whether it&#x27;s worth the trouble but thought
I should mention it.

Either way:
Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;</pre>
</details>
<div class="review-comment-signals">Signals: suggested update, considered worthwhile</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Cheatham, Benjamin</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-11">2026-02-11</a>
<span class="inline-review-badge">Inline Review</span>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer noted that the function parameter @val should remain an unsigned int, as it is passed as such in sysfs and was originally coded to expect this type.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">@val should probably stay an unsigned int. You pass an unsigned int in the sysfs function, and the
function was originally coded with that in mind (same with @save below). With that cleaned up:
Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;</pre>
</details>
<div class="review-comment-signals">Signals: requested_change</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Cheatham, Benjamin</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-11">2026-02-11</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#155724;background:#d4edda">Positive</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Gave Reviewed-by</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; By definition a type2 cxl device will use the host managed memory for
&gt; specific functionality, therefore it should not be available to other
&gt; uses.
&gt; 
&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
&gt; Reviewed-by: Davidlohr Bueso &lt;daves@stgolabs.net&gt;
&gt; Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
&gt; Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
&gt; ---
&gt;  drivers/cxl/core/region.c | 7 +++++++
&gt;  1 file changed, 7 insertions(+)
&gt; 
&gt; diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
&gt; index 293e63dfef22..12df717cc881 100644
&gt; --- a/drivers/cxl/core/region.c
&gt; +++ b/drivers/cxl/core/region.c
&gt; @@ -4441,6 +4441,13 @@ static int cxl_region_probe(struct device *dev)
&gt;  	if (rc)
&gt;  		return rc;
&gt;  
&gt; +	/*
&gt; +	 * HDM-D[B] (device-memory) regions have accelerator specific usage.
&gt; +	 * Skip device-dax registration.
&gt; +	 */
&gt; +	if (cxlr-&gt;type == CXL_DECODER_DEVMEM)
&gt; +		return 0;

Minor nit: Should probably move this to be the first thing in the function. It would save
having to acquire a lock in cxl_region_can_probe() above. Keep my reviewed-by either way,
it&#x27;s really just a minor optimization.
&gt; +
&gt;  	/*
&gt;  	 * From this point on any path that changes the region&#x27;s state away from
&gt;  	 * CXL_CONFIG_COMMIT is also responsible for releasing the driver.



---

On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; CXL region creation involves allocating capacity from Device Physical
&gt; Address (DPA) and assigning it to decode a given Host Physical Address
&gt; (HPA). Before determining how much DPA to allocate the amount of available
&gt; HPA must be determined. Also, not all HPA is created equal, some HPA
&gt; targets RAM, some targets PMEM, some is prepared for device-memory flows
&gt; like HDM-D and HDM-DB, and some is HDM-H (host-only).
&gt; 
&gt; In order to support Type2 CXL devices, wrap all of those concerns into
&gt; an API that retrieves a root decoder (platform CXL window) that fits the
&gt; specified constraints and the capacity available for a new region.
&gt; 
&gt; Add a complementary function for releasing the reference to such root
&gt; decoder.
&gt; 
&gt; Based on https://lore.kernel.org/linux-cxl/168592159290.1948938.13522227102445462976.stgit@dwillia2-xfh.jf.intel.com/
&gt; 
&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
&gt; ---
&gt;  drivers/cxl/core/region.c | 164 ++++++++++++++++++++++++++++++++++++++
&gt;  drivers/cxl/cxl.h         |   3 +
&gt;  include/cxl/cxl.h         |   6 ++
&gt;  3 files changed, 173 insertions(+)
&gt; 
&gt; diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
&gt; index 954b8fcdbac6..bdefd088f5f1 100644
&gt; --- a/drivers/cxl/core/region.c
&gt; +++ b/drivers/cxl/core/region.c
&gt; @@ -705,6 +705,170 @@ static int free_hpa(struct cxl_region *cxlr)
&gt;  	return 0;
&gt;  }
&gt;  
&gt; +struct cxlrd_max_context {
&gt; +	struct device * const *host_bridges;
&gt; +	int interleave_ways;
&gt; +	unsigned long flags;
&gt; +	resource_size_t max_hpa;
&gt; +	struct cxl_root_decoder *cxlrd;
&gt; +};
&gt; +
&gt; +static int find_max_hpa(struct device *dev, void *data)
&gt; +{
&gt; +	struct cxlrd_max_context *ctx = data;
&gt; +	struct cxl_switch_decoder *cxlsd;
&gt; +	struct cxl_root_decoder *cxlrd;
&gt; +	struct resource *res, *prev;
&gt; +	struct cxl_decoder *cxld;
&gt; +	resource_size_t free = 0;
&gt; +	resource_size_t max;
&gt; +	int found = 0;
&gt; +
&gt; +	if (!is_root_decoder(dev))
&gt; +		return 0;
&gt; +
&gt; +	cxlrd = to_cxl_root_decoder(dev);
&gt; +	cxlsd = &amp;cxlrd-&gt;cxlsd;
&gt; +	cxld = &amp;cxlsd-&gt;cxld;
&gt; +
&gt; +	if ((cxld-&gt;flags &amp; ctx-&gt;flags) != ctx-&gt;flags) {
&gt; +		dev_dbg(dev, &quot;flags not matching: %08lx vs %08lx\n&quot;,
&gt; +			cxld-&gt;flags, ctx-&gt;flags);
&gt; +		return 0;
&gt; +	}
&gt; +
&gt; +	for (int i = 0; i &lt; ctx-&gt;interleave_ways; i++) {
&gt; +		for (int j = 0; j &lt; ctx-&gt;interleave_ways; j++) {
&gt; +			if (ctx-&gt;host_bridges[i] == cxlsd-&gt;target[j]-&gt;dport_dev) {
&gt; +				found++;
&gt; +				break;
&gt; +			}
&gt; +		}
&gt; +	}

This may be over complicated. I&#x27;m not quite sure how it works (I&#x27;m just slow today I guess), but I understand
what the intention is based on the debug print below. My issue is that ctx-&gt;host_bridges is only set to 1 host
bridge (endpoint-&gt;host_bridge) in cxl_get_hpa_freespace(), which is the only caller of this function. At that
point, why have the outer loop at all? At that point, you could also simplify ctx-&gt;host_bridges to only
be a struct device * const.

Maybe this gets called elsewhere later on in the series? I haven&#x27;t looked at the rest yet. If I&#x27;m wrong, then
I&#x27;d probably add a comment saying what the cxlsd-&gt;target[] entries are supposed to be pointing at.
&gt; +
&gt; +	if (found != ctx-&gt;interleave_ways) {
&gt; +		dev_dbg(dev,
&gt; +			&quot;Not enough host bridges. Found %d for %d interleave ways requested\n&quot;,
&gt; +			found, ctx-&gt;interleave_ways);
&gt; +		return 0;
&gt; +	}
&gt; +
&gt; +	/*
&gt; +	 * Walk the root decoder resource range relying on cxl_rwsem.region to
&gt; +	 * preclude sibling arrival/departure and find the largest free space
&gt; +	 * gap.
&gt; +	 */
&gt; +	lockdep_assert_held_read(&amp;cxl_rwsem.region);
&gt; +	res = cxlrd-&gt;res-&gt;child;
&gt; +
&gt; +	/* With no resource child the whole parent resource is available */
&gt; +	if (!res)
&gt; +		max = resource_size(cxlrd-&gt;res);
&gt; +	else
&gt; +		max = 0;
&gt; +
&gt; +	for (prev = NULL; res; prev = res, res = res-&gt;sibling) {
&gt; +		if (!prev &amp;&amp; res-&gt;start == cxlrd-&gt;res-&gt;start &amp;&amp;
&gt; +		    res-&gt;end == cxlrd-&gt;res-&gt;end) {
&gt; +			max = resource_size(cxlrd-&gt;res);
&gt; +			break;
&gt; +		}
&gt; +		/*
&gt; +		 * Sanity check for preventing arithmetic problems below as a
&gt; +		 * resource with size 0 could imply using the end field below
&gt; +		 * when set to unsigned zero - 1 or all f in hex.
&gt; +		 */
&gt; +		if (prev &amp;&amp; !resource_size(prev))
&gt; +			continue;
&gt; +
&gt; +		if (!prev &amp;&amp; res-&gt;start &gt; cxlrd-&gt;res-&gt;start) {
&gt; +			free = res-&gt;start - cxlrd-&gt;res-&gt;start;
&gt; +			max = max(free, max);
&gt; +		}
&gt; +		if (prev &amp;&amp; res-&gt;start &gt; prev-&gt;end + 1) {
&gt; +			free = res-&gt;start - prev-&gt;end + 1;
&gt; +			max = max(free, max);
&gt; +		}
&gt; +	}
&gt; +
&gt; +	if (prev &amp;&amp; prev-&gt;end + 1 &lt; cxlrd-&gt;res-&gt;end + 1) {
&gt; +		free = cxlrd-&gt;res-&gt;end + 1 - prev-&gt;end + 1;
&gt; +		max = max(free, max);
&gt; +	}
&gt; +
&gt; +	dev_dbg(cxlrd_dev(cxlrd), &quot;found %pa bytes of free space\n&quot;, &amp;max);
&gt; +	if (max &gt; ctx-&gt;max_hpa) {
&gt; +		if (ctx-&gt;cxlrd)
&gt; +			put_device(cxlrd_dev(ctx-&gt;cxlrd));
&gt; +		get_device(cxlrd_dev(cxlrd));
&gt; +		ctx-&gt;cxlrd = cxlrd;
&gt; +		ctx-&gt;max_hpa = max;
&gt; +	}
&gt; +	return 0;
&gt; +}
&gt; +
&gt; +/**
&gt; + * cxl_get_hpa_freespace - find a root decoder with free capacity per constraints
&gt; + * @cxlmd: the mem device requiring the HPA
&gt; + * @interleave_ways: number of entries in @host_bridges
&gt; + * @flags: CXL_DECODER_F flags for selecting RAM vs PMEM, and Type2 device
&gt; + * @max_avail_contig: output parameter of max contiguous bytes available in the
&gt; + *		      returned decoder
&gt; + *
&gt; + * Returns a pointer to a struct cxl_root_decoder
&gt; + *
&gt; + * The return tuple of a &#x27;struct cxl_root_decoder&#x27; and &#x27;bytes available given
&gt; + * in (@max_avail_contig))&#x27; is a point in time snapshot. If by the time the
&gt; + * caller goes to use this decoder and its capacity is reduced then caller needs
&gt; + * to loop and retry.
&gt; + *
&gt; + * The returned root decoder has an elevated reference count that needs to be
&gt; + * put with cxl_put_root_decoder(cxlrd).
&gt; + */
&gt; +struct cxl_root_decoder *cxl_get_hpa_freespace(struct cxl_memdev *cxlmd,
&gt; +					       int interleave_ways,
&gt; +					       unsigned long flags,
&gt; +					       resource_size_t *max_avail_contig)
&gt; +{
&gt; +	struct cxlrd_max_context ctx = {
&gt; +		.flags = flags,
&gt; +		.interleave_ways = interleave_ways,
&gt; +	};
&gt; +	struct cxl_port *root_port;
&gt; +	struct cxl_port *endpoint;
&gt; +
&gt; +	endpoint = cxlmd-&gt;endpoint;
&gt; +	if (!endpoint) {
&gt; +		dev_dbg(&amp;cxlmd-&gt;dev, &quot;endpoint not linked to memdev\n&quot;);
&gt; +		return ERR_PTR(-ENXIO);
&gt; +	}
&gt; +
&gt; +	ctx.host_bridges = &amp;endpoint-&gt;host_bridge;

Mentioned earlier, interleave_ways is effectively hardcoded to 1 (unless I&#x27;m misunderstanding
something). I think what you want here is to go to the CXL root and pass in the children (i.e. host bridges)?
I&#x27;m not sure of what the fix is to get the intended behavior.

It may be worth getting rid of the interleave_ways portion of this function and
add it later when someone needs it. You could also explain it&#x27;s hard coded to 1/unused
in the doc comment if you know of an immediate need for it.

&gt; +
&gt; +	struct cxl_root *root __free(put_cxl_root) = find_cxl_root(endpoint);
&gt; +	if (!root) {
&gt; +		dev_dbg(&amp;endpoint-&gt;dev, &quot;endpoint is not related to a root port\n&quot;);
&gt; +		return ERR_PTR(-ENXIO);
&gt; +	}
&gt; +
&gt; +	root_port = &amp;root-&gt;port;
&gt; +	scoped_guard(rwsem_read, &amp;cxl_rwsem.region)
&gt; +		device_for_each_child(&amp;root_port-&gt;dev, &amp;ctx, find_max_hpa);

Can just use a guard() here.

&gt; +
&gt; +	if (!ctx.cxlrd)
&gt; +		return ERR_PTR(-ENOMEM);
&gt; +
&gt; +	*max_avail_contig = ctx.max_hpa;
&gt; +	return ctx.cxlrd;
&gt; +}
&gt; +EXPORT_SYMBOL_NS_GPL(cxl_get_hpa_freespace, &quot;CXL&quot;);
&gt; +
&gt; +void cxl_put_root_decoder(struct cxl_root_decoder *cxlrd)
&gt; +{
&gt; +	put_device(cxlrd_dev(cxlrd));
&gt; +}
&gt; +EXPORT_SYMBOL_NS_GPL(cxl_put_root_decoder, &quot;CXL&quot;);
&gt; +
&gt;  static ssize_t size_store(struct device *dev, struct device_attribute *attr,
&gt;  			  const char *buf, size_t len)
&gt;  {
&gt; diff --git a/drivers/cxl/cxl.h b/drivers/cxl/cxl.h
&gt; index 944c5d1ccceb..c7d9b2c2908f 100644
&gt; --- a/drivers/cxl/cxl.h
&gt; +++ b/drivers/cxl/cxl.h
&gt; @@ -706,6 +706,9 @@ struct cxl_root_decoder *to_cxl_root_decoder(struct device *dev);
&gt;  struct cxl_switch_decoder *to_cxl_switch_decoder(struct device *dev);
&gt;  struct cxl_endpoint_decoder *to_cxl_endpoint_decoder(struct device *dev);
&gt;  bool is_root_decoder(struct device *dev);
&gt; +
&gt; +#define cxlrd_dev(cxlrd) (&amp;(cxlrd)-&gt;cxlsd.cxld.dev)
&gt; +
&gt;  bool is_switch_decoder(struct device *dev);
&gt;  bool is_endpoint_decoder(struct device *dev);
&gt;  struct cxl_root_decoder *cxl_root_decoder_alloc(struct cxl_port *port,
&gt; diff --git a/include/cxl/cxl.h b/include/cxl/cxl.h
&gt; index 92880c26b2d5..834dc7e78934 100644
&gt; --- a/include/cxl/cxl.h
&gt; +++ b/include/cxl/cxl.h
&gt; @@ -255,4 +255,10 @@ struct cxl_endpoint_decoder *cxl_get_committed_decoder(struct cxl_memdev *cxlmd,
&gt;  struct range;
&gt;  int cxl_get_region_range(struct cxl_region *region, struct range *range);
&gt;  void cxl_unregister_region(struct cxl_region *cxlr);
&gt; +struct cxl_port;
&gt; +struct cxl_root_decoder *cxl_get_hpa_freespace(struct cxl_memdev *cxlmd,
&gt; +					       int interleave_ways,
&gt; +					       unsigned long flags,
&gt; +					       resource_size_t *max);
&gt; +void cxl_put_root_decoder(struct cxl_root_decoder *cxlrd);
&gt;  #endif /* __CXL_CXL_H__ */



---

On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; Check if device HDM is already committed during firmware/BIOS
&gt; initialization.
&gt; 
&gt; A CXL region should exist if so after memdev allocation/initialization.
&gt; Get HPA from region and map it.
&gt; 
&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; ---
&gt;  drivers/net/ethernet/sfc/efx_cxl.c | 28 +++++++++++++++++++++++++++-
&gt;  1 file changed, 27 insertions(+), 1 deletion(-)
&gt; 
&gt; diff --git a/drivers/net/ethernet/sfc/efx_cxl.c b/drivers/net/ethernet/sfc/efx_cxl.c
&gt; index a77ef4783fcb..3536eccf1b2a 100644
&gt; --- a/drivers/net/ethernet/sfc/efx_cxl.c
&gt; +++ b/drivers/net/ethernet/sfc/efx_cxl.c
&gt; @@ -19,6 +19,7 @@ int efx_cxl_init(struct efx_probe_data *probe_data)
&gt;  	struct efx_nic *efx = &amp;probe_data-&gt;efx;
&gt;  	struct pci_dev *pci_dev = efx-&gt;pci_dev;
&gt;  	struct efx_cxl *cxl;
&gt; +	struct range range;
&gt;  	u16 dvsec;
&gt;  	int rc;
&gt;  
&gt; @@ -90,13 +91,38 @@ int efx_cxl_init(struct efx_probe_data *probe_data)
&gt;  		return PTR_ERR(cxl-&gt;cxlmd);
&gt;  	}
&gt;  
&gt; -	probe_data-&gt;cxl = cxl;
&gt; +	cxl-&gt;cxled = cxl_get_committed_decoder(cxl-&gt;cxlmd, &amp;cxl-&gt;efx_region);
&gt; +	if (cxl-&gt;cxled) {
&gt; +		if (!cxl-&gt;efx_region) {
&gt; +			pci_err(pci_dev, &quot;CXL found committed decoder without a region&quot;);
&gt; +			return -ENODEV;
&gt; +		}
&gt; +		rc = cxl_get_region_range(cxl-&gt;efx_region, &amp;range);

Missing an empty line above.

&gt; +		if (rc) {
&gt; +			pci_err(pci_dev,
&gt; +				&quot;CXL getting regions params from a committed decoder failed&quot;);
&gt; +			return rc;
&gt; +		}
&gt; +
&gt; +		cxl-&gt;ctpio_cxl = ioremap(range.start, range.end - range.start + 1);

Maybe use range_len() instead for the second parameter?

&gt; +		if (!cxl-&gt;ctpio_cxl) {
&gt; +			pci_err(pci_dev, &quot;CXL ioremap region (%pra) failed&quot;, &amp;range);
&gt; +			return -ENOMEM;
&gt; +		}
&gt; +
&gt; +		probe_data-&gt;cxl = cxl;
&gt; +	}
&gt;  
&gt;  	return 0;
&gt;  }
&gt;  
&gt;  void efx_cxl_exit(struct efx_probe_data *probe_data)
&gt;  {
&gt; +	if (!probe_data-&gt;cxl)
&gt; +		return;
&gt; +
&gt; +	iounmap(probe_data-&gt;cxl-&gt;ctpio_cxl);
&gt; +	cxl_unregister_region(probe_data-&gt;cxl-&gt;efx_region);
&gt;  }
&gt;  
&gt;  MODULE_IMPORT_NS(&quot;CXL&quot;);



---

On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; Region creation involves finding available DPA (device-physical-address)
&gt; capacity to map into HPA (host-physical-address) space.
&gt; 
&gt; In order to support CXL Type2 devices, define an API, cxl_request_dpa(),
&gt; that tries to allocate the DPA memory the driver requires to operate.The
&gt; memory requested should not be bigger than the max available HPA obtained
&gt; previously with cxl_get_hpa_freespace().
&gt; 
&gt; Based on https://lore.kernel.org/linux-cxl/168592158743.1948938.7622563891193802610.stgit@dwillia2-xfh.jf.intel.com/
&gt; 
&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
&gt; Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
&gt; ---
&gt;  drivers/cxl/core/hdm.c | 84 ++++++++++++++++++++++++++++++++++++++++++
&gt;  drivers/cxl/cxl.h      |  1 +
&gt;  include/cxl/cxl.h      |  5 +++
&gt;  3 files changed, 90 insertions(+)
&gt; 
&gt; diff --git a/drivers/cxl/core/hdm.c b/drivers/cxl/core/hdm.c
&gt; index a172ce4e9b19..d60a697f12cc 100644
&gt; --- a/drivers/cxl/core/hdm.c
&gt; +++ b/drivers/cxl/core/hdm.c
&gt; @@ -3,6 +3,7 @@
&gt;  #include &lt;linux/seq_file.h&gt;
&gt;  #include &lt;linux/device.h&gt;
&gt;  #include &lt;linux/delay.h&gt;
&gt; +#include &lt;cxl/cxl.h&gt;
&gt;  
&gt;  #include &quot;cxlmem.h&quot;
&gt;  #include &quot;core.h&quot;
&gt; @@ -546,6 +547,12 @@ bool cxl_resource_contains_addr(const struct resource *res, const resource_size_
&gt;  	return resource_contains(res, &amp;_addr);
&gt;  }
&gt;  
&gt; +/**
&gt; + * cxl_dpa_free - release DPA (Device Physical Address)
&gt; + * @cxled: endpoint decoder linked to the DPA
&gt; + *
&gt; + * Returns 0 or error.
&gt; + */
&gt;  int cxl_dpa_free(struct cxl_endpoint_decoder *cxled)
&gt;  {
&gt;  	struct cxl_port *port = cxled_to_port(cxled);
&gt; @@ -572,6 +579,7 @@ int cxl_dpa_free(struct cxl_endpoint_decoder *cxled)
&gt;  	devm_cxl_dpa_release(cxled);
&gt;  	return 0;
&gt;  }
&gt; +EXPORT_SYMBOL_NS_GPL(cxl_dpa_free, &quot;CXL&quot;);
&gt;  
&gt;  int cxl_dpa_set_part(struct cxl_endpoint_decoder *cxled,
&gt;  		     enum cxl_partition_mode mode)
&gt; @@ -603,6 +611,82 @@ int cxl_dpa_set_part(struct cxl_endpoint_decoder *cxled,
&gt;  	return 0;
&gt;  }
&gt;  
&gt; +static int find_free_decoder(struct device *dev, const void *data)
&gt; +{
&gt; +	struct cxl_endpoint_decoder *cxled;
&gt; +	struct cxl_port *port;
&gt; +
&gt; +	if (!is_endpoint_decoder(dev))
&gt; +		return 0;
&gt; +
&gt; +	cxled = to_cxl_endpoint_decoder(dev);
&gt; +	port = cxled_to_port(cxled);
&gt; +
&gt; +	return cxled-&gt;cxld.id == (port-&gt;hdm_end + 1);
&gt; +}
&gt; +
&gt; +static struct cxl_endpoint_decoder *
&gt; +cxl_find_free_decoder(struct cxl_memdev *cxlmd)
&gt; +{
&gt; +	struct cxl_port *endpoint = cxlmd-&gt;endpoint;
&gt; +	struct device *dev;
&gt; +
&gt; +	guard(rwsem_read)(&amp;cxl_rwsem.dpa);
&gt; +	dev = device_find_child(&amp;endpoint-&gt;dev, NULL,
&gt; +				find_free_decoder);
&gt; +	if (!dev)
&gt; +		return NULL;
&gt; +
&gt; +	return to_cxl_endpoint_decoder(dev);
&gt; +}
&gt; +
&gt; +/**
&gt; + * cxl_request_dpa - search and reserve DPA given input constraints
&gt; + * @cxlmd: memdev with an endpoint port with available decoders
&gt; + * @mode: CXL partition mode (ram vs pmem)
&gt; + * @alloc: dpa size required
&gt; + *
&gt; + * Returns a pointer to a &#x27;struct cxl_endpoint_decoder&#x27; on success or
&gt; + * an errno encoded pointer on failure.
&gt; + *
&gt; + * Given that a region needs to allocate from limited HPA capacity it
&gt; + * may be the case that a device has more mappable DPA capacity than
&gt; + * available HPA. The expectation is that @alloc is a driver known
&gt; + * value based on the device capacity but which could not be fully
&gt; + * available due to HPA constraints.
&gt; + *
&gt; + * Returns a pinned cxl_decoder with at least @alloc bytes of capacity
&gt; + * reserved, or an error pointer. The caller is also expected to own the
&gt; + * lifetime of the memdev registration associated with the endpoint to
&gt; + * pin the decoder registered as well.
&gt; + */
&gt; +struct cxl_endpoint_decoder *cxl_request_dpa(struct cxl_memdev *cxlmd,
&gt; +					     enum cxl_partition_mode mode,
&gt; +					     resource_size_t alloc)
&gt; +{
&gt; +	int rc;
&gt; +
&gt; +	if (!IS_ALIGNED(alloc, SZ_256M))
&gt; +		return ERR_PTR(-EINVAL);
&gt; +
&gt; +	struct cxl_endpoint_decoder *cxled __free(put_cxled) =
&gt; +		cxl_find_free_decoder(cxlmd);
&gt; +
&gt; +	if (!cxled)
&gt; +		return ERR_PTR(-ENODEV);
&gt; +
&gt; +	rc = cxl_dpa_set_part(cxled, mode);
&gt; +	if (rc)
&gt; +		return ERR_PTR(rc);
&gt; +
&gt; +	rc = cxl_dpa_alloc(cxled, alloc);
&gt; +	if (rc)
&gt; +		return ERR_PTR(rc);

Should cxl_dpa_set_part() be unwound here, or does it not matter? If it doesn&#x27;t matter:
Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
&gt; +
&gt; +	return no_free_ptr(cxled);
&gt; +}
&gt; +EXPORT_SYMBOL_NS_GPL(cxl_request_dpa, &quot;CXL&quot;);
&gt; +
&gt;  static int __cxl_dpa_alloc(struct cxl_endpoint_decoder *cxled, u64 size)
&gt;  {
&gt;  	struct cxl_memdev *cxlmd = cxled_to_memdev(cxled);
&gt; diff --git a/drivers/cxl/cxl.h b/drivers/cxl/cxl.h
&gt; index d1b010e5e1d0..2b1f7d687a0e 100644
&gt; --- a/drivers/cxl/cxl.h
&gt; +++ b/drivers/cxl/cxl.h
&gt; @@ -667,6 +667,7 @@ struct cxl_root *find_cxl_root(struct cxl_port *port);
&gt;  
&gt;  DEFINE_FREE(put_cxl_root, struct cxl_root *, if (_T) put_device(&amp;_T-&gt;port.dev))
&gt;  DEFINE_FREE(put_cxl_port, struct cxl_port *, if (!IS_ERR_OR_NULL(_T)) put_device(&amp;_T-&gt;dev))
&gt; +DEFINE_FREE(put_cxled, struct cxl_endpoint_decoder *, if (!IS_ERR_OR_NULL(_T)) put_device(&amp;_T-&gt;cxld.dev))
&gt;  DEFINE_FREE(put_cxl_root_decoder, struct cxl_root_decoder *, if (!IS_ERR_OR_NULL(_T)) put_device(&amp;_T-&gt;cxlsd.cxld.dev))
&gt;  DEFINE_FREE(put_cxl_region, struct cxl_region *, if (!IS_ERR_OR_NULL(_T)) put_device(&amp;_T-&gt;dev))
&gt;  
&gt; diff --git a/include/cxl/cxl.h b/include/cxl/cxl.h
&gt; index 783ad570a6eb..4802371db00e 100644
&gt; --- a/include/cxl/cxl.h
&gt; +++ b/include/cxl/cxl.h
&gt; @@ -7,6 +7,7 @@
&gt;  
&gt;  #include &lt;linux/node.h&gt;
&gt;  #include &lt;linux/ioport.h&gt;
&gt; +#include &lt;linux/range.h&gt;
&gt;  #include &lt;cxl/mailbox.h&gt;
&gt;  
&gt;  /**
&gt; @@ -276,4 +277,8 @@ struct cxl_root_decoder *cxl_get_hpa_freespace(struct cxl_memdev *cxlmd,
&gt;  					       unsigned long flags,
&gt;  					       resource_size_t *max);
&gt;  void cxl_put_root_decoder(struct cxl_root_decoder *cxlrd);
&gt; +struct cxl_endpoint_decoder *cxl_request_dpa(struct cxl_memdev *cxlmd,
&gt; +					     enum cxl_partition_mode mode,
&gt; +					     resource_size_t alloc);
&gt; +int cxl_dpa_free(struct cxl_endpoint_decoder *cxled);
&gt;  #endif /* __CXL_CXL_H__ */



---

On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; Current code is expecting Type3 or CXL_DECODER_HOSTONLYMEM devices only.
&gt; Support for Type2 implies region type needs to be based on the endpoint
&gt; type HDM-D[B] instead.
&gt; 
&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; Reviewed-by: Zhi Wang &lt;zhiw@nvidia.com&gt;
&gt; Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
&gt; Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
&gt; Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
&gt; Reviewed-by: Alison Schofield &lt;alison.schofield@intel.com&gt;
&gt; Reviewed-by: Davidlohr Bueso &lt;daves@stgolabs.net&gt;
&gt; ---
&gt;  drivers/cxl/core/region.c | 10 ++++++----
&gt;  1 file changed, 6 insertions(+), 4 deletions(-)
&gt; 
&gt; diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
&gt; index bdefd088f5f1..f53b2e9fd9e6 100644
&gt; --- a/drivers/cxl/core/region.c
&gt; +++ b/drivers/cxl/core/region.c
&gt; @@ -2833,7 +2833,8 @@ static ssize_t create_ram_region_show(struct device *dev,
&gt;  }
&gt;  
&gt;  static struct cxl_region *__create_region(struct cxl_root_decoder *cxlrd,
&gt; -					  enum cxl_partition_mode mode, int id)
&gt; +					  enum cxl_partition_mode mode, int id,
&gt; +					  enum cxl_decoder_type target_type)
&gt;  {
&gt;  	int rc;
&gt;  
&gt; @@ -2855,7 +2856,7 @@ static struct cxl_region *__create_region(struct cxl_root_decoder *cxlrd,
&gt;  		return ERR_PTR(-EBUSY);
&gt;  	}
&gt;  
&gt; -	return devm_cxl_add_region(cxlrd, id, mode, CXL_DECODER_HOSTONLYMEM);
&gt; +	return devm_cxl_add_region(cxlrd, id, mode, target_type);
&gt;  }
&gt;  
&gt;  static ssize_t create_region_store(struct device *dev, const char *buf,
&gt; @@ -2869,7 +2870,7 @@ static ssize_t create_region_store(struct device *dev, const char *buf,
&gt;  	if (rc != 1)
&gt;  		return -EINVAL;
&gt;  
&gt; -	cxlr = __create_region(cxlrd, mode, id);
&gt; +	cxlr = __create_region(cxlrd, mode, id, CXL_DECODER_HOSTONLYMEM);

I haven&#x27;t read the ABI docs, but would it be worthwhile to update the documentation for this attribute
to mention it only makes type 3 regions? I&#x27;m flip-flopping on whether it&#x27;s worth the trouble but thought
I should mention it.

Either way:
Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;

&gt;  	if (IS_ERR(cxlr))
&gt;  		return PTR_ERR(cxlr);
&gt;  
&gt; @@ -4036,7 +4037,8 @@ static struct cxl_region *construct_region(struct cxl_root_decoder *cxlrd,
&gt;  
&gt;  	do {
&gt;  		cxlr = __create_region(cxlrd, cxlds-&gt;part[part].mode,
&gt; -				       atomic_read(&amp;cxlrd-&gt;region_id));
&gt; +				       atomic_read(&amp;cxlrd-&gt;region_id),
&gt; +				       cxled-&gt;cxld.target_type);
&gt;  	} while (IS_ERR(cxlr) &amp;&amp; PTR_ERR(cxlr) == -EBUSY);
&gt;  
&gt;  	if (IS_ERR(cxlr)) {



---

On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; Region creation based on Type3 devices is triggered from user space
&gt; allowing memory combination through interleaving.
&gt; 
&gt; In preparation for kernel driven region creation, that is Type2 drivers
&gt; triggering region creation backed with its advertised CXL memory, factor
&gt; out a common helper from the user-sysfs region setup for interleave ways.
&gt; 
&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; Reviewed-by: Zhi Wang &lt;zhiw@nvidia.com&gt;
&gt; Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
&gt; Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
&gt; Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
&gt; Reviewed-by: Alison Schofield &lt;alison.schofield@intel.com&gt;
&gt; ---
&gt;  drivers/cxl/core/region.c | 43 ++++++++++++++++++++++++---------------
&gt;  1 file changed, 27 insertions(+), 16 deletions(-)
&gt; 
&gt; diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
&gt; index f53b2e9fd9e6..ece1d3df7cf1 100644
&gt; --- a/drivers/cxl/core/region.c
&gt; +++ b/drivers/cxl/core/region.c
&gt; @@ -485,22 +485,14 @@ static ssize_t interleave_ways_show(struct device *dev,
&gt;  
&gt;  static const struct attribute_group *get_cxl_region_target_group(void);
&gt;  
&gt; -static ssize_t interleave_ways_store(struct device *dev,
&gt; -				     struct device_attribute *attr,
&gt; -				     const char *buf, size_t len)
&gt; +static int set_interleave_ways(struct cxl_region *cxlr, int val)

@val should probably stay an unsigned int. You pass an unsigned int in the sysfs function, and the
function was originally coded with that in mind (same with @save below). With that cleaned up:
Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;

&gt;  {
&gt; -	struct cxl_root_decoder *cxlrd = to_cxl_root_decoder(dev-&gt;parent);
&gt; +	struct cxl_root_decoder *cxlrd = to_cxl_root_decoder(cxlr-&gt;dev.parent);
&gt;  	struct cxl_decoder *cxld = &amp;cxlrd-&gt;cxlsd.cxld;
&gt; -	struct cxl_region *cxlr = to_cxl_region(dev);
&gt;  	struct cxl_region_params *p = &amp;cxlr-&gt;params;
&gt; -	unsigned int val, save;
&gt; -	int rc;
&gt; +	int save, rc;
&gt;  	u8 iw;
&gt;  
&gt; -	rc = kstrtouint(buf, 0, &amp;val);
&gt; -	if (rc)
&gt; -		return rc;
&gt; -
&gt;  	rc = ways_to_eiw(val, &amp;iw);
&gt;  	if (rc)
&gt;  		return rc;
&gt; @@ -515,9 +507,7 @@ static ssize_t interleave_ways_store(struct device *dev,
&gt;  		return -EINVAL;
&gt;  	}
&gt;  
&gt; -	ACQUIRE(rwsem_write_kill, rwsem)(&amp;cxl_rwsem.region);
&gt; -	if ((rc = ACQUIRE_ERR(rwsem_write_kill, &amp;rwsem)))
&gt; -		return rc;
&gt; +	lockdep_assert_held_write(&amp;cxl_rwsem.region);
&gt;  
&gt;  	if (p-&gt;state &gt;= CXL_CONFIG_INTERLEAVE_ACTIVE)
&gt;  		return -EBUSY;
&gt; @@ -525,10 +515,31 @@ static ssize_t interleave_ways_store(struct device *dev,
&gt;  	save = p-&gt;interleave_ways;
&gt;  	p-&gt;interleave_ways = val;
&gt;  	rc = sysfs_update_group(&amp;cxlr-&gt;dev.kobj, get_cxl_region_target_group());
&gt; -	if (rc) {
&gt; +	if (rc)
&gt;  		p-&gt;interleave_ways = save;
&gt; +
&gt; +	return rc;
&gt; +}
&gt; +
&gt; +static ssize_t interleave_ways_store(struct device *dev,
&gt; +				     struct device_attribute *attr,
&gt; +				     const char *buf, size_t len)
&gt; +{
&gt; +	struct cxl_region *cxlr = to_cxl_region(dev);
&gt; +	unsigned int val;
&gt; +	int rc;
&gt; +
&gt; +	rc = kstrtouint(buf, 0, &amp;val);
&gt; +	if (rc)
&gt; +		return rc;
&gt; +
&gt; +	ACQUIRE(rwsem_write_kill, rwsem)(&amp;cxl_rwsem.region);
&gt; +	if ((rc = ACQUIRE_ERR(rwsem_write_kill, &amp;rwsem)))
&gt; +		return rc;
&gt; +
&gt; +	rc = set_interleave_ways(cxlr, val);
&gt; +	if (rc)
&gt;  		return rc;
&gt; -	}
&gt;  
&gt;  	return len;
&gt;  }



---

On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; Region creation based on Type3 devices is triggered from user space
&gt; allowing memory combination through interleaving.
&gt; 
&gt; In preparation for kernel driven region creation, that is Type2 drivers
&gt; triggering region creation backed with its advertised CXL memory, factor
&gt; out a common helper from the user-sysfs region setup forinterleave
&gt; granularity.
&gt; 
&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; Reviewed-by: Zhi Wang &lt;zhiw@nvidia.com&gt;
&gt; Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
&gt; Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
&gt; Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
&gt; Reviewed-by: Alison Schofield &lt;alison.schofield@intel.com&gt;
&gt; ---
&gt;  drivers/cxl/core/region.c | 39 +++++++++++++++++++++++++--------------
&gt;  1 file changed, 25 insertions(+), 14 deletions(-)
&gt; 
&gt; diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
&gt; index ece1d3df7cf1..63c2aeb2ee1f 100644
&gt; --- a/drivers/cxl/core/region.c
&gt; +++ b/drivers/cxl/core/region.c
&gt; @@ -559,21 +559,14 @@ static ssize_t interleave_granularity_show(struct device *dev,
&gt;  	return sysfs_emit(buf, &quot;%d\n&quot;, p-&gt;interleave_granularity);
&gt;  }
&gt;  
&gt; -static ssize_t interleave_granularity_store(struct device *dev,
&gt; -					    struct device_attribute *attr,
&gt; -					    const char *buf, size_t len)
&gt; +static int set_interleave_granularity(struct cxl_region *cxlr, int val)

Same thing as last patch. Assuming it&#x27;s fixed:
Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
&gt;  {
&gt; -	struct cxl_root_decoder *cxlrd = to_cxl_root_decoder(dev-&gt;parent);
&gt; +	struct cxl_root_decoder *cxlrd = to_cxl_root_decoder(cxlr-&gt;dev.parent);
&gt;  	struct cxl_decoder *cxld = &amp;cxlrd-&gt;cxlsd.cxld;
&gt; -	struct cxl_region *cxlr = to_cxl_region(dev);
&gt;  	struct cxl_region_params *p = &amp;cxlr-&gt;params;
&gt; -	int rc, val;
&gt; +	int rc;
&gt;  	u16 ig;
&gt;  
&gt; -	rc = kstrtoint(buf, 0, &amp;val);
&gt; -	if (rc)
&gt; -		return rc;
&gt; -
&gt;  	rc = granularity_to_eig(val, &amp;ig);
&gt;  	if (rc)
&gt;  		return rc;
&gt; @@ -589,14 +582,32 @@ static ssize_t interleave_granularity_store(struct device *dev,
&gt;  	if (cxld-&gt;interleave_ways &gt; 1 &amp;&amp; val != cxld-&gt;interleave_granularity)
&gt;  		return -EINVAL;
&gt;  
&gt; -	ACQUIRE(rwsem_write_kill, rwsem)(&amp;cxl_rwsem.region);
&gt; -	if ((rc = ACQUIRE_ERR(rwsem_write_kill, &amp;rwsem)))
&gt; -		return rc;
&gt; -
&gt; +	lockdep_assert_held_write(&amp;cxl_rwsem.region);
&gt;  	if (p-&gt;state &gt;= CXL_CONFIG_INTERLEAVE_ACTIVE)
&gt;  		return -EBUSY;
&gt;  
&gt;  	p-&gt;interleave_granularity = val;
&gt; +	return 0;
&gt; +}
&gt; +
&gt; +static ssize_t interleave_granularity_store(struct device *dev,
&gt; +					    struct device_attribute *attr,
&gt; +					    const char *buf, size_t len)
&gt; +{
&gt; +	struct cxl_region *cxlr = to_cxl_region(dev);
&gt; +	int rc, val;
&gt; +
&gt; +	rc = kstrtoint(buf, 0, &amp;val);
&gt; +	if (rc)
&gt; +		return rc;
&gt; +
&gt; +	ACQUIRE(rwsem_write_kill, rwsem)(&amp;cxl_rwsem.region);
&gt; +	if ((rc = ACQUIRE_ERR(rwsem_write_kill, &amp;rwsem)))
&gt; +		return rc;
&gt; +
&gt; +	rc = set_interleave_granularity(cxlr, val);
&gt; +	if (rc)
&gt; +		return rc;
&gt;  
&gt;  	return len;
&gt;  }



---

On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; Creating a CXL region requires userspace intervention through the cxl
&gt; sysfs files. Type2 support should allow accelerator drivers to create
&gt; such cxl region from kernel code.
&gt; 
&gt; Adding that functionality and integrating it with current support for
&gt; memory expanders.
&gt; 
&gt; Based on https://lore.kernel.org/linux-cxl/168592159835.1948938.1647215579839222774.stgit@dwillia2-xfh.jf.intel.com/
&gt; 
&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
&gt; Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
&gt; ---
&gt;  drivers/cxl/core/region.c | 131 ++++++++++++++++++++++++++++++++++++--
&gt;  include/cxl/cxl.h         |   3 +
&gt;  2 files changed, 127 insertions(+), 7 deletions(-)
&gt; 
&gt; diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
&gt; index 63c2aeb2ee1f..293e63dfef22 100644
&gt; --- a/drivers/cxl/core/region.c
&gt; +++ b/drivers/cxl/core/region.c
&gt; @@ -2944,6 +2944,14 @@ cxl_find_region_by_name(struct cxl_root_decoder *cxlrd, const char *name)
&gt;  	return to_cxl_region(region_dev);
&gt;  }
&gt;  
&gt; +static void drop_region(struct cxl_region *cxlr)
&gt; +{
&gt; +	struct cxl_root_decoder *cxlrd = to_cxl_root_decoder(cxlr-&gt;dev.parent);
&gt; +	struct cxl_port *port = cxlrd_to_port(cxlrd);
&gt; +
&gt; +	devm_release_action(port-&gt;uport_dev, __unregister_region, cxlr);
&gt; +}
&gt; +
&gt;  static ssize_t delete_region_store(struct device *dev,
&gt;  				   struct device_attribute *attr,
&gt;  				   const char *buf, size_t len)
&gt; @@ -4047,14 +4055,12 @@ static int __construct_region(struct cxl_region *cxlr,
&gt;  	return 0;
&gt;  }
&gt;  
&gt; -/* Establish an empty region covering the given HPA range */
&gt; -static struct cxl_region *construct_region(struct cxl_root_decoder *cxlrd,
&gt; -					   struct cxl_endpoint_decoder *cxled)
&gt; +static struct cxl_region *construct_region_begin(struct cxl_root_decoder *cxlrd,
&gt; +						 struct cxl_endpoint_decoder *cxled)
&gt;  {
&gt;  	struct cxl_memdev *cxlmd = cxled_to_memdev(cxled);
&gt; -	struct cxl_port *port = cxlrd_to_port(cxlrd);
&gt;  	struct cxl_dev_state *cxlds = cxlmd-&gt;cxlds;
&gt; -	int rc, part = READ_ONCE(cxled-&gt;part);
&gt; +	int part = READ_ONCE(cxled-&gt;part);
&gt;  	struct cxl_region *cxlr;
&gt;  
&gt;  	do {
&gt; @@ -4063,13 +4069,26 @@ static struct cxl_region *construct_region(struct cxl_root_decoder *cxlrd,
&gt;  				       cxled-&gt;cxld.target_type);
&gt;  	} while (IS_ERR(cxlr) &amp;&amp; PTR_ERR(cxlr) == -EBUSY);
&gt;  
&gt; -	if (IS_ERR(cxlr)) {
&gt; +	if (IS_ERR(cxlr))
&gt;  		dev_err(cxlmd-&gt;dev.parent,
&gt;  			&quot;%s:%s: %s failed assign region: %ld\n&quot;,
&gt;  			dev_name(&amp;cxlmd-&gt;dev), dev_name(&amp;cxled-&gt;cxld.dev),
&gt;  			__func__, PTR_ERR(cxlr));
&gt; +
&gt; +	return cxlr;
&gt; +}
&gt; +
&gt; +/* Establish an empty region covering the given HPA range */
&gt; +static struct cxl_region *construct_region(struct cxl_root_decoder *cxlrd,
&gt; +					   struct cxl_endpoint_decoder *cxled)
&gt; +{
&gt; +	struct cxl_port *port = cxlrd_to_port(cxlrd);
&gt; +	struct cxl_region *cxlr;
&gt; +	int rc;
&gt; +
&gt; +	cxlr = construct_region_begin(cxlrd, cxled);
&gt; +	if (IS_ERR(cxlr))
&gt;  		return cxlr;
&gt; -	}
&gt;  
&gt;  	rc = __construct_region(cxlr, cxlrd, cxled);
&gt;  	if (rc) {
&gt; @@ -4080,6 +4099,104 @@ static struct cxl_region *construct_region(struct cxl_root_decoder *cxlrd,
&gt;  	return cxlr;
&gt;  }
&gt;  
&gt; +DEFINE_FREE(cxl_region_drop, struct cxl_region *, if (_T) drop_region(_T))

This needs to be &quot;if (!IS_ERR_OR_NULL(_T) drop_region(_T)&quot;. If construct_region_begin() returns an
error pointer, drop_region() will be called with it as of now leading to a garbage pointer deref.

&gt; +
&gt; +static struct cxl_region *
&gt; +__construct_new_region(struct cxl_root_decoder *cxlrd,
&gt; +		       struct cxl_endpoint_decoder **cxled, int ways)
&gt; +{
&gt; +	struct cxl_memdev *cxlmd = cxled_to_memdev(cxled[0]);
&gt; +	struct cxl_decoder *cxld = &amp;cxlrd-&gt;cxlsd.cxld;
&gt; +	struct cxl_region_params *p;
&gt; +	resource_size_t size = 0;
&gt; +	int rc, i;
&gt; +
&gt; +	struct cxl_region *cxlr __free(cxl_region_drop) =
&gt; +		construct_region_begin(cxlrd, cxled[0]);
&gt; +	if (IS_ERR(cxlr))
&gt; +		return cxlr;
&gt; +
&gt; +	guard(rwsem_write)(&amp;cxl_rwsem.region);
&gt; +
&gt; +	/*
&gt; +	 * Sanity check. This should not happen with an accel driver handling
&gt; +	 * the region creation.
&gt; +	 */
&gt; +	p = &amp;cxlr-&gt;params;
&gt; +	if (p-&gt;state &gt;= CXL_CONFIG_INTERLEAVE_ACTIVE) {
&gt; +		dev_err(cxlmd-&gt;dev.parent,
&gt; +			&quot;%s:%s: %s  unexpected region state\n&quot;,
&gt; +			dev_name(&amp;cxlmd-&gt;dev), dev_name(&amp;cxled[0]-&gt;cxld.dev),
&gt; +			__func__);
&gt; +		return ERR_PTR(-EBUSY);
&gt; +	}
&gt; +
&gt; +	rc = set_interleave_ways(cxlr, ways);
&gt; +	if (rc)
&gt; +		return ERR_PTR(rc);
&gt; +
&gt; +	rc = set_interleave_granularity(cxlr, cxld-&gt;interleave_granularity);
&gt; +	if (rc)
&gt; +		return ERR_PTR(rc);
&gt; +
&gt; +	scoped_guard(rwsem_read, &amp;cxl_rwsem.dpa) {
&gt; +		for (i = 0; i &lt; ways; i++) {
&gt; +			if (!cxled[i]-&gt;dpa_res)
&gt; +				return ERR_PTR(-EINVAL);
&gt; +			size += resource_size(cxled[i]-&gt;dpa_res);
&gt; +		}
&gt; +
&gt; +		rc = alloc_hpa(cxlr, size);
&gt; +		if (rc)
&gt; +			return ERR_PTR(rc);
&gt; +
&gt; +		for (i = 0; i &lt; ways; i++) {
&gt; +			rc = cxl_region_attach(cxlr, cxled[i], 0);

Position parameter is hardcoded to 0. It should be set to i, right? This kind of goes back to my
issues in patch 12/22; the interleaving functionality is there but it looks unused.

&gt; +			if (rc)
&gt; +				return ERR_PTR(rc);
&gt; +		}
&gt; +	}
&gt; +
&gt; +	rc = cxl_region_decode_commit(cxlr);
&gt; +	if (rc)
&gt; +		return ERR_PTR(rc);
&gt; +
&gt; +	p-&gt;state = CXL_CONFIG_COMMIT;
&gt; +
&gt; +	return no_free_ptr(cxlr);
&gt; +}
&gt; +
&gt; +/**
&gt; + * cxl_create_region - Establish a region given an endpoint decoder
&gt; + * @cxlrd: root decoder to allocate HPA
&gt; + * @cxled: endpoint decoders with reserved DPA capacity
&gt; + * @ways: interleave ways required
&gt; + *
&gt; + * Returns a fully formed region in the commit state and attached to the
&gt; + * cxl_region driver.
&gt; + */
&gt; +struct cxl_region *cxl_create_region(struct cxl_root_decoder *cxlrd,
&gt; +				     struct cxl_endpoint_decoder **cxled,
&gt; +				     int ways)
&gt; +{
&gt; +	struct cxl_region *cxlr;
&gt; +
&gt; +	mutex_lock(&amp;cxlrd-&gt;range_lock);
&gt; +	cxlr = __construct_new_region(cxlrd, cxled, ways);
&gt; +	mutex_unlock(&amp;cxlrd-&gt;range_lock);
&gt; +	if (IS_ERR(cxlr))
&gt; +		return cxlr;
&gt; +
&gt; +	if (device_attach(&amp;cxlr-&gt;dev) &lt;= 0) {
&gt; +		dev_err(&amp;cxlr-&gt;dev, &quot;failed to create region\n&quot;);
&gt; +		drop_region(cxlr);
&gt; +		return ERR_PTR(-ENODEV);
&gt; +	}
&gt; +
&gt; +	return cxlr;
&gt; +}
&gt; +EXPORT_SYMBOL_NS_GPL(cxl_create_region, &quot;CXL&quot;);
&gt; +
&gt;  static struct cxl_region *
&gt;  cxl_find_region_by_range(struct cxl_root_decoder *cxlrd, struct range *hpa)
&gt;  {
&gt; diff --git a/include/cxl/cxl.h b/include/cxl/cxl.h
&gt; index 4802371db00e..50acbd13bcf8 100644
&gt; --- a/include/cxl/cxl.h
&gt; +++ b/include/cxl/cxl.h
&gt; @@ -281,4 +281,7 @@ struct cxl_endpoint_decoder *cxl_request_dpa(struct cxl_memdev *cxlmd,
&gt;  					     enum cxl_partition_mode mode,
&gt;  					     resource_size_t alloc);
&gt;  int cxl_dpa_free(struct cxl_endpoint_decoder *cxled);
&gt; +struct cxl_region *cxl_create_region(struct cxl_root_decoder *cxlrd,
&gt; +				     struct cxl_endpoint_decoder **cxled,
&gt; +				     int ways);
&gt;  #endif /* __CXL_CXL_H__ */



---

On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; Differentiate CXL memory expanders (type 3) from CXL device accelerators
&gt; (type 2) with a new function for initializing cxl_dev_state and a macro
&gt; for helping accel drivers to embed cxl_dev_state inside a private
&gt; struct.
&gt; 
&gt; Move structs to include/cxl as the size of the accel driver private
&gt; struct embedding cxl_dev_state needs to know the size of this struct.
&gt; 
&gt; Use same new initialization with the type3 pci driver.
&gt; 
&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
&gt; Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
&gt; Reviewed-by: Alison Schofield &lt;alison.schofield@intel.com&gt;
&gt; Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
&gt; ---
&gt;  drivers/cxl/core/mbox.c      |  12 +-
&gt;  drivers/cxl/core/memdev.c    |  32 +++++
&gt;  drivers/cxl/cxl.h            |  97 +--------------
&gt;  drivers/cxl/cxlmem.h         |  86 +------------
&gt;  drivers/cxl/pci.c            |  14 +--
&gt;  include/cxl/cxl.h            | 226 +++++++++++++++++++++++++++++++++++
&gt;  tools/testing/cxl/test/mem.c |   3 +-
&gt;  7 files changed, 274 insertions(+), 196 deletions(-)
&gt;  create mode 100644 include/cxl/cxl.h
&gt; 
&gt; diff --git a/drivers/cxl/core/mbox.c b/drivers/cxl/core/mbox.c
&gt; index fa6dd0c94656..bee84d0101d1 100644
&gt; --- a/drivers/cxl/core/mbox.c
&gt; +++ b/drivers/cxl/core/mbox.c
&gt; @@ -1514,23 +1514,21 @@ int cxl_mailbox_init(struct cxl_mailbox *cxl_mbox, struct device *host)
&gt;  }
&gt;  EXPORT_SYMBOL_NS_GPL(cxl_mailbox_init, &quot;CXL&quot;);
&gt;  
&gt; -struct cxl_memdev_state *cxl_memdev_state_create(struct device *dev)
&gt; +struct cxl_memdev_state *cxl_memdev_state_create(struct device *dev, u64 serial,
&gt; +						 u16 dvsec)
&gt;  {
&gt;  	struct cxl_memdev_state *mds;
&gt;  	int rc;
&gt;  
&gt; -	mds = devm_kzalloc(dev, sizeof(*mds), GFP_KERNEL);
&gt; +	mds = devm_cxl_dev_state_create(dev, CXL_DEVTYPE_CLASSMEM, serial,
&gt; +					dvsec, struct cxl_memdev_state, cxlds,
&gt; +					true);
&gt;  	if (!mds) {
&gt;  		dev_err(dev, &quot;No memory available\n&quot;);
&gt;  		return ERR_PTR(-ENOMEM);
&gt;  	}
&gt;  
&gt;  	mutex_init(&amp;mds-&gt;event.log_lock);
&gt; -	mds-&gt;cxlds.dev = dev;
&gt; -	mds-&gt;cxlds.reg_map.host = dev;
&gt; -	mds-&gt;cxlds.cxl_mbox.host = dev;
&gt; -	mds-&gt;cxlds.reg_map.resource = CXL_RESOURCE_NONE;
&gt; -	mds-&gt;cxlds.type = CXL_DEVTYPE_CLASSMEM;
&gt;  
&gt;  	rc = devm_cxl_register_mce_notifier(dev, &amp;mds-&gt;mce_notifier);
&gt;  	if (rc == -EOPNOTSUPP)
&gt; diff --git a/drivers/cxl/core/memdev.c b/drivers/cxl/core/memdev.c
&gt; index af3d0cc65138..22d156f25305 100644
&gt; --- a/drivers/cxl/core/memdev.c
&gt; +++ b/drivers/cxl/core/memdev.c
&gt; @@ -656,6 +656,38 @@ static void detach_memdev(struct work_struct *work)
&gt;  
&gt;  static struct lock_class_key cxl_memdev_key;
&gt;  
&gt; +static void cxl_dev_state_init(struct cxl_dev_state *cxlds, struct device *dev,
&gt; +			       enum cxl_devtype type, u64 serial, u16 dvsec,
&gt; +			       bool has_mbox)
&gt; +{
&gt; +	*cxlds = (struct cxl_dev_state) {
&gt; +		.dev = dev,
&gt; +		.type = type,
&gt; +		.serial = serial,
&gt; +		.cxl_dvsec = dvsec,
&gt; +		.reg_map.host = dev,
&gt; +		.reg_map.resource = CXL_RESOURCE_NONE,
&gt; +	};
&gt; +
&gt; +	if (has_mbox)
&gt; +		cxlds-&gt;cxl_mbox.host = dev;
&gt; +}
&gt; +
&gt; +struct cxl_dev_state *_devm_cxl_dev_state_create(struct device *dev,
&gt; +						 enum cxl_devtype type,
&gt; +						 u64 serial, u16 dvsec,
&gt; +						 size_t size, bool has_mbox)
&gt; +{
&gt; +	struct cxl_dev_state *cxlds = devm_kzalloc(dev, size, GFP_KERNEL);
&gt; +
&gt; +	if (!cxlds)
&gt; +		return NULL;
&gt; +
&gt; +	cxl_dev_state_init(cxlds, dev, type, serial, dvsec, has_mbox);

Nit: Having a second function to do the init seems overkill here, especially since cxl_dev_state_init() isn&#x27;t called outside this
function. I&#x27;d fold it into this function instead, but I&#x27;m fine with it either way (especially if you were told otherwise before).

Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
&gt; +	return cxlds;
&gt; +}
&gt; +EXPORT_SYMBOL_NS_GPL(_devm_cxl_dev_state_create, &quot;CXL&quot;);
&gt; +
&gt;  static struct cxl_memdev *cxl_memdev_alloc(struct cxl_dev_state *cxlds,
&gt;  					   const struct file_operations *fops,
&gt;  					   const struct cxl_memdev_attach *attach)
&gt; diff --git a/drivers/cxl/cxl.h b/drivers/cxl/cxl.h
&gt; index e1d47062e1d3..3eaa353e430b 100644
&gt; --- a/drivers/cxl/cxl.h
&gt; +++ b/drivers/cxl/cxl.h
&gt; @@ -12,6 +12,7 @@
&gt;  #include &lt;linux/node.h&gt;
&gt;  #include &lt;linux/io.h&gt;
&gt;  #include &lt;linux/range.h&gt;
&gt; +#include &lt;cxl/cxl.h&gt;
&gt;  
&gt;  extern const struct nvdimm_security_ops *cxl_security_ops;
&gt;  
&gt; @@ -201,97 +202,6 @@ static inline int ways_to_eiw(unsigned int ways, u8 *eiw)
&gt;  #define   CXLDEV_MBOX_BG_CMD_COMMAND_VENDOR_MASK GENMASK_ULL(63, 48)
&gt;  #define CXLDEV_MBOX_PAYLOAD_OFFSET 0x20
&gt;  
&gt; -/*
&gt; - * Using struct_group() allows for per register-block-type helper routines,
&gt; - * without requiring block-type agnostic code to include the prefix.
&gt; - */
&gt; -struct cxl_regs {
&gt; -	/*
&gt; -	 * Common set of CXL Component register block base pointers
&gt; -	 * @hdm_decoder: CXL 2.0 8.2.5.12 CXL HDM Decoder Capability Structure
&gt; -	 * @ras: CXL 2.0 8.2.5.9 CXL RAS Capability Structure
&gt; -	 */
&gt; -	struct_group_tagged(cxl_component_regs, component,
&gt; -		void __iomem *hdm_decoder;
&gt; -		void __iomem *ras;
&gt; -	);
&gt; -	/*
&gt; -	 * Common set of CXL Device register block base pointers
&gt; -	 * @status: CXL 2.0 8.2.8.3 Device Status Registers
&gt; -	 * @mbox: CXL 2.0 8.2.8.4 Mailbox Registers
&gt; -	 * @memdev: CXL 2.0 8.2.8.5 Memory Device Registers
&gt; -	 */
&gt; -	struct_group_tagged(cxl_device_regs, device_regs,
&gt; -		void __iomem *status, *mbox, *memdev;
&gt; -	);
&gt; -
&gt; -	struct_group_tagged(cxl_pmu_regs, pmu_regs,
&gt; -		void __iomem *pmu;
&gt; -	);
&gt; -
&gt; -	/*
&gt; -	 * RCH downstream port specific RAS register
&gt; -	 * @aer: CXL 3.0 8.2.1.1 RCH Downstream Port RCRB
&gt; -	 */
&gt; -	struct_group_tagged(cxl_rch_regs, rch_regs,
&gt; -		void __iomem *dport_aer;
&gt; -	);
&gt; -
&gt; -	/*
&gt; -	 * RCD upstream port specific PCIe cap register
&gt; -	 * @pcie_cap: CXL 3.0 8.2.1.2 RCD Upstream Port RCRB
&gt; -	 */
&gt; -	struct_group_tagged(cxl_rcd_regs, rcd_regs,
&gt; -		void __iomem *rcd_pcie_cap;
&gt; -	);
&gt; -};
&gt; -
&gt; -struct cxl_reg_map {
&gt; -	bool valid;
&gt; -	int id;
&gt; -	unsigned long offset;
&gt; -	unsigned long size;
&gt; -};
&gt; -
&gt; -struct cxl_component_reg_map {
&gt; -	struct cxl_reg_map hdm_decoder;
&gt; -	struct cxl_reg_map ras;
&gt; -};
&gt; -
&gt; -struct cxl_device_reg_map {
&gt; -	struct cxl_reg_map status;
&gt; -	struct cxl_reg_map mbox;
&gt; -	struct cxl_reg_map memdev;
&gt; -};
&gt; -
&gt; -struct cxl_pmu_reg_map {
&gt; -	struct cxl_reg_map pmu;
&gt; -};
&gt; -
&gt; -/**
&gt; - * struct cxl_register_map - DVSEC harvested register block mapping parameters
&gt; - * @host: device for devm operations and logging
&gt; - * @base: virtual base of the register-block-BAR + @block_offset
&gt; - * @resource: physical resource base of the register block
&gt; - * @max_size: maximum mapping size to perform register search
&gt; - * @reg_type: see enum cxl_regloc_type
&gt; - * @component_map: cxl_reg_map for component registers
&gt; - * @device_map: cxl_reg_maps for device registers
&gt; - * @pmu_map: cxl_reg_maps for CXL Performance Monitoring Units
&gt; - */
&gt; -struct cxl_register_map {
&gt; -	struct device *host;
&gt; -	void __iomem *base;
&gt; -	resource_size_t resource;
&gt; -	resource_size_t max_size;
&gt; -	u8 reg_type;
&gt; -	union {
&gt; -		struct cxl_component_reg_map component_map;
&gt; -		struct cxl_device_reg_map device_map;
&gt; -		struct cxl_pmu_reg_map pmu_map;
&gt; -	};
&gt; -};
&gt; -
&gt;  void cxl_probe_component_regs(struct device *dev, void __iomem *base,
&gt;  			      struct cxl_component_reg_map *map);
&gt;  void cxl_probe_device_regs(struct device *dev, void __iomem *base,
&gt; @@ -497,11 +407,6 @@ struct cxl_region_params {
&gt;  	resource_size_t cache_size;
&gt;  };
&gt;  
&gt; -enum cxl_partition_mode {
&gt; -	CXL_PARTMODE_RAM,
&gt; -	CXL_PARTMODE_PMEM,
&gt; -};
&gt; -
&gt;  /*
&gt;   * Indicate whether this region has been assembled by autodetection or
&gt;   * userspace assembly. Prevent endpoint decoders outside of automatic
&gt; diff --git a/drivers/cxl/cxlmem.h b/drivers/cxl/cxlmem.h
&gt; index ef202b34e5ea..281546de426e 100644
&gt; --- a/drivers/cxl/cxlmem.h
&gt; +++ b/drivers/cxl/cxlmem.h
&gt; @@ -113,8 +113,6 @@ int devm_cxl_dpa_reserve(struct cxl_endpoint_decoder *cxled,
&gt;  			 resource_size_t base, resource_size_t len,
&gt;  			 resource_size_t skipped);
&gt;  
&gt; -#define CXL_NR_PARTITIONS_MAX 2
&gt; -
&gt;  struct cxl_dpa_info {
&gt;  	u64 size;
&gt;  	struct cxl_dpa_part_info {
&gt; @@ -373,87 +371,6 @@ struct cxl_security_state {
&gt;  	struct kernfs_node *sanitize_node;
&gt;  };
&gt;  
&gt; -/*
&gt; - * enum cxl_devtype - delineate type-2 from a generic type-3 device
&gt; - * @CXL_DEVTYPE_DEVMEM - Vendor specific CXL Type-2 device implementing HDM-D or
&gt; - *			 HDM-DB, no requirement that this device implements a
&gt; - *			 mailbox, or other memory-device-standard manageability
&gt; - *			 flows.
&gt; - * @CXL_DEVTYPE_CLASSMEM - Common class definition of a CXL Type-3 device with
&gt; - *			   HDM-H and class-mandatory memory device registers
&gt; - */
&gt; -enum cxl_devtype {
&gt; -	CXL_DEVTYPE_DEVMEM,
&gt; -	CXL_DEVTYPE_CLASSMEM,
&gt; -};
&gt; -
&gt; -/**
&gt; - * struct cxl_dpa_perf - DPA performance property entry
&gt; - * @dpa_range: range for DPA address
&gt; - * @coord: QoS performance data (i.e. latency, bandwidth)
&gt; - * @cdat_coord: raw QoS performance data from CDAT
&gt; - * @qos_class: QoS Class cookies
&gt; - */
&gt; -struct cxl_dpa_perf {
&gt; -	struct range dpa_range;
&gt; -	struct access_coordinate coord[ACCESS_COORDINATE_MAX];
&gt; -	struct access_coordinate cdat_coord[ACCESS_COORDINATE_MAX];
&gt; -	int qos_class;
&gt; -};
&gt; -
&gt; -/**
&gt; - * struct cxl_dpa_partition - DPA partition descriptor
&gt; - * @res: shortcut to the partition in the DPA resource tree (cxlds-&gt;dpa_res)
&gt; - * @perf: performance attributes of the partition from CDAT
&gt; - * @mode: operation mode for the DPA capacity, e.g. ram, pmem, dynamic...
&gt; - */
&gt; -struct cxl_dpa_partition {
&gt; -	struct resource res;
&gt; -	struct cxl_dpa_perf perf;
&gt; -	enum cxl_partition_mode mode;
&gt; -};
&gt; -
&gt; -/**
&gt; - * struct cxl_dev_state - The driver device state
&gt; - *
&gt; - * cxl_dev_state represents the CXL driver/device state.  It provides an
&gt; - * interface to mailbox commands as well as some cached data about the device.
&gt; - * Currently only memory devices are represented.
&gt; - *
&gt; - * @dev: The device associated with this CXL state
&gt; - * @cxlmd: The device representing the CXL.mem capabilities of @dev
&gt; - * @reg_map: component and ras register mapping parameters
&gt; - * @regs: Parsed register blocks
&gt; - * @cxl_dvsec: Offset to the PCIe device DVSEC
&gt; - * @rcd: operating in RCD mode (CXL 3.0 9.11.8 CXL Devices Attached to an RCH)
&gt; - * @media_ready: Indicate whether the device media is usable
&gt; - * @dpa_res: Overall DPA resource tree for the device
&gt; - * @part: DPA partition array
&gt; - * @nr_partitions: Number of DPA partitions
&gt; - * @serial: PCIe Device Serial Number
&gt; - * @type: Generic Memory Class device or Vendor Specific Memory device
&gt; - * @cxl_mbox: CXL mailbox context
&gt; - * @cxlfs: CXL features context
&gt; - */
&gt; -struct cxl_dev_state {
&gt; -	struct device *dev;
&gt; -	struct cxl_memdev *cxlmd;
&gt; -	struct cxl_register_map reg_map;
&gt; -	struct cxl_regs regs;
&gt; -	int cxl_dvsec;
&gt; -	bool rcd;
&gt; -	bool media_ready;
&gt; -	struct resource dpa_res;
&gt; -	struct cxl_dpa_partition part[CXL_NR_PARTITIONS_MAX];
&gt; -	unsigned int nr_partitions;
&gt; -	u64 serial;
&gt; -	enum cxl_devtype type;
&gt; -	struct cxl_mailbox cxl_mbox;
&gt; -#ifdef CONFIG_CXL_FEATURES
&gt; -	struct cxl_features_state *cxlfs;
&gt; -#endif
&gt; -};
&gt; -
&gt;  static inline resource_size_t cxl_pmem_size(struct cxl_dev_state *cxlds)
&gt;  {
&gt;  	/*
&gt; @@ -858,7 +775,8 @@ int cxl_dev_state_identify(struct cxl_memdev_state *mds);
&gt;  int cxl_await_media_ready(struct cxl_dev_state *cxlds);
&gt;  int cxl_enumerate_cmds(struct cxl_memdev_state *mds);
&gt;  int cxl_mem_dpa_fetch(struct cxl_memdev_state *mds, struct cxl_dpa_info *info);
&gt; -struct cxl_memdev_state *cxl_memdev_state_create(struct device *dev);
&gt; +struct cxl_memdev_state *cxl_memdev_state_create(struct device *dev, u64 serial,
&gt; +						 u16 dvsec);
&gt;  void set_exclusive_cxl_commands(struct cxl_memdev_state *mds,
&gt;  				unsigned long *cmds);
&gt;  void clear_exclusive_cxl_commands(struct cxl_memdev_state *mds,
&gt; diff --git a/drivers/cxl/pci.c b/drivers/cxl/pci.c
&gt; index 1cf232220873..24179cc702bf 100644
&gt; --- a/drivers/cxl/pci.c
&gt; +++ b/drivers/cxl/pci.c
&gt; @@ -911,25 +911,25 @@ static int cxl_pci_probe(struct pci_dev *pdev, const struct pci_device_id *id)
&gt;  	int rc, pmu_count;
&gt;  	unsigned int i;
&gt;  	bool irq_avail;
&gt; +	u16 dvsec;
&gt;  
&gt;  	rc = pcim_enable_device(pdev);
&gt;  	if (rc)
&gt;  		return rc;
&gt;  	pci_set_master(pdev);
&gt;  
&gt; -	mds = cxl_memdev_state_create(&amp;pdev-&gt;dev);
&gt; +	dvsec = pci_find_dvsec_capability(pdev, PCI_VENDOR_ID_CXL,
&gt; +					  PCI_DVSEC_CXL_DEVICE);
&gt; +	if (!dvsec)
&gt; +		pci_warn(pdev, &quot;Device DVSEC not present, skip CXL.mem init\n&quot;);
&gt; +
&gt; +	mds = cxl_memdev_state_create(&amp;pdev-&gt;dev, pci_get_dsn(pdev), dvsec);
&gt;  	if (IS_ERR(mds))
&gt;  		return PTR_ERR(mds);
&gt;  	cxlds = &amp;mds-&gt;cxlds;
&gt;  	pci_set_drvdata(pdev, cxlds);
&gt;  
&gt;  	cxlds-&gt;rcd = is_cxl_restricted(pdev);
&gt; -	cxlds-&gt;serial = pci_get_dsn(pdev);
&gt; -	cxlds-&gt;cxl_dvsec = pci_find_dvsec_capability(
&gt; -		pdev, PCI_VENDOR_ID_CXL, PCI_DVSEC_CXL_DEVICE);
&gt; -	if (!cxlds-&gt;cxl_dvsec)
&gt; -		dev_warn(&amp;pdev-&gt;dev,
&gt; -			 &quot;Device DVSEC not present, skip CXL.mem init\n&quot;);
&gt;  
&gt;  	rc = cxl_pci_setup_regs(pdev, CXL_REGLOC_RBI_MEMDEV, &amp;map);
&gt;  	if (rc)
&gt; diff --git a/include/cxl/cxl.h b/include/cxl/cxl.h
&gt; new file mode 100644
&gt; index 000000000000..13d448686189
&gt; --- /dev/null
&gt; +++ b/include/cxl/cxl.h
&gt; @@ -0,0 +1,226 @@
&gt; +/* SPDX-License-Identifier: GPL-2.0 */
&gt; +/* Copyright(c) 2020 Intel Corporation. */
&gt; +/* Copyright(c) 2025 Advanced Micro Devices, Inc. */
&gt; +
&gt; +#ifndef __CXL_CXL_H__
&gt; +#define __CXL_CXL_H__
&gt; +
&gt; +#include &lt;linux/node.h&gt;
&gt; +#include &lt;linux/ioport.h&gt;
&gt; +#include &lt;cxl/mailbox.h&gt;
&gt; +
&gt; +/**
&gt; + * enum cxl_devtype - delineate type-2 from a generic type-3 device
&gt; + * @CXL_DEVTYPE_DEVMEM: Vendor specific CXL Type-2 device implementing HDM-D or
&gt; + *			 HDM-DB, no requirement that this device implements a
&gt; + *			 mailbox, or other memory-device-standard manageability
&gt; + *			 flows.
&gt; + * @CXL_DEVTYPE_CLASSMEM: Common class definition of a CXL Type-3 device with
&gt; + *			   HDM-H and class-mandatory memory device registers
&gt; + */
&gt; +enum cxl_devtype {
&gt; +	CXL_DEVTYPE_DEVMEM,
&gt; +	CXL_DEVTYPE_CLASSMEM,
&gt; +};
&gt; +
&gt; +struct device;
&gt; +
&gt; +/*
&gt; + * Using struct_group() allows for per register-block-type helper routines,
&gt; + * without requiring block-type agnostic code to include the prefix.
&gt; + */
&gt; +struct cxl_regs {
&gt; +	/*
&gt; +	 * Common set of CXL Component register block base pointers
&gt; +	 * @hdm_decoder: CXL 2.0 8.2.5.12 CXL HDM Decoder Capability Structure
&gt; +	 * @ras: CXL 2.0 8.2.5.9 CXL RAS Capability Structure
&gt; +	 */
&gt; +	struct_group_tagged(cxl_component_regs, component,
&gt; +		void __iomem *hdm_decoder;
&gt; +		void __iomem *ras;
&gt; +	);
&gt; +	/*
&gt; +	 * Common set of CXL Device register block base pointers
&gt; +	 * @status: CXL 2.0 8.2.8.3 Device Status Registers
&gt; +	 * @mbox: CXL 2.0 8.2.8.4 Mailbox Registers
&gt; +	 * @memdev: CXL 2.0 8.2.8.5 Memory Device Registers
&gt; +	 */
&gt; +	struct_group_tagged(cxl_device_regs, device_regs,
&gt; +		void __iomem *status, *mbox, *memdev;
&gt; +	);
&gt; +
&gt; +	struct_group_tagged(cxl_pmu_regs, pmu_regs,
&gt; +		void __iomem *pmu;
&gt; +	);
&gt; +
&gt; +	/*
&gt; +	 * RCH downstream port specific RAS register
&gt; +	 * @aer: CXL 3.0 8.2.1.1 RCH Downstream Port RCRB
&gt; +	 */
&gt; +	struct_group_tagged(cxl_rch_regs, rch_regs,
&gt; +		void __iomem *dport_aer;
&gt; +	);
&gt; +
&gt; +	/*
&gt; +	 * RCD upstream port specific PCIe cap register
&gt; +	 * @pcie_cap: CXL 3.0 8.2.1.2 RCD Upstream Port RCRB
&gt; +	 */
&gt; +	struct_group_tagged(cxl_rcd_regs, rcd_regs,
&gt; +		void __iomem *rcd_pcie_cap;
&gt; +	);
&gt; +};
&gt; +
&gt; +struct cxl_reg_map {
&gt; +	bool valid;
&gt; +	int id;
&gt; +	unsigned long offset;
&gt; +	unsigned long size;
&gt; +};
&gt; +
&gt; +struct cxl_component_reg_map {
&gt; +	struct cxl_reg_map hdm_decoder;
&gt; +	struct cxl_reg_map ras;
&gt; +};
&gt; +
&gt; +struct cxl_device_reg_map {
&gt; +	struct cxl_reg_map status;
&gt; +	struct cxl_reg_map mbox;
&gt; +	struct cxl_reg_map memdev;
&gt; +};
&gt; +
&gt; +struct cxl_pmu_reg_map {
&gt; +	struct cxl_reg_map pmu;
&gt; +};
&gt; +
&gt; +/**
&gt; + * struct cxl_register_map - DVSEC harvested register block mapping parameters
&gt; + * @host: device for devm operations and logging
&gt; + * @base: virtual base of the register-block-BAR + @block_offset
&gt; + * @resource: physical resource base of the register block
&gt; + * @max_size: maximum mapping size to perform register search
&gt; + * @reg_type: see enum cxl_regloc_type
&gt; + * @component_map: cxl_reg_map for component registers
&gt; + * @device_map: cxl_reg_maps for device registers
&gt; + * @pmu_map: cxl_reg_maps for CXL Performance Monitoring Units
&gt; + */
&gt; +struct cxl_register_map {
&gt; +	struct device *host;
&gt; +	void __iomem *base;
&gt; +	resource_size_t resource;
&gt; +	resource_size_t max_size;
&gt; +	u8 reg_type;
&gt; +	union {
&gt; +		struct cxl_component_reg_map component_map;
&gt; +		struct cxl_device_reg_map device_map;
&gt; +		struct cxl_pmu_reg_map pmu_map;
&gt; +	};
&gt; +};
&gt; +
&gt; +/**
&gt; + * struct cxl_dpa_perf - DPA performance property entry
&gt; + * @dpa_range: range for DPA address
&gt; + * @coord: QoS performance data (i.e. latency, bandwidth)
&gt; + * @cdat_coord: raw QoS performance data from CDAT
&gt; + * @qos_class: QoS Class cookies
&gt; + */
&gt; +struct cxl_dpa_perf {
&gt; +	struct range dpa_range;
&gt; +	struct access_coordinate coord[ACCESS_COORDINATE_MAX];
&gt; +	struct access_coordinate cdat_coord[ACCESS_COORDINATE_MAX];
&gt; +	int qos_class;
&gt; +};
&gt; +
&gt; +enum cxl_partition_mode {
&gt; +	CXL_PARTMODE_RAM,
&gt; +	CXL_PARTMODE_PMEM,
&gt; +};
&gt; +
&gt; +/**
&gt; + * struct cxl_dpa_partition - DPA partition descriptor
&gt; + * @res: shortcut to the partition in the DPA resource tree (cxlds-&gt;dpa_res)
&gt; + * @perf: performance attributes of the partition from CDAT
&gt; + * @mode: operation mode for the DPA capacity, e.g. ram, pmem, dynamic...
&gt; + */
&gt; +struct cxl_dpa_partition {
&gt; +	struct resource res;
&gt; +	struct cxl_dpa_perf perf;
&gt; +	enum cxl_partition_mode mode;
&gt; +};
&gt; +
&gt; +#define CXL_NR_PARTITIONS_MAX 2
&gt; +
&gt; +/**
&gt; + * struct cxl_dev_state - The driver device state
&gt; + *
&gt; + * cxl_dev_state represents the CXL driver/device state.  It provides an
&gt; + * interface to mailbox commands as well as some cached data about the device.
&gt; + * Currently only memory devices are represented.
&gt; + *
&gt; + * @dev: The device associated with this CXL state
&gt; + * @cxlmd: The device representing the CXL.mem capabilities of @dev
&gt; + * @reg_map: component and ras register mapping parameters
&gt; + * @regs: Parsed register blocks
&gt; + * @cxl_dvsec: Offset to the PCIe device DVSEC
&gt; + * @rcd: operating in RCD mode (CXL 3.0 9.11.8 CXL Devices Attached to an RCH)
&gt; + * @media_ready: Indicate whether the device media is usable
&gt; + * @dpa_res: Overall DPA resource tree for the device
&gt; + * @part: DPA partition array
&gt; + * @nr_partitions: Number of DPA partitions
&gt; + * @serial: PCIe Device Serial Number
&gt; + * @type: Generic Memory Class device or Vendor Specific Memory device
&gt; + * @cxl_mbox: CXL mailbox context
&gt; + * @cxlfs: CXL features context
&gt; + */
&gt; +struct cxl_dev_state {
&gt; +	/* public for Type2 drivers */
&gt; +	struct device *dev;
&gt; +	struct cxl_memdev *cxlmd;
&gt; +
&gt; +	/* private for Type2 drivers */
&gt; +	struct cxl_register_map reg_map;
&gt; +	struct cxl_regs regs;
&gt; +	int cxl_dvsec;
&gt; +	bool rcd;
&gt; +	bool media_ready;
&gt; +	struct resource dpa_res;
&gt; +	struct cxl_dpa_partition part[CXL_NR_PARTITIONS_MAX];
&gt; +	unsigned int nr_partitions;
&gt; +	u64 serial;
&gt; +	enum cxl_devtype type;
&gt; +	struct cxl_mailbox cxl_mbox;
&gt; +#ifdef CONFIG_CXL_FEATURES
&gt; +	struct cxl_features_state *cxlfs;
&gt; +#endif
&gt; +};
&gt; +
&gt; +struct cxl_dev_state *_devm_cxl_dev_state_create(struct device *dev,
&gt; +						 enum cxl_devtype type,
&gt; +						 u64 serial, u16 dvsec,
&gt; +						 size_t size, bool has_mbox);
&gt; +
&gt; +/**
&gt; + * cxl_dev_state_create - safely create and cast a cxl dev state embedded in a
&gt; + * driver specific struct.
&gt; + *
&gt; + * @parent: device behind the request
&gt; + * @type: CXL device type
&gt; + * @serial: device identification
&gt; + * @dvsec: dvsec capability offset
&gt; + * @drv_struct: driver struct embedding a cxl_dev_state struct
&gt; + * @member: drv_struct member as cxl_dev_state
&gt; + * @mbox: true if mailbox supported
&gt; + *
&gt; + * Returns a pointer to the drv_struct allocated and embedding a cxl_dev_state
&gt; + * struct initialized.
&gt; + *
&gt; + * Introduced for Type2 driver support.
&gt; + */
&gt; +#define devm_cxl_dev_state_create(parent, type, serial, dvsec, drv_struct, member, mbox)	\
&gt; +	({										\
&gt; +		static_assert(__same_type(struct cxl_dev_state,				\
&gt; +			      ((drv_struct *)NULL)-&gt;member));				\
&gt; +		static_assert(offsetof(drv_struct, member) == 0);			\
&gt; +		(drv_struct *)_devm_cxl_dev_state_create(parent, type, serial, dvsec,	\
&gt; +						      sizeof(drv_struct), mbox);	\
&gt; +	})
&gt; +#endif /* __CXL_CXL_H__ */
&gt; diff --git a/tools/testing/cxl/test/mem.c b/tools/testing/cxl/test/mem.c
&gt; index cb87e8c0e63c..79f42f4474d4 100644
&gt; --- a/tools/testing/cxl/test/mem.c
&gt; +++ b/tools/testing/cxl/test/mem.c
&gt; @@ -1716,7 +1716,7 @@ static int cxl_mock_mem_probe(struct platform_device *pdev)
&gt;  	if (rc)
&gt;  		return rc;
&gt;  
&gt; -	mds = cxl_memdev_state_create(dev);
&gt; +	mds = cxl_memdev_state_create(dev, pdev-&gt;id + 1, 0);
&gt;  	if (IS_ERR(mds))
&gt;  		return PTR_ERR(mds);
&gt;  
&gt; @@ -1732,7 +1732,6 @@ static int cxl_mock_mem_probe(struct platform_device *pdev)
&gt;  	mds-&gt;event.buf = (struct cxl_get_event_payload *) mdata-&gt;event_buf;
&gt;  	INIT_DELAYED_WORK(&amp;mds-&gt;security.poll_dwork, cxl_mockmem_sanitize_work);
&gt;  
&gt; -	cxlds-&gt;serial = pdev-&gt;id + 1;
&gt;  	if (is_rcd(pdev))
&gt;  		cxlds-&gt;rcd = true;
&gt;  



---

On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; A Type2 device configured by the BIOS can already have its HDM
&gt; committed. Add a cxl_get_committed_decoder() function for cheking
&gt; so after memdev creation. A CXL region should have been created
&gt; during memdev initialization, therefore a Type2 driver can ask for
&gt; such a region for working with the HPA. If the HDM is not committed,
&gt; a Type2 driver will create the region after obtaining proper HPA
&gt; and DPA space.
&gt; 
&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; ---
&gt;  drivers/cxl/core/hdm.c | 39 +++++++++++++++++++++++++++++++++++++++
&gt;  include/cxl/cxl.h      |  3 +++
&gt;  2 files changed, 42 insertions(+)
&gt; 
&gt; diff --git a/drivers/cxl/core/hdm.c b/drivers/cxl/core/hdm.c
&gt; index 6e516c69b2d2..a172ce4e9b19 100644
&gt; --- a/drivers/cxl/core/hdm.c
&gt; +++ b/drivers/cxl/core/hdm.c
&gt; @@ -686,6 +686,45 @@ int cxl_dpa_alloc(struct cxl_endpoint_decoder *cxled, u64 size)
&gt;  	return devm_add_action_or_reset(&amp;port-&gt;dev, cxl_dpa_release, cxled);
&gt;  }
&gt;  
&gt; +static int find_committed_endpoint_decoder(struct device *dev, const void *data)
&gt; +{
&gt; +	struct cxl_endpoint_decoder *cxled;
&gt; +	struct cxl_port *port;
&gt; +
&gt; +	if (!is_endpoint_decoder(dev))
&gt; +		return 0;
&gt; +
&gt; +	cxled = to_cxl_endpoint_decoder(dev);
&gt; +	port = cxled_to_port(cxled);
&gt; +
&gt; +	return cxled-&gt;cxld.id == port-&gt;hdm_end;

Is this the way you&#x27;re supposed to check if a decoder is committed? The doc comment for @hdm_end in
struct cxl_port says it&#x27;s just the last allocated decoder. If allocated decoders are always committed then
I&#x27;m fine with this, otherwise I think you&#x27;d want to a register read or something to find the commit state.
&gt; +}
&gt; +
&gt; +struct cxl_endpoint_decoder *cxl_get_committed_decoder(struct cxl_memdev *cxlmd,
&gt; +						       struct cxl_region **cxlr)
&gt; +{
&gt; +	struct cxl_port *endpoint = cxlmd-&gt;endpoint;
&gt; +	struct cxl_endpoint_decoder *cxled;
&gt; +	struct device *cxled_dev;
&gt; +
&gt; +	if (!endpoint)
&gt; +		return NULL;
&gt; +
&gt; +	guard(rwsem_read)(&amp;cxl_rwsem.dpa);
&gt; +	cxled_dev = device_find_child(&amp;endpoint-&gt;dev, NULL,
&gt; +				      find_committed_endpoint_decoder);
&gt; +
&gt; +	if (!cxled_dev)
&gt; +		return NULL;
&gt; +
&gt; +	cxled = to_cxl_endpoint_decoder(cxled_dev);
&gt; +	*cxlr = cxled-&gt;cxld.region;
&gt; +
&gt; +	put_device(cxled_dev);
&gt; +	return cxled;
&gt; +}
&gt; +EXPORT_SYMBOL_NS_GPL(cxl_get_committed_decoder, &quot;CXL&quot;);
&gt; +
&gt;  static void cxld_set_interleave(struct cxl_decoder *cxld, u32 *ctrl)
&gt;  {
&gt;  	u16 eig;
&gt; diff --git a/include/cxl/cxl.h b/include/cxl/cxl.h
&gt; index 6f8d365067af..928276dba952 100644
&gt; --- a/include/cxl/cxl.h
&gt; +++ b/include/cxl/cxl.h
&gt; @@ -249,4 +249,7 @@ int cxl_map_component_regs(const struct cxl_register_map *map,
&gt;  int cxl_set_capacity(struct cxl_dev_state *cxlds, u64 capacity);
&gt;  struct cxl_memdev *devm_cxl_add_memdev(struct cxl_dev_state *cxlds,
&gt;  				       const struct cxl_memdev_attach *attach);
&gt; +struct cxl_region;
&gt; +struct cxl_endpoint_decoder *cxl_get_committed_decoder(struct cxl_memdev *cxlmd,
&gt; +						       struct cxl_region **cxlr);
&gt;  #endif /* __CXL_CXL_H__ */



---

On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; This patchset should be applied on the cxl next branch using the base
&gt; specified at the end of this cover letter.
&gt; 
&gt; Dependencies on Dan&#x27;s work has gone and also on Terry&#x27;s as the only
&gt; patch required is now in next. The other dependency is on Smita patchset
&gt; but it does not exist such a dependency as that work will not avoid the
&gt; problem with Type2 and DAX/hmem if soft reserved memory. This needs to
&gt; be solved by the BIOS and Type2 UEFI driver for populating the CXL.mem
&gt; range as EFI_RESERVED_TYPE instead of default EFI_CONVENTIONAL_MEMORY
&gt; with the EFI_MEMORY_SP attribute. There exists though a dependency on
&gt; one Smita&#x27;s patches:
&gt; 
&gt; [PATCH v5 3/7] cxl/region: Skip decoder reset on detach for autodiscovered regions
&gt; 
&gt; This is needed for the default behaviour with current BIOS configuration
&gt; where the HDM Type2 decoders will be kept unreset when driver unloads.
&gt; This is the main change introduced in v23: committed decoders will not
&gt; be reset. Previous v22 functionality supported first driver load finding
&gt; committed decoders but resetting them at unload and supporting
&gt; uncommitted decoders in next driver loads. This will be suported in
&gt; follow-up works.
&gt; 
&gt; v23 changes:
&gt; 
&gt;   patch 11: fixing minor issues and droping change in
&gt; 	    should_emulate_decoders (Jonathan Cameron)
&gt; 
&gt;   patch13: refactoring unregister_region for safety type in Type2 API
&gt; 
&gt;   sfc changes: slight modifications to error path
&gt; 

This cover letter is really long, I&#x27;d remove the change logs for anything more
than 3 revisions back (assuming a v24 is needed). After that you could leave
a lore link for older revisions if you want, but it&#x27;s not needed imo.
Also, feel free to add my Reviewed-by for anything I didn&#x27;t leave a comment on
(felt I should cut down on the mail).

Thanks,
Ben


---

On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; Region creation involves finding available DPA (device-physical-address)
&gt; capacity to map into HPA (host-physical-address) space.
&gt; 
&gt; In order to support CXL Type2 devices, define an API, cxl_request_dpa(),
&gt; that tries to allocate the DPA memory the driver requires to operate.The
&gt; memory requested should not be bigger than the max available HPA obtained
&gt; previously with cxl_get_hpa_freespace().
&gt; 
&gt; Based on https://lore.kernel.org/linux-cxl/168592158743.1948938.7622563891193802610.stgit@dwillia2-xfh.jf.intel.com/
&gt; 
&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
&gt; Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
&gt; ---
&gt;  drivers/cxl/core/hdm.c | 84 ++++++++++++++++++++++++++++++++++++++++++
&gt;  drivers/cxl/cxl.h      |  1 +
&gt;  include/cxl/cxl.h      |  5 +++
&gt;  3 files changed, 90 insertions(+)
&gt; 
&gt; diff --git a/drivers/cxl/core/hdm.c b/drivers/cxl/core/hdm.c
&gt; index a172ce4e9b19..d60a697f12cc 100644
&gt; --- a/drivers/cxl/core/hdm.c
&gt; +++ b/drivers/cxl/core/hdm.c
&gt; @@ -3,6 +3,7 @@
&gt;  #include &lt;linux/seq_file.h&gt;
&gt;  #include &lt;linux/device.h&gt;
&gt;  #include &lt;linux/delay.h&gt;
&gt; +#include &lt;cxl/cxl.h&gt;
&gt;  
&gt;  #include &quot;cxlmem.h&quot;
&gt;  #include &quot;core.h&quot;
&gt; @@ -546,6 +547,12 @@ bool cxl_resource_contains_addr(const struct resource *res, const resource_size_
&gt;  	return resource_contains(res, &amp;_addr);
&gt;  }
&gt;  
&gt; +/**
&gt; + * cxl_dpa_free - release DPA (Device Physical Address)
&gt; + * @cxled: endpoint decoder linked to the DPA
&gt; + *
&gt; + * Returns 0 or error.
&gt; + */
&gt;  int cxl_dpa_free(struct cxl_endpoint_decoder *cxled)
&gt;  {
&gt;  	struct cxl_port *port = cxled_to_port(cxled);
&gt; @@ -572,6 +579,7 @@ int cxl_dpa_free(struct cxl_endpoint_decoder *cxled)
&gt;  	devm_cxl_dpa_release(cxled);
&gt;  	return 0;
&gt;  }
&gt; +EXPORT_SYMBOL_NS_GPL(cxl_dpa_free, &quot;CXL&quot;);
&gt;  
&gt;  int cxl_dpa_set_part(struct cxl_endpoint_decoder *cxled,
&gt;  		     enum cxl_partition_mode mode)
&gt; @@ -603,6 +611,82 @@ int cxl_dpa_set_part(struct cxl_endpoint_decoder *cxled,
&gt;  	return 0;
&gt;  }
&gt;  
&gt; +static int find_free_decoder(struct device *dev, const void *data)
&gt; +{
&gt; +	struct cxl_endpoint_decoder *cxled;
&gt; +	struct cxl_port *port;
&gt; +
&gt; +	if (!is_endpoint_decoder(dev))
&gt; +		return 0;
&gt; +
&gt; +	cxled = to_cxl_endpoint_decoder(dev);
&gt; +	port = cxled_to_port(cxled);
&gt; +
&gt; +	return cxled-&gt;cxld.id == (port-&gt;hdm_end + 1);
&gt; +}
&gt; +
&gt; +static struct cxl_endpoint_decoder *
&gt; +cxl_find_free_decoder(struct cxl_memdev *cxlmd)
&gt; +{
&gt; +	struct cxl_port *endpoint = cxlmd-&gt;endpoint;
&gt; +	struct device *dev;
&gt; +
&gt; +	guard(rwsem_read)(&amp;cxl_rwsem.dpa);
&gt; +	dev = device_find_child(&amp;endpoint-&gt;dev, NULL,
&gt; +				find_free_decoder);
&gt; +	if (!dev)
&gt; +		return NULL;
&gt; +
&gt; +	return to_cxl_endpoint_decoder(dev);
&gt; +}
&gt; +
&gt; +/**
&gt; + * cxl_request_dpa - search and reserve DPA given input constraints
&gt; + * @cxlmd: memdev with an endpoint port with available decoders
&gt; + * @mode: CXL partition mode (ram vs pmem)
&gt; + * @alloc: dpa size required
&gt; + *
&gt; + * Returns a pointer to a &#x27;struct cxl_endpoint_decoder&#x27; on success or
&gt; + * an errno encoded pointer on failure.
&gt; + *
&gt; + * Given that a region needs to allocate from limited HPA capacity it
&gt; + * may be the case that a device has more mappable DPA capacity than
&gt; + * available HPA. The expectation is that @alloc is a driver known
&gt; + * value based on the device capacity but which could not be fully
&gt; + * available due to HPA constraints.
&gt; + *
&gt; + * Returns a pinned cxl_decoder with at least @alloc bytes of capacity
&gt; + * reserved, or an error pointer. The caller is also expected to own the
&gt; + * lifetime of the memdev registration associated with the endpoint to
&gt; + * pin the decoder registered as well.
&gt; + */
&gt; +struct cxl_endpoint_decoder *cxl_request_dpa(struct cxl_memdev *cxlmd,
&gt; +					     enum cxl_partition_mode mode,
&gt; +					     resource_size_t alloc)
&gt; +{
&gt; +	int rc;
&gt; +
&gt; +	if (!IS_ALIGNED(alloc, SZ_256M))
&gt; +		return ERR_PTR(-EINVAL);
&gt; +
&gt; +	struct cxl_endpoint_decoder *cxled __free(put_cxled) =
&gt; +		cxl_find_free_decoder(cxlmd);
&gt; +
&gt; +	if (!cxled)
&gt; +		return ERR_PTR(-ENODEV);
&gt; +
&gt; +	rc = cxl_dpa_set_part(cxled, mode);
&gt; +	if (rc)
&gt; +		return ERR_PTR(rc);
&gt; +
&gt; +	rc = cxl_dpa_alloc(cxled, alloc);
&gt; +	if (rc)
&gt; +		return ERR_PTR(rc);

Should cxl_dpa_set_part() be unwound here, or does it not matter? If it doesn&#x27;t matter:
Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
&gt; +
&gt; +	return no_free_ptr(cxled);
&gt; +}
&gt; +EXPORT_SYMBOL_NS_GPL(cxl_request_dpa, &quot;CXL&quot;);
&gt; +
&gt;  static int __cxl_dpa_alloc(struct cxl_endpoint_decoder *cxled, u64 size)
&gt;  {
&gt;  	struct cxl_memdev *cxlmd = cxled_to_memdev(cxled);
&gt; diff --git a/drivers/cxl/cxl.h b/drivers/cxl/cxl.h
&gt; index d1b010e5e1d0..2b1f7d687a0e 100644
&gt; --- a/drivers/cxl/cxl.h
&gt; +++ b/drivers/cxl/cxl.h
&gt; @@ -667,6 +667,7 @@ struct cxl_root *find_cxl_root(struct cxl_port *port);
&gt;  
&gt;  DEFINE_FREE(put_cxl_root, struct cxl_root *, if (_T) put_device(&amp;_T-&gt;port.dev))
&gt;  DEFINE_FREE(put_cxl_port, struct cxl_port *, if (!IS_ERR_OR_NULL(_T)) put_device(&amp;_T-&gt;dev))
&gt; +DEFINE_FREE(put_cxled, struct cxl_endpoint_decoder *, if (!IS_ERR_OR_NULL(_T)) put_device(&amp;_T-&gt;cxld.dev))
&gt;  DEFINE_FREE(put_cxl_root_decoder, struct cxl_root_decoder *, if (!IS_ERR_OR_NULL(_T)) put_device(&amp;_T-&gt;cxlsd.cxld.dev))
&gt;  DEFINE_FREE(put_cxl_region, struct cxl_region *, if (!IS_ERR_OR_NULL(_T)) put_device(&amp;_T-&gt;dev))
&gt;  
&gt; diff --git a/include/cxl/cxl.h b/include/cxl/cxl.h
&gt; index 783ad570a6eb..4802371db00e 100644
&gt; --- a/include/cxl/cxl.h
&gt; +++ b/include/cxl/cxl.h
&gt; @@ -7,6 +7,7 @@
&gt;  
&gt;  #include &lt;linux/node.h&gt;
&gt;  #include &lt;linux/ioport.h&gt;
&gt; +#include &lt;linux/range.h&gt;
&gt;  #include &lt;cxl/mailbox.h&gt;
&gt;  
&gt;  /**
&gt; @@ -276,4 +277,8 @@ struct cxl_root_decoder *cxl_get_hpa_freespace(struct cxl_memdev *cxlmd,
&gt;  					       unsigned long flags,
&gt;  					       resource_size_t *max);
&gt;  void cxl_put_root_decoder(struct cxl_root_decoder *cxlrd);
&gt; +struct cxl_endpoint_decoder *cxl_request_dpa(struct cxl_memdev *cxlmd,
&gt; +					     enum cxl_partition_mode mode,
&gt; +					     resource_size_t alloc);
&gt; +int cxl_dpa_free(struct cxl_endpoint_decoder *cxled);
&gt;  #endif /* __CXL_CXL_H__ */



---



On 2/19/2026 4:40 AM, Alejandro Lucero Palau wrote:
&gt; 
&gt; On 2/11/26 22:11, Cheatham, Benjamin wrote:
&gt;&gt; On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt;&gt;&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; Region creation based on Type3 devices is triggered from user space
&gt;&gt;&gt; allowing memory combination through interleaving.
&gt;&gt;&gt;
&gt;&gt;&gt; In preparation for kernel driven region creation, that is Type2 drivers
&gt;&gt;&gt; triggering region creation backed with its advertised CXL memory, factor
&gt;&gt;&gt; out a common helper from the user-sysfs region setup for interleave ways.
&gt;&gt;&gt;
&gt;&gt;&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt;&gt;&gt; Reviewed-by: Zhi Wang &lt;zhiw@nvidia.com&gt;
&gt;&gt;&gt; Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
&gt;&gt;&gt; Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
&gt;&gt;&gt; Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
&gt;&gt;&gt; Reviewed-by: Alison Schofield &lt;alison.schofield@intel.com&gt;
&gt;&gt;&gt; ---
&gt;&gt;&gt;  drivers/cxl/core/region.c | 43 ++++++++++++++++++++++++---------------
&gt;&gt;&gt;  1 file changed, 27 insertions(+), 16 deletions(-)
&gt;&gt;&gt;
&gt;&gt;&gt; diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
&gt;&gt;&gt; index f53b2e9fd9e6..ece1d3df7cf1 100644
&gt;&gt;&gt; --- a/drivers/cxl/core/region.c
&gt;&gt;&gt; +++ b/drivers/cxl/core/region.c
&gt;&gt;&gt; @@ -485,22 +485,14 @@ static ssize_t interleave_ways_show(struct device *dev,
&gt;&gt;&gt;   static const struct attribute_group *get_cxl_region_target_group(void);
&gt;&gt;&gt;  -static ssize_t interleave_ways_store(struct device *dev,
&gt;&gt;&gt; - struct device_attribute *attr,
&gt;&gt;&gt; - const char *buf, size_t len)
&gt;&gt;&gt; +static int set_interleave_ways(struct cxl_region *cxlr, int val)
&gt;&gt; @val should probably stay an unsigned int. You pass an unsigned int in the sysfs function, and the
&gt;&gt; function was originally coded with that in mind (same with @save below).
&gt; 
&gt; Good catch. I wonder if I should just change the way the value is obtained, using kstrtoint instead of kstrtouint, as those values are used for cxl_region_params fields defined as int. In other words, it seems doing that simpler than changing all the other places you mention and the structs involved. I can not see a reason for using unsigned int so I think I will follow that approach. Tell me if you think otherwise.
&gt; 

If I had to guess unsigned int was used because a negative interleave granularity/ways makes no sense. I think your suggestion is fine though since no one
in their right mind would give anything but a (relatively) small and positive value for these.

Thanks,
Ben

&gt; 
&gt; Thank you
&gt; 
&gt; 
&gt;&gt; With that cleaned up:
&gt;&gt; Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
&gt;&gt;
&gt;&gt;&gt;  {
&gt;&gt;&gt; - struct cxl_root_decoder *cxlrd = to_cxl_root_decoder(dev-&gt;parent);
&gt;&gt;&gt; + struct cxl_root_decoder *cxlrd = to_cxl_root_decoder(cxlr-&gt;dev.parent);
&gt;&gt;&gt;  struct cxl_decoder *cxld = &amp;cxlrd-&gt;cxlsd.cxld;
&gt;&gt;&gt; - struct cxl_region *cxlr = to_cxl_region(dev);
&gt;&gt;&gt;  struct cxl_region_params *p = &amp;cxlr-&gt;params;
&gt;&gt;&gt; - unsigned int val, save;
&gt;&gt;&gt; - int rc;
&gt;&gt;&gt; + int save, rc;
&gt;&gt;&gt;  u8 iw;
&gt;&gt;&gt;  - rc = kstrtouint(buf, 0, &amp;val);
&gt;&gt;&gt; - if (rc)
&gt;&gt;&gt; - return rc;
&gt;&gt;&gt; -
&gt;&gt;&gt;  rc = ways_to_eiw(val, &amp;iw);
&gt;&gt;&gt;  if (rc)
&gt;&gt;&gt;  return rc;
&gt;&gt;&gt; @@ -515,9 +507,7 @@ static ssize_t interleave_ways_store(struct device *dev,
&gt;&gt;&gt;  return -EINVAL;
&gt;&gt;&gt;  }
&gt;&gt;&gt;  - ACQUIRE(rwsem_write_kill, rwsem)(&amp;cxl_rwsem.region);
&gt;&gt;&gt; - if ((rc = ACQUIRE_ERR(rwsem_write_kill, &amp;rwsem)))
&gt;&gt;&gt; - return rc;
&gt;&gt;&gt; + lockdep_assert_held_write(&amp;cxl_rwsem.region);
&gt;&gt;&gt;   if (p-&gt;state &gt;= CXL_CONFIG_INTERLEAVE_ACTIVE)
&gt;&gt;&gt;  return -EBUSY;
&gt;&gt;&gt; @@ -525,10 +515,31 @@ static ssize_t interleave_ways_store(struct device *dev,
&gt;&gt;&gt;  save = p-&gt;interleave_ways;
&gt;&gt;&gt;  p-&gt;interleave_ways = val;
&gt;&gt;&gt;  rc = sysfs_update_group(&amp;cxlr-&gt;dev.kobj, get_cxl_region_target_group());
&gt;&gt;&gt; - if (rc) {
&gt;&gt;&gt; + if (rc)
&gt;&gt;&gt;  p-&gt;interleave_ways = save;
&gt;&gt;&gt; +
&gt;&gt;&gt; + return rc;
&gt;&gt;&gt; +}
&gt;&gt;&gt; +
&gt;&gt;&gt; +static ssize_t interleave_ways_store(struct device *dev,
&gt;&gt;&gt; + struct device_attribute *attr,
&gt;&gt;&gt; + const char *buf, size_t len)
&gt;&gt;&gt; +{
&gt;&gt;&gt; + struct cxl_region *cxlr = to_cxl_region(dev);
&gt;&gt;&gt; + unsigned int val;
&gt;&gt;&gt; + int rc;
&gt;&gt;&gt; +
&gt;&gt;&gt; + rc = kstrtouint(buf, 0, &amp;val);
&gt;&gt;&gt; + if (rc)
&gt;&gt;&gt; + return rc;
&gt;&gt;&gt; +
&gt;&gt;&gt; + ACQUIRE(rwsem_write_kill, rwsem)(&amp;cxl_rwsem.region);
&gt;&gt;&gt; + if ((rc = ACQUIRE_ERR(rwsem_write_kill, &amp;rwsem)))
&gt;&gt;&gt; + return rc;
&gt;&gt;&gt; +
&gt;&gt;&gt; + rc = set_interleave_ways(cxlr, val);
&gt;&gt;&gt; + if (rc)
&gt;&gt;&gt;  return rc;
&gt;&gt;&gt; - }
&gt;&gt;&gt;   return len;
&gt;&gt;&gt;  }



---

On 2/19/2026 3:58 AM, Alejandro Lucero Palau wrote:
&gt; 
&gt; On 2/11/26 22:10, Cheatham, Benjamin wrote:
&gt;&gt; On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt;&gt;&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; CXL region creation involves allocating capacity from Device Physical
&gt;&gt;&gt; Address (DPA) and assigning it to decode a given Host Physical Address
&gt;&gt;&gt; (HPA). Before determining how much DPA to allocate the amount of available
&gt;&gt;&gt; HPA must be determined. Also, not all HPA is created equal, some HPA
&gt;&gt;&gt; targets RAM, some targets PMEM, some is prepared for device-memory flows
&gt;&gt;&gt; like HDM-D and HDM-DB, and some is HDM-H (host-only).
&gt;&gt;&gt;
&gt;&gt;&gt; In order to support Type2 CXL devices, wrap all of those concerns into
&gt;&gt;&gt; an API that retrieves a root decoder (platform CXL window) that fits the
&gt;&gt;&gt; specified constraints and the capacity available for a new region.
&gt;&gt;&gt;
&gt;&gt;&gt; Add a complementary function for releasing the reference to such root
&gt;&gt;&gt; decoder.
&gt;&gt;&gt;
&gt;&gt;&gt; Based on https://lore.kernel.org/linux-cxl/168592159290.1948938.13522227102445462976.stgit@dwillia2-xfh.jf.intel.com/
&gt;&gt;&gt;
&gt;&gt;&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt;&gt;&gt; Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
&gt;&gt;&gt; ---
&gt;&gt;&gt;  drivers/cxl/core/region.c | 164 ++++++++++++++++++++++++++++++++++++++
&gt;&gt;&gt;  drivers/cxl/cxl.h | 3 +
&gt;&gt;&gt;  include/cxl/cxl.h | 6 ++
&gt;&gt;&gt;  3 files changed, 173 insertions(+)
&gt;&gt;&gt;
&gt;&gt;&gt; diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
&gt;&gt;&gt; index 954b8fcdbac6..bdefd088f5f1 100644
&gt;&gt;&gt; --- a/drivers/cxl/core/region.c
&gt;&gt;&gt; +++ b/drivers/cxl/core/region.c
&gt;&gt;&gt; @@ -705,6 +705,170 @@ static int free_hpa(struct cxl_region *cxlr)
&gt;&gt;&gt;  return 0;
&gt;&gt;&gt;  }
&gt;&gt;&gt;  +struct cxlrd_max_context {
&gt;&gt;&gt; + struct device * const *host_bridges;
&gt;&gt;&gt; + int interleave_ways;
&gt;&gt;&gt; + unsigned long flags;
&gt;&gt;&gt; + resource_size_t max_hpa;
&gt;&gt;&gt; + struct cxl_root_decoder *cxlrd;
&gt;&gt;&gt; +};
&gt;&gt;&gt; +
&gt;&gt;&gt; +static int find_max_hpa(struct device *dev, void *data)
&gt;&gt;&gt; +{
&gt;&gt;&gt; + struct cxlrd_max_context *ctx = data;
&gt;&gt;&gt; + struct cxl_switch_decoder *cxlsd;
&gt;&gt;&gt; + struct cxl_root_decoder *cxlrd;
&gt;&gt;&gt; + struct resource *res, *prev;
&gt;&gt;&gt; + struct cxl_decoder *cxld;
&gt;&gt;&gt; + resource_size_t free = 0;
&gt;&gt;&gt; + resource_size_t max;
&gt;&gt;&gt; + int found = 0;
&gt;&gt;&gt; +
&gt;&gt;&gt; + if (!is_root_decoder(dev))
&gt;&gt;&gt; + return 0;
&gt;&gt;&gt; +
&gt;&gt;&gt; + cxlrd = to_cxl_root_decoder(dev);
&gt;&gt;&gt; + cxlsd = &amp;cxlrd-&gt;cxlsd;
&gt;&gt;&gt; + cxld = &amp;cxlsd-&gt;cxld;
&gt;&gt;&gt; +
&gt;&gt;&gt; + if ((cxld-&gt;flags &amp; ctx-&gt;flags) != ctx-&gt;flags) {
&gt;&gt;&gt; + dev_dbg(dev, &quot;flags not matching: %08lx vs %08lx\n&quot;,
&gt;&gt;&gt; + cxld-&gt;flags, ctx-&gt;flags);
&gt;&gt;&gt; + return 0;
&gt;&gt;&gt; + }
&gt;&gt;&gt; +
&gt;&gt;&gt; + for (int i = 0; i &lt; ctx-&gt;interleave_ways; i++) {
&gt;&gt;&gt; + for (int j = 0; j &lt; ctx-&gt;interleave_ways; j++) {
&gt;&gt;&gt; + if (ctx-&gt;host_bridges[i] == cxlsd-&gt;target[j]-&gt;dport_dev) {
&gt;&gt;&gt; + found++;
&gt;&gt;&gt; + break;
&gt;&gt;&gt; + }
&gt;&gt;&gt; + }
&gt;&gt;&gt; + }
&gt;&gt; This may be over complicated. I&#x27;m not quite sure how it works (I&#x27;m just slow today I guess), but I understand
&gt;&gt; what the intention is based on the debug print below. My issue is that ctx-&gt;host_bridges is only set to 1 host
&gt;&gt; bridge (endpoint-&gt;host_bridge) in cxl_get_hpa_freespace(), which is the only caller of this function. At that
&gt;&gt; point, why have the outer loop at all? At that point, you could also simplify ctx-&gt;host_bridges to only
&gt;&gt; be a struct device * const.
&gt;&gt;
&gt;&gt; Maybe this gets called elsewhere later on in the series? I haven&#x27;t looked at the rest yet. If I&#x27;m wrong, then
&gt;&gt; I&#x27;d probably add a comment saying what the cxlsd-&gt;target[] entries are supposed to be pointing at.
&gt; 
&gt; 
&gt; Hi Ben,
&gt; 
&gt; 
&gt; I do remember this one.
&gt; 
&gt; 
&gt; Dan&#x27;s original patches had this support for interleaving, then I removed it as the case for Type2 and interleaving is quite unlikely, at least right now and likely in the near future. But I was told why do not support it as it was trivial to do so. FWIW, If I think only about the use case coming with the patchset, I agree with you, but because those previous discussions, I think I have to leave it.
&gt; 

I&#x27;m fine with that, but I would at least do the fix with the decoder position in 19/22 and make a note that the
interleave_ways parameter in cxl_get_hpa_freespace() below is currently unused (unless I&#x27;m misunderstanding
the endpoint-&gt;host_bridge member).

That way, the support is mostly there and just requires a small, previously noted, addition to enable. If you&#x27;re
fine with that then feel free to add my Reviewed-by after implementing in v24.

Thanks,
Ben

&gt; 
&gt; Thank you
&gt; 
&gt; 
&gt;&gt;&gt; +
&gt;&gt;&gt; + if (found != ctx-&gt;interleave_ways) {
&gt;&gt;&gt; + dev_dbg(dev,
&gt;&gt;&gt; + &quot;Not enough host bridges. Found %d for %d interleave ways requested\n&quot;,
&gt;&gt;&gt; + found, ctx-&gt;interleave_ways);
&gt;&gt;&gt; + return 0;
&gt;&gt;&gt; + }
&gt;&gt;&gt; +
&gt;&gt;&gt; + /*
&gt;&gt;&gt; + * Walk the root decoder resource range relying on cxl_rwsem.region to
&gt;&gt;&gt; + * preclude sibling arrival/departure and find the largest free space
&gt;&gt;&gt; + * gap.
&gt;&gt;&gt; + */
&gt;&gt;&gt; + lockdep_assert_held_read(&amp;cxl_rwsem.region);
&gt;&gt;&gt; + res = cxlrd-&gt;res-&gt;child;
&gt;&gt;&gt; +
&gt;&gt;&gt; + /* With no resource child the whole parent resource is available */
&gt;&gt;&gt; + if (!res)
&gt;&gt;&gt; + max = resource_size(cxlrd-&gt;res);
&gt;&gt;&gt; + else
&gt;&gt;&gt; + max = 0;
&gt;&gt;&gt; +
&gt;&gt;&gt; + for (prev = NULL; res; prev = res, res = res-&gt;sibling) {
&gt;&gt;&gt; + if (!prev &amp;&amp; res-&gt;start == cxlrd-&gt;res-&gt;start &amp;&amp;
&gt;&gt;&gt; + res-&gt;end == cxlrd-&gt;res-&gt;end) {
&gt;&gt;&gt; + max = resource_size(cxlrd-&gt;res);
&gt;&gt;&gt; + break;
&gt;&gt;&gt; + }
&gt;&gt;&gt; + /*
&gt;&gt;&gt; + * Sanity check for preventing arithmetic problems below as a
&gt;&gt;&gt; + * resource with size 0 could imply using the end field below
&gt;&gt;&gt; + * when set to unsigned zero - 1 or all f in hex.
&gt;&gt;&gt; + */
&gt;&gt;&gt; + if (prev &amp;&amp; !resource_size(prev))
&gt;&gt;&gt; + continue;
&gt;&gt;&gt; +
&gt;&gt;&gt; + if (!prev &amp;&amp; res-&gt;start &gt; cxlrd-&gt;res-&gt;start) {
&gt;&gt;&gt; + free = res-&gt;start - cxlrd-&gt;res-&gt;start;
&gt;&gt;&gt; + max = max(free, max);
&gt;&gt;&gt; + }
&gt;&gt;&gt; + if (prev &amp;&amp; res-&gt;start &gt; prev-&gt;end + 1) {
&gt;&gt;&gt; + free = res-&gt;start - prev-&gt;end + 1;
&gt;&gt;&gt; + max = max(free, max);
&gt;&gt;&gt; + }
&gt;&gt;&gt; + }
&gt;&gt;&gt; +
&gt;&gt;&gt; + if (prev &amp;&amp; prev-&gt;end + 1 &lt; cxlrd-&gt;res-&gt;end + 1) {
&gt;&gt;&gt; + free = cxlrd-&gt;res-&gt;end + 1 - prev-&gt;end + 1;
&gt;&gt;&gt; + max = max(free, max);
&gt;&gt;&gt; + }
&gt;&gt;&gt; +
&gt;&gt;&gt; + dev_dbg(cxlrd_dev(cxlrd), &quot;found %pa bytes of free space\n&quot;, &amp;max);
&gt;&gt;&gt; + if (max &gt; ctx-&gt;max_hpa) {
&gt;&gt;&gt; + if (ctx-&gt;cxlrd)
&gt;&gt;&gt; + put_device(cxlrd_dev(ctx-&gt;cxlrd));
&gt;&gt;&gt; + get_device(cxlrd_dev(cxlrd));
&gt;&gt;&gt; + ctx-&gt;cxlrd = cxlrd;
&gt;&gt;&gt; + ctx-&gt;max_hpa = max;
&gt;&gt;&gt; + }
&gt;&gt;&gt; + return 0;
&gt;&gt;&gt; +}
&gt;&gt;&gt; +
&gt;&gt;&gt; +/**
&gt;&gt;&gt; + * cxl_get_hpa_freespace - find a root decoder with free capacity per constraints
&gt;&gt;&gt; + * @cxlmd: the mem device requiring the HPA
&gt;&gt;&gt; + * @interleave_ways: number of entries in @host_bridges
&gt;&gt;&gt; + * @flags: CXL_DECODER_F flags for selecting RAM vs PMEM, and Type2 device
&gt;&gt;&gt; + * @max_avail_contig: output parameter of max contiguous bytes available in the
&gt;&gt;&gt; + * returned decoder
&gt;&gt;&gt; + *
&gt;&gt;&gt; + * Returns a pointer to a struct cxl_root_decoder
&gt;&gt;&gt; + *
&gt;&gt;&gt; + * The return tuple of a &#x27;struct cxl_root_decoder&#x27; and &#x27;bytes available given
&gt;&gt;&gt; + * in (@max_avail_contig))&#x27; is a point in time snapshot. If by the time the
&gt;&gt;&gt; + * caller goes to use this decoder and its capacity is reduced then caller needs
&gt;&gt;&gt; + * to loop and retry.
&gt;&gt;&gt; + *
&gt;&gt;&gt; + * The returned root decoder has an elevated reference count that needs to be
&gt;&gt;&gt; + * put with cxl_put_root_decoder(cxlrd).
&gt;&gt;&gt; + */
&gt;&gt;&gt; +struct cxl_root_decoder *cxl_get_hpa_freespace(struct cxl_memdev *cxlmd,
&gt;&gt;&gt; + int interleave_ways,
&gt;&gt;&gt; + unsigned long flags,
&gt;&gt;&gt; + resource_size_t *max_avail_contig)
&gt;&gt;&gt; +{
&gt;&gt;&gt; + struct cxlrd_max_context ctx = {
&gt;&gt;&gt; + .flags = flags,
&gt;&gt;&gt; + .interleave_ways = interleave_ways,
&gt;&gt;&gt; + };
&gt;&gt;&gt; + struct cxl_port *root_port;
&gt;&gt;&gt; + struct cxl_port *endpoint;
&gt;&gt;&gt; +
&gt;&gt;&gt; + endpoint = cxlmd-&gt;endpoint;
&gt;&gt;&gt; + if (!endpoint) {
&gt;&gt;&gt; + dev_dbg(&amp;cxlmd-&gt;dev, &quot;endpoint not linked to memdev\n&quot;);
&gt;&gt;&gt; + return ERR_PTR(-ENXIO);
&gt;&gt;&gt; + }
&gt;&gt;&gt; +
&gt;&gt;&gt; + ctx.host_bridges = &amp;endpoint-&gt;host_bridge;
&gt;&gt; Mentioned earlier, interleave_ways is effectively hardcoded to 1 (unless I&#x27;m misunderstanding
&gt;&gt; something). I think what you want here is to go to the CXL root and pass in the children (i.e. host bridges)?
&gt;&gt; I&#x27;m not sure of what the fix is to get the intended behavior.
&gt;&gt;
&gt;&gt; It may be worth getting rid of the interleave_ways portion of this function and
&gt;&gt; add it later when someone needs it. You could also explain it&#x27;s hard coded to 1/unused
&gt;&gt; in the doc comment if you know of an immediate need for it.
&gt;&gt;
&gt;&gt;&gt; +
&gt;&gt;&gt; + struct cxl_root *root __free(put_cxl_root) = find_cxl_root(endpoint);
&gt;&gt;&gt; + if (!root) {
&gt;&gt;&gt; + dev_dbg(&amp;endpoint-&gt;dev, &quot;endpoint is not related to a root port\n&quot;);
&gt;&gt;&gt; + return ERR_PTR(-ENXIO);
&gt;&gt;&gt; + }
&gt;&gt;&gt; +
&gt;&gt;&gt; + root_port = &amp;root-&gt;port;
&gt;&gt;&gt; + scoped_guard(rwsem_read, &amp;cxl_rwsem.region)
&gt;&gt;&gt; + device_for_each_child(&amp;root_port-&gt;dev, &amp;ctx, find_max_hpa);
&gt;&gt; Can just use a guard() here.
&gt;&gt;
&gt;&gt;&gt; +
&gt;&gt;&gt; + if (!ctx.cxlrd)
&gt;&gt;&gt; + return ERR_PTR(-ENOMEM);
&gt;&gt;&gt; +
&gt;&gt;&gt; + *max_avail_contig = ctx.max_hpa;
&gt;&gt;&gt; + return ctx.cxlrd;
&gt;&gt;&gt; +}
&gt;&gt;&gt; +EXPORT_SYMBOL_NS_GPL(cxl_get_hpa_freespace, &quot;CXL&quot;);
&gt;&gt;&gt; +
&gt;&gt;&gt; +void cxl_put_root_decoder(struct cxl_root_decoder *cxlrd)
&gt;&gt;&gt; +{
&gt;&gt;&gt; + put_device(cxlrd_dev(cxlrd));
&gt;&gt;&gt; +}
&gt;&gt;&gt; +EXPORT_SYMBOL_NS_GPL(cxl_put_root_decoder, &quot;CXL&quot;);
&gt;&gt;&gt; +
&gt;&gt;&gt;  static ssize_t size_store(struct device *dev, struct device_attribute *attr,
&gt;&gt;&gt;  const char *buf, size_t len)
&gt;&gt;&gt;  {
&gt;&gt;&gt; diff --git a/drivers/cxl/cxl.h b/drivers/cxl/cxl.h
&gt;&gt;&gt; index 944c5d1ccceb..c7d9b2c2908f 100644
&gt;&gt;&gt; --- a/drivers/cxl/cxl.h
&gt;&gt;&gt; +++ b/drivers/cxl/cxl.h
&gt;&gt;&gt; @@ -706,6 +706,9 @@ struct cxl_root_decoder *to_cxl_root_decoder(struct device *dev);
&gt;&gt;&gt;  struct cxl_switch_decoder *to_cxl_switch_decoder(struct device *dev);
&gt;&gt;&gt;  struct cxl_endpoint_decoder *to_cxl_endpoint_decoder(struct device *dev);
&gt;&gt;&gt;  bool is_root_decoder(struct device *dev);
&gt;&gt;&gt; +
&gt;&gt;&gt; +#define cxlrd_dev(cxlrd) (&amp;(cxlrd)-&gt;cxlsd.cxld.dev)
&gt;&gt;&gt; +
&gt;&gt;&gt;  bool is_switch_decoder(struct device *dev);
&gt;&gt;&gt;  bool is_endpoint_decoder(struct device *dev);
&gt;&gt;&gt;  struct cxl_root_decoder *cxl_root_decoder_alloc(struct cxl_port *port,
&gt;&gt;&gt; diff --git a/include/cxl/cxl.h b/include/cxl/cxl.h
&gt;&gt;&gt; index 92880c26b2d5..834dc7e78934 100644
&gt;&gt;&gt; --- a/include/cxl/cxl.h
&gt;&gt;&gt; +++ b/include/cxl/cxl.h
&gt;&gt;&gt; @@ -255,4 +255,10 @@ struct cxl_endpoint_decoder *cxl_get_committed_decoder(struct cxl_memdev *cxlmd,
&gt;&gt;&gt;  struct range;
&gt;&gt;&gt;  int cxl_get_region_range(struct cxl_region *region, struct range *range);
&gt;&gt;&gt;  void cxl_unregister_region(struct cxl_region *cxlr);
&gt;&gt;&gt; +struct cxl_port;
&gt;&gt;&gt; +struct cxl_root_decoder *cxl_get_hpa_freespace(struct cxl_memdev *cxlmd,
&gt;&gt;&gt; + int interleave_ways,
&gt;&gt;&gt; + unsigned long flags,
&gt;&gt;&gt; + resource_size_t *max);
&gt;&gt;&gt; +void cxl_put_root_decoder(struct cxl_root_decoder *cxlrd);
&gt;&gt;&gt;  #endif /* __CXL_CXL_H__ */

</pre>
</details>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Cheatham, Benjamin</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-11">2026-02-11</a>
<span class="inline-review-badge">Inline Review</span>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer noted that the current implementation calls drop_region() with an error pointer returned by construct_region_begin(), which would lead to a garbage pointer dereference, and suggested changing the if condition to check for IS_ERR_OR_NULL before calling drop_region().

Reviewer noted that the position parameter in a function is hardcoded to 0, and suggested setting it to &#x27;i&#x27; instead, referencing an earlier patch where interleaving functionality was added but appears unused.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">This needs to be &quot;if (!IS_ERR_OR_NULL(_T) drop_region(_T)&quot;. If construct_region_begin() returns an
error pointer, drop_region() will be called with it as of now leading to a garbage pointer deref.

---

Position parameter is hardcoded to 0. It should be set to i, right? This kind of goes back to my
issues in patch 12/22; the interleaving functionality is there but it looks unused.</pre>
</details>
<div class="review-comment-signals">Signals: requested changes</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Cheatham, Benjamin</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-11">2026-02-11</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer suggested folding cxl_dev_state_init() into the existing function, citing that it&#x27;s only called within this function and thus unnecessary to have a separate init function.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Nit: Having a second function to do the init seems overkill here, especially since cxl_dev_state_init() isn&#x27;t called outside this
function. I&#x27;d fold it into this function instead, but I&#x27;m fine with it either way (especially if you were told otherwise before).

Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;</pre>
</details>
<div class="review-comment-signals">Signals: NEEDS_WORK</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Cheatham, Benjamin</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-11">2026-02-11</a>
<span class="inline-review-badge">Inline Review</span>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer questioned whether checking if a decoder is committed should be done by verifying the last allocated decoder (hdm_end), pointing out that this might not accurately reflect the commit state and suggesting an alternative approach of reading the register directly.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Is this the way you&#x27;re supposed to check if a decoder is committed? The doc comment for @hdm_end in
struct cxl_port says it&#x27;s just the last allocated decoder. If allocated decoders are always committed then
I&#x27;m fine with this, otherwise I think you&#x27;d want to a register read or something to find the commit state.</pre>
</details>
<div class="review-comment-signals">Signals: requested changes</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Cheatham, Benjamin</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-11">2026-02-11</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer suggested removing change logs for revisions more than 3 back, and adding a lore link for older revisions if desired.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">This cover letter is really long, I&#x27;d remove the change logs for anything more
than 3 revisions back (assuming a v24 is needed). After that you could leave
a lore link for older revisions if you want, but it&#x27;s not needed imo.
Also, feel free to add my Reviewed-by for anything I didn&#x27;t leave a comment on
(felt I should cut down on the mail).

Thanks,
Ben</pre>
</details>
<div class="review-comment-signals">Signals: Requested changes, Suggested improvement</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Cheatham, Benjamin</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-11">2026-02-11</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#155724;background:#d4edda">Positive</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Gave Reviewed-by</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; By definition a type2 cxl device will use the host managed memory for
&gt; specific functionality, therefore it should not be available to other
&gt; uses.
&gt; 
&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
&gt; Reviewed-by: Davidlohr Bueso &lt;daves@stgolabs.net&gt;
&gt; Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
&gt; Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
&gt; ---
&gt;  drivers/cxl/core/region.c | 7 +++++++
&gt;  1 file changed, 7 insertions(+)
&gt; 
&gt; diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
&gt; index 293e63dfef22..12df717cc881 100644
&gt; --- a/drivers/cxl/core/region.c
&gt; +++ b/drivers/cxl/core/region.c
&gt; @@ -4441,6 +4441,13 @@ static int cxl_region_probe(struct device *dev)
&gt;  	if (rc)
&gt;  		return rc;
&gt;  
&gt; +	/*
&gt; +	 * HDM-D[B] (device-memory) regions have accelerator specific usage.
&gt; +	 * Skip device-dax registration.
&gt; +	 */
&gt; +	if (cxlr-&gt;type == CXL_DECODER_DEVMEM)
&gt; +		return 0;

Minor nit: Should probably move this to be the first thing in the function. It would save
having to acquire a lock in cxl_region_can_probe() above. Keep my reviewed-by either way,
it&#x27;s really just a minor optimization.
&gt; +
&gt;  	/*
&gt;  	 * From this point on any path that changes the region&#x27;s state away from
&gt;  	 * CXL_CONFIG_COMMIT is also responsible for releasing the driver.



---

On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; CXL region creation involves allocating capacity from Device Physical
&gt; Address (DPA) and assigning it to decode a given Host Physical Address
&gt; (HPA). Before determining how much DPA to allocate the amount of available
&gt; HPA must be determined. Also, not all HPA is created equal, some HPA
&gt; targets RAM, some targets PMEM, some is prepared for device-memory flows
&gt; like HDM-D and HDM-DB, and some is HDM-H (host-only).
&gt; 
&gt; In order to support Type2 CXL devices, wrap all of those concerns into
&gt; an API that retrieves a root decoder (platform CXL window) that fits the
&gt; specified constraints and the capacity available for a new region.
&gt; 
&gt; Add a complementary function for releasing the reference to such root
&gt; decoder.
&gt; 
&gt; Based on https://lore.kernel.org/linux-cxl/168592159290.1948938.13522227102445462976.stgit@dwillia2-xfh.jf.intel.com/
&gt; 
&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
&gt; ---
&gt;  drivers/cxl/core/region.c | 164 ++++++++++++++++++++++++++++++++++++++
&gt;  drivers/cxl/cxl.h         |   3 +
&gt;  include/cxl/cxl.h         |   6 ++
&gt;  3 files changed, 173 insertions(+)
&gt; 
&gt; diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
&gt; index 954b8fcdbac6..bdefd088f5f1 100644
&gt; --- a/drivers/cxl/core/region.c
&gt; +++ b/drivers/cxl/core/region.c
&gt; @@ -705,6 +705,170 @@ static int free_hpa(struct cxl_region *cxlr)
&gt;  	return 0;
&gt;  }
&gt;  
&gt; +struct cxlrd_max_context {
&gt; +	struct device * const *host_bridges;
&gt; +	int interleave_ways;
&gt; +	unsigned long flags;
&gt; +	resource_size_t max_hpa;
&gt; +	struct cxl_root_decoder *cxlrd;
&gt; +};
&gt; +
&gt; +static int find_max_hpa(struct device *dev, void *data)
&gt; +{
&gt; +	struct cxlrd_max_context *ctx = data;
&gt; +	struct cxl_switch_decoder *cxlsd;
&gt; +	struct cxl_root_decoder *cxlrd;
&gt; +	struct resource *res, *prev;
&gt; +	struct cxl_decoder *cxld;
&gt; +	resource_size_t free = 0;
&gt; +	resource_size_t max;
&gt; +	int found = 0;
&gt; +
&gt; +	if (!is_root_decoder(dev))
&gt; +		return 0;
&gt; +
&gt; +	cxlrd = to_cxl_root_decoder(dev);
&gt; +	cxlsd = &amp;cxlrd-&gt;cxlsd;
&gt; +	cxld = &amp;cxlsd-&gt;cxld;
&gt; +
&gt; +	if ((cxld-&gt;flags &amp; ctx-&gt;flags) != ctx-&gt;flags) {
&gt; +		dev_dbg(dev, &quot;flags not matching: %08lx vs %08lx\n&quot;,
&gt; +			cxld-&gt;flags, ctx-&gt;flags);
&gt; +		return 0;
&gt; +	}
&gt; +
&gt; +	for (int i = 0; i &lt; ctx-&gt;interleave_ways; i++) {
&gt; +		for (int j = 0; j &lt; ctx-&gt;interleave_ways; j++) {
&gt; +			if (ctx-&gt;host_bridges[i] == cxlsd-&gt;target[j]-&gt;dport_dev) {
&gt; +				found++;
&gt; +				break;
&gt; +			}
&gt; +		}
&gt; +	}

This may be over complicated. I&#x27;m not quite sure how it works (I&#x27;m just slow today I guess), but I understand
what the intention is based on the debug print below. My issue is that ctx-&gt;host_bridges is only set to 1 host
bridge (endpoint-&gt;host_bridge) in cxl_get_hpa_freespace(), which is the only caller of this function. At that
point, why have the outer loop at all? At that point, you could also simplify ctx-&gt;host_bridges to only
be a struct device * const.

Maybe this gets called elsewhere later on in the series? I haven&#x27;t looked at the rest yet. If I&#x27;m wrong, then
I&#x27;d probably add a comment saying what the cxlsd-&gt;target[] entries are supposed to be pointing at.
&gt; +
&gt; +	if (found != ctx-&gt;interleave_ways) {
&gt; +		dev_dbg(dev,
&gt; +			&quot;Not enough host bridges. Found %d for %d interleave ways requested\n&quot;,
&gt; +			found, ctx-&gt;interleave_ways);
&gt; +		return 0;
&gt; +	}
&gt; +
&gt; +	/*
&gt; +	 * Walk the root decoder resource range relying on cxl_rwsem.region to
&gt; +	 * preclude sibling arrival/departure and find the largest free space
&gt; +	 * gap.
&gt; +	 */
&gt; +	lockdep_assert_held_read(&amp;cxl_rwsem.region);
&gt; +	res = cxlrd-&gt;res-&gt;child;
&gt; +
&gt; +	/* With no resource child the whole parent resource is available */
&gt; +	if (!res)
&gt; +		max = resource_size(cxlrd-&gt;res);
&gt; +	else
&gt; +		max = 0;
&gt; +
&gt; +	for (prev = NULL; res; prev = res, res = res-&gt;sibling) {
&gt; +		if (!prev &amp;&amp; res-&gt;start == cxlrd-&gt;res-&gt;start &amp;&amp;
&gt; +		    res-&gt;end == cxlrd-&gt;res-&gt;end) {
&gt; +			max = resource_size(cxlrd-&gt;res);
&gt; +			break;
&gt; +		}
&gt; +		/*
&gt; +		 * Sanity check for preventing arithmetic problems below as a
&gt; +		 * resource with size 0 could imply using the end field below
&gt; +		 * when set to unsigned zero - 1 or all f in hex.
&gt; +		 */
&gt; +		if (prev &amp;&amp; !resource_size(prev))
&gt; +			continue;
&gt; +
&gt; +		if (!prev &amp;&amp; res-&gt;start &gt; cxlrd-&gt;res-&gt;start) {
&gt; +			free = res-&gt;start - cxlrd-&gt;res-&gt;start;
&gt; +			max = max(free, max);
&gt; +		}
&gt; +		if (prev &amp;&amp; res-&gt;start &gt; prev-&gt;end + 1) {
&gt; +			free = res-&gt;start - prev-&gt;end + 1;
&gt; +			max = max(free, max);
&gt; +		}
&gt; +	}
&gt; +
&gt; +	if (prev &amp;&amp; prev-&gt;end + 1 &lt; cxlrd-&gt;res-&gt;end + 1) {
&gt; +		free = cxlrd-&gt;res-&gt;end + 1 - prev-&gt;end + 1;
&gt; +		max = max(free, max);
&gt; +	}
&gt; +
&gt; +	dev_dbg(cxlrd_dev(cxlrd), &quot;found %pa bytes of free space\n&quot;, &amp;max);
&gt; +	if (max &gt; ctx-&gt;max_hpa) {
&gt; +		if (ctx-&gt;cxlrd)
&gt; +			put_device(cxlrd_dev(ctx-&gt;cxlrd));
&gt; +		get_device(cxlrd_dev(cxlrd));
&gt; +		ctx-&gt;cxlrd = cxlrd;
&gt; +		ctx-&gt;max_hpa = max;
&gt; +	}
&gt; +	return 0;
&gt; +}
&gt; +
&gt; +/**
&gt; + * cxl_get_hpa_freespace - find a root decoder with free capacity per constraints
&gt; + * @cxlmd: the mem device requiring the HPA
&gt; + * @interleave_ways: number of entries in @host_bridges
&gt; + * @flags: CXL_DECODER_F flags for selecting RAM vs PMEM, and Type2 device
&gt; + * @max_avail_contig: output parameter of max contiguous bytes available in the
&gt; + *		      returned decoder
&gt; + *
&gt; + * Returns a pointer to a struct cxl_root_decoder
&gt; + *
&gt; + * The return tuple of a &#x27;struct cxl_root_decoder&#x27; and &#x27;bytes available given
&gt; + * in (@max_avail_contig))&#x27; is a point in time snapshot. If by the time the
&gt; + * caller goes to use this decoder and its capacity is reduced then caller needs
&gt; + * to loop and retry.
&gt; + *
&gt; + * The returned root decoder has an elevated reference count that needs to be
&gt; + * put with cxl_put_root_decoder(cxlrd).
&gt; + */
&gt; +struct cxl_root_decoder *cxl_get_hpa_freespace(struct cxl_memdev *cxlmd,
&gt; +					       int interleave_ways,
&gt; +					       unsigned long flags,
&gt; +					       resource_size_t *max_avail_contig)
&gt; +{
&gt; +	struct cxlrd_max_context ctx = {
&gt; +		.flags = flags,
&gt; +		.interleave_ways = interleave_ways,
&gt; +	};
&gt; +	struct cxl_port *root_port;
&gt; +	struct cxl_port *endpoint;
&gt; +
&gt; +	endpoint = cxlmd-&gt;endpoint;
&gt; +	if (!endpoint) {
&gt; +		dev_dbg(&amp;cxlmd-&gt;dev, &quot;endpoint not linked to memdev\n&quot;);
&gt; +		return ERR_PTR(-ENXIO);
&gt; +	}
&gt; +
&gt; +	ctx.host_bridges = &amp;endpoint-&gt;host_bridge;

Mentioned earlier, interleave_ways is effectively hardcoded to 1 (unless I&#x27;m misunderstanding
something). I think what you want here is to go to the CXL root and pass in the children (i.e. host bridges)?
I&#x27;m not sure of what the fix is to get the intended behavior.

It may be worth getting rid of the interleave_ways portion of this function and
add it later when someone needs it. You could also explain it&#x27;s hard coded to 1/unused
in the doc comment if you know of an immediate need for it.

&gt; +
&gt; +	struct cxl_root *root __free(put_cxl_root) = find_cxl_root(endpoint);
&gt; +	if (!root) {
&gt; +		dev_dbg(&amp;endpoint-&gt;dev, &quot;endpoint is not related to a root port\n&quot;);
&gt; +		return ERR_PTR(-ENXIO);
&gt; +	}
&gt; +
&gt; +	root_port = &amp;root-&gt;port;
&gt; +	scoped_guard(rwsem_read, &amp;cxl_rwsem.region)
&gt; +		device_for_each_child(&amp;root_port-&gt;dev, &amp;ctx, find_max_hpa);

Can just use a guard() here.

&gt; +
&gt; +	if (!ctx.cxlrd)
&gt; +		return ERR_PTR(-ENOMEM);
&gt; +
&gt; +	*max_avail_contig = ctx.max_hpa;
&gt; +	return ctx.cxlrd;
&gt; +}
&gt; +EXPORT_SYMBOL_NS_GPL(cxl_get_hpa_freespace, &quot;CXL&quot;);
&gt; +
&gt; +void cxl_put_root_decoder(struct cxl_root_decoder *cxlrd)
&gt; +{
&gt; +	put_device(cxlrd_dev(cxlrd));
&gt; +}
&gt; +EXPORT_SYMBOL_NS_GPL(cxl_put_root_decoder, &quot;CXL&quot;);
&gt; +
&gt;  static ssize_t size_store(struct device *dev, struct device_attribute *attr,
&gt;  			  const char *buf, size_t len)
&gt;  {
&gt; diff --git a/drivers/cxl/cxl.h b/drivers/cxl/cxl.h
&gt; index 944c5d1ccceb..c7d9b2c2908f 100644
&gt; --- a/drivers/cxl/cxl.h
&gt; +++ b/drivers/cxl/cxl.h
&gt; @@ -706,6 +706,9 @@ struct cxl_root_decoder *to_cxl_root_decoder(struct device *dev);
&gt;  struct cxl_switch_decoder *to_cxl_switch_decoder(struct device *dev);
&gt;  struct cxl_endpoint_decoder *to_cxl_endpoint_decoder(struct device *dev);
&gt;  bool is_root_decoder(struct device *dev);
&gt; +
&gt; +#define cxlrd_dev(cxlrd) (&amp;(cxlrd)-&gt;cxlsd.cxld.dev)
&gt; +
&gt;  bool is_switch_decoder(struct device *dev);
&gt;  bool is_endpoint_decoder(struct device *dev);
&gt;  struct cxl_root_decoder *cxl_root_decoder_alloc(struct cxl_port *port,
&gt; diff --git a/include/cxl/cxl.h b/include/cxl/cxl.h
&gt; index 92880c26b2d5..834dc7e78934 100644
&gt; --- a/include/cxl/cxl.h
&gt; +++ b/include/cxl/cxl.h
&gt; @@ -255,4 +255,10 @@ struct cxl_endpoint_decoder *cxl_get_committed_decoder(struct cxl_memdev *cxlmd,
&gt;  struct range;
&gt;  int cxl_get_region_range(struct cxl_region *region, struct range *range);
&gt;  void cxl_unregister_region(struct cxl_region *cxlr);
&gt; +struct cxl_port;
&gt; +struct cxl_root_decoder *cxl_get_hpa_freespace(struct cxl_memdev *cxlmd,
&gt; +					       int interleave_ways,
&gt; +					       unsigned long flags,
&gt; +					       resource_size_t *max);
&gt; +void cxl_put_root_decoder(struct cxl_root_decoder *cxlrd);
&gt;  #endif /* __CXL_CXL_H__ */



---

On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; Check if device HDM is already committed during firmware/BIOS
&gt; initialization.
&gt; 
&gt; A CXL region should exist if so after memdev allocation/initialization.
&gt; Get HPA from region and map it.
&gt; 
&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; ---
&gt;  drivers/net/ethernet/sfc/efx_cxl.c | 28 +++++++++++++++++++++++++++-
&gt;  1 file changed, 27 insertions(+), 1 deletion(-)
&gt; 
&gt; diff --git a/drivers/net/ethernet/sfc/efx_cxl.c b/drivers/net/ethernet/sfc/efx_cxl.c
&gt; index a77ef4783fcb..3536eccf1b2a 100644
&gt; --- a/drivers/net/ethernet/sfc/efx_cxl.c
&gt; +++ b/drivers/net/ethernet/sfc/efx_cxl.c
&gt; @@ -19,6 +19,7 @@ int efx_cxl_init(struct efx_probe_data *probe_data)
&gt;  	struct efx_nic *efx = &amp;probe_data-&gt;efx;
&gt;  	struct pci_dev *pci_dev = efx-&gt;pci_dev;
&gt;  	struct efx_cxl *cxl;
&gt; +	struct range range;
&gt;  	u16 dvsec;
&gt;  	int rc;
&gt;  
&gt; @@ -90,13 +91,38 @@ int efx_cxl_init(struct efx_probe_data *probe_data)
&gt;  		return PTR_ERR(cxl-&gt;cxlmd);
&gt;  	}
&gt;  
&gt; -	probe_data-&gt;cxl = cxl;
&gt; +	cxl-&gt;cxled = cxl_get_committed_decoder(cxl-&gt;cxlmd, &amp;cxl-&gt;efx_region);
&gt; +	if (cxl-&gt;cxled) {
&gt; +		if (!cxl-&gt;efx_region) {
&gt; +			pci_err(pci_dev, &quot;CXL found committed decoder without a region&quot;);
&gt; +			return -ENODEV;
&gt; +		}
&gt; +		rc = cxl_get_region_range(cxl-&gt;efx_region, &amp;range);

Missing an empty line above.

&gt; +		if (rc) {
&gt; +			pci_err(pci_dev,
&gt; +				&quot;CXL getting regions params from a committed decoder failed&quot;);
&gt; +			return rc;
&gt; +		}
&gt; +
&gt; +		cxl-&gt;ctpio_cxl = ioremap(range.start, range.end - range.start + 1);

Maybe use range_len() instead for the second parameter?

&gt; +		if (!cxl-&gt;ctpio_cxl) {
&gt; +			pci_err(pci_dev, &quot;CXL ioremap region (%pra) failed&quot;, &amp;range);
&gt; +			return -ENOMEM;
&gt; +		}
&gt; +
&gt; +		probe_data-&gt;cxl = cxl;
&gt; +	}
&gt;  
&gt;  	return 0;
&gt;  }
&gt;  
&gt;  void efx_cxl_exit(struct efx_probe_data *probe_data)
&gt;  {
&gt; +	if (!probe_data-&gt;cxl)
&gt; +		return;
&gt; +
&gt; +	iounmap(probe_data-&gt;cxl-&gt;ctpio_cxl);
&gt; +	cxl_unregister_region(probe_data-&gt;cxl-&gt;efx_region);
&gt;  }
&gt;  
&gt;  MODULE_IMPORT_NS(&quot;CXL&quot;);



---

On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; Region creation involves finding available DPA (device-physical-address)
&gt; capacity to map into HPA (host-physical-address) space.
&gt; 
&gt; In order to support CXL Type2 devices, define an API, cxl_request_dpa(),
&gt; that tries to allocate the DPA memory the driver requires to operate.The
&gt; memory requested should not be bigger than the max available HPA obtained
&gt; previously with cxl_get_hpa_freespace().
&gt; 
&gt; Based on https://lore.kernel.org/linux-cxl/168592158743.1948938.7622563891193802610.stgit@dwillia2-xfh.jf.intel.com/
&gt; 
&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
&gt; Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
&gt; ---
&gt;  drivers/cxl/core/hdm.c | 84 ++++++++++++++++++++++++++++++++++++++++++
&gt;  drivers/cxl/cxl.h      |  1 +
&gt;  include/cxl/cxl.h      |  5 +++
&gt;  3 files changed, 90 insertions(+)
&gt; 
&gt; diff --git a/drivers/cxl/core/hdm.c b/drivers/cxl/core/hdm.c
&gt; index a172ce4e9b19..d60a697f12cc 100644
&gt; --- a/drivers/cxl/core/hdm.c
&gt; +++ b/drivers/cxl/core/hdm.c
&gt; @@ -3,6 +3,7 @@
&gt;  #include &lt;linux/seq_file.h&gt;
&gt;  #include &lt;linux/device.h&gt;
&gt;  #include &lt;linux/delay.h&gt;
&gt; +#include &lt;cxl/cxl.h&gt;
&gt;  
&gt;  #include &quot;cxlmem.h&quot;
&gt;  #include &quot;core.h&quot;
&gt; @@ -546,6 +547,12 @@ bool cxl_resource_contains_addr(const struct resource *res, const resource_size_
&gt;  	return resource_contains(res, &amp;_addr);
&gt;  }
&gt;  
&gt; +/**
&gt; + * cxl_dpa_free - release DPA (Device Physical Address)
&gt; + * @cxled: endpoint decoder linked to the DPA
&gt; + *
&gt; + * Returns 0 or error.
&gt; + */
&gt;  int cxl_dpa_free(struct cxl_endpoint_decoder *cxled)
&gt;  {
&gt;  	struct cxl_port *port = cxled_to_port(cxled);
&gt; @@ -572,6 +579,7 @@ int cxl_dpa_free(struct cxl_endpoint_decoder *cxled)
&gt;  	devm_cxl_dpa_release(cxled);
&gt;  	return 0;
&gt;  }
&gt; +EXPORT_SYMBOL_NS_GPL(cxl_dpa_free, &quot;CXL&quot;);
&gt;  
&gt;  int cxl_dpa_set_part(struct cxl_endpoint_decoder *cxled,
&gt;  		     enum cxl_partition_mode mode)
&gt; @@ -603,6 +611,82 @@ int cxl_dpa_set_part(struct cxl_endpoint_decoder *cxled,
&gt;  	return 0;
&gt;  }
&gt;  
&gt; +static int find_free_decoder(struct device *dev, const void *data)
&gt; +{
&gt; +	struct cxl_endpoint_decoder *cxled;
&gt; +	struct cxl_port *port;
&gt; +
&gt; +	if (!is_endpoint_decoder(dev))
&gt; +		return 0;
&gt; +
&gt; +	cxled = to_cxl_endpoint_decoder(dev);
&gt; +	port = cxled_to_port(cxled);
&gt; +
&gt; +	return cxled-&gt;cxld.id == (port-&gt;hdm_end + 1);
&gt; +}
&gt; +
&gt; +static struct cxl_endpoint_decoder *
&gt; +cxl_find_free_decoder(struct cxl_memdev *cxlmd)
&gt; +{
&gt; +	struct cxl_port *endpoint = cxlmd-&gt;endpoint;
&gt; +	struct device *dev;
&gt; +
&gt; +	guard(rwsem_read)(&amp;cxl_rwsem.dpa);
&gt; +	dev = device_find_child(&amp;endpoint-&gt;dev, NULL,
&gt; +				find_free_decoder);
&gt; +	if (!dev)
&gt; +		return NULL;
&gt; +
&gt; +	return to_cxl_endpoint_decoder(dev);
&gt; +}
&gt; +
&gt; +/**
&gt; + * cxl_request_dpa - search and reserve DPA given input constraints
&gt; + * @cxlmd: memdev with an endpoint port with available decoders
&gt; + * @mode: CXL partition mode (ram vs pmem)
&gt; + * @alloc: dpa size required
&gt; + *
&gt; + * Returns a pointer to a &#x27;struct cxl_endpoint_decoder&#x27; on success or
&gt; + * an errno encoded pointer on failure.
&gt; + *
&gt; + * Given that a region needs to allocate from limited HPA capacity it
&gt; + * may be the case that a device has more mappable DPA capacity than
&gt; + * available HPA. The expectation is that @alloc is a driver known
&gt; + * value based on the device capacity but which could not be fully
&gt; + * available due to HPA constraints.
&gt; + *
&gt; + * Returns a pinned cxl_decoder with at least @alloc bytes of capacity
&gt; + * reserved, or an error pointer. The caller is also expected to own the
&gt; + * lifetime of the memdev registration associated with the endpoint to
&gt; + * pin the decoder registered as well.
&gt; + */
&gt; +struct cxl_endpoint_decoder *cxl_request_dpa(struct cxl_memdev *cxlmd,
&gt; +					     enum cxl_partition_mode mode,
&gt; +					     resource_size_t alloc)
&gt; +{
&gt; +	int rc;
&gt; +
&gt; +	if (!IS_ALIGNED(alloc, SZ_256M))
&gt; +		return ERR_PTR(-EINVAL);
&gt; +
&gt; +	struct cxl_endpoint_decoder *cxled __free(put_cxled) =
&gt; +		cxl_find_free_decoder(cxlmd);
&gt; +
&gt; +	if (!cxled)
&gt; +		return ERR_PTR(-ENODEV);
&gt; +
&gt; +	rc = cxl_dpa_set_part(cxled, mode);
&gt; +	if (rc)
&gt; +		return ERR_PTR(rc);
&gt; +
&gt; +	rc = cxl_dpa_alloc(cxled, alloc);
&gt; +	if (rc)
&gt; +		return ERR_PTR(rc);

Should cxl_dpa_set_part() be unwound here, or does it not matter? If it doesn&#x27;t matter:
Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
&gt; +
&gt; +	return no_free_ptr(cxled);
&gt; +}
&gt; +EXPORT_SYMBOL_NS_GPL(cxl_request_dpa, &quot;CXL&quot;);
&gt; +
&gt;  static int __cxl_dpa_alloc(struct cxl_endpoint_decoder *cxled, u64 size)
&gt;  {
&gt;  	struct cxl_memdev *cxlmd = cxled_to_memdev(cxled);
&gt; diff --git a/drivers/cxl/cxl.h b/drivers/cxl/cxl.h
&gt; index d1b010e5e1d0..2b1f7d687a0e 100644
&gt; --- a/drivers/cxl/cxl.h
&gt; +++ b/drivers/cxl/cxl.h
&gt; @@ -667,6 +667,7 @@ struct cxl_root *find_cxl_root(struct cxl_port *port);
&gt;  
&gt;  DEFINE_FREE(put_cxl_root, struct cxl_root *, if (_T) put_device(&amp;_T-&gt;port.dev))
&gt;  DEFINE_FREE(put_cxl_port, struct cxl_port *, if (!IS_ERR_OR_NULL(_T)) put_device(&amp;_T-&gt;dev))
&gt; +DEFINE_FREE(put_cxled, struct cxl_endpoint_decoder *, if (!IS_ERR_OR_NULL(_T)) put_device(&amp;_T-&gt;cxld.dev))
&gt;  DEFINE_FREE(put_cxl_root_decoder, struct cxl_root_decoder *, if (!IS_ERR_OR_NULL(_T)) put_device(&amp;_T-&gt;cxlsd.cxld.dev))
&gt;  DEFINE_FREE(put_cxl_region, struct cxl_region *, if (!IS_ERR_OR_NULL(_T)) put_device(&amp;_T-&gt;dev))
&gt;  
&gt; diff --git a/include/cxl/cxl.h b/include/cxl/cxl.h
&gt; index 783ad570a6eb..4802371db00e 100644
&gt; --- a/include/cxl/cxl.h
&gt; +++ b/include/cxl/cxl.h
&gt; @@ -7,6 +7,7 @@
&gt;  
&gt;  #include &lt;linux/node.h&gt;
&gt;  #include &lt;linux/ioport.h&gt;
&gt; +#include &lt;linux/range.h&gt;
&gt;  #include &lt;cxl/mailbox.h&gt;
&gt;  
&gt;  /**
&gt; @@ -276,4 +277,8 @@ struct cxl_root_decoder *cxl_get_hpa_freespace(struct cxl_memdev *cxlmd,
&gt;  					       unsigned long flags,
&gt;  					       resource_size_t *max);
&gt;  void cxl_put_root_decoder(struct cxl_root_decoder *cxlrd);
&gt; +struct cxl_endpoint_decoder *cxl_request_dpa(struct cxl_memdev *cxlmd,
&gt; +					     enum cxl_partition_mode mode,
&gt; +					     resource_size_t alloc);
&gt; +int cxl_dpa_free(struct cxl_endpoint_decoder *cxled);
&gt;  #endif /* __CXL_CXL_H__ */



---

On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; Current code is expecting Type3 or CXL_DECODER_HOSTONLYMEM devices only.
&gt; Support for Type2 implies region type needs to be based on the endpoint
&gt; type HDM-D[B] instead.
&gt; 
&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; Reviewed-by: Zhi Wang &lt;zhiw@nvidia.com&gt;
&gt; Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
&gt; Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
&gt; Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
&gt; Reviewed-by: Alison Schofield &lt;alison.schofield@intel.com&gt;
&gt; Reviewed-by: Davidlohr Bueso &lt;daves@stgolabs.net&gt;
&gt; ---
&gt;  drivers/cxl/core/region.c | 10 ++++++----
&gt;  1 file changed, 6 insertions(+), 4 deletions(-)
&gt; 
&gt; diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
&gt; index bdefd088f5f1..f53b2e9fd9e6 100644
&gt; --- a/drivers/cxl/core/region.c
&gt; +++ b/drivers/cxl/core/region.c
&gt; @@ -2833,7 +2833,8 @@ static ssize_t create_ram_region_show(struct device *dev,
&gt;  }
&gt;  
&gt;  static struct cxl_region *__create_region(struct cxl_root_decoder *cxlrd,
&gt; -					  enum cxl_partition_mode mode, int id)
&gt; +					  enum cxl_partition_mode mode, int id,
&gt; +					  enum cxl_decoder_type target_type)
&gt;  {
&gt;  	int rc;
&gt;  
&gt; @@ -2855,7 +2856,7 @@ static struct cxl_region *__create_region(struct cxl_root_decoder *cxlrd,
&gt;  		return ERR_PTR(-EBUSY);
&gt;  	}
&gt;  
&gt; -	return devm_cxl_add_region(cxlrd, id, mode, CXL_DECODER_HOSTONLYMEM);
&gt; +	return devm_cxl_add_region(cxlrd, id, mode, target_type);
&gt;  }
&gt;  
&gt;  static ssize_t create_region_store(struct device *dev, const char *buf,
&gt; @@ -2869,7 +2870,7 @@ static ssize_t create_region_store(struct device *dev, const char *buf,
&gt;  	if (rc != 1)
&gt;  		return -EINVAL;
&gt;  
&gt; -	cxlr = __create_region(cxlrd, mode, id);
&gt; +	cxlr = __create_region(cxlrd, mode, id, CXL_DECODER_HOSTONLYMEM);

I haven&#x27;t read the ABI docs, but would it be worthwhile to update the documentation for this attribute
to mention it only makes type 3 regions? I&#x27;m flip-flopping on whether it&#x27;s worth the trouble but thought
I should mention it.

Either way:
Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;

&gt;  	if (IS_ERR(cxlr))
&gt;  		return PTR_ERR(cxlr);
&gt;  
&gt; @@ -4036,7 +4037,8 @@ static struct cxl_region *construct_region(struct cxl_root_decoder *cxlrd,
&gt;  
&gt;  	do {
&gt;  		cxlr = __create_region(cxlrd, cxlds-&gt;part[part].mode,
&gt; -				       atomic_read(&amp;cxlrd-&gt;region_id));
&gt; +				       atomic_read(&amp;cxlrd-&gt;region_id),
&gt; +				       cxled-&gt;cxld.target_type);
&gt;  	} while (IS_ERR(cxlr) &amp;&amp; PTR_ERR(cxlr) == -EBUSY);
&gt;  
&gt;  	if (IS_ERR(cxlr)) {



---

On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; Region creation based on Type3 devices is triggered from user space
&gt; allowing memory combination through interleaving.
&gt; 
&gt; In preparation for kernel driven region creation, that is Type2 drivers
&gt; triggering region creation backed with its advertised CXL memory, factor
&gt; out a common helper from the user-sysfs region setup for interleave ways.
&gt; 
&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; Reviewed-by: Zhi Wang &lt;zhiw@nvidia.com&gt;
&gt; Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
&gt; Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
&gt; Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
&gt; Reviewed-by: Alison Schofield &lt;alison.schofield@intel.com&gt;
&gt; ---
&gt;  drivers/cxl/core/region.c | 43 ++++++++++++++++++++++++---------------
&gt;  1 file changed, 27 insertions(+), 16 deletions(-)
&gt; 
&gt; diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
&gt; index f53b2e9fd9e6..ece1d3df7cf1 100644
&gt; --- a/drivers/cxl/core/region.c
&gt; +++ b/drivers/cxl/core/region.c
&gt; @@ -485,22 +485,14 @@ static ssize_t interleave_ways_show(struct device *dev,
&gt;  
&gt;  static const struct attribute_group *get_cxl_region_target_group(void);
&gt;  
&gt; -static ssize_t interleave_ways_store(struct device *dev,
&gt; -				     struct device_attribute *attr,
&gt; -				     const char *buf, size_t len)
&gt; +static int set_interleave_ways(struct cxl_region *cxlr, int val)

@val should probably stay an unsigned int. You pass an unsigned int in the sysfs function, and the
function was originally coded with that in mind (same with @save below). With that cleaned up:
Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;

&gt;  {
&gt; -	struct cxl_root_decoder *cxlrd = to_cxl_root_decoder(dev-&gt;parent);
&gt; +	struct cxl_root_decoder *cxlrd = to_cxl_root_decoder(cxlr-&gt;dev.parent);
&gt;  	struct cxl_decoder *cxld = &amp;cxlrd-&gt;cxlsd.cxld;
&gt; -	struct cxl_region *cxlr = to_cxl_region(dev);
&gt;  	struct cxl_region_params *p = &amp;cxlr-&gt;params;
&gt; -	unsigned int val, save;
&gt; -	int rc;
&gt; +	int save, rc;
&gt;  	u8 iw;
&gt;  
&gt; -	rc = kstrtouint(buf, 0, &amp;val);
&gt; -	if (rc)
&gt; -		return rc;
&gt; -
&gt;  	rc = ways_to_eiw(val, &amp;iw);
&gt;  	if (rc)
&gt;  		return rc;
&gt; @@ -515,9 +507,7 @@ static ssize_t interleave_ways_store(struct device *dev,
&gt;  		return -EINVAL;
&gt;  	}
&gt;  
&gt; -	ACQUIRE(rwsem_write_kill, rwsem)(&amp;cxl_rwsem.region);
&gt; -	if ((rc = ACQUIRE_ERR(rwsem_write_kill, &amp;rwsem)))
&gt; -		return rc;
&gt; +	lockdep_assert_held_write(&amp;cxl_rwsem.region);
&gt;  
&gt;  	if (p-&gt;state &gt;= CXL_CONFIG_INTERLEAVE_ACTIVE)
&gt;  		return -EBUSY;
&gt; @@ -525,10 +515,31 @@ static ssize_t interleave_ways_store(struct device *dev,
&gt;  	save = p-&gt;interleave_ways;
&gt;  	p-&gt;interleave_ways = val;
&gt;  	rc = sysfs_update_group(&amp;cxlr-&gt;dev.kobj, get_cxl_region_target_group());
&gt; -	if (rc) {
&gt; +	if (rc)
&gt;  		p-&gt;interleave_ways = save;
&gt; +
&gt; +	return rc;
&gt; +}
&gt; +
&gt; +static ssize_t interleave_ways_store(struct device *dev,
&gt; +				     struct device_attribute *attr,
&gt; +				     const char *buf, size_t len)
&gt; +{
&gt; +	struct cxl_region *cxlr = to_cxl_region(dev);
&gt; +	unsigned int val;
&gt; +	int rc;
&gt; +
&gt; +	rc = kstrtouint(buf, 0, &amp;val);
&gt; +	if (rc)
&gt; +		return rc;
&gt; +
&gt; +	ACQUIRE(rwsem_write_kill, rwsem)(&amp;cxl_rwsem.region);
&gt; +	if ((rc = ACQUIRE_ERR(rwsem_write_kill, &amp;rwsem)))
&gt; +		return rc;
&gt; +
&gt; +	rc = set_interleave_ways(cxlr, val);
&gt; +	if (rc)
&gt;  		return rc;
&gt; -	}
&gt;  
&gt;  	return len;
&gt;  }



---

On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; Region creation based on Type3 devices is triggered from user space
&gt; allowing memory combination through interleaving.
&gt; 
&gt; In preparation for kernel driven region creation, that is Type2 drivers
&gt; triggering region creation backed with its advertised CXL memory, factor
&gt; out a common helper from the user-sysfs region setup forinterleave
&gt; granularity.
&gt; 
&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; Reviewed-by: Zhi Wang &lt;zhiw@nvidia.com&gt;
&gt; Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
&gt; Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
&gt; Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
&gt; Reviewed-by: Alison Schofield &lt;alison.schofield@intel.com&gt;
&gt; ---
&gt;  drivers/cxl/core/region.c | 39 +++++++++++++++++++++++++--------------
&gt;  1 file changed, 25 insertions(+), 14 deletions(-)
&gt; 
&gt; diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
&gt; index ece1d3df7cf1..63c2aeb2ee1f 100644
&gt; --- a/drivers/cxl/core/region.c
&gt; +++ b/drivers/cxl/core/region.c
&gt; @@ -559,21 +559,14 @@ static ssize_t interleave_granularity_show(struct device *dev,
&gt;  	return sysfs_emit(buf, &quot;%d\n&quot;, p-&gt;interleave_granularity);
&gt;  }
&gt;  
&gt; -static ssize_t interleave_granularity_store(struct device *dev,
&gt; -					    struct device_attribute *attr,
&gt; -					    const char *buf, size_t len)
&gt; +static int set_interleave_granularity(struct cxl_region *cxlr, int val)

Same thing as last patch. Assuming it&#x27;s fixed:
Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
&gt;  {
&gt; -	struct cxl_root_decoder *cxlrd = to_cxl_root_decoder(dev-&gt;parent);
&gt; +	struct cxl_root_decoder *cxlrd = to_cxl_root_decoder(cxlr-&gt;dev.parent);
&gt;  	struct cxl_decoder *cxld = &amp;cxlrd-&gt;cxlsd.cxld;
&gt; -	struct cxl_region *cxlr = to_cxl_region(dev);
&gt;  	struct cxl_region_params *p = &amp;cxlr-&gt;params;
&gt; -	int rc, val;
&gt; +	int rc;
&gt;  	u16 ig;
&gt;  
&gt; -	rc = kstrtoint(buf, 0, &amp;val);
&gt; -	if (rc)
&gt; -		return rc;
&gt; -
&gt;  	rc = granularity_to_eig(val, &amp;ig);
&gt;  	if (rc)
&gt;  		return rc;
&gt; @@ -589,14 +582,32 @@ static ssize_t interleave_granularity_store(struct device *dev,
&gt;  	if (cxld-&gt;interleave_ways &gt; 1 &amp;&amp; val != cxld-&gt;interleave_granularity)
&gt;  		return -EINVAL;
&gt;  
&gt; -	ACQUIRE(rwsem_write_kill, rwsem)(&amp;cxl_rwsem.region);
&gt; -	if ((rc = ACQUIRE_ERR(rwsem_write_kill, &amp;rwsem)))
&gt; -		return rc;
&gt; -
&gt; +	lockdep_assert_held_write(&amp;cxl_rwsem.region);
&gt;  	if (p-&gt;state &gt;= CXL_CONFIG_INTERLEAVE_ACTIVE)
&gt;  		return -EBUSY;
&gt;  
&gt;  	p-&gt;interleave_granularity = val;
&gt; +	return 0;
&gt; +}
&gt; +
&gt; +static ssize_t interleave_granularity_store(struct device *dev,
&gt; +					    struct device_attribute *attr,
&gt; +					    const char *buf, size_t len)
&gt; +{
&gt; +	struct cxl_region *cxlr = to_cxl_region(dev);
&gt; +	int rc, val;
&gt; +
&gt; +	rc = kstrtoint(buf, 0, &amp;val);
&gt; +	if (rc)
&gt; +		return rc;
&gt; +
&gt; +	ACQUIRE(rwsem_write_kill, rwsem)(&amp;cxl_rwsem.region);
&gt; +	if ((rc = ACQUIRE_ERR(rwsem_write_kill, &amp;rwsem)))
&gt; +		return rc;
&gt; +
&gt; +	rc = set_interleave_granularity(cxlr, val);
&gt; +	if (rc)
&gt; +		return rc;
&gt;  
&gt;  	return len;
&gt;  }



---

On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; Creating a CXL region requires userspace intervention through the cxl
&gt; sysfs files. Type2 support should allow accelerator drivers to create
&gt; such cxl region from kernel code.
&gt; 
&gt; Adding that functionality and integrating it with current support for
&gt; memory expanders.
&gt; 
&gt; Based on https://lore.kernel.org/linux-cxl/168592159835.1948938.1647215579839222774.stgit@dwillia2-xfh.jf.intel.com/
&gt; 
&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
&gt; Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
&gt; ---
&gt;  drivers/cxl/core/region.c | 131 ++++++++++++++++++++++++++++++++++++--
&gt;  include/cxl/cxl.h         |   3 +
&gt;  2 files changed, 127 insertions(+), 7 deletions(-)
&gt; 
&gt; diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
&gt; index 63c2aeb2ee1f..293e63dfef22 100644
&gt; --- a/drivers/cxl/core/region.c
&gt; +++ b/drivers/cxl/core/region.c
&gt; @@ -2944,6 +2944,14 @@ cxl_find_region_by_name(struct cxl_root_decoder *cxlrd, const char *name)
&gt;  	return to_cxl_region(region_dev);
&gt;  }
&gt;  
&gt; +static void drop_region(struct cxl_region *cxlr)
&gt; +{
&gt; +	struct cxl_root_decoder *cxlrd = to_cxl_root_decoder(cxlr-&gt;dev.parent);
&gt; +	struct cxl_port *port = cxlrd_to_port(cxlrd);
&gt; +
&gt; +	devm_release_action(port-&gt;uport_dev, __unregister_region, cxlr);
&gt; +}
&gt; +
&gt;  static ssize_t delete_region_store(struct device *dev,
&gt;  				   struct device_attribute *attr,
&gt;  				   const char *buf, size_t len)
&gt; @@ -4047,14 +4055,12 @@ static int __construct_region(struct cxl_region *cxlr,
&gt;  	return 0;
&gt;  }
&gt;  
&gt; -/* Establish an empty region covering the given HPA range */
&gt; -static struct cxl_region *construct_region(struct cxl_root_decoder *cxlrd,
&gt; -					   struct cxl_endpoint_decoder *cxled)
&gt; +static struct cxl_region *construct_region_begin(struct cxl_root_decoder *cxlrd,
&gt; +						 struct cxl_endpoint_decoder *cxled)
&gt;  {
&gt;  	struct cxl_memdev *cxlmd = cxled_to_memdev(cxled);
&gt; -	struct cxl_port *port = cxlrd_to_port(cxlrd);
&gt;  	struct cxl_dev_state *cxlds = cxlmd-&gt;cxlds;
&gt; -	int rc, part = READ_ONCE(cxled-&gt;part);
&gt; +	int part = READ_ONCE(cxled-&gt;part);
&gt;  	struct cxl_region *cxlr;
&gt;  
&gt;  	do {
&gt; @@ -4063,13 +4069,26 @@ static struct cxl_region *construct_region(struct cxl_root_decoder *cxlrd,
&gt;  				       cxled-&gt;cxld.target_type);
&gt;  	} while (IS_ERR(cxlr) &amp;&amp; PTR_ERR(cxlr) == -EBUSY);
&gt;  
&gt; -	if (IS_ERR(cxlr)) {
&gt; +	if (IS_ERR(cxlr))
&gt;  		dev_err(cxlmd-&gt;dev.parent,
&gt;  			&quot;%s:%s: %s failed assign region: %ld\n&quot;,
&gt;  			dev_name(&amp;cxlmd-&gt;dev), dev_name(&amp;cxled-&gt;cxld.dev),
&gt;  			__func__, PTR_ERR(cxlr));
&gt; +
&gt; +	return cxlr;
&gt; +}
&gt; +
&gt; +/* Establish an empty region covering the given HPA range */
&gt; +static struct cxl_region *construct_region(struct cxl_root_decoder *cxlrd,
&gt; +					   struct cxl_endpoint_decoder *cxled)
&gt; +{
&gt; +	struct cxl_port *port = cxlrd_to_port(cxlrd);
&gt; +	struct cxl_region *cxlr;
&gt; +	int rc;
&gt; +
&gt; +	cxlr = construct_region_begin(cxlrd, cxled);
&gt; +	if (IS_ERR(cxlr))
&gt;  		return cxlr;
&gt; -	}
&gt;  
&gt;  	rc = __construct_region(cxlr, cxlrd, cxled);
&gt;  	if (rc) {
&gt; @@ -4080,6 +4099,104 @@ static struct cxl_region *construct_region(struct cxl_root_decoder *cxlrd,
&gt;  	return cxlr;
&gt;  }
&gt;  
&gt; +DEFINE_FREE(cxl_region_drop, struct cxl_region *, if (_T) drop_region(_T))

This needs to be &quot;if (!IS_ERR_OR_NULL(_T) drop_region(_T)&quot;. If construct_region_begin() returns an
error pointer, drop_region() will be called with it as of now leading to a garbage pointer deref.

&gt; +
&gt; +static struct cxl_region *
&gt; +__construct_new_region(struct cxl_root_decoder *cxlrd,
&gt; +		       struct cxl_endpoint_decoder **cxled, int ways)
&gt; +{
&gt; +	struct cxl_memdev *cxlmd = cxled_to_memdev(cxled[0]);
&gt; +	struct cxl_decoder *cxld = &amp;cxlrd-&gt;cxlsd.cxld;
&gt; +	struct cxl_region_params *p;
&gt; +	resource_size_t size = 0;
&gt; +	int rc, i;
&gt; +
&gt; +	struct cxl_region *cxlr __free(cxl_region_drop) =
&gt; +		construct_region_begin(cxlrd, cxled[0]);
&gt; +	if (IS_ERR(cxlr))
&gt; +		return cxlr;
&gt; +
&gt; +	guard(rwsem_write)(&amp;cxl_rwsem.region);
&gt; +
&gt; +	/*
&gt; +	 * Sanity check. This should not happen with an accel driver handling
&gt; +	 * the region creation.
&gt; +	 */
&gt; +	p = &amp;cxlr-&gt;params;
&gt; +	if (p-&gt;state &gt;= CXL_CONFIG_INTERLEAVE_ACTIVE) {
&gt; +		dev_err(cxlmd-&gt;dev.parent,
&gt; +			&quot;%s:%s: %s  unexpected region state\n&quot;,
&gt; +			dev_name(&amp;cxlmd-&gt;dev), dev_name(&amp;cxled[0]-&gt;cxld.dev),
&gt; +			__func__);
&gt; +		return ERR_PTR(-EBUSY);
&gt; +	}
&gt; +
&gt; +	rc = set_interleave_ways(cxlr, ways);
&gt; +	if (rc)
&gt; +		return ERR_PTR(rc);
&gt; +
&gt; +	rc = set_interleave_granularity(cxlr, cxld-&gt;interleave_granularity);
&gt; +	if (rc)
&gt; +		return ERR_PTR(rc);
&gt; +
&gt; +	scoped_guard(rwsem_read, &amp;cxl_rwsem.dpa) {
&gt; +		for (i = 0; i &lt; ways; i++) {
&gt; +			if (!cxled[i]-&gt;dpa_res)
&gt; +				return ERR_PTR(-EINVAL);
&gt; +			size += resource_size(cxled[i]-&gt;dpa_res);
&gt; +		}
&gt; +
&gt; +		rc = alloc_hpa(cxlr, size);
&gt; +		if (rc)
&gt; +			return ERR_PTR(rc);
&gt; +
&gt; +		for (i = 0; i &lt; ways; i++) {
&gt; +			rc = cxl_region_attach(cxlr, cxled[i], 0);

Position parameter is hardcoded to 0. It should be set to i, right? This kind of goes back to my
issues in patch 12/22; the interleaving functionality is there but it looks unused.

&gt; +			if (rc)
&gt; +				return ERR_PTR(rc);
&gt; +		}
&gt; +	}
&gt; +
&gt; +	rc = cxl_region_decode_commit(cxlr);
&gt; +	if (rc)
&gt; +		return ERR_PTR(rc);
&gt; +
&gt; +	p-&gt;state = CXL_CONFIG_COMMIT;
&gt; +
&gt; +	return no_free_ptr(cxlr);
&gt; +}
&gt; +
&gt; +/**
&gt; + * cxl_create_region - Establish a region given an endpoint decoder
&gt; + * @cxlrd: root decoder to allocate HPA
&gt; + * @cxled: endpoint decoders with reserved DPA capacity
&gt; + * @ways: interleave ways required
&gt; + *
&gt; + * Returns a fully formed region in the commit state and attached to the
&gt; + * cxl_region driver.
&gt; + */
&gt; +struct cxl_region *cxl_create_region(struct cxl_root_decoder *cxlrd,
&gt; +				     struct cxl_endpoint_decoder **cxled,
&gt; +				     int ways)
&gt; +{
&gt; +	struct cxl_region *cxlr;
&gt; +
&gt; +	mutex_lock(&amp;cxlrd-&gt;range_lock);
&gt; +	cxlr = __construct_new_region(cxlrd, cxled, ways);
&gt; +	mutex_unlock(&amp;cxlrd-&gt;range_lock);
&gt; +	if (IS_ERR(cxlr))
&gt; +		return cxlr;
&gt; +
&gt; +	if (device_attach(&amp;cxlr-&gt;dev) &lt;= 0) {
&gt; +		dev_err(&amp;cxlr-&gt;dev, &quot;failed to create region\n&quot;);
&gt; +		drop_region(cxlr);
&gt; +		return ERR_PTR(-ENODEV);
&gt; +	}
&gt; +
&gt; +	return cxlr;
&gt; +}
&gt; +EXPORT_SYMBOL_NS_GPL(cxl_create_region, &quot;CXL&quot;);
&gt; +
&gt;  static struct cxl_region *
&gt;  cxl_find_region_by_range(struct cxl_root_decoder *cxlrd, struct range *hpa)
&gt;  {
&gt; diff --git a/include/cxl/cxl.h b/include/cxl/cxl.h
&gt; index 4802371db00e..50acbd13bcf8 100644
&gt; --- a/include/cxl/cxl.h
&gt; +++ b/include/cxl/cxl.h
&gt; @@ -281,4 +281,7 @@ struct cxl_endpoint_decoder *cxl_request_dpa(struct cxl_memdev *cxlmd,
&gt;  					     enum cxl_partition_mode mode,
&gt;  					     resource_size_t alloc);
&gt;  int cxl_dpa_free(struct cxl_endpoint_decoder *cxled);
&gt; +struct cxl_region *cxl_create_region(struct cxl_root_decoder *cxlrd,
&gt; +				     struct cxl_endpoint_decoder **cxled,
&gt; +				     int ways);
&gt;  #endif /* __CXL_CXL_H__ */



---

On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; Differentiate CXL memory expanders (type 3) from CXL device accelerators
&gt; (type 2) with a new function for initializing cxl_dev_state and a macro
&gt; for helping accel drivers to embed cxl_dev_state inside a private
&gt; struct.
&gt; 
&gt; Move structs to include/cxl as the size of the accel driver private
&gt; struct embedding cxl_dev_state needs to know the size of this struct.
&gt; 
&gt; Use same new initialization with the type3 pci driver.
&gt; 
&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
&gt; Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
&gt; Reviewed-by: Alison Schofield &lt;alison.schofield@intel.com&gt;
&gt; Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
&gt; ---
&gt;  drivers/cxl/core/mbox.c      |  12 +-
&gt;  drivers/cxl/core/memdev.c    |  32 +++++
&gt;  drivers/cxl/cxl.h            |  97 +--------------
&gt;  drivers/cxl/cxlmem.h         |  86 +------------
&gt;  drivers/cxl/pci.c            |  14 +--
&gt;  include/cxl/cxl.h            | 226 +++++++++++++++++++++++++++++++++++
&gt;  tools/testing/cxl/test/mem.c |   3 +-
&gt;  7 files changed, 274 insertions(+), 196 deletions(-)
&gt;  create mode 100644 include/cxl/cxl.h
&gt; 
&gt; diff --git a/drivers/cxl/core/mbox.c b/drivers/cxl/core/mbox.c
&gt; index fa6dd0c94656..bee84d0101d1 100644
&gt; --- a/drivers/cxl/core/mbox.c
&gt; +++ b/drivers/cxl/core/mbox.c
&gt; @@ -1514,23 +1514,21 @@ int cxl_mailbox_init(struct cxl_mailbox *cxl_mbox, struct device *host)
&gt;  }
&gt;  EXPORT_SYMBOL_NS_GPL(cxl_mailbox_init, &quot;CXL&quot;);
&gt;  
&gt; -struct cxl_memdev_state *cxl_memdev_state_create(struct device *dev)
&gt; +struct cxl_memdev_state *cxl_memdev_state_create(struct device *dev, u64 serial,
&gt; +						 u16 dvsec)
&gt;  {
&gt;  	struct cxl_memdev_state *mds;
&gt;  	int rc;
&gt;  
&gt; -	mds = devm_kzalloc(dev, sizeof(*mds), GFP_KERNEL);
&gt; +	mds = devm_cxl_dev_state_create(dev, CXL_DEVTYPE_CLASSMEM, serial,
&gt; +					dvsec, struct cxl_memdev_state, cxlds,
&gt; +					true);
&gt;  	if (!mds) {
&gt;  		dev_err(dev, &quot;No memory available\n&quot;);
&gt;  		return ERR_PTR(-ENOMEM);
&gt;  	}
&gt;  
&gt;  	mutex_init(&amp;mds-&gt;event.log_lock);
&gt; -	mds-&gt;cxlds.dev = dev;
&gt; -	mds-&gt;cxlds.reg_map.host = dev;
&gt; -	mds-&gt;cxlds.cxl_mbox.host = dev;
&gt; -	mds-&gt;cxlds.reg_map.resource = CXL_RESOURCE_NONE;
&gt; -	mds-&gt;cxlds.type = CXL_DEVTYPE_CLASSMEM;
&gt;  
&gt;  	rc = devm_cxl_register_mce_notifier(dev, &amp;mds-&gt;mce_notifier);
&gt;  	if (rc == -EOPNOTSUPP)
&gt; diff --git a/drivers/cxl/core/memdev.c b/drivers/cxl/core/memdev.c
&gt; index af3d0cc65138..22d156f25305 100644
&gt; --- a/drivers/cxl/core/memdev.c
&gt; +++ b/drivers/cxl/core/memdev.c
&gt; @@ -656,6 +656,38 @@ static void detach_memdev(struct work_struct *work)
&gt;  
&gt;  static struct lock_class_key cxl_memdev_key;
&gt;  
&gt; +static void cxl_dev_state_init(struct cxl_dev_state *cxlds, struct device *dev,
&gt; +			       enum cxl_devtype type, u64 serial, u16 dvsec,
&gt; +			       bool has_mbox)
&gt; +{
&gt; +	*cxlds = (struct cxl_dev_state) {
&gt; +		.dev = dev,
&gt; +		.type = type,
&gt; +		.serial = serial,
&gt; +		.cxl_dvsec = dvsec,
&gt; +		.reg_map.host = dev,
&gt; +		.reg_map.resource = CXL_RESOURCE_NONE,
&gt; +	};
&gt; +
&gt; +	if (has_mbox)
&gt; +		cxlds-&gt;cxl_mbox.host = dev;
&gt; +}
&gt; +
&gt; +struct cxl_dev_state *_devm_cxl_dev_state_create(struct device *dev,
&gt; +						 enum cxl_devtype type,
&gt; +						 u64 serial, u16 dvsec,
&gt; +						 size_t size, bool has_mbox)
&gt; +{
&gt; +	struct cxl_dev_state *cxlds = devm_kzalloc(dev, size, GFP_KERNEL);
&gt; +
&gt; +	if (!cxlds)
&gt; +		return NULL;
&gt; +
&gt; +	cxl_dev_state_init(cxlds, dev, type, serial, dvsec, has_mbox);

Nit: Having a second function to do the init seems overkill here, especially since cxl_dev_state_init() isn&#x27;t called outside this
function. I&#x27;d fold it into this function instead, but I&#x27;m fine with it either way (especially if you were told otherwise before).

Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
&gt; +	return cxlds;
&gt; +}
&gt; +EXPORT_SYMBOL_NS_GPL(_devm_cxl_dev_state_create, &quot;CXL&quot;);
&gt; +
&gt;  static struct cxl_memdev *cxl_memdev_alloc(struct cxl_dev_state *cxlds,
&gt;  					   const struct file_operations *fops,
&gt;  					   const struct cxl_memdev_attach *attach)
&gt; diff --git a/drivers/cxl/cxl.h b/drivers/cxl/cxl.h
&gt; index e1d47062e1d3..3eaa353e430b 100644
&gt; --- a/drivers/cxl/cxl.h
&gt; +++ b/drivers/cxl/cxl.h
&gt; @@ -12,6 +12,7 @@
&gt;  #include &lt;linux/node.h&gt;
&gt;  #include &lt;linux/io.h&gt;
&gt;  #include &lt;linux/range.h&gt;
&gt; +#include &lt;cxl/cxl.h&gt;
&gt;  
&gt;  extern const struct nvdimm_security_ops *cxl_security_ops;
&gt;  
&gt; @@ -201,97 +202,6 @@ static inline int ways_to_eiw(unsigned int ways, u8 *eiw)
&gt;  #define   CXLDEV_MBOX_BG_CMD_COMMAND_VENDOR_MASK GENMASK_ULL(63, 48)
&gt;  #define CXLDEV_MBOX_PAYLOAD_OFFSET 0x20
&gt;  
&gt; -/*
&gt; - * Using struct_group() allows for per register-block-type helper routines,
&gt; - * without requiring block-type agnostic code to include the prefix.
&gt; - */
&gt; -struct cxl_regs {
&gt; -	/*
&gt; -	 * Common set of CXL Component register block base pointers
&gt; -	 * @hdm_decoder: CXL 2.0 8.2.5.12 CXL HDM Decoder Capability Structure
&gt; -	 * @ras: CXL 2.0 8.2.5.9 CXL RAS Capability Structure
&gt; -	 */
&gt; -	struct_group_tagged(cxl_component_regs, component,
&gt; -		void __iomem *hdm_decoder;
&gt; -		void __iomem *ras;
&gt; -	);
&gt; -	/*
&gt; -	 * Common set of CXL Device register block base pointers
&gt; -	 * @status: CXL 2.0 8.2.8.3 Device Status Registers
&gt; -	 * @mbox: CXL 2.0 8.2.8.4 Mailbox Registers
&gt; -	 * @memdev: CXL 2.0 8.2.8.5 Memory Device Registers
&gt; -	 */
&gt; -	struct_group_tagged(cxl_device_regs, device_regs,
&gt; -		void __iomem *status, *mbox, *memdev;
&gt; -	);
&gt; -
&gt; -	struct_group_tagged(cxl_pmu_regs, pmu_regs,
&gt; -		void __iomem *pmu;
&gt; -	);
&gt; -
&gt; -	/*
&gt; -	 * RCH downstream port specific RAS register
&gt; -	 * @aer: CXL 3.0 8.2.1.1 RCH Downstream Port RCRB
&gt; -	 */
&gt; -	struct_group_tagged(cxl_rch_regs, rch_regs,
&gt; -		void __iomem *dport_aer;
&gt; -	);
&gt; -
&gt; -	/*
&gt; -	 * RCD upstream port specific PCIe cap register
&gt; -	 * @pcie_cap: CXL 3.0 8.2.1.2 RCD Upstream Port RCRB
&gt; -	 */
&gt; -	struct_group_tagged(cxl_rcd_regs, rcd_regs,
&gt; -		void __iomem *rcd_pcie_cap;
&gt; -	);
&gt; -};
&gt; -
&gt; -struct cxl_reg_map {
&gt; -	bool valid;
&gt; -	int id;
&gt; -	unsigned long offset;
&gt; -	unsigned long size;
&gt; -};
&gt; -
&gt; -struct cxl_component_reg_map {
&gt; -	struct cxl_reg_map hdm_decoder;
&gt; -	struct cxl_reg_map ras;
&gt; -};
&gt; -
&gt; -struct cxl_device_reg_map {
&gt; -	struct cxl_reg_map status;
&gt; -	struct cxl_reg_map mbox;
&gt; -	struct cxl_reg_map memdev;
&gt; -};
&gt; -
&gt; -struct cxl_pmu_reg_map {
&gt; -	struct cxl_reg_map pmu;
&gt; -};
&gt; -
&gt; -/**
&gt; - * struct cxl_register_map - DVSEC harvested register block mapping parameters
&gt; - * @host: device for devm operations and logging
&gt; - * @base: virtual base of the register-block-BAR + @block_offset
&gt; - * @resource: physical resource base of the register block
&gt; - * @max_size: maximum mapping size to perform register search
&gt; - * @reg_type: see enum cxl_regloc_type
&gt; - * @component_map: cxl_reg_map for component registers
&gt; - * @device_map: cxl_reg_maps for device registers
&gt; - * @pmu_map: cxl_reg_maps for CXL Performance Monitoring Units
&gt; - */
&gt; -struct cxl_register_map {
&gt; -	struct device *host;
&gt; -	void __iomem *base;
&gt; -	resource_size_t resource;
&gt; -	resource_size_t max_size;
&gt; -	u8 reg_type;
&gt; -	union {
&gt; -		struct cxl_component_reg_map component_map;
&gt; -		struct cxl_device_reg_map device_map;
&gt; -		struct cxl_pmu_reg_map pmu_map;
&gt; -	};
&gt; -};
&gt; -
&gt;  void cxl_probe_component_regs(struct device *dev, void __iomem *base,
&gt;  			      struct cxl_component_reg_map *map);
&gt;  void cxl_probe_device_regs(struct device *dev, void __iomem *base,
&gt; @@ -497,11 +407,6 @@ struct cxl_region_params {
&gt;  	resource_size_t cache_size;
&gt;  };
&gt;  
&gt; -enum cxl_partition_mode {
&gt; -	CXL_PARTMODE_RAM,
&gt; -	CXL_PARTMODE_PMEM,
&gt; -};
&gt; -
&gt;  /*
&gt;   * Indicate whether this region has been assembled by autodetection or
&gt;   * userspace assembly. Prevent endpoint decoders outside of automatic
&gt; diff --git a/drivers/cxl/cxlmem.h b/drivers/cxl/cxlmem.h
&gt; index ef202b34e5ea..281546de426e 100644
&gt; --- a/drivers/cxl/cxlmem.h
&gt; +++ b/drivers/cxl/cxlmem.h
&gt; @@ -113,8 +113,6 @@ int devm_cxl_dpa_reserve(struct cxl_endpoint_decoder *cxled,
&gt;  			 resource_size_t base, resource_size_t len,
&gt;  			 resource_size_t skipped);
&gt;  
&gt; -#define CXL_NR_PARTITIONS_MAX 2
&gt; -
&gt;  struct cxl_dpa_info {
&gt;  	u64 size;
&gt;  	struct cxl_dpa_part_info {
&gt; @@ -373,87 +371,6 @@ struct cxl_security_state {
&gt;  	struct kernfs_node *sanitize_node;
&gt;  };
&gt;  
&gt; -/*
&gt; - * enum cxl_devtype - delineate type-2 from a generic type-3 device
&gt; - * @CXL_DEVTYPE_DEVMEM - Vendor specific CXL Type-2 device implementing HDM-D or
&gt; - *			 HDM-DB, no requirement that this device implements a
&gt; - *			 mailbox, or other memory-device-standard manageability
&gt; - *			 flows.
&gt; - * @CXL_DEVTYPE_CLASSMEM - Common class definition of a CXL Type-3 device with
&gt; - *			   HDM-H and class-mandatory memory device registers
&gt; - */
&gt; -enum cxl_devtype {
&gt; -	CXL_DEVTYPE_DEVMEM,
&gt; -	CXL_DEVTYPE_CLASSMEM,
&gt; -};
&gt; -
&gt; -/**
&gt; - * struct cxl_dpa_perf - DPA performance property entry
&gt; - * @dpa_range: range for DPA address
&gt; - * @coord: QoS performance data (i.e. latency, bandwidth)
&gt; - * @cdat_coord: raw QoS performance data from CDAT
&gt; - * @qos_class: QoS Class cookies
&gt; - */
&gt; -struct cxl_dpa_perf {
&gt; -	struct range dpa_range;
&gt; -	struct access_coordinate coord[ACCESS_COORDINATE_MAX];
&gt; -	struct access_coordinate cdat_coord[ACCESS_COORDINATE_MAX];
&gt; -	int qos_class;
&gt; -};
&gt; -
&gt; -/**
&gt; - * struct cxl_dpa_partition - DPA partition descriptor
&gt; - * @res: shortcut to the partition in the DPA resource tree (cxlds-&gt;dpa_res)
&gt; - * @perf: performance attributes of the partition from CDAT
&gt; - * @mode: operation mode for the DPA capacity, e.g. ram, pmem, dynamic...
&gt; - */
&gt; -struct cxl_dpa_partition {
&gt; -	struct resource res;
&gt; -	struct cxl_dpa_perf perf;
&gt; -	enum cxl_partition_mode mode;
&gt; -};
&gt; -
&gt; -/**
&gt; - * struct cxl_dev_state - The driver device state
&gt; - *
&gt; - * cxl_dev_state represents the CXL driver/device state.  It provides an
&gt; - * interface to mailbox commands as well as some cached data about the device.
&gt; - * Currently only memory devices are represented.
&gt; - *
&gt; - * @dev: The device associated with this CXL state
&gt; - * @cxlmd: The device representing the CXL.mem capabilities of @dev
&gt; - * @reg_map: component and ras register mapping parameters
&gt; - * @regs: Parsed register blocks
&gt; - * @cxl_dvsec: Offset to the PCIe device DVSEC
&gt; - * @rcd: operating in RCD mode (CXL 3.0 9.11.8 CXL Devices Attached to an RCH)
&gt; - * @media_ready: Indicate whether the device media is usable
&gt; - * @dpa_res: Overall DPA resource tree for the device
&gt; - * @part: DPA partition array
&gt; - * @nr_partitions: Number of DPA partitions
&gt; - * @serial: PCIe Device Serial Number
&gt; - * @type: Generic Memory Class device or Vendor Specific Memory device
&gt; - * @cxl_mbox: CXL mailbox context
&gt; - * @cxlfs: CXL features context
&gt; - */
&gt; -struct cxl_dev_state {
&gt; -	struct device *dev;
&gt; -	struct cxl_memdev *cxlmd;
&gt; -	struct cxl_register_map reg_map;
&gt; -	struct cxl_regs regs;
&gt; -	int cxl_dvsec;
&gt; -	bool rcd;
&gt; -	bool media_ready;
&gt; -	struct resource dpa_res;
&gt; -	struct cxl_dpa_partition part[CXL_NR_PARTITIONS_MAX];
&gt; -	unsigned int nr_partitions;
&gt; -	u64 serial;
&gt; -	enum cxl_devtype type;
&gt; -	struct cxl_mailbox cxl_mbox;
&gt; -#ifdef CONFIG_CXL_FEATURES
&gt; -	struct cxl_features_state *cxlfs;
&gt; -#endif
&gt; -};
&gt; -
&gt;  static inline resource_size_t cxl_pmem_size(struct cxl_dev_state *cxlds)
&gt;  {
&gt;  	/*
&gt; @@ -858,7 +775,8 @@ int cxl_dev_state_identify(struct cxl_memdev_state *mds);
&gt;  int cxl_await_media_ready(struct cxl_dev_state *cxlds);
&gt;  int cxl_enumerate_cmds(struct cxl_memdev_state *mds);
&gt;  int cxl_mem_dpa_fetch(struct cxl_memdev_state *mds, struct cxl_dpa_info *info);
&gt; -struct cxl_memdev_state *cxl_memdev_state_create(struct device *dev);
&gt; +struct cxl_memdev_state *cxl_memdev_state_create(struct device *dev, u64 serial,
&gt; +						 u16 dvsec);
&gt;  void set_exclusive_cxl_commands(struct cxl_memdev_state *mds,
&gt;  				unsigned long *cmds);
&gt;  void clear_exclusive_cxl_commands(struct cxl_memdev_state *mds,
&gt; diff --git a/drivers/cxl/pci.c b/drivers/cxl/pci.c
&gt; index 1cf232220873..24179cc702bf 100644
&gt; --- a/drivers/cxl/pci.c
&gt; +++ b/drivers/cxl/pci.c
&gt; @@ -911,25 +911,25 @@ static int cxl_pci_probe(struct pci_dev *pdev, const struct pci_device_id *id)
&gt;  	int rc, pmu_count;
&gt;  	unsigned int i;
&gt;  	bool irq_avail;
&gt; +	u16 dvsec;
&gt;  
&gt;  	rc = pcim_enable_device(pdev);
&gt;  	if (rc)
&gt;  		return rc;
&gt;  	pci_set_master(pdev);
&gt;  
&gt; -	mds = cxl_memdev_state_create(&amp;pdev-&gt;dev);
&gt; +	dvsec = pci_find_dvsec_capability(pdev, PCI_VENDOR_ID_CXL,
&gt; +					  PCI_DVSEC_CXL_DEVICE);
&gt; +	if (!dvsec)
&gt; +		pci_warn(pdev, &quot;Device DVSEC not present, skip CXL.mem init\n&quot;);
&gt; +
&gt; +	mds = cxl_memdev_state_create(&amp;pdev-&gt;dev, pci_get_dsn(pdev), dvsec);
&gt;  	if (IS_ERR(mds))
&gt;  		return PTR_ERR(mds);
&gt;  	cxlds = &amp;mds-&gt;cxlds;
&gt;  	pci_set_drvdata(pdev, cxlds);
&gt;  
&gt;  	cxlds-&gt;rcd = is_cxl_restricted(pdev);
&gt; -	cxlds-&gt;serial = pci_get_dsn(pdev);
&gt; -	cxlds-&gt;cxl_dvsec = pci_find_dvsec_capability(
&gt; -		pdev, PCI_VENDOR_ID_CXL, PCI_DVSEC_CXL_DEVICE);
&gt; -	if (!cxlds-&gt;cxl_dvsec)
&gt; -		dev_warn(&amp;pdev-&gt;dev,
&gt; -			 &quot;Device DVSEC not present, skip CXL.mem init\n&quot;);
&gt;  
&gt;  	rc = cxl_pci_setup_regs(pdev, CXL_REGLOC_RBI_MEMDEV, &amp;map);
&gt;  	if (rc)
&gt; diff --git a/include/cxl/cxl.h b/include/cxl/cxl.h
&gt; new file mode 100644
&gt; index 000000000000..13d448686189
&gt; --- /dev/null
&gt; +++ b/include/cxl/cxl.h
&gt; @@ -0,0 +1,226 @@
&gt; +/* SPDX-License-Identifier: GPL-2.0 */
&gt; +/* Copyright(c) 2020 Intel Corporation. */
&gt; +/* Copyright(c) 2025 Advanced Micro Devices, Inc. */
&gt; +
&gt; +#ifndef __CXL_CXL_H__
&gt; +#define __CXL_CXL_H__
&gt; +
&gt; +#include &lt;linux/node.h&gt;
&gt; +#include &lt;linux/ioport.h&gt;
&gt; +#include &lt;cxl/mailbox.h&gt;
&gt; +
&gt; +/**
&gt; + * enum cxl_devtype - delineate type-2 from a generic type-3 device
&gt; + * @CXL_DEVTYPE_DEVMEM: Vendor specific CXL Type-2 device implementing HDM-D or
&gt; + *			 HDM-DB, no requirement that this device implements a
&gt; + *			 mailbox, or other memory-device-standard manageability
&gt; + *			 flows.
&gt; + * @CXL_DEVTYPE_CLASSMEM: Common class definition of a CXL Type-3 device with
&gt; + *			   HDM-H and class-mandatory memory device registers
&gt; + */
&gt; +enum cxl_devtype {
&gt; +	CXL_DEVTYPE_DEVMEM,
&gt; +	CXL_DEVTYPE_CLASSMEM,
&gt; +};
&gt; +
&gt; +struct device;
&gt; +
&gt; +/*
&gt; + * Using struct_group() allows for per register-block-type helper routines,
&gt; + * without requiring block-type agnostic code to include the prefix.
&gt; + */
&gt; +struct cxl_regs {
&gt; +	/*
&gt; +	 * Common set of CXL Component register block base pointers
&gt; +	 * @hdm_decoder: CXL 2.0 8.2.5.12 CXL HDM Decoder Capability Structure
&gt; +	 * @ras: CXL 2.0 8.2.5.9 CXL RAS Capability Structure
&gt; +	 */
&gt; +	struct_group_tagged(cxl_component_regs, component,
&gt; +		void __iomem *hdm_decoder;
&gt; +		void __iomem *ras;
&gt; +	);
&gt; +	/*
&gt; +	 * Common set of CXL Device register block base pointers
&gt; +	 * @status: CXL 2.0 8.2.8.3 Device Status Registers
&gt; +	 * @mbox: CXL 2.0 8.2.8.4 Mailbox Registers
&gt; +	 * @memdev: CXL 2.0 8.2.8.5 Memory Device Registers
&gt; +	 */
&gt; +	struct_group_tagged(cxl_device_regs, device_regs,
&gt; +		void __iomem *status, *mbox, *memdev;
&gt; +	);
&gt; +
&gt; +	struct_group_tagged(cxl_pmu_regs, pmu_regs,
&gt; +		void __iomem *pmu;
&gt; +	);
&gt; +
&gt; +	/*
&gt; +	 * RCH downstream port specific RAS register
&gt; +	 * @aer: CXL 3.0 8.2.1.1 RCH Downstream Port RCRB
&gt; +	 */
&gt; +	struct_group_tagged(cxl_rch_regs, rch_regs,
&gt; +		void __iomem *dport_aer;
&gt; +	);
&gt; +
&gt; +	/*
&gt; +	 * RCD upstream port specific PCIe cap register
&gt; +	 * @pcie_cap: CXL 3.0 8.2.1.2 RCD Upstream Port RCRB
&gt; +	 */
&gt; +	struct_group_tagged(cxl_rcd_regs, rcd_regs,
&gt; +		void __iomem *rcd_pcie_cap;
&gt; +	);
&gt; +};
&gt; +
&gt; +struct cxl_reg_map {
&gt; +	bool valid;
&gt; +	int id;
&gt; +	unsigned long offset;
&gt; +	unsigned long size;
&gt; +};
&gt; +
&gt; +struct cxl_component_reg_map {
&gt; +	struct cxl_reg_map hdm_decoder;
&gt; +	struct cxl_reg_map ras;
&gt; +};
&gt; +
&gt; +struct cxl_device_reg_map {
&gt; +	struct cxl_reg_map status;
&gt; +	struct cxl_reg_map mbox;
&gt; +	struct cxl_reg_map memdev;
&gt; +};
&gt; +
&gt; +struct cxl_pmu_reg_map {
&gt; +	struct cxl_reg_map pmu;
&gt; +};
&gt; +
&gt; +/**
&gt; + * struct cxl_register_map - DVSEC harvested register block mapping parameters
&gt; + * @host: device for devm operations and logging
&gt; + * @base: virtual base of the register-block-BAR + @block_offset
&gt; + * @resource: physical resource base of the register block
&gt; + * @max_size: maximum mapping size to perform register search
&gt; + * @reg_type: see enum cxl_regloc_type
&gt; + * @component_map: cxl_reg_map for component registers
&gt; + * @device_map: cxl_reg_maps for device registers
&gt; + * @pmu_map: cxl_reg_maps for CXL Performance Monitoring Units
&gt; + */
&gt; +struct cxl_register_map {
&gt; +	struct device *host;
&gt; +	void __iomem *base;
&gt; +	resource_size_t resource;
&gt; +	resource_size_t max_size;
&gt; +	u8 reg_type;
&gt; +	union {
&gt; +		struct cxl_component_reg_map component_map;
&gt; +		struct cxl_device_reg_map device_map;
&gt; +		struct cxl_pmu_reg_map pmu_map;
&gt; +	};
&gt; +};
&gt; +
&gt; +/**
&gt; + * struct cxl_dpa_perf - DPA performance property entry
&gt; + * @dpa_range: range for DPA address
&gt; + * @coord: QoS performance data (i.e. latency, bandwidth)
&gt; + * @cdat_coord: raw QoS performance data from CDAT
&gt; + * @qos_class: QoS Class cookies
&gt; + */
&gt; +struct cxl_dpa_perf {
&gt; +	struct range dpa_range;
&gt; +	struct access_coordinate coord[ACCESS_COORDINATE_MAX];
&gt; +	struct access_coordinate cdat_coord[ACCESS_COORDINATE_MAX];
&gt; +	int qos_class;
&gt; +};
&gt; +
&gt; +enum cxl_partition_mode {
&gt; +	CXL_PARTMODE_RAM,
&gt; +	CXL_PARTMODE_PMEM,
&gt; +};
&gt; +
&gt; +/**
&gt; + * struct cxl_dpa_partition - DPA partition descriptor
&gt; + * @res: shortcut to the partition in the DPA resource tree (cxlds-&gt;dpa_res)
&gt; + * @perf: performance attributes of the partition from CDAT
&gt; + * @mode: operation mode for the DPA capacity, e.g. ram, pmem, dynamic...
&gt; + */
&gt; +struct cxl_dpa_partition {
&gt; +	struct resource res;
&gt; +	struct cxl_dpa_perf perf;
&gt; +	enum cxl_partition_mode mode;
&gt; +};
&gt; +
&gt; +#define CXL_NR_PARTITIONS_MAX 2
&gt; +
&gt; +/**
&gt; + * struct cxl_dev_state - The driver device state
&gt; + *
&gt; + * cxl_dev_state represents the CXL driver/device state.  It provides an
&gt; + * interface to mailbox commands as well as some cached data about the device.
&gt; + * Currently only memory devices are represented.
&gt; + *
&gt; + * @dev: The device associated with this CXL state
&gt; + * @cxlmd: The device representing the CXL.mem capabilities of @dev
&gt; + * @reg_map: component and ras register mapping parameters
&gt; + * @regs: Parsed register blocks
&gt; + * @cxl_dvsec: Offset to the PCIe device DVSEC
&gt; + * @rcd: operating in RCD mode (CXL 3.0 9.11.8 CXL Devices Attached to an RCH)
&gt; + * @media_ready: Indicate whether the device media is usable
&gt; + * @dpa_res: Overall DPA resource tree for the device
&gt; + * @part: DPA partition array
&gt; + * @nr_partitions: Number of DPA partitions
&gt; + * @serial: PCIe Device Serial Number
&gt; + * @type: Generic Memory Class device or Vendor Specific Memory device
&gt; + * @cxl_mbox: CXL mailbox context
&gt; + * @cxlfs: CXL features context
&gt; + */
&gt; +struct cxl_dev_state {
&gt; +	/* public for Type2 drivers */
&gt; +	struct device *dev;
&gt; +	struct cxl_memdev *cxlmd;
&gt; +
&gt; +	/* private for Type2 drivers */
&gt; +	struct cxl_register_map reg_map;
&gt; +	struct cxl_regs regs;
&gt; +	int cxl_dvsec;
&gt; +	bool rcd;
&gt; +	bool media_ready;
&gt; +	struct resource dpa_res;
&gt; +	struct cxl_dpa_partition part[CXL_NR_PARTITIONS_MAX];
&gt; +	unsigned int nr_partitions;
&gt; +	u64 serial;
&gt; +	enum cxl_devtype type;
&gt; +	struct cxl_mailbox cxl_mbox;
&gt; +#ifdef CONFIG_CXL_FEATURES
&gt; +	struct cxl_features_state *cxlfs;
&gt; +#endif
&gt; +};
&gt; +
&gt; +struct cxl_dev_state *_devm_cxl_dev_state_create(struct device *dev,
&gt; +						 enum cxl_devtype type,
&gt; +						 u64 serial, u16 dvsec,
&gt; +						 size_t size, bool has_mbox);
&gt; +
&gt; +/**
&gt; + * cxl_dev_state_create - safely create and cast a cxl dev state embedded in a
&gt; + * driver specific struct.
&gt; + *
&gt; + * @parent: device behind the request
&gt; + * @type: CXL device type
&gt; + * @serial: device identification
&gt; + * @dvsec: dvsec capability offset
&gt; + * @drv_struct: driver struct embedding a cxl_dev_state struct
&gt; + * @member: drv_struct member as cxl_dev_state
&gt; + * @mbox: true if mailbox supported
&gt; + *
&gt; + * Returns a pointer to the drv_struct allocated and embedding a cxl_dev_state
&gt; + * struct initialized.
&gt; + *
&gt; + * Introduced for Type2 driver support.
&gt; + */
&gt; +#define devm_cxl_dev_state_create(parent, type, serial, dvsec, drv_struct, member, mbox)	\
&gt; +	({										\
&gt; +		static_assert(__same_type(struct cxl_dev_state,				\
&gt; +			      ((drv_struct *)NULL)-&gt;member));				\
&gt; +		static_assert(offsetof(drv_struct, member) == 0);			\
&gt; +		(drv_struct *)_devm_cxl_dev_state_create(parent, type, serial, dvsec,	\
&gt; +						      sizeof(drv_struct), mbox);	\
&gt; +	})
&gt; +#endif /* __CXL_CXL_H__ */
&gt; diff --git a/tools/testing/cxl/test/mem.c b/tools/testing/cxl/test/mem.c
&gt; index cb87e8c0e63c..79f42f4474d4 100644
&gt; --- a/tools/testing/cxl/test/mem.c
&gt; +++ b/tools/testing/cxl/test/mem.c
&gt; @@ -1716,7 +1716,7 @@ static int cxl_mock_mem_probe(struct platform_device *pdev)
&gt;  	if (rc)
&gt;  		return rc;
&gt;  
&gt; -	mds = cxl_memdev_state_create(dev);
&gt; +	mds = cxl_memdev_state_create(dev, pdev-&gt;id + 1, 0);
&gt;  	if (IS_ERR(mds))
&gt;  		return PTR_ERR(mds);
&gt;  
&gt; @@ -1732,7 +1732,6 @@ static int cxl_mock_mem_probe(struct platform_device *pdev)
&gt;  	mds-&gt;event.buf = (struct cxl_get_event_payload *) mdata-&gt;event_buf;
&gt;  	INIT_DELAYED_WORK(&amp;mds-&gt;security.poll_dwork, cxl_mockmem_sanitize_work);
&gt;  
&gt; -	cxlds-&gt;serial = pdev-&gt;id + 1;
&gt;  	if (is_rcd(pdev))
&gt;  		cxlds-&gt;rcd = true;
&gt;  



---

On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; A Type2 device configured by the BIOS can already have its HDM
&gt; committed. Add a cxl_get_committed_decoder() function for cheking
&gt; so after memdev creation. A CXL region should have been created
&gt; during memdev initialization, therefore a Type2 driver can ask for
&gt; such a region for working with the HPA. If the HDM is not committed,
&gt; a Type2 driver will create the region after obtaining proper HPA
&gt; and DPA space.
&gt; 
&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; ---
&gt;  drivers/cxl/core/hdm.c | 39 +++++++++++++++++++++++++++++++++++++++
&gt;  include/cxl/cxl.h      |  3 +++
&gt;  2 files changed, 42 insertions(+)
&gt; 
&gt; diff --git a/drivers/cxl/core/hdm.c b/drivers/cxl/core/hdm.c
&gt; index 6e516c69b2d2..a172ce4e9b19 100644
&gt; --- a/drivers/cxl/core/hdm.c
&gt; +++ b/drivers/cxl/core/hdm.c
&gt; @@ -686,6 +686,45 @@ int cxl_dpa_alloc(struct cxl_endpoint_decoder *cxled, u64 size)
&gt;  	return devm_add_action_or_reset(&amp;port-&gt;dev, cxl_dpa_release, cxled);
&gt;  }
&gt;  
&gt; +static int find_committed_endpoint_decoder(struct device *dev, const void *data)
&gt; +{
&gt; +	struct cxl_endpoint_decoder *cxled;
&gt; +	struct cxl_port *port;
&gt; +
&gt; +	if (!is_endpoint_decoder(dev))
&gt; +		return 0;
&gt; +
&gt; +	cxled = to_cxl_endpoint_decoder(dev);
&gt; +	port = cxled_to_port(cxled);
&gt; +
&gt; +	return cxled-&gt;cxld.id == port-&gt;hdm_end;

Is this the way you&#x27;re supposed to check if a decoder is committed? The doc comment for @hdm_end in
struct cxl_port says it&#x27;s just the last allocated decoder. If allocated decoders are always committed then
I&#x27;m fine with this, otherwise I think you&#x27;d want to a register read or something to find the commit state.
&gt; +}
&gt; +
&gt; +struct cxl_endpoint_decoder *cxl_get_committed_decoder(struct cxl_memdev *cxlmd,
&gt; +						       struct cxl_region **cxlr)
&gt; +{
&gt; +	struct cxl_port *endpoint = cxlmd-&gt;endpoint;
&gt; +	struct cxl_endpoint_decoder *cxled;
&gt; +	struct device *cxled_dev;
&gt; +
&gt; +	if (!endpoint)
&gt; +		return NULL;
&gt; +
&gt; +	guard(rwsem_read)(&amp;cxl_rwsem.dpa);
&gt; +	cxled_dev = device_find_child(&amp;endpoint-&gt;dev, NULL,
&gt; +				      find_committed_endpoint_decoder);
&gt; +
&gt; +	if (!cxled_dev)
&gt; +		return NULL;
&gt; +
&gt; +	cxled = to_cxl_endpoint_decoder(cxled_dev);
&gt; +	*cxlr = cxled-&gt;cxld.region;
&gt; +
&gt; +	put_device(cxled_dev);
&gt; +	return cxled;
&gt; +}
&gt; +EXPORT_SYMBOL_NS_GPL(cxl_get_committed_decoder, &quot;CXL&quot;);
&gt; +
&gt;  static void cxld_set_interleave(struct cxl_decoder *cxld, u32 *ctrl)
&gt;  {
&gt;  	u16 eig;
&gt; diff --git a/include/cxl/cxl.h b/include/cxl/cxl.h
&gt; index 6f8d365067af..928276dba952 100644
&gt; --- a/include/cxl/cxl.h
&gt; +++ b/include/cxl/cxl.h
&gt; @@ -249,4 +249,7 @@ int cxl_map_component_regs(const struct cxl_register_map *map,
&gt;  int cxl_set_capacity(struct cxl_dev_state *cxlds, u64 capacity);
&gt;  struct cxl_memdev *devm_cxl_add_memdev(struct cxl_dev_state *cxlds,
&gt;  				       const struct cxl_memdev_attach *attach);
&gt; +struct cxl_region;
&gt; +struct cxl_endpoint_decoder *cxl_get_committed_decoder(struct cxl_memdev *cxlmd,
&gt; +						       struct cxl_region **cxlr);
&gt;  #endif /* __CXL_CXL_H__ */



---

On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; This patchset should be applied on the cxl next branch using the base
&gt; specified at the end of this cover letter.
&gt; 
&gt; Dependencies on Dan&#x27;s work has gone and also on Terry&#x27;s as the only
&gt; patch required is now in next. The other dependency is on Smita patchset
&gt; but it does not exist such a dependency as that work will not avoid the
&gt; problem with Type2 and DAX/hmem if soft reserved memory. This needs to
&gt; be solved by the BIOS and Type2 UEFI driver for populating the CXL.mem
&gt; range as EFI_RESERVED_TYPE instead of default EFI_CONVENTIONAL_MEMORY
&gt; with the EFI_MEMORY_SP attribute. There exists though a dependency on
&gt; one Smita&#x27;s patches:
&gt; 
&gt; [PATCH v5 3/7] cxl/region: Skip decoder reset on detach for autodiscovered regions
&gt; 
&gt; This is needed for the default behaviour with current BIOS configuration
&gt; where the HDM Type2 decoders will be kept unreset when driver unloads.
&gt; This is the main change introduced in v23: committed decoders will not
&gt; be reset. Previous v22 functionality supported first driver load finding
&gt; committed decoders but resetting them at unload and supporting
&gt; uncommitted decoders in next driver loads. This will be suported in
&gt; follow-up works.
&gt; 
&gt; v23 changes:
&gt; 
&gt;   patch 11: fixing minor issues and droping change in
&gt; 	    should_emulate_decoders (Jonathan Cameron)
&gt; 
&gt;   patch13: refactoring unregister_region for safety type in Type2 API
&gt; 
&gt;   sfc changes: slight modifications to error path
&gt; 

This cover letter is really long, I&#x27;d remove the change logs for anything more
than 3 revisions back (assuming a v24 is needed). After that you could leave
a lore link for older revisions if you want, but it&#x27;s not needed imo.
Also, feel free to add my Reviewed-by for anything I didn&#x27;t leave a comment on
(felt I should cut down on the mail).

Thanks,
Ben


---

On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; Region creation involves finding available DPA (device-physical-address)
&gt; capacity to map into HPA (host-physical-address) space.
&gt; 
&gt; In order to support CXL Type2 devices, define an API, cxl_request_dpa(),
&gt; that tries to allocate the DPA memory the driver requires to operate.The
&gt; memory requested should not be bigger than the max available HPA obtained
&gt; previously with cxl_get_hpa_freespace().
&gt; 
&gt; Based on https://lore.kernel.org/linux-cxl/168592158743.1948938.7622563891193802610.stgit@dwillia2-xfh.jf.intel.com/
&gt; 
&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
&gt; Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
&gt; ---
&gt;  drivers/cxl/core/hdm.c | 84 ++++++++++++++++++++++++++++++++++++++++++
&gt;  drivers/cxl/cxl.h      |  1 +
&gt;  include/cxl/cxl.h      |  5 +++
&gt;  3 files changed, 90 insertions(+)
&gt; 
&gt; diff --git a/drivers/cxl/core/hdm.c b/drivers/cxl/core/hdm.c
&gt; index a172ce4e9b19..d60a697f12cc 100644
&gt; --- a/drivers/cxl/core/hdm.c
&gt; +++ b/drivers/cxl/core/hdm.c
&gt; @@ -3,6 +3,7 @@
&gt;  #include &lt;linux/seq_file.h&gt;
&gt;  #include &lt;linux/device.h&gt;
&gt;  #include &lt;linux/delay.h&gt;
&gt; +#include &lt;cxl/cxl.h&gt;
&gt;  
&gt;  #include &quot;cxlmem.h&quot;
&gt;  #include &quot;core.h&quot;
&gt; @@ -546,6 +547,12 @@ bool cxl_resource_contains_addr(const struct resource *res, const resource_size_
&gt;  	return resource_contains(res, &amp;_addr);
&gt;  }
&gt;  
&gt; +/**
&gt; + * cxl_dpa_free - release DPA (Device Physical Address)
&gt; + * @cxled: endpoint decoder linked to the DPA
&gt; + *
&gt; + * Returns 0 or error.
&gt; + */
&gt;  int cxl_dpa_free(struct cxl_endpoint_decoder *cxled)
&gt;  {
&gt;  	struct cxl_port *port = cxled_to_port(cxled);
&gt; @@ -572,6 +579,7 @@ int cxl_dpa_free(struct cxl_endpoint_decoder *cxled)
&gt;  	devm_cxl_dpa_release(cxled);
&gt;  	return 0;
&gt;  }
&gt; +EXPORT_SYMBOL_NS_GPL(cxl_dpa_free, &quot;CXL&quot;);
&gt;  
&gt;  int cxl_dpa_set_part(struct cxl_endpoint_decoder *cxled,
&gt;  		     enum cxl_partition_mode mode)
&gt; @@ -603,6 +611,82 @@ int cxl_dpa_set_part(struct cxl_endpoint_decoder *cxled,
&gt;  	return 0;
&gt;  }
&gt;  
&gt; +static int find_free_decoder(struct device *dev, const void *data)
&gt; +{
&gt; +	struct cxl_endpoint_decoder *cxled;
&gt; +	struct cxl_port *port;
&gt; +
&gt; +	if (!is_endpoint_decoder(dev))
&gt; +		return 0;
&gt; +
&gt; +	cxled = to_cxl_endpoint_decoder(dev);
&gt; +	port = cxled_to_port(cxled);
&gt; +
&gt; +	return cxled-&gt;cxld.id == (port-&gt;hdm_end + 1);
&gt; +}
&gt; +
&gt; +static struct cxl_endpoint_decoder *
&gt; +cxl_find_free_decoder(struct cxl_memdev *cxlmd)
&gt; +{
&gt; +	struct cxl_port *endpoint = cxlmd-&gt;endpoint;
&gt; +	struct device *dev;
&gt; +
&gt; +	guard(rwsem_read)(&amp;cxl_rwsem.dpa);
&gt; +	dev = device_find_child(&amp;endpoint-&gt;dev, NULL,
&gt; +				find_free_decoder);
&gt; +	if (!dev)
&gt; +		return NULL;
&gt; +
&gt; +	return to_cxl_endpoint_decoder(dev);
&gt; +}
&gt; +
&gt; +/**
&gt; + * cxl_request_dpa - search and reserve DPA given input constraints
&gt; + * @cxlmd: memdev with an endpoint port with available decoders
&gt; + * @mode: CXL partition mode (ram vs pmem)
&gt; + * @alloc: dpa size required
&gt; + *
&gt; + * Returns a pointer to a &#x27;struct cxl_endpoint_decoder&#x27; on success or
&gt; + * an errno encoded pointer on failure.
&gt; + *
&gt; + * Given that a region needs to allocate from limited HPA capacity it
&gt; + * may be the case that a device has more mappable DPA capacity than
&gt; + * available HPA. The expectation is that @alloc is a driver known
&gt; + * value based on the device capacity but which could not be fully
&gt; + * available due to HPA constraints.
&gt; + *
&gt; + * Returns a pinned cxl_decoder with at least @alloc bytes of capacity
&gt; + * reserved, or an error pointer. The caller is also expected to own the
&gt; + * lifetime of the memdev registration associated with the endpoint to
&gt; + * pin the decoder registered as well.
&gt; + */
&gt; +struct cxl_endpoint_decoder *cxl_request_dpa(struct cxl_memdev *cxlmd,
&gt; +					     enum cxl_partition_mode mode,
&gt; +					     resource_size_t alloc)
&gt; +{
&gt; +	int rc;
&gt; +
&gt; +	if (!IS_ALIGNED(alloc, SZ_256M))
&gt; +		return ERR_PTR(-EINVAL);
&gt; +
&gt; +	struct cxl_endpoint_decoder *cxled __free(put_cxled) =
&gt; +		cxl_find_free_decoder(cxlmd);
&gt; +
&gt; +	if (!cxled)
&gt; +		return ERR_PTR(-ENODEV);
&gt; +
&gt; +	rc = cxl_dpa_set_part(cxled, mode);
&gt; +	if (rc)
&gt; +		return ERR_PTR(rc);
&gt; +
&gt; +	rc = cxl_dpa_alloc(cxled, alloc);
&gt; +	if (rc)
&gt; +		return ERR_PTR(rc);

Should cxl_dpa_set_part() be unwound here, or does it not matter? If it doesn&#x27;t matter:
Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
&gt; +
&gt; +	return no_free_ptr(cxled);
&gt; +}
&gt; +EXPORT_SYMBOL_NS_GPL(cxl_request_dpa, &quot;CXL&quot;);
&gt; +
&gt;  static int __cxl_dpa_alloc(struct cxl_endpoint_decoder *cxled, u64 size)
&gt;  {
&gt;  	struct cxl_memdev *cxlmd = cxled_to_memdev(cxled);
&gt; diff --git a/drivers/cxl/cxl.h b/drivers/cxl/cxl.h
&gt; index d1b010e5e1d0..2b1f7d687a0e 100644
&gt; --- a/drivers/cxl/cxl.h
&gt; +++ b/drivers/cxl/cxl.h
&gt; @@ -667,6 +667,7 @@ struct cxl_root *find_cxl_root(struct cxl_port *port);
&gt;  
&gt;  DEFINE_FREE(put_cxl_root, struct cxl_root *, if (_T) put_device(&amp;_T-&gt;port.dev))
&gt;  DEFINE_FREE(put_cxl_port, struct cxl_port *, if (!IS_ERR_OR_NULL(_T)) put_device(&amp;_T-&gt;dev))
&gt; +DEFINE_FREE(put_cxled, struct cxl_endpoint_decoder *, if (!IS_ERR_OR_NULL(_T)) put_device(&amp;_T-&gt;cxld.dev))
&gt;  DEFINE_FREE(put_cxl_root_decoder, struct cxl_root_decoder *, if (!IS_ERR_OR_NULL(_T)) put_device(&amp;_T-&gt;cxlsd.cxld.dev))
&gt;  DEFINE_FREE(put_cxl_region, struct cxl_region *, if (!IS_ERR_OR_NULL(_T)) put_device(&amp;_T-&gt;dev))
&gt;  
&gt; diff --git a/include/cxl/cxl.h b/include/cxl/cxl.h
&gt; index 783ad570a6eb..4802371db00e 100644
&gt; --- a/include/cxl/cxl.h
&gt; +++ b/include/cxl/cxl.h
&gt; @@ -7,6 +7,7 @@
&gt;  
&gt;  #include &lt;linux/node.h&gt;
&gt;  #include &lt;linux/ioport.h&gt;
&gt; +#include &lt;linux/range.h&gt;
&gt;  #include &lt;cxl/mailbox.h&gt;
&gt;  
&gt;  /**
&gt; @@ -276,4 +277,8 @@ struct cxl_root_decoder *cxl_get_hpa_freespace(struct cxl_memdev *cxlmd,
&gt;  					       unsigned long flags,
&gt;  					       resource_size_t *max);
&gt;  void cxl_put_root_decoder(struct cxl_root_decoder *cxlrd);
&gt; +struct cxl_endpoint_decoder *cxl_request_dpa(struct cxl_memdev *cxlmd,
&gt; +					     enum cxl_partition_mode mode,
&gt; +					     resource_size_t alloc);
&gt; +int cxl_dpa_free(struct cxl_endpoint_decoder *cxled);
&gt;  #endif /* __CXL_CXL_H__ */



---



On 2/19/2026 4:40 AM, Alejandro Lucero Palau wrote:
&gt; 
&gt; On 2/11/26 22:11, Cheatham, Benjamin wrote:
&gt;&gt; On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt;&gt;&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; Region creation based on Type3 devices is triggered from user space
&gt;&gt;&gt; allowing memory combination through interleaving.
&gt;&gt;&gt;
&gt;&gt;&gt; In preparation for kernel driven region creation, that is Type2 drivers
&gt;&gt;&gt; triggering region creation backed with its advertised CXL memory, factor
&gt;&gt;&gt; out a common helper from the user-sysfs region setup for interleave ways.
&gt;&gt;&gt;
&gt;&gt;&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt;&gt;&gt; Reviewed-by: Zhi Wang &lt;zhiw@nvidia.com&gt;
&gt;&gt;&gt; Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
&gt;&gt;&gt; Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
&gt;&gt;&gt; Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
&gt;&gt;&gt; Reviewed-by: Alison Schofield &lt;alison.schofield@intel.com&gt;
&gt;&gt;&gt; ---
&gt;&gt;&gt;  drivers/cxl/core/region.c | 43 ++++++++++++++++++++++++---------------
&gt;&gt;&gt;  1 file changed, 27 insertions(+), 16 deletions(-)
&gt;&gt;&gt;
&gt;&gt;&gt; diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
&gt;&gt;&gt; index f53b2e9fd9e6..ece1d3df7cf1 100644
&gt;&gt;&gt; --- a/drivers/cxl/core/region.c
&gt;&gt;&gt; +++ b/drivers/cxl/core/region.c
&gt;&gt;&gt; @@ -485,22 +485,14 @@ static ssize_t interleave_ways_show(struct device *dev,
&gt;&gt;&gt;   static const struct attribute_group *get_cxl_region_target_group(void);
&gt;&gt;&gt;  -static ssize_t interleave_ways_store(struct device *dev,
&gt;&gt;&gt; - struct device_attribute *attr,
&gt;&gt;&gt; - const char *buf, size_t len)
&gt;&gt;&gt; +static int set_interleave_ways(struct cxl_region *cxlr, int val)
&gt;&gt; @val should probably stay an unsigned int. You pass an unsigned int in the sysfs function, and the
&gt;&gt; function was originally coded with that in mind (same with @save below).
&gt; 
&gt; Good catch. I wonder if I should just change the way the value is obtained, using kstrtoint instead of kstrtouint, as those values are used for cxl_region_params fields defined as int. In other words, it seems doing that simpler than changing all the other places you mention and the structs involved. I can not see a reason for using unsigned int so I think I will follow that approach. Tell me if you think otherwise.
&gt; 

If I had to guess unsigned int was used because a negative interleave granularity/ways makes no sense. I think your suggestion is fine though since no one
in their right mind would give anything but a (relatively) small and positive value for these.

Thanks,
Ben

&gt; 
&gt; Thank you
&gt; 
&gt; 
&gt;&gt; With that cleaned up:
&gt;&gt; Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
&gt;&gt;
&gt;&gt;&gt;  {
&gt;&gt;&gt; - struct cxl_root_decoder *cxlrd = to_cxl_root_decoder(dev-&gt;parent);
&gt;&gt;&gt; + struct cxl_root_decoder *cxlrd = to_cxl_root_decoder(cxlr-&gt;dev.parent);
&gt;&gt;&gt;  struct cxl_decoder *cxld = &amp;cxlrd-&gt;cxlsd.cxld;
&gt;&gt;&gt; - struct cxl_region *cxlr = to_cxl_region(dev);
&gt;&gt;&gt;  struct cxl_region_params *p = &amp;cxlr-&gt;params;
&gt;&gt;&gt; - unsigned int val, save;
&gt;&gt;&gt; - int rc;
&gt;&gt;&gt; + int save, rc;
&gt;&gt;&gt;  u8 iw;
&gt;&gt;&gt;  - rc = kstrtouint(buf, 0, &amp;val);
&gt;&gt;&gt; - if (rc)
&gt;&gt;&gt; - return rc;
&gt;&gt;&gt; -
&gt;&gt;&gt;  rc = ways_to_eiw(val, &amp;iw);
&gt;&gt;&gt;  if (rc)
&gt;&gt;&gt;  return rc;
&gt;&gt;&gt; @@ -515,9 +507,7 @@ static ssize_t interleave_ways_store(struct device *dev,
&gt;&gt;&gt;  return -EINVAL;
&gt;&gt;&gt;  }
&gt;&gt;&gt;  - ACQUIRE(rwsem_write_kill, rwsem)(&amp;cxl_rwsem.region);
&gt;&gt;&gt; - if ((rc = ACQUIRE_ERR(rwsem_write_kill, &amp;rwsem)))
&gt;&gt;&gt; - return rc;
&gt;&gt;&gt; + lockdep_assert_held_write(&amp;cxl_rwsem.region);
&gt;&gt;&gt;   if (p-&gt;state &gt;= CXL_CONFIG_INTERLEAVE_ACTIVE)
&gt;&gt;&gt;  return -EBUSY;
&gt;&gt;&gt; @@ -525,10 +515,31 @@ static ssize_t interleave_ways_store(struct device *dev,
&gt;&gt;&gt;  save = p-&gt;interleave_ways;
&gt;&gt;&gt;  p-&gt;interleave_ways = val;
&gt;&gt;&gt;  rc = sysfs_update_group(&amp;cxlr-&gt;dev.kobj, get_cxl_region_target_group());
&gt;&gt;&gt; - if (rc) {
&gt;&gt;&gt; + if (rc)
&gt;&gt;&gt;  p-&gt;interleave_ways = save;
&gt;&gt;&gt; +
&gt;&gt;&gt; + return rc;
&gt;&gt;&gt; +}
&gt;&gt;&gt; +
&gt;&gt;&gt; +static ssize_t interleave_ways_store(struct device *dev,
&gt;&gt;&gt; + struct device_attribute *attr,
&gt;&gt;&gt; + const char *buf, size_t len)
&gt;&gt;&gt; +{
&gt;&gt;&gt; + struct cxl_region *cxlr = to_cxl_region(dev);
&gt;&gt;&gt; + unsigned int val;
&gt;&gt;&gt; + int rc;
&gt;&gt;&gt; +
&gt;&gt;&gt; + rc = kstrtouint(buf, 0, &amp;val);
&gt;&gt;&gt; + if (rc)
&gt;&gt;&gt; + return rc;
&gt;&gt;&gt; +
&gt;&gt;&gt; + ACQUIRE(rwsem_write_kill, rwsem)(&amp;cxl_rwsem.region);
&gt;&gt;&gt; + if ((rc = ACQUIRE_ERR(rwsem_write_kill, &amp;rwsem)))
&gt;&gt;&gt; + return rc;
&gt;&gt;&gt; +
&gt;&gt;&gt; + rc = set_interleave_ways(cxlr, val);
&gt;&gt;&gt; + if (rc)
&gt;&gt;&gt;  return rc;
&gt;&gt;&gt; - }
&gt;&gt;&gt;   return len;
&gt;&gt;&gt;  }



---

On 2/19/2026 3:58 AM, Alejandro Lucero Palau wrote:
&gt; 
&gt; On 2/11/26 22:10, Cheatham, Benjamin wrote:
&gt;&gt; On 2/1/2026 9:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt;&gt;&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; CXL region creation involves allocating capacity from Device Physical
&gt;&gt;&gt; Address (DPA) and assigning it to decode a given Host Physical Address
&gt;&gt;&gt; (HPA). Before determining how much DPA to allocate the amount of available
&gt;&gt;&gt; HPA must be determined. Also, not all HPA is created equal, some HPA
&gt;&gt;&gt; targets RAM, some targets PMEM, some is prepared for device-memory flows
&gt;&gt;&gt; like HDM-D and HDM-DB, and some is HDM-H (host-only).
&gt;&gt;&gt;
&gt;&gt;&gt; In order to support Type2 CXL devices, wrap all of those concerns into
&gt;&gt;&gt; an API that retrieves a root decoder (platform CXL window) that fits the
&gt;&gt;&gt; specified constraints and the capacity available for a new region.
&gt;&gt;&gt;
&gt;&gt;&gt; Add a complementary function for releasing the reference to such root
&gt;&gt;&gt; decoder.
&gt;&gt;&gt;
&gt;&gt;&gt; Based on https://lore.kernel.org/linux-cxl/168592159290.1948938.13522227102445462976.stgit@dwillia2-xfh.jf.intel.com/
&gt;&gt;&gt;
&gt;&gt;&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt;&gt;&gt; Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
&gt;&gt;&gt; ---
&gt;&gt;&gt;  drivers/cxl/core/region.c | 164 ++++++++++++++++++++++++++++++++++++++
&gt;&gt;&gt;  drivers/cxl/cxl.h | 3 +
&gt;&gt;&gt;  include/cxl/cxl.h | 6 ++
&gt;&gt;&gt;  3 files changed, 173 insertions(+)
&gt;&gt;&gt;
&gt;&gt;&gt; diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
&gt;&gt;&gt; index 954b8fcdbac6..bdefd088f5f1 100644
&gt;&gt;&gt; --- a/drivers/cxl/core/region.c
&gt;&gt;&gt; +++ b/drivers/cxl/core/region.c
&gt;&gt;&gt; @@ -705,6 +705,170 @@ static int free_hpa(struct cxl_region *cxlr)
&gt;&gt;&gt;  return 0;
&gt;&gt;&gt;  }
&gt;&gt;&gt;  +struct cxlrd_max_context {
&gt;&gt;&gt; + struct device * const *host_bridges;
&gt;&gt;&gt; + int interleave_ways;
&gt;&gt;&gt; + unsigned long flags;
&gt;&gt;&gt; + resource_size_t max_hpa;
&gt;&gt;&gt; + struct cxl_root_decoder *cxlrd;
&gt;&gt;&gt; +};
&gt;&gt;&gt; +
&gt;&gt;&gt; +static int find_max_hpa(struct device *dev, void *data)
&gt;&gt;&gt; +{
&gt;&gt;&gt; + struct cxlrd_max_context *ctx = data;
&gt;&gt;&gt; + struct cxl_switch_decoder *cxlsd;
&gt;&gt;&gt; + struct cxl_root_decoder *cxlrd;
&gt;&gt;&gt; + struct resource *res, *prev;
&gt;&gt;&gt; + struct cxl_decoder *cxld;
&gt;&gt;&gt; + resource_size_t free = 0;
&gt;&gt;&gt; + resource_size_t max;
&gt;&gt;&gt; + int found = 0;
&gt;&gt;&gt; +
&gt;&gt;&gt; + if (!is_root_decoder(dev))
&gt;&gt;&gt; + return 0;
&gt;&gt;&gt; +
&gt;&gt;&gt; + cxlrd = to_cxl_root_decoder(dev);
&gt;&gt;&gt; + cxlsd = &amp;cxlrd-&gt;cxlsd;
&gt;&gt;&gt; + cxld = &amp;cxlsd-&gt;cxld;
&gt;&gt;&gt; +
&gt;&gt;&gt; + if ((cxld-&gt;flags &amp; ctx-&gt;flags) != ctx-&gt;flags) {
&gt;&gt;&gt; + dev_dbg(dev, &quot;flags not matching: %08lx vs %08lx\n&quot;,
&gt;&gt;&gt; + cxld-&gt;flags, ctx-&gt;flags);
&gt;&gt;&gt; + return 0;
&gt;&gt;&gt; + }
&gt;&gt;&gt; +
&gt;&gt;&gt; + for (int i = 0; i &lt; ctx-&gt;interleave_ways; i++) {
&gt;&gt;&gt; + for (int j = 0; j &lt; ctx-&gt;interleave_ways; j++) {
&gt;&gt;&gt; + if (ctx-&gt;host_bridges[i] == cxlsd-&gt;target[j]-&gt;dport_dev) {
&gt;&gt;&gt; + found++;
&gt;&gt;&gt; + break;
&gt;&gt;&gt; + }
&gt;&gt;&gt; + }
&gt;&gt;&gt; + }
&gt;&gt; This may be over complicated. I&#x27;m not quite sure how it works (I&#x27;m just slow today I guess), but I understand
&gt;&gt; what the intention is based on the debug print below. My issue is that ctx-&gt;host_bridges is only set to 1 host
&gt;&gt; bridge (endpoint-&gt;host_bridge) in cxl_get_hpa_freespace(), which is the only caller of this function. At that
&gt;&gt; point, why have the outer loop at all? At that point, you could also simplify ctx-&gt;host_bridges to only
&gt;&gt; be a struct device * const.
&gt;&gt;
&gt;&gt; Maybe this gets called elsewhere later on in the series? I haven&#x27;t looked at the rest yet. If I&#x27;m wrong, then
&gt;&gt; I&#x27;d probably add a comment saying what the cxlsd-&gt;target[] entries are supposed to be pointing at.
&gt; 
&gt; 
&gt; Hi Ben,
&gt; 
&gt; 
&gt; I do remember this one.
&gt; 
&gt; 
&gt; Dan&#x27;s original patches had this support for interleaving, then I removed it as the case for Type2 and interleaving is quite unlikely, at least right now and likely in the near future. But I was told why do not support it as it was trivial to do so. FWIW, If I think only about the use case coming with the patchset, I agree with you, but because those previous discussions, I think I have to leave it.
&gt; 

I&#x27;m fine with that, but I would at least do the fix with the decoder position in 19/22 and make a note that the
interleave_ways parameter in cxl_get_hpa_freespace() below is currently unused (unless I&#x27;m misunderstanding
the endpoint-&gt;host_bridge member).

That way, the support is mostly there and just requires a small, previously noted, addition to enable. If you&#x27;re
fine with that then feel free to add my Reviewed-by after implementing in v24.

Thanks,
Ben

&gt; 
&gt; Thank you
&gt; 
&gt; 
&gt;&gt;&gt; +
&gt;&gt;&gt; + if (found != ctx-&gt;interleave_ways) {
&gt;&gt;&gt; + dev_dbg(dev,
&gt;&gt;&gt; + &quot;Not enough host bridges. Found %d for %d interleave ways requested\n&quot;,
&gt;&gt;&gt; + found, ctx-&gt;interleave_ways);
&gt;&gt;&gt; + return 0;
&gt;&gt;&gt; + }
&gt;&gt;&gt; +
&gt;&gt;&gt; + /*
&gt;&gt;&gt; + * Walk the root decoder resource range relying on cxl_rwsem.region to
&gt;&gt;&gt; + * preclude sibling arrival/departure and find the largest free space
&gt;&gt;&gt; + * gap.
&gt;&gt;&gt; + */
&gt;&gt;&gt; + lockdep_assert_held_read(&amp;cxl_rwsem.region);
&gt;&gt;&gt; + res = cxlrd-&gt;res-&gt;child;
&gt;&gt;&gt; +
&gt;&gt;&gt; + /* With no resource child the whole parent resource is available */
&gt;&gt;&gt; + if (!res)
&gt;&gt;&gt; + max = resource_size(cxlrd-&gt;res);
&gt;&gt;&gt; + else
&gt;&gt;&gt; + max = 0;
&gt;&gt;&gt; +
&gt;&gt;&gt; + for (prev = NULL; res; prev = res, res = res-&gt;sibling) {
&gt;&gt;&gt; + if (!prev &amp;&amp; res-&gt;start == cxlrd-&gt;res-&gt;start &amp;&amp;
&gt;&gt;&gt; + res-&gt;end == cxlrd-&gt;res-&gt;end) {
&gt;&gt;&gt; + max = resource_size(cxlrd-&gt;res);
&gt;&gt;&gt; + break;
&gt;&gt;&gt; + }
&gt;&gt;&gt; + /*
&gt;&gt;&gt; + * Sanity check for preventing arithmetic problems below as a
&gt;&gt;&gt; + * resource with size 0 could imply using the end field below
&gt;&gt;&gt; + * when set to unsigned zero - 1 or all f in hex.
&gt;&gt;&gt; + */
&gt;&gt;&gt; + if (prev &amp;&amp; !resource_size(prev))
&gt;&gt;&gt; + continue;
&gt;&gt;&gt; +
&gt;&gt;&gt; + if (!prev &amp;&amp; res-&gt;start &gt; cxlrd-&gt;res-&gt;start) {
&gt;&gt;&gt; + free = res-&gt;start - cxlrd-&gt;res-&gt;start;
&gt;&gt;&gt; + max = max(free, max);
&gt;&gt;&gt; + }
&gt;&gt;&gt; + if (prev &amp;&amp; res-&gt;start &gt; prev-&gt;end + 1) {
&gt;&gt;&gt; + free = res-&gt;start - prev-&gt;end + 1;
&gt;&gt;&gt; + max = max(free, max);
&gt;&gt;&gt; + }
&gt;&gt;&gt; + }
&gt;&gt;&gt; +
&gt;&gt;&gt; + if (prev &amp;&amp; prev-&gt;end + 1 &lt; cxlrd-&gt;res-&gt;end + 1) {
&gt;&gt;&gt; + free = cxlrd-&gt;res-&gt;end + 1 - prev-&gt;end + 1;
&gt;&gt;&gt; + max = max(free, max);
&gt;&gt;&gt; + }
&gt;&gt;&gt; +
&gt;&gt;&gt; + dev_dbg(cxlrd_dev(cxlrd), &quot;found %pa bytes of free space\n&quot;, &amp;max);
&gt;&gt;&gt; + if (max &gt; ctx-&gt;max_hpa) {
&gt;&gt;&gt; + if (ctx-&gt;cxlrd)
&gt;&gt;&gt; + put_device(cxlrd_dev(ctx-&gt;cxlrd));
&gt;&gt;&gt; + get_device(cxlrd_dev(cxlrd));
&gt;&gt;&gt; + ctx-&gt;cxlrd = cxlrd;
&gt;&gt;&gt; + ctx-&gt;max_hpa = max;
&gt;&gt;&gt; + }
&gt;&gt;&gt; + return 0;
&gt;&gt;&gt; +}
&gt;&gt;&gt; +
&gt;&gt;&gt; +/**
&gt;&gt;&gt; + * cxl_get_hpa_freespace - find a root decoder with free capacity per constraints
&gt;&gt;&gt; + * @cxlmd: the mem device requiring the HPA
&gt;&gt;&gt; + * @interleave_ways: number of entries in @host_bridges
&gt;&gt;&gt; + * @flags: CXL_DECODER_F flags for selecting RAM vs PMEM, and Type2 device
&gt;&gt;&gt; + * @max_avail_contig: output parameter of max contiguous bytes available in the
&gt;&gt;&gt; + * returned decoder
&gt;&gt;&gt; + *
&gt;&gt;&gt; + * Returns a pointer to a struct cxl_root_decoder
&gt;&gt;&gt; + *
&gt;&gt;&gt; + * The return tuple of a &#x27;struct cxl_root_decoder&#x27; and &#x27;bytes available given
&gt;&gt;&gt; + * in (@max_avail_contig))&#x27; is a point in time snapshot. If by the time the
&gt;&gt;&gt; + * caller goes to use this decoder and its capacity is reduced then caller needs
&gt;&gt;&gt; + * to loop and retry.
&gt;&gt;&gt; + *
&gt;&gt;&gt; + * The returned root decoder has an elevated reference count that needs to be
&gt;&gt;&gt; + * put with cxl_put_root_decoder(cxlrd).
&gt;&gt;&gt; + */
&gt;&gt;&gt; +struct cxl_root_decoder *cxl_get_hpa_freespace(struct cxl_memdev *cxlmd,
&gt;&gt;&gt; + int interleave_ways,
&gt;&gt;&gt; + unsigned long flags,
&gt;&gt;&gt; + resource_size_t *max_avail_contig)
&gt;&gt;&gt; +{
&gt;&gt;&gt; + struct cxlrd_max_context ctx = {
&gt;&gt;&gt; + .flags = flags,
&gt;&gt;&gt; + .interleave_ways = interleave_ways,
&gt;&gt;&gt; + };
&gt;&gt;&gt; + struct cxl_port *root_port;
&gt;&gt;&gt; + struct cxl_port *endpoint;
&gt;&gt;&gt; +
&gt;&gt;&gt; + endpoint = cxlmd-&gt;endpoint;
&gt;&gt;&gt; + if (!endpoint) {
&gt;&gt;&gt; + dev_dbg(&amp;cxlmd-&gt;dev, &quot;endpoint not linked to memdev\n&quot;);
&gt;&gt;&gt; + return ERR_PTR(-ENXIO);
&gt;&gt;&gt; + }
&gt;&gt;&gt; +
&gt;&gt;&gt; + ctx.host_bridges = &amp;endpoint-&gt;host_bridge;
&gt;&gt; Mentioned earlier, interleave_ways is effectively hardcoded to 1 (unless I&#x27;m misunderstanding
&gt;&gt; something). I think what you want here is to go to the CXL root and pass in the children (i.e. host bridges)?
&gt;&gt; I&#x27;m not sure of what the fix is to get the intended behavior.
&gt;&gt;
&gt;&gt; It may be worth getting rid of the interleave_ways portion of this function and
&gt;&gt; add it later when someone needs it. You could also explain it&#x27;s hard coded to 1/unused
&gt;&gt; in the doc comment if you know of an immediate need for it.
&gt;&gt;
&gt;&gt;&gt; +
&gt;&gt;&gt; + struct cxl_root *root __free(put_cxl_root) = find_cxl_root(endpoint);
&gt;&gt;&gt; + if (!root) {
&gt;&gt;&gt; + dev_dbg(&amp;endpoint-&gt;dev, &quot;endpoint is not related to a root port\n&quot;);
&gt;&gt;&gt; + return ERR_PTR(-ENXIO);
&gt;&gt;&gt; + }
&gt;&gt;&gt; +
&gt;&gt;&gt; + root_port = &amp;root-&gt;port;
&gt;&gt;&gt; + scoped_guard(rwsem_read, &amp;cxl_rwsem.region)
&gt;&gt;&gt; + device_for_each_child(&amp;root_port-&gt;dev, &amp;ctx, find_max_hpa);
&gt;&gt; Can just use a guard() here.
&gt;&gt;
&gt;&gt;&gt; +
&gt;&gt;&gt; + if (!ctx.cxlrd)
&gt;&gt;&gt; + return ERR_PTR(-ENOMEM);
&gt;&gt;&gt; +
&gt;&gt;&gt; + *max_avail_contig = ctx.max_hpa;
&gt;&gt;&gt; + return ctx.cxlrd;
&gt;&gt;&gt; +}
&gt;&gt;&gt; +EXPORT_SYMBOL_NS_GPL(cxl_get_hpa_freespace, &quot;CXL&quot;);
&gt;&gt;&gt; +
&gt;&gt;&gt; +void cxl_put_root_decoder(struct cxl_root_decoder *cxlrd)
&gt;&gt;&gt; +{
&gt;&gt;&gt; + put_device(cxlrd_dev(cxlrd));
&gt;&gt;&gt; +}
&gt;&gt;&gt; +EXPORT_SYMBOL_NS_GPL(cxl_put_root_decoder, &quot;CXL&quot;);
&gt;&gt;&gt; +
&gt;&gt;&gt;  static ssize_t size_store(struct device *dev, struct device_attribute *attr,
&gt;&gt;&gt;  const char *buf, size_t len)
&gt;&gt;&gt;  {
&gt;&gt;&gt; diff --git a/drivers/cxl/cxl.h b/drivers/cxl/cxl.h
&gt;&gt;&gt; index 944c5d1ccceb..c7d9b2c2908f 100644
&gt;&gt;&gt; --- a/drivers/cxl/cxl.h
&gt;&gt;&gt; +++ b/drivers/cxl/cxl.h
&gt;&gt;&gt; @@ -706,6 +706,9 @@ struct cxl_root_decoder *to_cxl_root_decoder(struct device *dev);
&gt;&gt;&gt;  struct cxl_switch_decoder *to_cxl_switch_decoder(struct device *dev);
&gt;&gt;&gt;  struct cxl_endpoint_decoder *to_cxl_endpoint_decoder(struct device *dev);
&gt;&gt;&gt;  bool is_root_decoder(struct device *dev);
&gt;&gt;&gt; +
&gt;&gt;&gt; +#define cxlrd_dev(cxlrd) (&amp;(cxlrd)-&gt;cxlsd.cxld.dev)
&gt;&gt;&gt; +
&gt;&gt;&gt;  bool is_switch_decoder(struct device *dev);
&gt;&gt;&gt;  bool is_endpoint_decoder(struct device *dev);
&gt;&gt;&gt;  struct cxl_root_decoder *cxl_root_decoder_alloc(struct cxl_port *port,
&gt;&gt;&gt; diff --git a/include/cxl/cxl.h b/include/cxl/cxl.h
&gt;&gt;&gt; index 92880c26b2d5..834dc7e78934 100644
&gt;&gt;&gt; --- a/include/cxl/cxl.h
&gt;&gt;&gt; +++ b/include/cxl/cxl.h
&gt;&gt;&gt; @@ -255,4 +255,10 @@ struct cxl_endpoint_decoder *cxl_get_committed_decoder(struct cxl_memdev *cxlmd,
&gt;&gt;&gt;  struct range;
&gt;&gt;&gt;  int cxl_get_region_range(struct cxl_region *region, struct range *range);
&gt;&gt;&gt;  void cxl_unregister_region(struct cxl_region *cxlr);
&gt;&gt;&gt; +struct cxl_port;
&gt;&gt;&gt; +struct cxl_root_decoder *cxl_get_hpa_freespace(struct cxl_memdev *cxlmd,
&gt;&gt;&gt; + int interleave_ways,
&gt;&gt;&gt; + unsigned long flags,
&gt;&gt;&gt; + resource_size_t *max);
&gt;&gt;&gt; +void cxl_put_root_decoder(struct cxl_root_decoder *cxlrd);
&gt;&gt;&gt;  #endif /* __CXL_CXL_H__ */

</pre>
</details>
</div>
</div>
<div class="thread-node depth-1" id="2026-02-13">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Gregory Price</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="inline-review-badge">Inline Review</span>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Gregory Price noted that the patch introduces a potential reference leak and suggested further investigation.

The reviewer noted that in the cxl_find_free_decoder function, a device reference obtained by device_find_child is not properly released due to a missing put_device call, resulting in a permanent elevation of the endpoint decoder device refcount.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">This review was generated by kreview-0811365ff2. 

This is not an automated email, the reviewer though this report
looked valid enough to consider discussion.

----

Cursory browse, this does look like a legitimate reference leak.

~Gregory

----

---

Does this leak the device reference obtained by device_find_child()
in cxl_find_free_decoder()?

device_find_child() increments the device refcount (reference A).
Then cxl_dpa_alloc() -&gt; __cxl_dpa_reserve() calls get_device() on
the same device (reference B).

On the success path, no_free_ptr() inhibits the put_cxled cleanup,
so reference A is transferred to the caller.  The matching cleanup
function cxl_dpa_free() calls __cxl_dpa_release(), which drops
reference B via put_device(), but reference A is never released:

    cxl_dpa_free()
      -&gt; devm_cxl_dpa_release()
        -&gt; __cxl_dpa_release()
          -&gt; put_device()     /* drops reference B only */

    /* reference A from device_find_child() is still held */

The only caller in this series (sfc efx_cxl_init/efx_cxl_exit)
never calls put_device() on the returned cxled either, so the
endpoint decoder device refcount remains permanently elevated.</pre>
</details>
<div class="review-comment-signals">Signals: potential reference leak, leak, device reference</div>
</div>
<div class="thread-children">
<div class="thread-node depth-2" id="2026-02-16">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Alejandro Palau</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-16">2026-02-16</a>
<span class="inline-review-badge">Inline Review</span>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Alejandro Palau noted that the patch caused a memory leak due to not dropping the reference to the cxl device when allocating another one, and suggested adding a put_device() call to fix it.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">This is right, and it took a good bunch of time to debug it. Was it 
detected by an automatic tool?


Anyways, I had one patch for solving this which I forgot to apply to v23 
since the focus there was to mainly support the auto-discover region 
which does not go through this path:

+ /* removing the reference from cxl_find_free_decoder ...
+ * when alloc succeds another get happened
+ */
+
+ put_device(&amp;cxled-&gt;cxld.dev);


I added that comment because it is not trivial to know if it is right to 
do the put while you get a new reference to the device. I will apply it.

Thanks!</pre>
</details>
<div class="review-comment-signals">Signals: memory leak, requested changes</div>
</div>
</div>
<div class="thread-node depth-2" id="2026-02-20">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Alejandro Palau</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-20">2026-02-20</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer noted that the patchset should handle both module exit paths, specifically supporting cases where cxl is initialized before or after the driver is loaded.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Hi Gregory,


Yes, it makes sense and pointing out to those changes introduced in v22 
and mainly in v23.

I&#x27;ll fix it.


Regarding the below comment, which if I am not wrong comes from kreview, 
I think the patchset needs to support both cases and therefore the code 
needs to deal with both module exit paths.


Thank you</pre>
</details>
<div class="review-comment-signals">Signals: requested changes</div>
</div>
</div>
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Alejandro Palau</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-20">2026-02-20</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The reviewer noted that since they&#x27;ve only tested with one Virtual Interface (VI), they haven&#x27;t encountered an issue, but emphasized that it&#x27;s essential to fix the problem.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Yes, and again, it makes sense. We have only tried with one VI, so that 
explains why we have not suffered the issue. But it needs to be fixed.


Thanks!</pre>
</details>
<div class="review-comment-signals">Signals: issue, needs to be fixed</div>
</div>
</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Gregory Price</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="inline-review-badge">Inline Review</span>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">reviewer noted that the cxl by accelerators patch may have ordering issues due to acquiring the per-vswap spinlock while holding the folio lock in vswap_free(), which could lead to a lock ordering violation with reclaim paths

The reviewer noted that cxl_dpa_free() is called while the endpoint decoder is still attached to the region, resulting in a -EBUSY return value without freeing the DPA. The reviewer suggested calling cxl_unregister_region() before cxl_dpa_free() and cxl_put_root_decoder() to fix the ordering issue.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">This review was generated by kreview-0811365ff2. 

This is not an automated email, the reviewer though this report
looked valid enough to consider discussion.

----
sfc code so won&#x27;t speak to the internals, but ordering question seems
legit.

~Gregory
----

On Sat, Feb 01, 2026, Alejandro Lucero wrote:

---

In the non-committed path, cxl_dpa_free() is called while the
endpoint decoder is still attached to the region.  Looking at
cxl_dpa_free() in drivers/cxl/core/hdm.c:

    if (cxled-&gt;cxld.region) {
        dev_dbg(dev, &quot;decoder assigned to: %s\n&quot;,
            dev_name(&amp;cxled-&gt;cxld.region-&gt;dev));
        return -EBUSY;
    }

Since cxl_unregister_region() has not run yet, cxled-&gt;cxld.region
is still set, and cxl_dpa_free() returns -EBUSY without freeing
the DPA.  The return value is not checked.

Should cxl_unregister_region() be called before cxl_dpa_free()
and cxl_put_root_decoder() in the else branch, matching the
reverse order of allocation in efx_cxl_init()?

The cover letter notes that v23 expects committed decoders as the
primary flow, and uncommitted decoder support is deferred to
follow-up work, so this else branch may not be reachable in
practice today.  Still worth fixing the ordering now so it
doesn&#x27;t bite when the uncommitted path is enabled later.

This issue is not fixed by the remaining commits in the series
(through 10fe989f9e85).</pre>
</details>
<div class="review-comment-signals">Signals: ordering question seems legit, ordering issue, potential bug</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Gregory Price</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-13">2026-02-13</a>
<span class="inline-review-badge">Inline Review</span>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Gregory Price expressed uncertainty about the code and its purpose, stating he is unfamiliar with it but finds the question posed by the code reasonable.

The reviewer noted that the CXL path does not set nic_data-&gt;pio_write_vi_base, which causes efx_ef10_link_piobufs() to issue MC_CMD_LINK_PIOBUF commands and perform a special-case check using incorrect VI instances. The reviewer suggested that the struct field should be updated with the correct non-zero value of pio_write_vi_base.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">This review was generated by kreview-0811365ff2. 

This is not an automated email, the reviewer though this report
looked valid enough to consider discussion.

----
I am completely unfamiliar with this code, but the question it poses
at least seems reasonable.

~Gregory
----

On Sat, Feb 01, 2026, Alejandro Lucero wrote:

---

The CXL path sets nic_data-&gt;pio_write_base but does not set
nic_data-&gt;pio_write_vi_base, while the legacy path does:

    nic_data-&gt;pio_write_vi_base = pio_write_vi_base;

Since nic_data is kzalloc&#x27;d, pio_write_vi_base stays at 0 in the CXL
path.  efx_ef10_link_piobufs() then uses nic_data-&gt;pio_write_vi_base
to issue MC_CMD_LINK_PIOBUF commands:

    MCDI_SET_DWORD(inbuf, LINK_PIOBUF_IN_TXQ_INSTANCE,
                   nic_data-&gt;pio_write_vi_base + index);

and also for the special-case check:

    if (tx_queue-&gt;queue == nic_data-&gt;pio_write_vi_base) {

Wouldn&#x27;t this link PIO buffers to incorrect VI instances when using
CXL, since the local variable pio_write_vi_base has the correct
non-zero value but the struct field was never updated?</pre>
</details>
<div class="review-comment-signals">Signals: uncertainty, lack of familiarity, requested changes</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Dave Jiang</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-19">2026-02-19</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#155724;background:#d4edda">Positive</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Gave Reviewed-by</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">

On 2/1/26 8:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; Add cxl_unregister_region() to the accelerator driver API
&gt; for a clean exit.
&gt; 
&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;

Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;

&gt; ---
&gt;  drivers/cxl/core/region.c | 17 ++++++++++++-----
&gt;  include/cxl/cxl.h         |  1 +
&gt;  2 files changed, 13 insertions(+), 5 deletions(-)
&gt; 
&gt; diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
&gt; index acf29ba3b205..954b8fcdbac6 100644
&gt; --- a/drivers/cxl/core/region.c
&gt; +++ b/drivers/cxl/core/region.c
&gt; @@ -2438,9 +2438,8 @@ static struct cxl_region *to_cxl_region(struct device *dev)
&gt;  	return container_of(dev, struct cxl_region, dev);
&gt;  }
&gt;  
&gt; -static void unregister_region(void *_cxlr)
&gt; +void cxl_unregister_region(struct cxl_region *cxlr)
&gt;  {
&gt; -	struct cxl_region *cxlr = _cxlr;
&gt;  	struct cxl_region_params *p = &amp;cxlr-&gt;params;
&gt;  	int i;
&gt;  
&gt; @@ -2457,6 +2456,14 @@ static void unregister_region(void *_cxlr)
&gt;  	cxl_region_iomem_release(cxlr);
&gt;  	put_device(&amp;cxlr-&gt;dev);
&gt;  }
&gt; +EXPORT_SYMBOL_NS_GPL(cxl_unregister_region, &quot;CXL&quot;);
&gt; +
&gt; +static void __unregister_region(void *_cxlr)
&gt; +{
&gt; +	struct cxl_region *cxlr = _cxlr;
&gt; +
&gt; +	return cxl_unregister_region(cxlr);
&gt; +}
&gt;  
&gt;  static struct lock_class_key cxl_region_key;
&gt;  
&gt; @@ -2608,7 +2615,7 @@ static struct cxl_region *devm_cxl_add_region(struct cxl_root_decoder *cxlrd,
&gt;  	if (rc)
&gt;  		goto err;
&gt;  
&gt; -	rc = devm_add_action_or_reset(port-&gt;uport_dev, unregister_region, cxlr);
&gt; +	rc = devm_add_action_or_reset(port-&gt;uport_dev, __unregister_region, cxlr);
&gt;  	if (rc)
&gt;  		return ERR_PTR(rc);
&gt;  
&gt; @@ -2762,7 +2769,7 @@ static ssize_t delete_region_store(struct device *dev,
&gt;  	if (IS_ERR(cxlr))
&gt;  		return PTR_ERR(cxlr);
&gt;  
&gt; -	devm_release_action(port-&gt;uport_dev, unregister_region, cxlr);
&gt; +	devm_release_action(port-&gt;uport_dev, __unregister_region, cxlr);
&gt;  	put_device(&amp;cxlr-&gt;dev);
&gt;  
&gt;  	return len;
&gt; @@ -3878,7 +3885,7 @@ static struct cxl_region *construct_region(struct cxl_root_decoder *cxlrd,
&gt;  
&gt;  	rc = __construct_region(cxlr, cxlrd, cxled);
&gt;  	if (rc) {
&gt; -		devm_release_action(port-&gt;uport_dev, unregister_region, cxlr);
&gt; +		devm_release_action(port-&gt;uport_dev, __unregister_region, cxlr);
&gt;  		return ERR_PTR(rc);
&gt;  	}
&gt;  
&gt; diff --git a/include/cxl/cxl.h b/include/cxl/cxl.h
&gt; index 906065e0d2a6..92880c26b2d5 100644
&gt; --- a/include/cxl/cxl.h
&gt; +++ b/include/cxl/cxl.h
&gt; @@ -254,4 +254,5 @@ struct cxl_endpoint_decoder *cxl_get_committed_decoder(struct cxl_memdev *cxlmd,
&gt;  						       struct cxl_region **cxlr);
&gt;  struct range;
&gt;  int cxl_get_region_range(struct cxl_region *region, struct range *range);
&gt; +void cxl_unregister_region(struct cxl_region *cxlr);
&gt;  #endif /* __CXL_CXL_H__ */



---



On 2/1/26 8:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; Check if device HDM is already committed during firmware/BIOS
&gt; initialization.
&gt; 
&gt; A CXL region should exist if so after memdev allocation/initialization.
&gt; Get HPA from region and map it.
&gt; 
&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; ---
&gt;  drivers/net/ethernet/sfc/efx_cxl.c | 28 +++++++++++++++++++++++++++-
&gt;  1 file changed, 27 insertions(+), 1 deletion(-)
&gt; 
&gt; diff --git a/drivers/net/ethernet/sfc/efx_cxl.c b/drivers/net/ethernet/sfc/efx_cxl.c
&gt; index a77ef4783fcb..3536eccf1b2a 100644
&gt; --- a/drivers/net/ethernet/sfc/efx_cxl.c
&gt; +++ b/drivers/net/ethernet/sfc/efx_cxl.c
&gt; @@ -19,6 +19,7 @@ int efx_cxl_init(struct efx_probe_data *probe_data)
&gt;  	struct efx_nic *efx = &amp;probe_data-&gt;efx;
&gt;  	struct pci_dev *pci_dev = efx-&gt;pci_dev;
&gt;  	struct efx_cxl *cxl;
&gt; +	struct range range;
&gt;  	u16 dvsec;
&gt;  	int rc;
&gt;  
&gt; @@ -90,13 +91,38 @@ int efx_cxl_init(struct efx_probe_data *probe_data)
&gt;  		return PTR_ERR(cxl-&gt;cxlmd);
&gt;  	}
&gt;  
&gt; -	probe_data-&gt;cxl = cxl;
&gt; +	cxl-&gt;cxled = cxl_get_committed_decoder(cxl-&gt;cxlmd, &amp;cxl-&gt;efx_region);
&gt; +	if (cxl-&gt;cxled) {

if (!cxl-&gt;cxled)
	return 0;

Should save you a level of indent.

DJ

&gt; +		if (!cxl-&gt;efx_region) {
&gt; +			pci_err(pci_dev, &quot;CXL found committed decoder without a region&quot;);
&gt; +			return -ENODEV;
&gt; +		}
&gt; +		rc = cxl_get_region_range(cxl-&gt;efx_region, &amp;range);
&gt; +		if (rc) {
&gt; +			pci_err(pci_dev,
&gt; +				&quot;CXL getting regions params from a committed decoder failed&quot;);
&gt; +			return rc;
&gt; +		}
&gt; +
&gt; +		cxl-&gt;ctpio_cxl = ioremap(range.start, range.end - range.start + 1);
&gt; +		if (!cxl-&gt;ctpio_cxl) {
&gt; +			pci_err(pci_dev, &quot;CXL ioremap region (%pra) failed&quot;, &amp;range);
&gt; +			return -ENOMEM;
&gt; +		}
&gt; +
&gt; +		probe_data-&gt;cxl = cxl;
&gt; +	}
&gt;  
&gt;  	return 0;
&gt;  }
&gt;  
&gt;  void efx_cxl_exit(struct efx_probe_data *probe_data)
&gt;  {
&gt; +	if (!probe_data-&gt;cxl)
&gt; +		return;
&gt; +
&gt; +	iounmap(probe_data-&gt;cxl-&gt;ctpio_cxl);
&gt; +	cxl_unregister_region(probe_data-&gt;cxl-&gt;efx_region);
&gt;  }
&gt;  
&gt;  MODULE_IMPORT_NS(&quot;CXL&quot;);



---



On 2/1/26 8:54 AM, alejandro.lucero-palau@amd.com wrote:
&gt; From: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; 
&gt; CXL region creation involves allocating capacity from Device Physical
&gt; Address (DPA) and assigning it to decode a given Host Physical Address
&gt; (HPA). Before determining how much DPA to allocate the amount of available
&gt; HPA must be determined. Also, not all HPA is created equal, some HPA
&gt; targets RAM, some targets PMEM, some is prepared for device-memory flows
&gt; like HDM-D and HDM-DB, and some is HDM-H (host-only).
&gt; 
&gt; In order to support Type2 CXL devices, wrap all of those concerns into
&gt; an API that retrieves a root decoder (platform CXL window) that fits the
&gt; specified constraints and the capacity available for a new region.
&gt; 
&gt; Add a complementary function for releasing the reference to such root
&gt; decoder.
&gt; 
&gt; Based on https://lore.kernel.org/linux-cxl/168592159290.1948938.13522227102445462976.stgit@dwillia2-xfh.jf.intel.com/
&gt; 
&gt; Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
&gt; Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
&gt; ---
&gt;  drivers/cxl/core/region.c | 164 ++++++++++++++++++++++++++++++++++++++
&gt;  drivers/cxl/cxl.h         |   3 +
&gt;  include/cxl/cxl.h         |   6 ++
&gt;  3 files changed, 173 insertions(+)
&gt; 
&gt; diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
&gt; index 954b8fcdbac6..bdefd088f5f1 100644
&gt; --- a/drivers/cxl/core/region.c
&gt; +++ b/drivers/cxl/core/region.c
&gt; @@ -705,6 +705,170 @@ static int free_hpa(struct cxl_region *cxlr)
&gt;  	return 0;
&gt;  }
&gt;  
&gt; +struct cxlrd_max_context {
&gt; +	struct device * const *host_bridges;
&gt; +	int interleave_ways;
&gt; +	unsigned long flags;
&gt; +	resource_size_t max_hpa;
&gt; +	struct cxl_root_decoder *cxlrd;
&gt; +};
&gt; +
&gt; +static int find_max_hpa(struct device *dev, void *data)
&gt; +{
&gt; +	struct cxlrd_max_context *ctx = data;
&gt; +	struct cxl_switch_decoder *cxlsd;
&gt; +	struct cxl_root_decoder *cxlrd;
&gt; +	struct resource *res, *prev;
&gt; +	struct cxl_decoder *cxld;
&gt; +	resource_size_t free = 0;
&gt; +	resource_size_t max;
&gt; +	int found = 0;
&gt; +
&gt; +	if (!is_root_decoder(dev))
&gt; +		return 0;
&gt; +
&gt; +	cxlrd = to_cxl_root_decoder(dev);
&gt; +	cxlsd = &amp;cxlrd-&gt;cxlsd;
&gt; +	cxld = &amp;cxlsd-&gt;cxld;
&gt; +
&gt; +	if ((cxld-&gt;flags &amp; ctx-&gt;flags) != ctx-&gt;flags) {
&gt; +		dev_dbg(dev, &quot;flags not matching: %08lx vs %08lx\n&quot;,
&gt; +			cxld-&gt;flags, ctx-&gt;flags);
&gt; +		return 0;
&gt; +	}
&gt; +
&gt; +	for (int i = 0; i &lt; ctx-&gt;interleave_ways; i++) {
&gt; +		for (int j = 0; j &lt; ctx-&gt;interleave_ways; j++) {
&gt; +			if (ctx-&gt;host_bridges[i] == cxlsd-&gt;target[j]-&gt;dport_dev) {
&gt; +				found++;
&gt; +				break;
&gt; +			}
&gt; +		}
&gt; +	}
&gt; +
&gt; +	if (found != ctx-&gt;interleave_ways) {
&gt; +		dev_dbg(dev,
&gt; +			&quot;Not enough host bridges. Found %d for %d interleave ways requested\n&quot;,
&gt; +			found, ctx-&gt;interleave_ways);
&gt; +		return 0;
&gt; +	}
&gt; +
&gt; +	/*
&gt; +	 * Walk the root decoder resource range relying on cxl_rwsem.region to
&gt; +	 * preclude sibling arrival/departure and find the largest free space
&gt; +	 * gap.
&gt; +	 */
&gt; +	lockdep_assert_held_read(&amp;cxl_rwsem.region);
&gt; +	res = cxlrd-&gt;res-&gt;child;
&gt; +
&gt; +	/* With no resource child the whole parent resource is available */
&gt; +	if (!res)
&gt; +		max = resource_size(cxlrd-&gt;res);
&gt; +	else
&gt; +		max = 0;
&gt; +
&gt; +	for (prev = NULL; res; prev = res, res = res-&gt;sibling) {
&gt; +		if (!prev &amp;&amp; res-&gt;start == cxlrd-&gt;res-&gt;start &amp;&amp;
&gt; +		    res-&gt;end == cxlrd-&gt;res-&gt;end) {
&gt; +			max = resource_size(cxlrd-&gt;res);
&gt; +			break;
&gt; +		}

Can this block be pulled out of the for loop so it only needs to run once?

&gt; +		/*
&gt; +		 * Sanity check for preventing arithmetic problems below as a
&gt; +		 * resource with size 0 could imply using the end field below
&gt; +		 * when set to unsigned zero - 1 or all f in hex.
&gt; +		 */
&gt; +		if (prev &amp;&amp; !resource_size(prev))
&gt; +			continue;
&gt; +
&gt; +		if (!prev &amp;&amp; res-&gt;start &gt; cxlrd-&gt;res-&gt;start) {
&gt; +			free = res-&gt;start - cxlrd-&gt;res-&gt;start;
&gt; +			max = max(free, max);
&gt; +		}
&gt; +		if (prev &amp;&amp; res-&gt;start &gt; prev-&gt;end + 1) {
&gt; +			free = res-&gt;start - prev-&gt;end + 1;
&gt; +			max = max(free, max);
&gt; +		}
&gt; +	}
&gt; +
&gt; +	if (prev &amp;&amp; prev-&gt;end + 1 &lt; cxlrd-&gt;res-&gt;end + 1) {
&gt; +		free = cxlrd-&gt;res-&gt;end + 1 - prev-&gt;end + 1;
&gt; +		max = max(free, max);
&gt; +	}
&gt; +
&gt; +	dev_dbg(cxlrd_dev(cxlrd), &quot;found %pa bytes of free space\n&quot;, &amp;max);
&gt; +	if (max &gt; ctx-&gt;max_hpa) {
&gt; +		if (ctx-&gt;cxlrd)
&gt; +			put_device(cxlrd_dev(ctx-&gt;cxlrd));
&gt; +		get_device(cxlrd_dev(cxlrd));
&gt; +		ctx-&gt;cxlrd = cxlrd;
&gt; +		ctx-&gt;max_hpa = max;

Is there any chance that ctx-&gt;cxlrd == cxlrd? Maybe you can do:

if (ctx-&gt;cxlrd &amp;&amp; ctx-&gt;cxlrd != cxlrd) {
	put_device(cxlrd_dev(ctx-&gt;cxlrd));
	get_device(cxlrd_dev(cxlrd));
	ctx-&gt;cxlrd = cxlrd;
}
ctx-&gt;max_hpa = max;

DJ

&gt; +	}
&gt; +	return 0;
&gt; +}
&gt; +
&gt; +/**
&gt; + * cxl_get_hpa_freespace - find a root decoder with free capacity per constraints
&gt; + * @cxlmd: the mem device requiring the HPA
&gt; + * @interleave_ways: number of entries in @host_bridges
&gt; + * @flags: CXL_DECODER_F flags for selecting RAM vs PMEM, and Type2 device
&gt; + * @max_avail_contig: output parameter of max contiguous bytes available in the
&gt; + *		      returned decoder
&gt; + *
&gt; + * Returns a pointer to a struct cxl_root_decoder
&gt; + *
&gt; + * The return tuple of a &#x27;struct cxl_root_decoder&#x27; and &#x27;bytes available given
&gt; + * in (@max_avail_contig))&#x27; is a point in time snapshot. If by the time the
&gt; + * caller goes to use this decoder and its capacity is reduced then caller needs
&gt; + * to loop and retry.
&gt; + *
&gt; + * The returned root decoder has an elevated reference count that needs to be
&gt; + * put with cxl_put_root_decoder(cxlrd).
&gt; + */
&gt; +struct cxl_root_decoder *cxl_get_hpa_freespace(struct cxl_memdev *cxlmd,
&gt; +					       int interleave_ways,
&gt; +					       unsigned long flags,
&gt; +					       resource_size_t *max_avail_contig)
&gt; +{
&gt; +	struct cxlrd_max_context ctx = {
&gt; +		.flags = flags,
&gt; +		.interleave_ways = interleave_ways,
&gt; +	};
&gt; +	struct cxl_port *root_port;
&gt; +	struct cxl_port *endpoint;
&gt; +
&gt; +	endpoint = cxlmd-&gt;endpoint;
&gt; +	if (!endpoint) {
&gt; +		dev_dbg(&amp;cxlmd-&gt;dev, &quot;endpoint not linked to memdev\n&quot;);
&gt; +		return ERR_PTR(-ENXIO);
&gt; +	}
&gt; +
&gt; +	ctx.host_bridges = &amp;endpoint-&gt;host_bridge;
&gt; +
&gt; +	struct cxl_root *root __free(put_cxl_root) = find_cxl_root(endpoint);
&gt; +	if (!root) {
&gt; +		dev_dbg(&amp;endpoint-&gt;dev, &quot;endpoint is not related to a root port\n&quot;);
&gt; +		return ERR_PTR(-ENXIO);
&gt; +	}
&gt; +
&gt; +	root_port = &amp;root-&gt;port;
&gt; +	scoped_guard(rwsem_read, &amp;cxl_rwsem.region)
&gt; +		device_for_each_child(&amp;root_port-&gt;dev, &amp;ctx, find_max_hpa);
&gt; +
&gt; +	if (!ctx.cxlrd)
&gt; +		return ERR_PTR(-ENOMEM);
&gt; +
&gt; +	*max_avail_contig = ctx.max_hpa;
&gt; +	return ctx.cxlrd;
&gt; +}
&gt; +EXPORT_SYMBOL_NS_GPL(cxl_get_hpa_freespace, &quot;CXL&quot;);
&gt; +
&gt; +void cxl_put_root_decoder(struct cxl_root_decoder *cxlrd)
&gt; +{
&gt; +	put_device(cxlrd_dev(cxlrd));
&gt; +}
&gt; +EXPORT_SYMBOL_NS_GPL(cxl_put_root_decoder, &quot;CXL&quot;);
&gt; +
&gt;  static ssize_t size_store(struct device *dev, struct device_attribute *attr,
&gt;  			  const char *buf, size_t len)
&gt;  {
&gt; diff --git a/drivers/cxl/cxl.h b/drivers/cxl/cxl.h
&gt; index 944c5d1ccceb..c7d9b2c2908f 100644
&gt; --- a/drivers/cxl/cxl.h
&gt; +++ b/drivers/cxl/cxl.h
&gt; @@ -706,6 +706,9 @@ struct cxl_root_decoder *to_cxl_root_decoder(struct device *dev);
&gt;  struct cxl_switch_decoder *to_cxl_switch_decoder(struct device *dev);
&gt;  struct cxl_endpoint_decoder *to_cxl_endpoint_decoder(struct device *dev);
&gt;  bool is_root_decoder(struct device *dev);
&gt; +
&gt; +#define cxlrd_dev(cxlrd) (&amp;(cxlrd)-&gt;cxlsd.cxld.dev)
&gt; +
&gt;  bool is_switch_decoder(struct device *dev);
&gt;  bool is_endpoint_decoder(struct device *dev);
&gt;  struct cxl_root_decoder *cxl_root_decoder_alloc(struct cxl_port *port,
&gt; diff --git a/include/cxl/cxl.h b/include/cxl/cxl.h
&gt; index 92880c26b2d5..834dc7e78934 100644
&gt; --- a/include/cxl/cxl.h
&gt; +++ b/include/cxl/cxl.h
&gt; @@ -255,4 +255,10 @@ struct cxl_endpoint_decoder *cxl_get_committed_decoder(struct cxl_memdev *cxlmd,
&gt;  struct range;
&gt;  int cxl_get_region_range(struct cxl_region *region, struct range *range);
&gt;  void cxl_unregister_region(struct cxl_region *cxlr);
&gt; +struct cxl_port;
&gt; +struct cxl_root_decoder *cxl_get_hpa_freespace(struct cxl_memdev *cxlmd,
&gt; +					       int interleave_ways,
&gt; +					       unsigned long flags,
&gt; +					       resource_size_t *max);
&gt; +void cxl_put_root_decoder(struct cxl_root_decoder *cxlrd);
&gt;  #endif /* __CXL_CXL_H__ */

</pre>
</details>
</div>
<div class="thread-children">
<div class="thread-node depth-2">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Alejandro Palau</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-20">2026-02-20</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">reviewer noted that the current implementation lacks an &#x27;else&#x27; branch for when CXL is not enabled, and requested that subsequent patches address this omission</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Yes, but subsequent patches add the else branch ...


Thanks</pre>
</details>
<div class="review-comment-signals">Signals: missing else branch</div>
</div>
</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Dave Jiang</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-19">2026-02-19</a>
<span class="inline-review-badge">Inline Review</span>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Dave Jiang suggested simplifying the cxl code by saving an indentation level, and provided a specific line to modify</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">if (!cxl-&gt;cxled)
	return 0;

Should save you a level of indent.

DJ</pre>
</details>
<div class="review-comment-signals">Signals: suggested improvement, code optimization</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Dave Jiang</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-20">2026-02-20</a>
<span class="inline-review-badge">Inline Review</span>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Dave Jiang noted that the ctx-&gt;cxlrd pointer might not be updated correctly, suggesting a check to ensure it matches cxlrd before updating it, and proposed code to handle this case</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">Is there any chance that ctx-&gt;cxlrd == cxlrd? Maybe you can do:

if (ctx-&gt;cxlrd &amp;&amp; ctx-&gt;cxlrd != cxlrd) {
	put_device(cxlrd_dev(ctx-&gt;cxlrd));
	get_device(cxlrd_dev(cxlrd));
	ctx-&gt;cxlrd = cxlrd;
}
ctx-&gt;max_hpa = max;

DJ</pre>
</details>
<div class="review-comment-signals">Signals: requested changes</div>
</div>
</div>
<div class="thread-node depth-1">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">Gregory Price</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-20">2026-02-20</a>
<span class="review-tag-badge">Reviewed-by</span>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Reviewer Gregory Price noted that during testing, he observed double-releases when aggressively loading and unloading certain drivers, which was fixed by adding a function to properly unregister regions in cxl_destroy_region()</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">kreview suggested you probably want this:

void cxl_destroy_region(struct cxl_region *cxlr)
{
	struct cxl_port *port = cxlrd_to_port(cxlr-&gt;cxlrd);

	devm_release_action(port-&gt;uport_dev, __unregister_region, cxlr);
}
EXPORT_SYMBOL_NS_GPL(cxl_destroy_region, &quot;CXL&quot;);


During testing I experienced some double-releases when doing aggressive
loads and unloads of some drivers.  This was one of the fixes.

~Gregory</pre>
</details>
<div class="review-comment-signals">Signals: fixes a bug, requested changes</div>
</div>
</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">alejandro.lucero-palau (author)</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-01">2026-02-01</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The author is addressing a concern about the dependency on Smita&#x27;s patchset, specifically [PATCH v5 3/7] cxl/region: Skip decoder reset on detach for autodiscovered regions. The author confirms that this patch is needed to support the default behavior with current BIOS configuration and explains that it will be supported in follow-up works.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">From: Alejandro Lucero &lt;alucerop@amd.com&gt;

This patchset should be applied on the cxl next branch using the base
specified at the end of this cover letter.

Dependencies on Dan&#x27;s work has gone and also on Terry&#x27;s as the only
patch required is now in next. The other dependency is on Smita patchset
but it does not exist such a dependency as that work will not avoid the
problem with Type2 and DAX/hmem if soft reserved memory. This needs to
be solved by the BIOS and Type2 UEFI driver for populating the CXL.mem
range as EFI_RESERVED_TYPE instead of default EFI_CONVENTIONAL_MEMORY
with the EFI_MEMORY_SP attribute. There exists though a dependency on
one Smita&#x27;s patches:

[PATCH v5 3/7] cxl/region: Skip decoder reset on detach for autodiscovered regions

This is needed for the default behaviour with current BIOS configuration
where the HDM Type2 decoders will be kept unreset when driver unloads.
This is the main change introduced in v23: committed decoders will not
be reset. Previous v22 functionality supported first driver load finding
committed decoders but resetting them at unload and supporting
uncommitted decoders in next driver loads. This will be suported in
follow-up works.

v23 changes:

  patch 11: fixing minor issues and droping change in
	    should_emulate_decoders (Jonathan Cameron)

  patch13: refactoring unregister_region for safety type in Type2 API

  sfc changes: slight modifications to error path


v22 changes:

  patch 1-3 from Dan&#x27;s branch without any changes.

  patch 11: new
  
  patch 12: moved here from v21 patch 22

  patch 13-14: new

  patch 23: move check ahead of type3 only checks

  All patches with sfc changes adapted to support both options.

v21 changes;

  patch1-2: v20 patch1 splitted up doing the code move in the second
	    patch in v21. (Jonathan)
 
  patch1-4: adding my Signed-off tag along with Dan&#x27;s

  patch5: fix duplication of CXL_NR_PARTITION definition

  patch7: dropped the cxl test fixes removing unused function. It was
	  sent independently ahead of this version.

  patch12: optimization for max free space calculation (Jonathan)

  patch19: optimization for returning on error (Jonathan)


v20 changes:

  patch 1: using release helps (Jonathan).

  patch 6: minor fix in comments (Jonathan).

  patch 7 &amp; 8: change commit mentioning sfc changes

  patch 11:	 Fix interleave_ways setting (Jonathan)
		Change assignament location (Dave)

  patch 13:  	changing error return order (Jonathan)
		removing blank line (Dave)

  patch 18:	Add check for only supporting uncommitted decoders
			(Ben, Dave)
		Add check for returned value (Dave)

v19 changes:

  Removal of cxl_acquire_endpoint and driver callback for unexpected cxl
  module removal. Dan&#x27;s patches made them unnecessary.

  patch 4: remove code already moved by Terry&#x27;s patches (Ben Cheatham)

  patch 6: removed unrelated change (Ben Cheatham)

  patch 7: fix error report inconsistencies (Jonathan, Dave)

  patch 9: remove unnecessary comment (Ben Cheatham)

  patch 11: fix __free usage (Jonathan Cameron, Ben Cheatham)

  patch 13: style fixes (Jonathan Cameron, Dave Jiag)

  patch 14: move code to previous patch (Jonathan Cameron)

  patch 18: group code in one locking (Dave Jian)
	    use __free helper (Ben Cheatham)


v18 changes:

  patch 1: minor changes and fixing docs generation (Jonathan, Dan)
 
  patch4: merged with v17 patch5

  patch 5: merging v17 patches 6 and 7

  patch 6: adding helpers for clarity

  patch 9:
	- minor changes (Dave)
	- simplifying flags check (Dan)

  patch 10: minor changes (Jonathan)

  patch 11:
	- minor changes (Dave)
	- fix mess (Jonathan, Dave)

  patch 18: minor changes (Jonathan, Dan)
  
v17 changes: (Dan Williams review)
 - use devm for cxl_dev_state allocation
 - using current cxl struct for checking capability registers found by
   the driver.
 - simplify dpa initialization without a mailbox not supporting pmem
 - add cxl_acquire_endpoint for protection during initialization
 - add callback/action to cxl_create_region for a driver notified about cxl
   core kernel modules removal.
 - add sfc function to disable CXL-based PIO buffers if such a callback
   is invoked.
 - Always manage a Type2 created region as private not allowing DAX.

v16 changes:
 - rebase against rc4 (Dave Jiang)
 - remove duplicate line (Ben Cheatham)

v15 changes:
 - remove reference to unused header file (Jonathan Cameron)
 - add proper kernel docs to exported functions (Alison Schofield)
 - using an array to map the enums to strings (Alison Schofield)
 - clarify comment when using bitmap_subset (Jonathan Cameron)
 - specify link to type2 support in all patches (Alison Schofield)

  Patches changed (minor): 4, 11

v14 changes:
 - static null initialization of bitmaps (Jonathan Cameron)
 - Fixing cxl tests (Alison Schofield)
 - Fixing robot compilation problems

  Patches changed (minor): 1, 4, 6, 13

v13 changes:
 - using names for headers checking more consistent (Jonathan Cameron)
 - using helper for caps bit setting (Jonathan Cameron)
 - provide generic function for reporting missing capabilities (Jonathan Cameron)
 - rename cxl_pci_setup_memdev_regs to cxl_pci_accel_setup_memdev_regs (Jonathan Cameron)
 - cxl_dpa_info size to be set by the Type2 driver (Jonathan Cameron)
 - avoiding rc variable when possible (Jonathan Cameron)
 - fix spelling (Simon Horman)
 - use scoped_guard (Dave Jiang)
 - use enum instead of bool (Dave Jiang)
 - dropping patch with hardware symbols

v12 changes:
 - use new macro cxl_dev_state_create in pci driver (Ben Cheatham)
 - add public/private sections in now exported cxl_dev_state struct (Ben
   Cheatham)
 - fix cxl/pci.h regarding file name for checking if defined
 - Clarify capabilities found vs expected in error message. (Ben
   Cheatham)
 - Clarify new CXL_DECODER_F flag (Ben Cheatham)
 - Fix changes about cxl memdev creation support moving code to the
   proper patch. (Ben Cheatham)
 - Avoid debug and function duplications (Ben Cheatham)

v11 changes:
 - Dropping the use of cxl_memdev_state and going back to using
   cxl_dev_state.
 - Using a helper for an accel driver to allocate its own cxl-related
   struct embedding cxl_dev_state.
 - Exporting the required structs in include/cxl/cxl.h for an accel
   driver being able to know the cxl_dev_state size required in the
   previously mentioned helper for allocation.
 - Avoid using any struct for dpa initialization by the accel driver
   adding a specific function for creating dpa partitions by accel
   drivers without a mailbox.

v10 changes:
 - Using cxl_memdev_state instead of cxl_dev_state for type2 which has a
   memory after all and facilitates the setup.
 - Adapt core for using cxl_memdev_state allowing accel drivers to work
   with them without further awareness of internal cxl structs.
 - Using last DPA changes for creating DPA partitions with accel driver
   hardcoding mds values when no mailbox.
 - capabilities not a new field but built up when current register maps
   is performed and returned to the caller for checking.
 - HPA free space supporting interleaving.
 - DPA free space droping max-min for a simple alloc size.

v9 changes:
 - adding forward definitions (Jonathan Cameron)
 - using set_bit instead of bitmap_set (Jonathan Cameron)
 - fix rebase problem (Jonathan Cameron)
 - Improve error path (Jonathan Cameron)
 - fix build problems with cxl region dependency (robot)
 - fix error path (Simon Horman)

v8 changes:
 - Change error path labeling inside sfc cxl code (Edward Cree)
 - Properly handling checks and error in sfc cxl code (Simon Horman)
 - Fix bug when checking resource_size (Simon Horman)
 - Avoid bisect problems reordering patches (Edward Cree)
 - Fix buffer allocation size in sfc (Simon Horman)

v7 changes:

 - fixing kernel test robot complains
 - fix type with Type3 mandatory capabilities (Zhi Wang)
 - optimize code in cxl_request_resource (Kalesh Anakkur Purayil)
 - add sanity check when dealing with resources arithmetics (Fan Ni)
 - fix typos and blank lines (Fan Ni)
 - keep previous log errors/warnings in sfc driver (Martin Habets)
 - add WARN_ON_ONCE if region given is NULL

v6 changes:

 - update sfc mcdi_pcol.h with full hardware changes most not related to
   this patchset. This is an automatic file created from hardware design
   changes and not touched by software. It is updated from time to time
   and it required update for the sfc driver CXL support.
 - remove CXL capabilities definitions not used by the patchset or
   previous kernel code. (Dave Jiang, Jonathan Cameron)
 - Use bitmap_subset instead of reinventing the wheel ... (Ben Cheatham)
 - Use cxl_accel_memdev for new device_type created (Ben Cheatham)
 - Fix construct_region use of rwsem (Zhi Wang)
 - Obtain region range instead of region params (Allison Schofield, Dave
   Jiang)

v5 changes:

 - Fix SFC configuration based on kernel CXL configuration
 - Add subset check for capabilities.
 - fix region creation when HDM decoders programmed by firmware/BIOS (Ben
   Cheatham)
 - Add option for creating dax region based on driver decission (Ben
   Cheatham)
 - Using sfc probe_data struct for keeping sfc cxl data

v4 changes:

 - Use bitmap for capabilities new field (Jonathan Cameron)
 - Use cxl_mem attributes for sysfs based on device type (Dave Jian)
 - Add conditional cxl sfc compilation relying on kernel CXL config (kernel test robot)
 - Add sfc changes in different patches for facilitating backport (Jonathan Cameron)
 - Remove patch for dealing with cxl modules dependencies and using sfc kconfig plus
   MODULE_SOFTDEP instead.

v3 changes:

 - cxl_dev_state not defined as opaque but only manipulated by accel drivers
   through accessors.
 - accessors names not identified as only for accel drivers.
 - move pci code from pci driver (drivers/cxl/pci.c) to generic pci code
   (drivers/cxl/core/pci.c).
 - capabilities field from u8 to u32 and initialised by CXL regs discovering
   code.
 - add capabilities check and removing current check by CXL regs discovering
   code.
 - Not fail if CXL Device Registers not found. Not mandatory for Type2.
 - add timeout in acquire_endpoint for solving a race with the endpoint port
   creation.
 - handle EPROBE_DEFER by sfc driver.
 - Limiting interleave ways to 1 for accel driver HPA/DPA requests.
 - factoring out interleave ways and granularity helpers from type2 region
   creation patch.
 - restricting region_creation for type2 to one endpoint decoder.

v2 changes:

I have removed the introduction about the concerns with BIOS/UEFI after the
discussion leading to confirm the need of the functionality implemented, at
least is some scenarios.

There are two main changes from the RFC:

1) Following concerns about drivers using CXL core without restrictions, the CXL
struct to work with is opaque to those drivers, therefore functions are
implemented for modifying or reading those structs indirectly.

2) The driver for using the added functionality is not a test driver but a real
one: the SFC ethernet network driver. It uses the CXL region mapped for PIO
buffers instead of regions inside PCIe BARs.

RFC:

Current CXL kernel code is focused on supporting Type3 CXL devices, aka memory
expanders. Type2 CXL devices, aka device accelerators, share some functionalities
but require some special handling.

First of all, Type2 are by definition specific to drivers doing something and not just
a memory expander, so it is expected to work with the CXL specifics. This implies the CXL
setup needs to be done by such a driver instead of by a generic CXL PCI driver
as for memory expanders. Most of such setup needs to use current CXL core code
and therefore needs to be accessible to those vendor drivers. This is accomplished
exporting opaque CXL structs and adding and exporting functions for working with
those structs indirectly.

Some of the patches are based on a patchset sent by Dan Williams [1] which was just
partially integrated, most related to making things ready for Type2 but none
related to specific Type2 support. Those patches based on Dans work have Dans
signing as co-developer, and a link to the original patch.

A final note about CXL.cache is needed. This patchset does not cover it at all,
although the emulated Type2 device advertises it. From the kernel point of view
supporting CXL.cache will imply to be sure the CXL path supports what the Type2
device needs. A device accelerator will likely be connected to a Root Switch,
but other configurations can not be discarded. Therefore the kernel will need to
check not just HPA, DPA, interleave and granularity, but also the available
CXL.cache support and resources in each switch in the CXL path to the Type2
device. I expect to contribute to this support in the following months, and
it would be good to discuss about it when possible.

[1] https://lore.kernel.org/linux-cxl/98b1f61a-e6c2-71d4-c368-50d958501b0c@intel.com/T/

Alejandro Lucero (22):
  cxl: Add type2 device basic support
  sfc: add cxl support
  cxl: Move pci generic code
  cxl/sfc: Map cxl component regs
  cxl/sfc: Initialize dpa without a mailbox
  cxl: Prepare memdev creation for type2
  sfc: create type2 cxl memdev
  cxl/hdm: Add support for getting region from committed decoder
  cxl: Add function for obtaining region range
  cxl: Export function for unwinding cxl by accelerators
  sfc: obtain decoder and region if committed by firmware
  cxl: Define a driver interface for HPA free space enumeration
  sfc: get root decoder
  cxl: Define a driver interface for DPA allocation
  sfc: get endpoint decoder
  cxl: Make region type based on endpoint type
  cxl/region: Factor out interleave ways setup
  cxl/region: Factor out interleave granularity setup
  cxl: Allow region creation by type2 drivers
  cxl: Avoid dax creation for accelerators
  sfc: create cxl region
  sfc: support pio mapping based on cxl

 drivers/cxl/core/core.h               |   5 +-
 drivers/cxl/core/hdm.c                | 123 ++++++++
 drivers/cxl/core/mbox.c               |  63 +---
 drivers/cxl/core/memdev.c             | 113 ++++++-
 drivers/cxl/core/pci.c                |  63 ++++
 drivers/cxl/core/port.c               |   1 +
 drivers/cxl/core/region.c             | 434 +++++++++++++++++++++++---
 drivers/cxl/core/regs.c               |   2 +-
 drivers/cxl/cxl.h                     | 125 +-------
 drivers/cxl/cxlmem.h                  |  92 +-----
 drivers/cxl/cxlpci.h                  |  21 +-
 drivers/cxl/mem.c                     |  45 ++-
 drivers/cxl/pci.c                     |  85 +----
 drivers/net/ethernet/sfc/Kconfig      |  10 +
 drivers/net/ethernet/sfc/Makefile     |   1 +
 drivers/net/ethernet/sfc/ef10.c       |  50 ++-
 drivers/net/ethernet/sfc/efx.c        |  15 +-
 drivers/net/ethernet/sfc/efx_cxl.c    | 186 +++++++++++
 drivers/net/ethernet/sfc/efx_cxl.h    |  41 +++
 drivers/net/ethernet/sfc/net_driver.h |  12 +
 drivers/net/ethernet/sfc/nic.h        |   3 +
 include/cxl/cxl.h                     | 287 +++++++++++++++++
 include/cxl/pci.h                     |  21 ++
 tools/testing/cxl/test/mem.c          |   3 +-
 24 files changed, 1376 insertions(+), 425 deletions(-)
 create mode 100644 drivers/net/ethernet/sfc/efx_cxl.c
 create mode 100644 drivers/net/ethernet/sfc/efx_cxl.h
 create mode 100644 include/cxl/cxl.h
 create mode 100644 include/cxl/pci.h


base-commit: 3f7938b1aec7f06d5b23adca83e4542fcf027001
-- 
2.34.1</pre>
</details>
<div class="review-comment-signals">Signals: clarification, explanation</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">alejandro.lucero-palau (author)</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-01">2026-02-01</a>
<span class="badge" style="color:#155724;background:#d4edda">Positive</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The author addressed a concern about the export of cxl core functions for Type2 driver discovery and mapping, explained that they are being used in sfc driver cxl initialization, and confirmed that this is the correct approach.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">From: Alejandro Lucero &lt;alucerop@amd.com&gt;

Export cxl core functions for a Type2 driver being able to discover and
map the device component registers.

Use it in sfc driver cxl initialization.

Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
Reviewed-by: Dan Williams &lt;dan.j.williams@intel.com&gt;
Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
---
 drivers/cxl/core/pci.c             |  1 +
 drivers/cxl/core/port.c            |  1 +
 drivers/cxl/core/regs.c            |  1 +
 drivers/cxl/cxl.h                  |  7 ------
 drivers/cxl/cxlpci.h               | 12 ----------
 drivers/cxl/pci.c                  |  1 +
 drivers/net/ethernet/sfc/efx_cxl.c | 35 ++++++++++++++++++++++++++++++
 include/cxl/cxl.h                  | 19 ++++++++++++++++
 include/cxl/pci.h                  | 21 ++++++++++++++++++
 9 files changed, 79 insertions(+), 19 deletions(-)
 create mode 100644 include/cxl/pci.h

diff --git a/drivers/cxl/core/pci.c b/drivers/cxl/core/pci.c
index 6b7e50858d56..ba2d393c540a 100644
--- a/drivers/cxl/core/pci.c
+++ b/drivers/cxl/core/pci.c
@@ -6,6 +6,7 @@
 #include &lt;linux/delay.h&gt;
 #include &lt;linux/pci.h&gt;
 #include &lt;linux/pci-doe.h&gt;
+#include &lt;cxl/pci.h&gt;
 #include &lt;linux/aer.h&gt;
 #include &lt;cxlpci.h&gt;
 #include &lt;cxlmem.h&gt;
diff --git a/drivers/cxl/core/port.c b/drivers/cxl/core/port.c
index 54f72452fb06..385588b8b30b 100644
--- a/drivers/cxl/core/port.c
+++ b/drivers/cxl/core/port.c
@@ -11,6 +11,7 @@
 #include &lt;linux/idr.h&gt;
 #include &lt;linux/node.h&gt;
 #include &lt;cxl/einj.h&gt;
+#include &lt;cxl/pci.h&gt;
 #include &lt;cxlmem.h&gt;
 #include &lt;cxlpci.h&gt;
 #include &lt;cxl.h&gt;
diff --git a/drivers/cxl/core/regs.c b/drivers/cxl/core/regs.c
index 93710cf4f0a6..20c2d9fbcfe7 100644
--- a/drivers/cxl/core/regs.c
+++ b/drivers/cxl/core/regs.c
@@ -4,6 +4,7 @@
 #include &lt;linux/device.h&gt;
 #include &lt;linux/slab.h&gt;
 #include &lt;linux/pci.h&gt;
+#include &lt;cxl/pci.h&gt;
 #include &lt;cxlmem.h&gt;
 #include &lt;cxlpci.h&gt;
 #include &lt;pmu.h&gt;
diff --git a/drivers/cxl/cxl.h b/drivers/cxl/cxl.h
index 5d111980d879..944c5d1ccceb 100644
--- a/drivers/cxl/cxl.h
+++ b/drivers/cxl/cxl.h
@@ -39,10 +39,6 @@ extern const struct nvdimm_security_ops *cxl_security_ops;
 #define   CXL_CM_CAP_HDR_ARRAY_SIZE_MASK GENMASK(31, 24)
 #define CXL_CM_CAP_PTR_MASK GENMASK(31, 20)
 
-#define   CXL_CM_CAP_CAP_ID_RAS 0x2
-#define   CXL_CM_CAP_CAP_ID_HDM 0x5
-#define   CXL_CM_CAP_CAP_HDM_VERSION 1
-
 /* HDM decoders CXL 2.0 8.2.5.12 CXL HDM Decoder Capability Structure */
 #define CXL_HDM_DECODER_CAP_OFFSET 0x0
 #define   CXL_HDM_DECODER_COUNT_MASK GENMASK(3, 0)
@@ -206,9 +202,6 @@ void cxl_probe_component_regs(struct device *dev, void __iomem *base,
 			      struct cxl_component_reg_map *map);
 void cxl_probe_device_regs(struct device *dev, void __iomem *base,
 			   struct cxl_device_reg_map *map);
-int cxl_map_component_regs(const struct cxl_register_map *map,
-			   struct cxl_component_regs *regs,
-			   unsigned long map_mask);
 int cxl_map_device_regs(const struct cxl_register_map *map,
 			struct cxl_device_regs *regs);
 int cxl_map_pmu_regs(struct cxl_register_map *map, struct cxl_pmu_regs *regs);
diff --git a/drivers/cxl/cxlpci.h b/drivers/cxl/cxlpci.h
index d879120b2780..93df1b1fa326 100644
--- a/drivers/cxl/cxlpci.h
+++ b/drivers/cxl/cxlpci.h
@@ -13,16 +13,6 @@
  */
 #define CXL_PCI_DEFAULT_MAX_VECTORS 16
 
-/* Register Block Identifier (RBI) */
-enum cxl_regloc_type {
-	CXL_REGLOC_RBI_EMPTY = 0,
-	CXL_REGLOC_RBI_COMPONENT,
-	CXL_REGLOC_RBI_VIRT,
-	CXL_REGLOC_RBI_MEMDEV,
-	CXL_REGLOC_RBI_PMU,
-	CXL_REGLOC_RBI_TYPES
-};
-
 /*
  * Table Access DOE, CDAT Read Entry Response
  *
@@ -106,6 +96,4 @@ static inline void cxl_dport_init_ras_reporting(struct cxl_dport *dport,
 						struct device *host) { }
 #endif
 
-int cxl_pci_setup_regs(struct pci_dev *pdev, enum cxl_regloc_type type,
-		       struct cxl_register_map *map);
 #endif /* __CXL_PCI_H__ */
diff --git a/drivers/cxl/pci.c b/drivers/cxl/pci.c
index 668d44eb1bf5..7b4699fb8870 100644
--- a/drivers/cxl/pci.c
+++ b/drivers/cxl/pci.c
@@ -11,6 +11,7 @@
 #include &lt;linux/pci.h&gt;
 #include &lt;linux/aer.h&gt;
 #include &lt;linux/io.h&gt;
+#include &lt;cxl/pci.h&gt;
 #include &lt;cxl/mailbox.h&gt;
 #include &quot;cxlmem.h&quot;
 #include &quot;cxlpci.h&quot;
diff --git a/drivers/net/ethernet/sfc/efx_cxl.c b/drivers/net/ethernet/sfc/efx_cxl.c
index 8e0481d8dced..34126bc4826c 100644
--- a/drivers/net/ethernet/sfc/efx_cxl.c
+++ b/drivers/net/ethernet/sfc/efx_cxl.c
@@ -7,6 +7,8 @@
 
 #include &lt;linux/pci.h&gt;
 
+#include &lt;cxl/cxl.h&gt;
+#include &lt;cxl/pci.h&gt;
 #include &quot;net_driver.h&quot;
 #include &quot;efx_cxl.h&quot;
 
@@ -18,6 +20,7 @@ int efx_cxl_init(struct efx_probe_data *probe_data)
 	struct pci_dev *pci_dev = efx-&gt;pci_dev;
 	struct efx_cxl *cxl;
 	u16 dvsec;
+	int rc;
 
 	probe_data-&gt;cxl_pio_initialised = false;
 
@@ -44,6 +47,38 @@ int efx_cxl_init(struct efx_probe_data *probe_data)
 	if (!cxl)
 		return -ENOMEM;
 
+	rc = cxl_pci_setup_regs(pci_dev, CXL_REGLOC_RBI_COMPONENT,
+				&amp;cxl-&gt;cxlds.reg_map);
+	if (rc) {
+		pci_err(pci_dev, &quot;No component registers\n&quot;);
+		return rc;
+	}
+
+	if (!cxl-&gt;cxlds.reg_map.component_map.hdm_decoder.valid) {
+		pci_err(pci_dev, &quot;Expected HDM component register not found\n&quot;);
+		return -ENODEV;
+	}
+
+	if (!cxl-&gt;cxlds.reg_map.component_map.ras.valid) {
+		pci_err(pci_dev, &quot;Expected RAS component register not found\n&quot;);
+		return -ENODEV;
+	}
+
+	rc = cxl_map_component_regs(&amp;cxl-&gt;cxlds.reg_map,
+				    &amp;cxl-&gt;cxlds.regs.component,
+				    BIT(CXL_CM_CAP_CAP_ID_RAS));
+	if (rc) {
+		pci_err(pci_dev, &quot;Failed to map RAS capability.\n&quot;);
+		return rc;
+	}
+
+	/*
+	 * Set media ready explicitly as there are neither mailbox for checking
+	 * this state nor the CXL register involved, both not mandatory for
+	 * type2.
+	 */
+	cxl-&gt;cxlds.media_ready = true;
+
 	probe_data-&gt;cxl = cxl;
 
 	return 0;
diff --git a/include/cxl/cxl.h b/include/cxl/cxl.h
index 13d448686189..7f2e23bce1f7 100644
--- a/include/cxl/cxl.h
+++ b/include/cxl/cxl.h
@@ -70,6 +70,10 @@ struct cxl_regs {
 	);
 };
 
+#define   CXL_CM_CAP_CAP_ID_RAS 0x2
+#define   CXL_CM_CAP_CAP_ID_HDM 0x5
+#define   CXL_CM_CAP_CAP_HDM_VERSION 1
+
 struct cxl_reg_map {
 	bool valid;
 	int id;
@@ -223,4 +227,19 @@ struct cxl_dev_state *_devm_cxl_dev_state_create(struct device *dev,
 		(drv_struct *)_devm_cxl_dev_state_create(parent, type, serial, dvsec,	\
 						      sizeof(drv_struct), mbox);	\
 	})
+
+/**
+ * cxl_map_component_regs - map cxl component registers
+ *
+ * @map: cxl register map to update with the mappings
+ * @regs: cxl component registers to work with
+ * @map_mask: cxl component regs to map
+ *
+ * Returns integer: success (0) or error (-ENOMEM)
+ *
+ * Made public for Type2 driver support.
+ */
+int cxl_map_component_regs(const struct cxl_register_map *map,
+			   struct cxl_component_regs *regs,
+			   unsigned long map_mask);
 #endif /* __CXL_CXL_H__ */
diff --git a/include/cxl/pci.h b/include/cxl/pci.h
new file mode 100644
index 000000000000..a172439f08c6
--- /dev/null
+++ b/include/cxl/pci.h
@@ -0,0 +1,21 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+/* Copyright(c) 2020 Intel Corporation. All rights reserved. */
+
+#ifndef __CXL_CXL_PCI_H__
+#define __CXL_CXL_PCI_H__
+
+/* Register Block Identifier (RBI) */
+enum cxl_regloc_type {
+	CXL_REGLOC_RBI_EMPTY = 0,
+	CXL_REGLOC_RBI_COMPONENT,
+	CXL_REGLOC_RBI_VIRT,
+	CXL_REGLOC_RBI_MEMDEV,
+	CXL_REGLOC_RBI_PMU,
+	CXL_REGLOC_RBI_TYPES
+};
+
+struct cxl_register_map;
+
+int cxl_pci_setup_regs(struct pci_dev *pdev, enum cxl_regloc_type type,
+		       struct cxl_register_map *map);
+#endif
-- 
2.34.1</pre>
</details>
<div class="review-comment-signals">Signals: confirmed_correct_approach</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">alejandro.lucero-palau (author)</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-01">2026-02-01</a>
<span class="badge" style="color:#155724;background:#d4edda">Positive</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The author addressed a concern about the cxl_pci_setup_regs function needing to handle both RCRB and RCiEP cases, explained that they moved helper functions from cxl/pci_drv.c to cxl/core/pci.c to be exported and shared with CXL Type2 device initialization, and confirmed that this change addresses the issue.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">From: Alejandro Lucero &lt;alucerop@amd.com&gt;

Inside cxl/core/pci.c there are helpers for CXL PCIe initialization
meanwhile cxl/pci_drv.c implements the functionality for a Type3 device
initialization.

Move helper functions from cxl/core/pci_drv.c to cxl/core/pci.c in order
to be exported and shared with CXL Type2 device initialization.

Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
Reviewed-by: Fan Ni &lt;fan.ni@samsung.com&gt;
Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
Reviewed-by: Alison Schofield &lt;alison.schofield@intel.com&gt;
Reviewed-by: Dan Williams &lt;dan.j.williams@intel.com&gt;
---
 drivers/cxl/core/core.h |  3 +-
 drivers/cxl/core/pci.c  | 62 ++++++++++++++++++++++++++++++++++++
 drivers/cxl/core/regs.c |  1 -
 drivers/cxl/cxl.h       |  2 --
 drivers/cxl/cxlpci.h    | 13 ++++++++
 drivers/cxl/pci.c       | 70 -----------------------------------------
 6 files changed, 77 insertions(+), 74 deletions(-)

diff --git a/drivers/cxl/core/core.h b/drivers/cxl/core/core.h
index 422531799af2..256799d39361 100644
--- a/drivers/cxl/core/core.h
+++ b/drivers/cxl/core/core.h
@@ -187,5 +187,6 @@ int cxl_set_feature(struct cxl_mailbox *cxl_mbox, const uuid_t *feat_uuid,
 		    size_t feat_data_size, u32 feat_flag, u16 offset,
 		    u16 *return_code);
 #endif
-
+resource_size_t cxl_rcd_component_reg_phys(struct device *dev,
+					   struct cxl_dport *dport);
 #endif /* __CXL_CORE_H__ */
diff --git a/drivers/cxl/core/pci.c b/drivers/cxl/core/pci.c
index b838c59d7a3c..6b7e50858d56 100644
--- a/drivers/cxl/core/pci.c
+++ b/drivers/cxl/core/pci.c
@@ -696,6 +696,68 @@ bool cxl_endpoint_decoder_reset_detected(struct cxl_port *port)
 }
 EXPORT_SYMBOL_NS_GPL(cxl_endpoint_decoder_reset_detected, &quot;CXL&quot;);
 
+static int cxl_rcrb_get_comp_regs(struct pci_dev *pdev,
+				  struct cxl_register_map *map,
+				  struct cxl_dport *dport)
+{
+	resource_size_t component_reg_phys;
+
+	*map = (struct cxl_register_map) {
+		.host = &amp;pdev-&gt;dev,
+		.resource = CXL_RESOURCE_NONE,
+	};
+
+	struct cxl_port *port __free(put_cxl_port) =
+		cxl_pci_find_port(pdev, &amp;dport);
+	if (!port)
+		return -EPROBE_DEFER;
+
+	component_reg_phys = cxl_rcd_component_reg_phys(&amp;pdev-&gt;dev, dport);
+	if (component_reg_phys == CXL_RESOURCE_NONE)
+		return -ENXIO;
+
+	map-&gt;resource = component_reg_phys;
+	map-&gt;reg_type = CXL_REGLOC_RBI_COMPONENT;
+	map-&gt;max_size = CXL_COMPONENT_REG_BLOCK_SIZE;
+
+	return 0;
+}
+
+int cxl_pci_setup_regs(struct pci_dev *pdev, enum cxl_regloc_type type,
+			struct cxl_register_map *map)
+{
+	int rc;
+
+	rc = cxl_find_regblock(pdev, type, map);
+
+	/*
+	 * If the Register Locator DVSEC does not exist, check if it
+	 * is an RCH and try to extract the Component Registers from
+	 * an RCRB.
+	 */
+	if (rc &amp;&amp; type == CXL_REGLOC_RBI_COMPONENT &amp;&amp; is_cxl_restricted(pdev)) {
+		struct cxl_dport *dport;
+		struct cxl_port *port __free(put_cxl_port) =
+			cxl_pci_find_port(pdev, &amp;dport);
+		if (!port)
+			return -EPROBE_DEFER;
+
+		rc = cxl_rcrb_get_comp_regs(pdev, map, dport);
+		if (rc)
+			return rc;
+
+		rc = cxl_dport_map_rcd_linkcap(pdev, dport);
+		if (rc)
+			return rc;
+
+	} else if (rc) {
+		return rc;
+	}
+
+	return cxl_setup_regs(map);
+}
+EXPORT_SYMBOL_NS_GPL(cxl_pci_setup_regs, &quot;CXL&quot;);
+
 int cxl_pci_get_bandwidth(struct pci_dev *pdev, struct access_coordinate *c)
 {
 	int speed, bw;
diff --git a/drivers/cxl/core/regs.c b/drivers/cxl/core/regs.c
index a010b3214342..93710cf4f0a6 100644
--- a/drivers/cxl/core/regs.c
+++ b/drivers/cxl/core/regs.c
@@ -641,4 +641,3 @@ resource_size_t cxl_rcd_component_reg_phys(struct device *dev,
 		return CXL_RESOURCE_NONE;
 	return __rcrb_to_component(dev, &amp;dport-&gt;rcrb, CXL_RCRB_UPSTREAM);
 }
-EXPORT_SYMBOL_NS_GPL(cxl_rcd_component_reg_phys, &quot;CXL&quot;);
diff --git a/drivers/cxl/cxl.h b/drivers/cxl/cxl.h
index 3eaa353e430b..5d111980d879 100644
--- a/drivers/cxl/cxl.h
+++ b/drivers/cxl/cxl.h
@@ -222,8 +222,6 @@ int cxl_find_regblock(struct pci_dev *pdev, enum cxl_regloc_type type,
 		      struct cxl_register_map *map);
 int cxl_setup_regs(struct cxl_register_map *map);
 struct cxl_dport;
-resource_size_t cxl_rcd_component_reg_phys(struct device *dev,
-					   struct cxl_dport *dport);
 int cxl_dport_map_rcd_linkcap(struct pci_dev *pdev, struct cxl_dport *dport);
 
 #define CXL_RESOURCE_NONE ((resource_size_t) -1)
diff --git a/drivers/cxl/cxlpci.h b/drivers/cxl/cxlpci.h
index 6f9c78886fd9..d879120b2780 100644
--- a/drivers/cxl/cxlpci.h
+++ b/drivers/cxl/cxlpci.h
@@ -74,6 +74,17 @@ static inline bool cxl_pci_flit_256(struct pci_dev *pdev)
 	return lnksta2 &amp; PCI_EXP_LNKSTA2_FLIT;
 }
 
+/*
+ * Assume that the caller has already validated that @pdev has CXL
+ * capabilities, any RCiEP with CXL capabilities is treated as a
+ * Restricted CXL Device (RCD) and finds upstream port and endpoint
+ * registers in a Root Complex Register Block (RCRB).
+ */
+static inline bool is_cxl_restricted(struct pci_dev *pdev)
+{
+	return pci_pcie_type(pdev) == PCI_EXP_TYPE_RC_END;
+}
+
 struct cxl_dev_state;
 void read_cdat_data(struct cxl_port *port);
 
@@ -95,4 +106,6 @@ static inline void cxl_dport_init_ras_reporting(struct cxl_dport *dport,
 						struct device *host) { }
 #endif
 
+int cxl_pci_setup_regs(struct pci_dev *pdev, enum cxl_regloc_type type,
+		       struct cxl_register_map *map);
 #endif /* __CXL_PCI_H__ */
diff --git a/drivers/cxl/pci.c b/drivers/cxl/pci.c
index 24179cc702bf..668d44eb1bf5 100644
--- a/drivers/cxl/pci.c
+++ b/drivers/cxl/pci.c
@@ -465,76 +465,6 @@ static int cxl_pci_setup_mailbox(struct cxl_memdev_state *mds, bool irq_avail)
 	return 0;
 }
 
-/*
- * Assume that any RCIEP that emits the CXL memory expander class code
- * is an RCD
- */
-static bool is_cxl_restricted(struct pci_dev *pdev)
-{
-	return pci_pcie_type(pdev) == PCI_EXP_TYPE_RC_END;
-}
-
-static int cxl_rcrb_get_comp_regs(struct pci_dev *pdev,
-				  struct cxl_register_map *map,
-				  struct cxl_dport *dport)
-{
-	resource_size_t component_reg_phys;
-
-	*map = (struct cxl_register_map) {
-		.host = &amp;pdev-&gt;dev,
-		.resource = CXL_RESOURCE_NONE,
-	};
-
-	struct cxl_port *port __free(put_cxl_port) =
-		cxl_pci_find_port(pdev, &amp;dport);
-	if (!port)
-		return -EPROBE_DEFER;
-
-	component_reg_phys = cxl_rcd_component_reg_phys(&amp;pdev-&gt;dev, dport);
-	if (component_reg_phys == CXL_RESOURCE_NONE)
-		return -ENXIO;
-
-	map-&gt;resource = component_reg_phys;
-	map-&gt;reg_type = CXL_REGLOC_RBI_COMPONENT;
-	map-&gt;max_size = CXL_COMPONENT_REG_BLOCK_SIZE;
-
-	return 0;
-}
-
-static int cxl_pci_setup_regs(struct pci_dev *pdev, enum cxl_regloc_type type,
-			      struct cxl_register_map *map)
-{
-	int rc;
-
-	rc = cxl_find_regblock(pdev, type, map);
-
-	/*
-	 * If the Register Locator DVSEC does not exist, check if it
-	 * is an RCH and try to extract the Component Registers from
-	 * an RCRB.
-	 */
-	if (rc &amp;&amp; type == CXL_REGLOC_RBI_COMPONENT &amp;&amp; is_cxl_restricted(pdev)) {
-		struct cxl_dport *dport;
-		struct cxl_port *port __free(put_cxl_port) =
-			cxl_pci_find_port(pdev, &amp;dport);
-		if (!port)
-			return -EPROBE_DEFER;
-
-		rc = cxl_rcrb_get_comp_regs(pdev, map, dport);
-		if (rc)
-			return rc;
-
-		rc = cxl_dport_map_rcd_linkcap(pdev, dport);
-		if (rc)
-			return rc;
-
-	} else if (rc) {
-		return rc;
-	}
-
-	return cxl_setup_regs(map);
-}
-
 static int cxl_pci_ras_unmask(struct pci_dev *pdev)
 {
 	struct cxl_dev_state *cxlds = pci_get_drvdata(pdev);
-- 
2.34.1</pre>
</details>
<div class="review-comment-signals">Signals: acknowledged a fix is needed, confirmed the issue is resolved</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">alejandro.lucero-palau (author)</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-01">2026-02-01</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The author is addressing a concern about the cxl_mem_get_partition_info function being moved to memdev.c, which was previously in mbox.c. The author explains that this move allows Type2 drivers to initialize DPA by giving the size of their volatile hardware partition, and adds the sfc driver as a client. No fix is planned for the current patch.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">From: Alejandro Lucero &lt;alucerop@amd.com&gt;

Type3 relies on mailbox CXL_MBOX_OP_IDENTIFY command for initializing
memdev state params which end up being used for DPA initialization.

Allow a Type2 driver to initialize DPA simply by giving the size of its
volatile hardware partition.

Move related functions to memdev.

Add sfc driver as the client.

Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
Reviewed-by: Dan Williams &lt;dan.j.williams@intel.com&gt;
Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
---
 drivers/cxl/core/core.h            |  2 +
 drivers/cxl/core/mbox.c            | 51 +----------------------
 drivers/cxl/core/memdev.c          | 66 ++++++++++++++++++++++++++++++
 drivers/net/ethernet/sfc/efx_cxl.c |  5 +++
 include/cxl/cxl.h                  |  1 +
 5 files changed, 75 insertions(+), 50 deletions(-)

diff --git a/drivers/cxl/core/core.h b/drivers/cxl/core/core.h
index 256799d39361..e3c85ceda248 100644
--- a/drivers/cxl/core/core.h
+++ b/drivers/cxl/core/core.h
@@ -89,6 +89,8 @@ void __iomem *devm_cxl_iomap_block(struct device *dev, resource_size_t addr,
 struct dentry *cxl_debugfs_create_dir(const char *dir);
 int cxl_dpa_set_part(struct cxl_endpoint_decoder *cxled,
 		     enum cxl_partition_mode mode);
+struct cxl_memdev_state;
+int cxl_mem_get_partition_info(struct cxl_memdev_state *mds);
 int cxl_dpa_alloc(struct cxl_endpoint_decoder *cxled, u64 size);
 int cxl_dpa_free(struct cxl_endpoint_decoder *cxled);
 resource_size_t cxl_dpa_size(struct cxl_endpoint_decoder *cxled);
diff --git a/drivers/cxl/core/mbox.c b/drivers/cxl/core/mbox.c
index bee84d0101d1..d57a0c2d39fb 100644
--- a/drivers/cxl/core/mbox.c
+++ b/drivers/cxl/core/mbox.c
@@ -1144,7 +1144,7 @@ EXPORT_SYMBOL_NS_GPL(cxl_mem_get_event_records, &quot;CXL&quot;);
  *
  * See CXL @8.2.9.5.2.1 Get Partition Info
  */
-static int cxl_mem_get_partition_info(struct cxl_memdev_state *mds)
+int cxl_mem_get_partition_info(struct cxl_memdev_state *mds)
 {
 	struct cxl_mailbox *cxl_mbox = &amp;mds-&gt;cxlds.cxl_mbox;
 	struct cxl_mbox_get_partition_info pi;
@@ -1300,55 +1300,6 @@ int cxl_mem_sanitize(struct cxl_memdev *cxlmd, u16 cmd)
 	return -EBUSY;
 }
 
-static void add_part(struct cxl_dpa_info *info, u64 start, u64 size, enum cxl_partition_mode mode)
-{
-	int i = info-&gt;nr_partitions;
-
-	if (size == 0)
-		return;
-
-	info-&gt;part[i].range = (struct range) {
-		.start = start,
-		.end = start + size - 1,
-	};
-	info-&gt;part[i].mode = mode;
-	info-&gt;nr_partitions++;
-}
-
-int cxl_mem_dpa_fetch(struct cxl_memdev_state *mds, struct cxl_dpa_info *info)
-{
-	struct cxl_dev_state *cxlds = &amp;mds-&gt;cxlds;
-	struct device *dev = cxlds-&gt;dev;
-	int rc;
-
-	if (!cxlds-&gt;media_ready) {
-		info-&gt;size = 0;
-		return 0;
-	}
-
-	info-&gt;size = mds-&gt;total_bytes;
-
-	if (mds-&gt;partition_align_bytes == 0) {
-		add_part(info, 0, mds-&gt;volatile_only_bytes, CXL_PARTMODE_RAM);
-		add_part(info, mds-&gt;volatile_only_bytes,
-			 mds-&gt;persistent_only_bytes, CXL_PARTMODE_PMEM);
-		return 0;
-	}
-
-	rc = cxl_mem_get_partition_info(mds);
-	if (rc) {
-		dev_err(dev, &quot;Failed to query partition information\n&quot;);
-		return rc;
-	}
-
-	add_part(info, 0, mds-&gt;active_volatile_bytes, CXL_PARTMODE_RAM);
-	add_part(info, mds-&gt;active_volatile_bytes, mds-&gt;active_persistent_bytes,
-		 CXL_PARTMODE_PMEM);
-
-	return 0;
-}
-EXPORT_SYMBOL_NS_GPL(cxl_mem_dpa_fetch, &quot;CXL&quot;);
-
 int cxl_get_dirty_count(struct cxl_memdev_state *mds, u32 *count)
 {
 	struct cxl_mailbox *cxl_mbox = &amp;mds-&gt;cxlds.cxl_mbox;
diff --git a/drivers/cxl/core/memdev.c b/drivers/cxl/core/memdev.c
index 22d156f25305..2c5dd72f43ca 100644
--- a/drivers/cxl/core/memdev.c
+++ b/drivers/cxl/core/memdev.c
@@ -582,6 +582,72 @@ bool is_cxl_memdev(const struct device *dev)
 }
 EXPORT_SYMBOL_NS_GPL(is_cxl_memdev, &quot;CXL&quot;);
 
+static void add_part(struct cxl_dpa_info *info, u64 start, u64 size, enum cxl_partition_mode mode)
+{
+	int i = info-&gt;nr_partitions;
+
+	if (size == 0)
+		return;
+
+	info-&gt;part[i].range = (struct range) {
+		.start = start,
+		.end = start + size - 1,
+	};
+	info-&gt;part[i].mode = mode;
+	info-&gt;nr_partitions++;
+}
+
+int cxl_mem_dpa_fetch(struct cxl_memdev_state *mds, struct cxl_dpa_info *info)
+{
+	struct cxl_dev_state *cxlds = &amp;mds-&gt;cxlds;
+	struct device *dev = cxlds-&gt;dev;
+	int rc;
+
+	if (!cxlds-&gt;media_ready) {
+		info-&gt;size = 0;
+		return 0;
+	}
+
+	info-&gt;size = mds-&gt;total_bytes;
+
+	if (mds-&gt;partition_align_bytes == 0) {
+		add_part(info, 0, mds-&gt;volatile_only_bytes, CXL_PARTMODE_RAM);
+		add_part(info, mds-&gt;volatile_only_bytes,
+			 mds-&gt;persistent_only_bytes, CXL_PARTMODE_PMEM);
+		return 0;
+	}
+
+	rc = cxl_mem_get_partition_info(mds);
+	if (rc) {
+		dev_err(dev, &quot;Failed to query partition information\n&quot;);
+		return rc;
+	}
+
+	add_part(info, 0, mds-&gt;active_volatile_bytes, CXL_PARTMODE_RAM);
+	add_part(info, mds-&gt;active_volatile_bytes, mds-&gt;active_persistent_bytes,
+		 CXL_PARTMODE_PMEM);
+
+	return 0;
+}
+EXPORT_SYMBOL_NS_GPL(cxl_mem_dpa_fetch, &quot;CXL&quot;);
+
+/**
+ * cxl_set_capacity: initialize dpa by a driver without a mailbox.
+ *
+ * @cxlds: pointer to cxl_dev_state
+ * @capacity: device volatile memory size
+ */
+int cxl_set_capacity(struct cxl_dev_state *cxlds, u64 capacity)
+{
+	struct cxl_dpa_info range_info = {
+		.size = capacity,
+	};
+
+	add_part(&amp;range_info, 0, capacity, CXL_PARTMODE_RAM);
+	return cxl_dpa_setup(cxlds, &amp;range_info);
+}
+EXPORT_SYMBOL_NS_GPL(cxl_set_capacity, &quot;CXL&quot;);
+
 /**
  * set_exclusive_cxl_commands() - atomically disable user cxl commands
  * @mds: The device state to operate on
diff --git a/drivers/net/ethernet/sfc/efx_cxl.c b/drivers/net/ethernet/sfc/efx_cxl.c
index 34126bc4826c..0b10a2e6aceb 100644
--- a/drivers/net/ethernet/sfc/efx_cxl.c
+++ b/drivers/net/ethernet/sfc/efx_cxl.c
@@ -79,6 +79,11 @@ int efx_cxl_init(struct efx_probe_data *probe_data)
 	 */
 	cxl-&gt;cxlds.media_ready = true;
 
+	if (cxl_set_capacity(&amp;cxl-&gt;cxlds, EFX_CTPIO_BUFFER_SIZE)) {
+		pci_err(pci_dev, &quot;dpa capacity setup failed\n&quot;);
+		return -ENODEV;
+	}
+
 	probe_data-&gt;cxl = cxl;
 
 	return 0;
diff --git a/include/cxl/cxl.h b/include/cxl/cxl.h
index 7f2e23bce1f7..fb2f8f2395d5 100644
--- a/include/cxl/cxl.h
+++ b/include/cxl/cxl.h
@@ -242,4 +242,5 @@ struct cxl_dev_state *_devm_cxl_dev_state_create(struct device *dev,
 int cxl_map_component_regs(const struct cxl_register_map *map,
 			   struct cxl_component_regs *regs,
 			   unsigned long map_mask);
+int cxl_set_capacity(struct cxl_dev_state *cxlds, u64 capacity);
 #endif /* __CXL_CXL_H__ */
-- 
2.34.1</pre>
</details>
<div class="review-comment-signals">Signals: clarification, explanation</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">alejandro.lucero-palau (author)</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-01">2026-02-01</a>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The author addressed a concern that the current CXL core relies on a specific device type when creating a memdev, leading to issues with obtaining cxl_memdev_state references from a different device type. The author modified the check for obtaining cxl_memdev_state to add support for the CXL_DEVTYPE_DEVMEM type and made devm_cxl_add_memdev accessible from an accel driver.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">From: Alejandro Lucero &lt;alucerop@amd.com&gt;

Current cxl core is relying on a CXL_DEVTYPE_CLASSMEM type device when
creating a memdev leading to problems when obtaining cxl_memdev_state
references from a CXL_DEVTYPE_DEVMEM type.

Modify check for obtaining cxl_memdev_state adding CXL_DEVTYPE_DEVMEM
support.

Make devm_cxl_add_memdev accessible from an accel driver.

Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
Reviewed-by: Alison Schofield &lt;alison.schofield@intel.com&gt;
Reviewed-by: Dan Williams &lt;dan.j.williams@intel.com&gt;
---
 drivers/cxl/core/memdev.c | 15 +++++++++++--
 drivers/cxl/cxlmem.h      |  6 ------
 drivers/cxl/mem.c         | 45 +++++++++++++++++++++++++++++----------
 include/cxl/cxl.h         |  6 ++++++
 4 files changed, 53 insertions(+), 19 deletions(-)

diff --git a/drivers/cxl/core/memdev.c b/drivers/cxl/core/memdev.c
index 2c5dd72f43ca..1b43763b8e20 100644
--- a/drivers/cxl/core/memdev.c
+++ b/drivers/cxl/core/memdev.c
@@ -7,6 +7,7 @@
 #include &lt;linux/slab.h&gt;
 #include &lt;linux/idr.h&gt;
 #include &lt;linux/pci.h&gt;
+#include &lt;cxl/cxl.h&gt;
 #include &lt;cxlmem.h&gt;
 #include &quot;trace.h&quot;
 #include &quot;core.h&quot;
@@ -576,9 +577,16 @@ static const struct device_type cxl_memdev_type = {
 	.groups = cxl_memdev_attribute_groups,
 };
 
+static const struct device_type cxl_accel_memdev_type = {
+	.name = &quot;cxl_accel_memdev&quot;,
+	.release = cxl_memdev_release,
+	.devnode = cxl_memdev_devnode,
+};
+
 bool is_cxl_memdev(const struct device *dev)
 {
-	return dev-&gt;type == &amp;cxl_memdev_type;
+	return (dev-&gt;type == &amp;cxl_memdev_type ||
+		dev-&gt;type == &amp;cxl_accel_memdev_type);
 }
 EXPORT_SYMBOL_NS_GPL(is_cxl_memdev, &quot;CXL&quot;);
 
@@ -781,7 +789,10 @@ static struct cxl_memdev *cxl_memdev_alloc(struct cxl_dev_state *cxlds,
 	dev-&gt;parent = cxlds-&gt;dev;
 	dev-&gt;bus = &amp;cxl_bus_type;
 	dev-&gt;devt = MKDEV(cxl_mem_major, cxlmd-&gt;id);
-	dev-&gt;type = &amp;cxl_memdev_type;
+	if (cxlds-&gt;type == CXL_DEVTYPE_DEVMEM)
+		dev-&gt;type = &amp;cxl_accel_memdev_type;
+	else
+		dev-&gt;type = &amp;cxl_memdev_type;
 	device_set_pm_not_required(dev);
 	INIT_WORK(&amp;cxlmd-&gt;detach_work, detach_memdev);
 
diff --git a/drivers/cxl/cxlmem.h b/drivers/cxl/cxlmem.h
index 281546de426e..c98db6f18aa2 100644
--- a/drivers/cxl/cxlmem.h
+++ b/drivers/cxl/cxlmem.h
@@ -34,10 +34,6 @@
 	(FIELD_GET(CXLMDEV_RESET_NEEDED_MASK, status) !=                       \
 	 CXLMDEV_RESET_NEEDED_NOT)
 
-struct cxl_memdev_attach {
-	int (*probe)(struct cxl_memdev *cxlmd);
-};
-
 /**
  * struct cxl_memdev - CXL bus object representing a Type-3 Memory Device
  * @dev: driver core device object
@@ -103,8 +99,6 @@ static inline bool is_cxl_endpoint(struct cxl_port *port)
 
 struct cxl_memdev *__devm_cxl_add_memdev(struct cxl_dev_state *cxlds,
 					 const struct cxl_memdev_attach *attach);
-struct cxl_memdev *devm_cxl_add_memdev(struct cxl_dev_state *cxlds,
-				       const struct cxl_memdev_attach *attach);
 int devm_cxl_sanitize_setup_notifier(struct device *host,
 				     struct cxl_memdev *cxlmd);
 struct cxl_memdev_state;
diff --git a/drivers/cxl/mem.c b/drivers/cxl/mem.c
index 0958bea915ac..39687baedd1a 100644
--- a/drivers/cxl/mem.c
+++ b/drivers/cxl/mem.c
@@ -65,6 +65,26 @@ static int cxl_debugfs_poison_clear(void *data, u64 dpa)
 DEFINE_DEBUGFS_ATTRIBUTE(cxl_poison_clear_fops, NULL,
 			 cxl_debugfs_poison_clear, &quot;%llx\n&quot;);
 
+static void cxl_memdev_poison_enable(struct cxl_memdev_state *mds,
+				     struct cxl_memdev *cxlmd,
+				     struct dentry *dentry)
+{
+	/*
+	 * Avoid poison debugfs for DEVMEM aka accelerators as they rely on
+	 * cxl_memdev_state.
+	 */
+	if (!mds)
+		return;
+
+	if (test_bit(CXL_POISON_ENABLED_INJECT, mds-&gt;poison.enabled_cmds))
+		debugfs_create_file(&quot;inject_poison&quot;, 0200, dentry, cxlmd,
+				    &amp;cxl_poison_inject_fops);
+
+	if (test_bit(CXL_POISON_ENABLED_CLEAR, mds-&gt;poison.enabled_cmds))
+		debugfs_create_file(&quot;clear_poison&quot;, 0200, dentry, cxlmd,
+				    &amp;cxl_poison_clear_fops);
+}
+
 static int cxl_mem_probe(struct device *dev)
 {
 	struct cxl_memdev *cxlmd = to_cxl_memdev(dev);
@@ -92,12 +112,7 @@ static int cxl_mem_probe(struct device *dev)
 	dentry = cxl_debugfs_create_dir(dev_name(dev));
 	debugfs_create_devm_seqfile(dev, &quot;dpamem&quot;, dentry, cxl_mem_dpa_show);
 
-	if (test_bit(CXL_POISON_ENABLED_INJECT, mds-&gt;poison.enabled_cmds))
-		debugfs_create_file(&quot;inject_poison&quot;, 0200, dentry, cxlmd,
-				    &amp;cxl_poison_inject_fops);
-	if (test_bit(CXL_POISON_ENABLED_CLEAR, mds-&gt;poison.enabled_cmds))
-		debugfs_create_file(&quot;clear_poison&quot;, 0200, dentry, cxlmd,
-				    &amp;cxl_poison_clear_fops);
+	cxl_memdev_poison_enable(mds, cxlmd, dentry);
 
 	rc = devm_add_action_or_reset(dev, remove_debugfs, dentry);
 	if (rc)
@@ -208,16 +223,24 @@ static ssize_t trigger_poison_list_store(struct device *dev,
 }
 static DEVICE_ATTR_WO(trigger_poison_list);
 
-static umode_t cxl_mem_visible(struct kobject *kobj, struct attribute *a, int n)
+static bool cxl_poison_attr_visible(struct kobject *kobj, struct attribute *a)
 {
 	struct device *dev = kobj_to_dev(kobj);
 	struct cxl_memdev *cxlmd = to_cxl_memdev(dev);
 	struct cxl_memdev_state *mds = to_cxl_memdev_state(cxlmd-&gt;cxlds);
 
-	if (a == &amp;dev_attr_trigger_poison_list.attr)
-		if (!test_bit(CXL_POISON_ENABLED_LIST,
-			      mds-&gt;poison.enabled_cmds))
-			return 0;
+	if (!mds ||
+	    !test_bit(CXL_POISON_ENABLED_LIST, mds-&gt;poison.enabled_cmds))
+		return false;
+
+	return true;
+}
+
+static umode_t cxl_mem_visible(struct kobject *kobj, struct attribute *a, int n)
+{
+	if (a == &amp;dev_attr_trigger_poison_list.attr &amp;&amp;
+	    !cxl_poison_attr_visible(kobj, a))
+		return 0;
 
 	return a-&gt;mode;
 }
diff --git a/include/cxl/cxl.h b/include/cxl/cxl.h
index fb2f8f2395d5..6f8d365067af 100644
--- a/include/cxl/cxl.h
+++ b/include/cxl/cxl.h
@@ -153,6 +153,10 @@ struct cxl_dpa_partition {
 
 #define CXL_NR_PARTITIONS_MAX 2
 
+struct cxl_memdev_attach {
+	int (*probe)(struct cxl_memdev *cxlmd);
+};
+
 /**
  * struct cxl_dev_state - The driver device state
  *
@@ -243,4 +247,6 @@ int cxl_map_component_regs(const struct cxl_register_map *map,
 			   struct cxl_component_regs *regs,
 			   unsigned long map_mask);
 int cxl_set_capacity(struct cxl_dev_state *cxlds, u64 capacity);
+struct cxl_memdev *devm_cxl_add_memdev(struct cxl_dev_state *cxlds,
+				       const struct cxl_memdev_attach *attach);
 #endif /* __CXL_CXL_H__ */
-- 
2.34.1</pre>
</details>
<div class="review-comment-signals">Signals: acknowledged a fix is needed</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">alejandro.lucero-palau (author)</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-01">2026-02-01</a>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The author is addressing a concern about the cxl memory device creation, specifically that it was not using the type2 cxl_dev_state struct as required by the new CXL API. The author has modified the code to use this struct and added error handling for creating the cxl memory device.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">From: Alejandro Lucero &lt;alucerop@amd.com&gt;

Use cxl API for creating a cxl memory device using the type2
cxl_dev_state struct.

Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
Reviewed-by: Martin Habets &lt;habetsm.xilinx@gmail.com&gt;
Reviewed-by: Fan Ni &lt;fan.ni@samsung.com&gt;
Acked-by: Edward Cree &lt;ecree.xilinx@gmail.com&gt;
Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
---
 drivers/net/ethernet/sfc/efx_cxl.c | 6 ++++++
 1 file changed, 6 insertions(+)

diff --git a/drivers/net/ethernet/sfc/efx_cxl.c b/drivers/net/ethernet/sfc/efx_cxl.c
index 0b10a2e6aceb..a77ef4783fcb 100644
--- a/drivers/net/ethernet/sfc/efx_cxl.c
+++ b/drivers/net/ethernet/sfc/efx_cxl.c
@@ -84,6 +84,12 @@ int efx_cxl_init(struct efx_probe_data *probe_data)
 		return -ENODEV;
 	}
 
+	cxl-&gt;cxlmd = devm_cxl_add_memdev(&amp;cxl-&gt;cxlds, NULL);
+	if (IS_ERR(cxl-&gt;cxlmd)) {
+		pci_err(pci_dev, &quot;CXL accel memdev creation failed&quot;);
+		return PTR_ERR(cxl-&gt;cxlmd);
+	}
+
 	probe_data-&gt;cxl = cxl;
 
 	return 0;
-- 
2.34.1</pre>
</details>
<div class="review-comment-signals">Signals: acknowledged a fix is needed</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">alejandro.lucero-palau (author)</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-01">2026-02-01</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The author is addressing a concern about the HDM (Host Data Management) being committed by the BIOS for Type2 devices, which can cause issues when trying to create a CXL region. The author has added a new function cxl_get_committed_decoder() that checks if the HDM is already committed after memdev creation and returns the corresponding decoder if it is. This change allows Type2 drivers to work with the HPA (Host Physical Address) and DPA (Device Physical Address) space even when the HDM is not committed.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">From: Alejandro Lucero &lt;alucerop@amd.com&gt;

A Type2 device configured by the BIOS can already have its HDM
committed. Add a cxl_get_committed_decoder() function for cheking
so after memdev creation. A CXL region should have been created
during memdev initialization, therefore a Type2 driver can ask for
such a region for working with the HPA. If the HDM is not committed,
a Type2 driver will create the region after obtaining proper HPA
and DPA space.

Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
---
 drivers/cxl/core/hdm.c | 39 +++++++++++++++++++++++++++++++++++++++
 include/cxl/cxl.h      |  3 +++
 2 files changed, 42 insertions(+)

diff --git a/drivers/cxl/core/hdm.c b/drivers/cxl/core/hdm.c
index 6e516c69b2d2..a172ce4e9b19 100644
--- a/drivers/cxl/core/hdm.c
+++ b/drivers/cxl/core/hdm.c
@@ -686,6 +686,45 @@ int cxl_dpa_alloc(struct cxl_endpoint_decoder *cxled, u64 size)
 	return devm_add_action_or_reset(&amp;port-&gt;dev, cxl_dpa_release, cxled);
 }
 
+static int find_committed_endpoint_decoder(struct device *dev, const void *data)
+{
+	struct cxl_endpoint_decoder *cxled;
+	struct cxl_port *port;
+
+	if (!is_endpoint_decoder(dev))
+		return 0;
+
+	cxled = to_cxl_endpoint_decoder(dev);
+	port = cxled_to_port(cxled);
+
+	return cxled-&gt;cxld.id == port-&gt;hdm_end;
+}
+
+struct cxl_endpoint_decoder *cxl_get_committed_decoder(struct cxl_memdev *cxlmd,
+						       struct cxl_region **cxlr)
+{
+	struct cxl_port *endpoint = cxlmd-&gt;endpoint;
+	struct cxl_endpoint_decoder *cxled;
+	struct device *cxled_dev;
+
+	if (!endpoint)
+		return NULL;
+
+	guard(rwsem_read)(&amp;cxl_rwsem.dpa);
+	cxled_dev = device_find_child(&amp;endpoint-&gt;dev, NULL,
+				      find_committed_endpoint_decoder);
+
+	if (!cxled_dev)
+		return NULL;
+
+	cxled = to_cxl_endpoint_decoder(cxled_dev);
+	*cxlr = cxled-&gt;cxld.region;
+
+	put_device(cxled_dev);
+	return cxled;
+}
+EXPORT_SYMBOL_NS_GPL(cxl_get_committed_decoder, &quot;CXL&quot;);
+
 static void cxld_set_interleave(struct cxl_decoder *cxld, u32 *ctrl)
 {
 	u16 eig;
diff --git a/include/cxl/cxl.h b/include/cxl/cxl.h
index 6f8d365067af..928276dba952 100644
--- a/include/cxl/cxl.h
+++ b/include/cxl/cxl.h
@@ -249,4 +249,7 @@ int cxl_map_component_regs(const struct cxl_register_map *map,
 int cxl_set_capacity(struct cxl_dev_state *cxlds, u64 capacity);
 struct cxl_memdev *devm_cxl_add_memdev(struct cxl_dev_state *cxlds,
 				       const struct cxl_memdev_attach *attach);
+struct cxl_region;
+struct cxl_endpoint_decoder *cxl_get_committed_decoder(struct cxl_memdev *cxlmd,
+						       struct cxl_region **cxlr);
 #endif /* __CXL_CXL_H__ */
-- 
2.34.1</pre>
</details>
<div class="review-comment-signals">Signals: added new function, addressed concern</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">alejandro.lucero-palau (author)</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-01">2026-02-01</a>
<span class="badge" style="color:#155724;background:#d4edda">Positive</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The author addressed a concern about the accelerator driver API not having a clean exit mechanism, and added cxl_unregister_region() to handle this. The function is exported for use by other drivers.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">From: Alejandro Lucero &lt;alucerop@amd.com&gt;

Add cxl_unregister_region() to the accelerator driver API
for a clean exit.

Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
---
 drivers/cxl/core/region.c | 17 ++++++++++++-----
 include/cxl/cxl.h         |  1 +
 2 files changed, 13 insertions(+), 5 deletions(-)

diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
index acf29ba3b205..954b8fcdbac6 100644
--- a/drivers/cxl/core/region.c
+++ b/drivers/cxl/core/region.c
@@ -2438,9 +2438,8 @@ static struct cxl_region *to_cxl_region(struct device *dev)
 	return container_of(dev, struct cxl_region, dev);
 }
 
-static void unregister_region(void *_cxlr)
+void cxl_unregister_region(struct cxl_region *cxlr)
 {
-	struct cxl_region *cxlr = _cxlr;
 	struct cxl_region_params *p = &amp;cxlr-&gt;params;
 	int i;
 
@@ -2457,6 +2456,14 @@ static void unregister_region(void *_cxlr)
 	cxl_region_iomem_release(cxlr);
 	put_device(&amp;cxlr-&gt;dev);
 }
+EXPORT_SYMBOL_NS_GPL(cxl_unregister_region, &quot;CXL&quot;);
+
+static void __unregister_region(void *_cxlr)
+{
+	struct cxl_region *cxlr = _cxlr;
+
+	return cxl_unregister_region(cxlr);
+}
 
 static struct lock_class_key cxl_region_key;
 
@@ -2608,7 +2615,7 @@ static struct cxl_region *devm_cxl_add_region(struct cxl_root_decoder *cxlrd,
 	if (rc)
 		goto err;
 
-	rc = devm_add_action_or_reset(port-&gt;uport_dev, unregister_region, cxlr);
+	rc = devm_add_action_or_reset(port-&gt;uport_dev, __unregister_region, cxlr);
 	if (rc)
 		return ERR_PTR(rc);
 
@@ -2762,7 +2769,7 @@ static ssize_t delete_region_store(struct device *dev,
 	if (IS_ERR(cxlr))
 		return PTR_ERR(cxlr);
 
-	devm_release_action(port-&gt;uport_dev, unregister_region, cxlr);
+	devm_release_action(port-&gt;uport_dev, __unregister_region, cxlr);
 	put_device(&amp;cxlr-&gt;dev);
 
 	return len;
@@ -3878,7 +3885,7 @@ static struct cxl_region *construct_region(struct cxl_root_decoder *cxlrd,
 
 	rc = __construct_region(cxlr, cxlrd, cxled);
 	if (rc) {
-		devm_release_action(port-&gt;uport_dev, unregister_region, cxlr);
+		devm_release_action(port-&gt;uport_dev, __unregister_region, cxlr);
 		return ERR_PTR(rc);
 	}
 
diff --git a/include/cxl/cxl.h b/include/cxl/cxl.h
index 906065e0d2a6..92880c26b2d5 100644
--- a/include/cxl/cxl.h
+++ b/include/cxl/cxl.h
@@ -254,4 +254,5 @@ struct cxl_endpoint_decoder *cxl_get_committed_decoder(struct cxl_memdev *cxlmd,
 						       struct cxl_region **cxlr);
 struct range;
 int cxl_get_region_range(struct cxl_region *region, struct range *range);
+void cxl_unregister_region(struct cxl_region *cxlr);
 #endif /* __CXL_CXL_H__ */
-- 
2.34.1</pre>
</details>
<div class="review-comment-signals">Signals: acknowledged fix needed, agreed with approach</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">alejandro.lucero-palau (author)</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-01">2026-02-01</a>
<span class="badge" style="color:#155724;background:#d4edda">Positive</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The author addressed a concern about Type2 drivers accessing CXL region structs by adding a function to get the cxl region range, which will be used for mapping memory ranges. The function is exported and added to the cxl.h header file.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">From: Alejandro Lucero &lt;alucerop@amd.com&gt;

A CXL region struct contains the physical address to work with.

Type2 drivers can create a CXL region but have not access to the
related struct as it is defined as private by the kernel CXL core.
Add a function for getting the cxl region range to be used for mapping
such memory range by a Type2 driver.

Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
Reviewed-by: Zhi Wang &lt;zhiw@nvidia.com&gt;
Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
---
 drivers/cxl/core/region.c | 23 +++++++++++++++++++++++
 include/cxl/cxl.h         |  2 ++
 2 files changed, 25 insertions(+)

diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
index 96888d87a8df..acf29ba3b205 100644
--- a/drivers/cxl/core/region.c
+++ b/drivers/cxl/core/region.c
@@ -2621,6 +2621,29 @@ static struct cxl_region *devm_cxl_add_region(struct cxl_root_decoder *cxlrd,
 	return ERR_PTR(rc);
 }
 
+/**
+ * cxl_get_region_range - obtain range linked to a CXL region
+ *
+ * @region: a pointer to struct cxl_region
+ * @range: a pointer to a struct range to be set
+ *
+ * Returns 0 or error.
+ */
+int cxl_get_region_range(struct cxl_region *region, struct range *range)
+{
+	if (WARN_ON_ONCE(!region))
+		return -ENODEV;
+
+	if (!region-&gt;params.res)
+		return -ENOSPC;
+
+	range-&gt;start = region-&gt;params.res-&gt;start;
+	range-&gt;end = region-&gt;params.res-&gt;end;
+
+	return 0;
+}
+EXPORT_SYMBOL_NS_GPL(cxl_get_region_range, &quot;CXL&quot;);
+
 static ssize_t __create_region_show(struct cxl_root_decoder *cxlrd, char *buf)
 {
 	return sysfs_emit(buf, &quot;region%u\n&quot;, atomic_read(&amp;cxlrd-&gt;region_id));
diff --git a/include/cxl/cxl.h b/include/cxl/cxl.h
index 928276dba952..906065e0d2a6 100644
--- a/include/cxl/cxl.h
+++ b/include/cxl/cxl.h
@@ -252,4 +252,6 @@ struct cxl_memdev *devm_cxl_add_memdev(struct cxl_dev_state *cxlds,
 struct cxl_region;
 struct cxl_endpoint_decoder *cxl_get_committed_decoder(struct cxl_memdev *cxlmd,
 						       struct cxl_region **cxlr);
+struct range;
+int cxl_get_region_range(struct cxl_region *region, struct range *range);
 #endif /* __CXL_CXL_H__ */
-- 
2.34.1</pre>
</details>
<div class="review-comment-signals">Signals: acknowledged fix needed, agreed to restructure</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">alejandro.lucero-palau (author)</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-01">2026-02-01</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The author addressed a concern about the complexity of finding a suitable root decoder for CXL region creation, explaining that it involves determining available Host Physical Address (HPA) and allocating capacity from Device Physical Address (DPA). They added a new API to retrieve a root decoder with specific constraints and capacity, along with a complementary function to release the reference to such a decoder. The author did not mention any plans for revising the patch in response to this feedback.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">From: Alejandro Lucero &lt;alucerop@amd.com&gt;

CXL region creation involves allocating capacity from Device Physical
Address (DPA) and assigning it to decode a given Host Physical Address
(HPA). Before determining how much DPA to allocate the amount of available
HPA must be determined. Also, not all HPA is created equal, some HPA
targets RAM, some targets PMEM, some is prepared for device-memory flows
like HDM-D and HDM-DB, and some is HDM-H (host-only).

In order to support Type2 CXL devices, wrap all of those concerns into
an API that retrieves a root decoder (platform CXL window) that fits the
specified constraints and the capacity available for a new region.

Add a complementary function for releasing the reference to such root
decoder.

Based on https://lore.kernel.org/linux-cxl/168592159290.1948938.13522227102445462976.stgit@dwillia2-xfh.jf.intel.com/

Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
---
 drivers/cxl/core/region.c | 164 ++++++++++++++++++++++++++++++++++++++
 drivers/cxl/cxl.h         |   3 +
 include/cxl/cxl.h         |   6 ++
 3 files changed, 173 insertions(+)

diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
index 954b8fcdbac6..bdefd088f5f1 100644
--- a/drivers/cxl/core/region.c
+++ b/drivers/cxl/core/region.c
@@ -705,6 +705,170 @@ static int free_hpa(struct cxl_region *cxlr)
 	return 0;
 }
 
+struct cxlrd_max_context {
+	struct device * const *host_bridges;
+	int interleave_ways;
+	unsigned long flags;
+	resource_size_t max_hpa;
+	struct cxl_root_decoder *cxlrd;
+};
+
+static int find_max_hpa(struct device *dev, void *data)
+{
+	struct cxlrd_max_context *ctx = data;
+	struct cxl_switch_decoder *cxlsd;
+	struct cxl_root_decoder *cxlrd;
+	struct resource *res, *prev;
+	struct cxl_decoder *cxld;
+	resource_size_t free = 0;
+	resource_size_t max;
+	int found = 0;
+
+	if (!is_root_decoder(dev))
+		return 0;
+
+	cxlrd = to_cxl_root_decoder(dev);
+	cxlsd = &amp;cxlrd-&gt;cxlsd;
+	cxld = &amp;cxlsd-&gt;cxld;
+
+	if ((cxld-&gt;flags &amp; ctx-&gt;flags) != ctx-&gt;flags) {
+		dev_dbg(dev, &quot;flags not matching: %08lx vs %08lx\n&quot;,
+			cxld-&gt;flags, ctx-&gt;flags);
+		return 0;
+	}
+
+	for (int i = 0; i &lt; ctx-&gt;interleave_ways; i++) {
+		for (int j = 0; j &lt; ctx-&gt;interleave_ways; j++) {
+			if (ctx-&gt;host_bridges[i] == cxlsd-&gt;target[j]-&gt;dport_dev) {
+				found++;
+				break;
+			}
+		}
+	}
+
+	if (found != ctx-&gt;interleave_ways) {
+		dev_dbg(dev,
+			&quot;Not enough host bridges. Found %d for %d interleave ways requested\n&quot;,
+			found, ctx-&gt;interleave_ways);
+		return 0;
+	}
+
+	/*
+	 * Walk the root decoder resource range relying on cxl_rwsem.region to
+	 * preclude sibling arrival/departure and find the largest free space
+	 * gap.
+	 */
+	lockdep_assert_held_read(&amp;cxl_rwsem.region);
+	res = cxlrd-&gt;res-&gt;child;
+
+	/* With no resource child the whole parent resource is available */
+	if (!res)
+		max = resource_size(cxlrd-&gt;res);
+	else
+		max = 0;
+
+	for (prev = NULL; res; prev = res, res = res-&gt;sibling) {
+		if (!prev &amp;&amp; res-&gt;start == cxlrd-&gt;res-&gt;start &amp;&amp;
+		    res-&gt;end == cxlrd-&gt;res-&gt;end) {
+			max = resource_size(cxlrd-&gt;res);
+			break;
+		}
+		/*
+		 * Sanity check for preventing arithmetic problems below as a
+		 * resource with size 0 could imply using the end field below
+		 * when set to unsigned zero - 1 or all f in hex.
+		 */
+		if (prev &amp;&amp; !resource_size(prev))
+			continue;
+
+		if (!prev &amp;&amp; res-&gt;start &gt; cxlrd-&gt;res-&gt;start) {
+			free = res-&gt;start - cxlrd-&gt;res-&gt;start;
+			max = max(free, max);
+		}
+		if (prev &amp;&amp; res-&gt;start &gt; prev-&gt;end + 1) {
+			free = res-&gt;start - prev-&gt;end + 1;
+			max = max(free, max);
+		}
+	}
+
+	if (prev &amp;&amp; prev-&gt;end + 1 &lt; cxlrd-&gt;res-&gt;end + 1) {
+		free = cxlrd-&gt;res-&gt;end + 1 - prev-&gt;end + 1;
+		max = max(free, max);
+	}
+
+	dev_dbg(cxlrd_dev(cxlrd), &quot;found %pa bytes of free space\n&quot;, &amp;max);
+	if (max &gt; ctx-&gt;max_hpa) {
+		if (ctx-&gt;cxlrd)
+			put_device(cxlrd_dev(ctx-&gt;cxlrd));
+		get_device(cxlrd_dev(cxlrd));
+		ctx-&gt;cxlrd = cxlrd;
+		ctx-&gt;max_hpa = max;
+	}
+	return 0;
+}
+
+/**
+ * cxl_get_hpa_freespace - find a root decoder with free capacity per constraints
+ * @cxlmd: the mem device requiring the HPA
+ * @interleave_ways: number of entries in @host_bridges
+ * @flags: CXL_DECODER_F flags for selecting RAM vs PMEM, and Type2 device
+ * @max_avail_contig: output parameter of max contiguous bytes available in the
+ *		      returned decoder
+ *
+ * Returns a pointer to a struct cxl_root_decoder
+ *
+ * The return tuple of a &#x27;struct cxl_root_decoder&#x27; and &#x27;bytes available given
+ * in (@max_avail_contig))&#x27; is a point in time snapshot. If by the time the
+ * caller goes to use this decoder and its capacity is reduced then caller needs
+ * to loop and retry.
+ *
+ * The returned root decoder has an elevated reference count that needs to be
+ * put with cxl_put_root_decoder(cxlrd).
+ */
+struct cxl_root_decoder *cxl_get_hpa_freespace(struct cxl_memdev *cxlmd,
+					       int interleave_ways,
+					       unsigned long flags,
+					       resource_size_t *max_avail_contig)
+{
+	struct cxlrd_max_context ctx = {
+		.flags = flags,
+		.interleave_ways = interleave_ways,
+	};
+	struct cxl_port *root_port;
+	struct cxl_port *endpoint;
+
+	endpoint = cxlmd-&gt;endpoint;
+	if (!endpoint) {
+		dev_dbg(&amp;cxlmd-&gt;dev, &quot;endpoint not linked to memdev\n&quot;);
+		return ERR_PTR(-ENXIO);
+	}
+
+	ctx.host_bridges = &amp;endpoint-&gt;host_bridge;
+
+	struct cxl_root *root __free(put_cxl_root) = find_cxl_root(endpoint);
+	if (!root) {
+		dev_dbg(&amp;endpoint-&gt;dev, &quot;endpoint is not related to a root port\n&quot;);
+		return ERR_PTR(-ENXIO);
+	}
+
+	root_port = &amp;root-&gt;port;
+	scoped_guard(rwsem_read, &amp;cxl_rwsem.region)
+		device_for_each_child(&amp;root_port-&gt;dev, &amp;ctx, find_max_hpa);
+
+	if (!ctx.cxlrd)
+		return ERR_PTR(-ENOMEM);
+
+	*max_avail_contig = ctx.max_hpa;
+	return ctx.cxlrd;
+}
+EXPORT_SYMBOL_NS_GPL(cxl_get_hpa_freespace, &quot;CXL&quot;);
+
+void cxl_put_root_decoder(struct cxl_root_decoder *cxlrd)
+{
+	put_device(cxlrd_dev(cxlrd));
+}
+EXPORT_SYMBOL_NS_GPL(cxl_put_root_decoder, &quot;CXL&quot;);
+
 static ssize_t size_store(struct device *dev, struct device_attribute *attr,
 			  const char *buf, size_t len)
 {
diff --git a/drivers/cxl/cxl.h b/drivers/cxl/cxl.h
index 944c5d1ccceb..c7d9b2c2908f 100644
--- a/drivers/cxl/cxl.h
+++ b/drivers/cxl/cxl.h
@@ -706,6 +706,9 @@ struct cxl_root_decoder *to_cxl_root_decoder(struct device *dev);
 struct cxl_switch_decoder *to_cxl_switch_decoder(struct device *dev);
 struct cxl_endpoint_decoder *to_cxl_endpoint_decoder(struct device *dev);
 bool is_root_decoder(struct device *dev);
+
+#define cxlrd_dev(cxlrd) (&amp;(cxlrd)-&gt;cxlsd.cxld.dev)
+
 bool is_switch_decoder(struct device *dev);
 bool is_endpoint_decoder(struct device *dev);
 struct cxl_root_decoder *cxl_root_decoder_alloc(struct cxl_port *port,
diff --git a/include/cxl/cxl.h b/include/cxl/cxl.h
index 92880c26b2d5..834dc7e78934 100644
--- a/include/cxl/cxl.h
+++ b/include/cxl/cxl.h
@@ -255,4 +255,10 @@ struct cxl_endpoint_decoder *cxl_get_committed_decoder(struct cxl_memdev *cxlmd,
 struct range;
 int cxl_get_region_range(struct cxl_region *region, struct range *range);
 void cxl_unregister_region(struct cxl_region *cxlr);
+struct cxl_port;
+struct cxl_root_decoder *cxl_get_hpa_freespace(struct cxl_memdev *cxlmd,
+					       int interleave_ways,
+					       unsigned long flags,
+					       resource_size_t *max);
+void cxl_put_root_decoder(struct cxl_root_decoder *cxlrd);
 #endif /* __CXL_CXL_H__ */
-- 
2.34.1</pre>
</details>
<div class="review-comment-signals">Signals: clarification, explanation</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">alejandro.lucero-palau (author)</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-01">2026-02-01</a>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author acknowledged that the current code only supports Type3 or CXL_DECODER_HOSTONLYMEM devices and agreed to modify the region type based on the endpoint type HDM-D[B] for Type2 support.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">From: Alejandro Lucero &lt;alucerop@amd.com&gt;

Current code is expecting Type3 or CXL_DECODER_HOSTONLYMEM devices only.
Support for Type2 implies region type needs to be based on the endpoint
type HDM-D[B] instead.

Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
Reviewed-by: Zhi Wang &lt;zhiw@nvidia.com&gt;
Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
Reviewed-by: Alison Schofield &lt;alison.schofield@intel.com&gt;
Reviewed-by: Davidlohr Bueso &lt;daves@stgolabs.net&gt;
---
 drivers/cxl/core/region.c | 10 ++++++----
 1 file changed, 6 insertions(+), 4 deletions(-)

diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
index bdefd088f5f1..f53b2e9fd9e6 100644
--- a/drivers/cxl/core/region.c
+++ b/drivers/cxl/core/region.c
@@ -2833,7 +2833,8 @@ static ssize_t create_ram_region_show(struct device *dev,
 }
 
 static struct cxl_region *__create_region(struct cxl_root_decoder *cxlrd,
-					  enum cxl_partition_mode mode, int id)
+					  enum cxl_partition_mode mode, int id,
+					  enum cxl_decoder_type target_type)
 {
 	int rc;
 
@@ -2855,7 +2856,7 @@ static struct cxl_region *__create_region(struct cxl_root_decoder *cxlrd,
 		return ERR_PTR(-EBUSY);
 	}
 
-	return devm_cxl_add_region(cxlrd, id, mode, CXL_DECODER_HOSTONLYMEM);
+	return devm_cxl_add_region(cxlrd, id, mode, target_type);
 }
 
 static ssize_t create_region_store(struct device *dev, const char *buf,
@@ -2869,7 +2870,7 @@ static ssize_t create_region_store(struct device *dev, const char *buf,
 	if (rc != 1)
 		return -EINVAL;
 
-	cxlr = __create_region(cxlrd, mode, id);
+	cxlr = __create_region(cxlrd, mode, id, CXL_DECODER_HOSTONLYMEM);
 	if (IS_ERR(cxlr))
 		return PTR_ERR(cxlr);
 
@@ -4036,7 +4037,8 @@ static struct cxl_region *construct_region(struct cxl_root_decoder *cxlrd,
 
 	do {
 		cxlr = __create_region(cxlrd, cxlds-&gt;part[part].mode,
-				       atomic_read(&amp;cxlrd-&gt;region_id));
+				       atomic_read(&amp;cxlrd-&gt;region_id),
+				       cxled-&gt;cxld.target_type);
 	} while (IS_ERR(cxlr) &amp;&amp; PTR_ERR(cxlr) == -EBUSY);
 
 	if (IS_ERR(cxlr)) {
-- 
2.34.1</pre>
</details>
<div class="review-comment-signals">Signals: acknowledged a limitation, agreed to modify</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">alejandro.lucero-palau (author)</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-01">2026-02-01</a>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The author addressed a concern about using the cxl API for getting HPA (Host Physical Address) from a CXL root decoder. They modified the code to use cxl_get_hpa_freespace() instead of directly accessing the hdm control register, and added checks for sufficient free HPA space. The patch will need further revision.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">From: Alejandro Lucero &lt;alucerop@amd.com&gt;

Use cxl api for getting HPA (Host Physical Address) to use from a
CXL root decoder.

Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
Reviewed-by: Martin Habets &lt;habetsm.xilinx@gmail.com&gt;
Acked-by: Edward Cree &lt;ecree.xilinx@gmail.com&gt;
Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
---
 drivers/cxl/cxl.h                  | 15 ---------------
 drivers/net/ethernet/sfc/Kconfig   |  1 +
 drivers/net/ethernet/sfc/efx_cxl.c | 26 +++++++++++++++++++++++---
 drivers/net/ethernet/sfc/efx_cxl.h |  1 +
 include/cxl/cxl.h                  | 15 +++++++++++++++
 5 files changed, 40 insertions(+), 18 deletions(-)

diff --git a/drivers/cxl/cxl.h b/drivers/cxl/cxl.h
index c7d9b2c2908f..d1b010e5e1d0 100644
--- a/drivers/cxl/cxl.h
+++ b/drivers/cxl/cxl.h
@@ -220,21 +220,6 @@ int cxl_dport_map_rcd_linkcap(struct pci_dev *pdev, struct cxl_dport *dport);
 #define CXL_RESOURCE_NONE ((resource_size_t) -1)
 #define CXL_TARGET_STRLEN 20
 
-/*
- * cxl_decoder flags that define the type of memory / devices this
- * decoder supports as well as configuration lock status See &quot;CXL 2.0
- * 8.2.5.12.7 CXL HDM Decoder 0 Control Register&quot; for details.
- * Additionally indicate whether decoder settings were autodetected,
- * user customized.
- */
-#define CXL_DECODER_F_RAM   BIT(0)
-#define CXL_DECODER_F_PMEM  BIT(1)
-#define CXL_DECODER_F_TYPE2 BIT(2)
-#define CXL_DECODER_F_TYPE3 BIT(3)
-#define CXL_DECODER_F_LOCK  BIT(4)
-#define CXL_DECODER_F_ENABLE    BIT(5)
-#define CXL_DECODER_F_MASK  GENMASK(5, 0)
-
 enum cxl_decoder_type {
 	CXL_DECODER_DEVMEM = 2,
 	CXL_DECODER_HOSTONLYMEM = 3,
diff --git a/drivers/net/ethernet/sfc/Kconfig b/drivers/net/ethernet/sfc/Kconfig
index 979f2801e2a8..e959d9b4f4ce 100644
--- a/drivers/net/ethernet/sfc/Kconfig
+++ b/drivers/net/ethernet/sfc/Kconfig
@@ -69,6 +69,7 @@ config SFC_MCDI_LOGGING
 config SFC_CXL
 	bool &quot;Solarflare SFC9100-family CXL support&quot;
 	depends on SFC &amp;&amp; CXL_BUS &gt;= SFC
+	depends on CXL_REGION
 	default SFC
 	help
 	  This enables SFC CXL support if the kernel is configuring CXL for
diff --git a/drivers/net/ethernet/sfc/efx_cxl.c b/drivers/net/ethernet/sfc/efx_cxl.c
index 3536eccf1b2a..1a4c1097c315 100644
--- a/drivers/net/ethernet/sfc/efx_cxl.c
+++ b/drivers/net/ethernet/sfc/efx_cxl.c
@@ -18,6 +18,7 @@ int efx_cxl_init(struct efx_probe_data *probe_data)
 {
 	struct efx_nic *efx = &amp;probe_data-&gt;efx;
 	struct pci_dev *pci_dev = efx-&gt;pci_dev;
+	resource_size_t max_size;
 	struct efx_cxl *cxl;
 	struct range range;
 	u16 dvsec;
@@ -110,9 +111,24 @@ int efx_cxl_init(struct efx_probe_data *probe_data)
 			return -ENOMEM;
 		}
 
-		probe_data-&gt;cxl = cxl;
+		cxl-&gt;hdm_was_committed = true;
+	} else {
+		cxl-&gt;cxlrd = cxl_get_hpa_freespace(cxl-&gt;cxlmd, 1, CXL_DECODER_F_RAM |
+						   CXL_DECODER_F_TYPE2, &amp;max_size);
+		if (IS_ERR(cxl-&gt;cxlrd)) {
+			dev_err(&amp;pci_dev-&gt;dev, &quot;cxl_get_hpa_freespace failed\n&quot;);
+			return PTR_ERR(cxl-&gt;cxlrd);
+		}
+
+		if (max_size &lt; EFX_CTPIO_BUFFER_SIZE) {
+			dev_err(&amp;pci_dev-&gt;dev, &quot;%s: not enough free HPA space %pap &lt; %u\n&quot;,
+				__func__, &amp;max_size, EFX_CTPIO_BUFFER_SIZE);
+			cxl_put_root_decoder(cxl-&gt;cxlrd);
+			return -ENOSPC;
+		}
 	}
 
+	probe_data-&gt;cxl = cxl;
 	return 0;
 }
 
@@ -121,8 +137,12 @@ void efx_cxl_exit(struct efx_probe_data *probe_data)
 	if (!probe_data-&gt;cxl)
 		return;
 
-	iounmap(probe_data-&gt;cxl-&gt;ctpio_cxl);
-	cxl_unregister_region(probe_data-&gt;cxl-&gt;efx_region);
+	if (probe_data-&gt;cxl-&gt;hdm_was_committed) {
+		iounmap(probe_data-&gt;cxl-&gt;ctpio_cxl);
+		cxl_unregister_region(probe_data-&gt;cxl-&gt;efx_region);
+	} else {
+		cxl_put_root_decoder(probe_data-&gt;cxl-&gt;cxlrd);
+	}
 }
 
 MODULE_IMPORT_NS(&quot;CXL&quot;);
diff --git a/drivers/net/ethernet/sfc/efx_cxl.h b/drivers/net/ethernet/sfc/efx_cxl.h
index 961639cef692..9a92e386695b 100644
--- a/drivers/net/ethernet/sfc/efx_cxl.h
+++ b/drivers/net/ethernet/sfc/efx_cxl.h
@@ -27,6 +27,7 @@ struct efx_cxl {
 	struct cxl_root_decoder *cxlrd;
 	struct cxl_port *endpoint;
 	struct cxl_endpoint_decoder *cxled;
+	bool hdm_was_committed;
 	struct cxl_region *efx_region;
 	void __iomem *ctpio_cxl;
 };
diff --git a/include/cxl/cxl.h b/include/cxl/cxl.h
index 834dc7e78934..783ad570a6eb 100644
--- a/include/cxl/cxl.h
+++ b/include/cxl/cxl.h
@@ -153,6 +153,21 @@ struct cxl_dpa_partition {
 
 #define CXL_NR_PARTITIONS_MAX 2
 
+/*
+ * cxl_decoder flags that define the type of memory / devices this
+ * decoder supports as well as configuration lock status See &quot;CXL 2.0
+ * 8.2.5.12.7 CXL HDM Decoder 0 Control Register&quot; for details.
+ * Additionally indicate whether decoder settings were autodetected,
+ * user customized.
+ */
+#define CXL_DECODER_F_RAM   BIT(0)
+#define CXL_DECODER_F_PMEM  BIT(1)
+#define CXL_DECODER_F_TYPE2 BIT(2)
+#define CXL_DECODER_F_TYPE3 BIT(3)
+#define CXL_DECODER_F_LOCK  BIT(4)
+#define CXL_DECODER_F_ENABLE    BIT(5)
+#define CXL_DECODER_F_MASK  GENMASK(5, 0)
+
 struct cxl_memdev_attach {
 	int (*probe)(struct cxl_memdev *cxlmd);
 };
-- 
2.34.1</pre>
</details>
<div class="review-comment-signals">Signals: patch modification, acknowledgment of concern</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">alejandro.lucero-palau (author)</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-01">2026-02-01</a>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author acknowledged that the CXL region should exist if a device HDM is already committed during firmware/BIOS initialization, and agreed to add code to check for this condition in efx_cxl_init().</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">From: Alejandro Lucero &lt;alucerop@amd.com&gt;

Check if device HDM is already committed during firmware/BIOS
initialization.

A CXL region should exist if so after memdev allocation/initialization.
Get HPA from region and map it.

Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
---
 drivers/net/ethernet/sfc/efx_cxl.c | 28 +++++++++++++++++++++++++++-
 1 file changed, 27 insertions(+), 1 deletion(-)

diff --git a/drivers/net/ethernet/sfc/efx_cxl.c b/drivers/net/ethernet/sfc/efx_cxl.c
index a77ef4783fcb..3536eccf1b2a 100644
--- a/drivers/net/ethernet/sfc/efx_cxl.c
+++ b/drivers/net/ethernet/sfc/efx_cxl.c
@@ -19,6 +19,7 @@ int efx_cxl_init(struct efx_probe_data *probe_data)
 	struct efx_nic *efx = &amp;probe_data-&gt;efx;
 	struct pci_dev *pci_dev = efx-&gt;pci_dev;
 	struct efx_cxl *cxl;
+	struct range range;
 	u16 dvsec;
 	int rc;
 
@@ -90,13 +91,38 @@ int efx_cxl_init(struct efx_probe_data *probe_data)
 		return PTR_ERR(cxl-&gt;cxlmd);
 	}
 
-	probe_data-&gt;cxl = cxl;
+	cxl-&gt;cxled = cxl_get_committed_decoder(cxl-&gt;cxlmd, &amp;cxl-&gt;efx_region);
+	if (cxl-&gt;cxled) {
+		if (!cxl-&gt;efx_region) {
+			pci_err(pci_dev, &quot;CXL found committed decoder without a region&quot;);
+			return -ENODEV;
+		}
+		rc = cxl_get_region_range(cxl-&gt;efx_region, &amp;range);
+		if (rc) {
+			pci_err(pci_dev,
+				&quot;CXL getting regions params from a committed decoder failed&quot;);
+			return rc;
+		}
+
+		cxl-&gt;ctpio_cxl = ioremap(range.start, range.end - range.start + 1);
+		if (!cxl-&gt;ctpio_cxl) {
+			pci_err(pci_dev, &quot;CXL ioremap region (%pra) failed&quot;, &amp;range);
+			return -ENOMEM;
+		}
+
+		probe_data-&gt;cxl = cxl;
+	}
 
 	return 0;
 }
 
 void efx_cxl_exit(struct efx_probe_data *probe_data)
 {
+	if (!probe_data-&gt;cxl)
+		return;
+
+	iounmap(probe_data-&gt;cxl-&gt;ctpio_cxl);
+	cxl_unregister_region(probe_data-&gt;cxl-&gt;efx_region);
 }
 
 MODULE_IMPORT_NS(&quot;CXL&quot;);
-- 
2.34.1</pre>
</details>
<div class="review-comment-signals">Signals: acknowledged fix needed</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">alejandro.lucero-palau (author)</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-01">2026-02-01</a>
<span class="badge" style="color:#155724;background:#d4edda">Positive</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author addressed a concern about the cxl_create_region() call in efx_cxl_init(), explained that it should be used to create a region using the endpoint decoder related to a DPA range, and confirmed that this change will be included in the patch.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">From: Alejandro Lucero &lt;alucerop@amd.com&gt;

Use cxl api for creating a region using the endpoint decoder related to
a DPA range.

Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
---
 drivers/net/ethernet/sfc/efx_cxl.c | 10 +++++++++-
 1 file changed, 9 insertions(+), 1 deletion(-)

diff --git a/drivers/net/ethernet/sfc/efx_cxl.c b/drivers/net/ethernet/sfc/efx_cxl.c
index 2cfd0a46225f..4d5f3974e51d 100644
--- a/drivers/net/ethernet/sfc/efx_cxl.c
+++ b/drivers/net/ethernet/sfc/efx_cxl.c
@@ -134,6 +134,14 @@ int efx_cxl_init(struct efx_probe_data *probe_data)
 			cxl_put_root_decoder(cxl-&gt;cxlrd);
 			return PTR_ERR(cxl-&gt;cxled);
 		}
+
+		cxl-&gt;efx_region = cxl_create_region(cxl-&gt;cxlrd, &amp;cxl-&gt;cxled, 1);
+		if (IS_ERR(cxl-&gt;efx_region)) {
+			pci_err(pci_dev, &quot;CXL accel create region failed&quot;);
+			cxl_put_root_decoder(cxl-&gt;cxlrd);
+			cxl_dpa_free(cxl-&gt;cxled);
+			return PTR_ERR(cxl-&gt;efx_region);
+		}
 	}
 
 	probe_data-&gt;cxl = cxl;
@@ -147,11 +155,11 @@ void efx_cxl_exit(struct efx_probe_data *probe_data)
 
 	if (probe_data-&gt;cxl-&gt;hdm_was_committed) {
 		iounmap(probe_data-&gt;cxl-&gt;ctpio_cxl);
-		cxl_unregister_region(probe_data-&gt;cxl-&gt;efx_region);
 	} else {
 		cxl_dpa_free(probe_data-&gt;cxl-&gt;cxled);
 		cxl_put_root_decoder(probe_data-&gt;cxl-&gt;cxlrd);
 	}
+	cxl_unregister_region(probe_data-&gt;cxl-&gt;efx_region);
 }
 
 MODULE_IMPORT_NS(&quot;CXL&quot;);
-- 
2.34.1</pre>
</details>
<div class="review-comment-signals">Signals: acknowledged concern, confirmed fix</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">alejandro.lucero-palau (author)</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-01">2026-02-01</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The author addressed a concern about the interleave ways store function, which was previously acquiring the region rwsem lock for write and then immediately releasing it. The author refactored the code to use the set_interleave_ways helper function, which acquires the lock only once and calls the helper function. This change is intended to improve performance by reducing lock contention.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">From: Alejandro Lucero &lt;alucerop@amd.com&gt;

Region creation based on Type3 devices is triggered from user space
allowing memory combination through interleaving.

In preparation for kernel driven region creation, that is Type2 drivers
triggering region creation backed with its advertised CXL memory, factor
out a common helper from the user-sysfs region setup for interleave ways.

Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
Reviewed-by: Zhi Wang &lt;zhiw@nvidia.com&gt;
Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
Reviewed-by: Alison Schofield &lt;alison.schofield@intel.com&gt;
---
 drivers/cxl/core/region.c | 43 ++++++++++++++++++++++++---------------
 1 file changed, 27 insertions(+), 16 deletions(-)

diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
index f53b2e9fd9e6..ece1d3df7cf1 100644
--- a/drivers/cxl/core/region.c
+++ b/drivers/cxl/core/region.c
@@ -485,22 +485,14 @@ static ssize_t interleave_ways_show(struct device *dev,
 
 static const struct attribute_group *get_cxl_region_target_group(void);
 
-static ssize_t interleave_ways_store(struct device *dev,
-				     struct device_attribute *attr,
-				     const char *buf, size_t len)
+static int set_interleave_ways(struct cxl_region *cxlr, int val)
 {
-	struct cxl_root_decoder *cxlrd = to_cxl_root_decoder(dev-&gt;parent);
+	struct cxl_root_decoder *cxlrd = to_cxl_root_decoder(cxlr-&gt;dev.parent);
 	struct cxl_decoder *cxld = &amp;cxlrd-&gt;cxlsd.cxld;
-	struct cxl_region *cxlr = to_cxl_region(dev);
 	struct cxl_region_params *p = &amp;cxlr-&gt;params;
-	unsigned int val, save;
-	int rc;
+	int save, rc;
 	u8 iw;
 
-	rc = kstrtouint(buf, 0, &amp;val);
-	if (rc)
-		return rc;
-
 	rc = ways_to_eiw(val, &amp;iw);
 	if (rc)
 		return rc;
@@ -515,9 +507,7 @@ static ssize_t interleave_ways_store(struct device *dev,
 		return -EINVAL;
 	}
 
-	ACQUIRE(rwsem_write_kill, rwsem)(&amp;cxl_rwsem.region);
-	if ((rc = ACQUIRE_ERR(rwsem_write_kill, &amp;rwsem)))
-		return rc;
+	lockdep_assert_held_write(&amp;cxl_rwsem.region);
 
 	if (p-&gt;state &gt;= CXL_CONFIG_INTERLEAVE_ACTIVE)
 		return -EBUSY;
@@ -525,10 +515,31 @@ static ssize_t interleave_ways_store(struct device *dev,
 	save = p-&gt;interleave_ways;
 	p-&gt;interleave_ways = val;
 	rc = sysfs_update_group(&amp;cxlr-&gt;dev.kobj, get_cxl_region_target_group());
-	if (rc) {
+	if (rc)
 		p-&gt;interleave_ways = save;
+
+	return rc;
+}
+
+static ssize_t interleave_ways_store(struct device *dev,
+				     struct device_attribute *attr,
+				     const char *buf, size_t len)
+{
+	struct cxl_region *cxlr = to_cxl_region(dev);
+	unsigned int val;
+	int rc;
+
+	rc = kstrtouint(buf, 0, &amp;val);
+	if (rc)
+		return rc;
+
+	ACQUIRE(rwsem_write_kill, rwsem)(&amp;cxl_rwsem.region);
+	if ((rc = ACQUIRE_ERR(rwsem_write_kill, &amp;rwsem)))
+		return rc;
+
+	rc = set_interleave_ways(cxlr, val);
+	if (rc)
 		return rc;
-	}
 
 	return len;
 }
-- 
2.34.1</pre>
</details>
<div class="review-comment-signals">Signals: clarification, refactoring</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">alejandro.lucero-palau (author)</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-01">2026-02-01</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The author addressed the concern about finding available DPA (device-physical-address) capacity to map into HPA (host-physical-address) space for CXL Type2 devices, and provided a new API cxl_request_dpa() that tries to allocate the required DPA memory. The author explained how this API works and included code changes to implement it.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">From: Alejandro Lucero &lt;alucerop@amd.com&gt;

Region creation involves finding available DPA (device-physical-address)
capacity to map into HPA (host-physical-address) space.

In order to support CXL Type2 devices, define an API, cxl_request_dpa(),
that tries to allocate the DPA memory the driver requires to operate.The
memory requested should not be bigger than the max available HPA obtained
previously with cxl_get_hpa_freespace().

Based on https://lore.kernel.org/linux-cxl/168592158743.1948938.7622563891193802610.stgit@dwillia2-xfh.jf.intel.com/

Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
---
 drivers/cxl/core/hdm.c | 84 ++++++++++++++++++++++++++++++++++++++++++
 drivers/cxl/cxl.h      |  1 +
 include/cxl/cxl.h      |  5 +++
 3 files changed, 90 insertions(+)

diff --git a/drivers/cxl/core/hdm.c b/drivers/cxl/core/hdm.c
index a172ce4e9b19..d60a697f12cc 100644
--- a/drivers/cxl/core/hdm.c
+++ b/drivers/cxl/core/hdm.c
@@ -3,6 +3,7 @@
 #include &lt;linux/seq_file.h&gt;
 #include &lt;linux/device.h&gt;
 #include &lt;linux/delay.h&gt;
+#include &lt;cxl/cxl.h&gt;
 
 #include &quot;cxlmem.h&quot;
 #include &quot;core.h&quot;
@@ -546,6 +547,12 @@ bool cxl_resource_contains_addr(const struct resource *res, const resource_size_
 	return resource_contains(res, &amp;_addr);
 }
 
+/**
+ * cxl_dpa_free - release DPA (Device Physical Address)
+ * @cxled: endpoint decoder linked to the DPA
+ *
+ * Returns 0 or error.
+ */
 int cxl_dpa_free(struct cxl_endpoint_decoder *cxled)
 {
 	struct cxl_port *port = cxled_to_port(cxled);
@@ -572,6 +579,7 @@ int cxl_dpa_free(struct cxl_endpoint_decoder *cxled)
 	devm_cxl_dpa_release(cxled);
 	return 0;
 }
+EXPORT_SYMBOL_NS_GPL(cxl_dpa_free, &quot;CXL&quot;);
 
 int cxl_dpa_set_part(struct cxl_endpoint_decoder *cxled,
 		     enum cxl_partition_mode mode)
@@ -603,6 +611,82 @@ int cxl_dpa_set_part(struct cxl_endpoint_decoder *cxled,
 	return 0;
 }
 
+static int find_free_decoder(struct device *dev, const void *data)
+{
+	struct cxl_endpoint_decoder *cxled;
+	struct cxl_port *port;
+
+	if (!is_endpoint_decoder(dev))
+		return 0;
+
+	cxled = to_cxl_endpoint_decoder(dev);
+	port = cxled_to_port(cxled);
+
+	return cxled-&gt;cxld.id == (port-&gt;hdm_end + 1);
+}
+
+static struct cxl_endpoint_decoder *
+cxl_find_free_decoder(struct cxl_memdev *cxlmd)
+{
+	struct cxl_port *endpoint = cxlmd-&gt;endpoint;
+	struct device *dev;
+
+	guard(rwsem_read)(&amp;cxl_rwsem.dpa);
+	dev = device_find_child(&amp;endpoint-&gt;dev, NULL,
+				find_free_decoder);
+	if (!dev)
+		return NULL;
+
+	return to_cxl_endpoint_decoder(dev);
+}
+
+/**
+ * cxl_request_dpa - search and reserve DPA given input constraints
+ * @cxlmd: memdev with an endpoint port with available decoders
+ * @mode: CXL partition mode (ram vs pmem)
+ * @alloc: dpa size required
+ *
+ * Returns a pointer to a &#x27;struct cxl_endpoint_decoder&#x27; on success or
+ * an errno encoded pointer on failure.
+ *
+ * Given that a region needs to allocate from limited HPA capacity it
+ * may be the case that a device has more mappable DPA capacity than
+ * available HPA. The expectation is that @alloc is a driver known
+ * value based on the device capacity but which could not be fully
+ * available due to HPA constraints.
+ *
+ * Returns a pinned cxl_decoder with at least @alloc bytes of capacity
+ * reserved, or an error pointer. The caller is also expected to own the
+ * lifetime of the memdev registration associated with the endpoint to
+ * pin the decoder registered as well.
+ */
+struct cxl_endpoint_decoder *cxl_request_dpa(struct cxl_memdev *cxlmd,
+					     enum cxl_partition_mode mode,
+					     resource_size_t alloc)
+{
+	int rc;
+
+	if (!IS_ALIGNED(alloc, SZ_256M))
+		return ERR_PTR(-EINVAL);
+
+	struct cxl_endpoint_decoder *cxled __free(put_cxled) =
+		cxl_find_free_decoder(cxlmd);
+
+	if (!cxled)
+		return ERR_PTR(-ENODEV);
+
+	rc = cxl_dpa_set_part(cxled, mode);
+	if (rc)
+		return ERR_PTR(rc);
+
+	rc = cxl_dpa_alloc(cxled, alloc);
+	if (rc)
+		return ERR_PTR(rc);
+
+	return no_free_ptr(cxled);
+}
+EXPORT_SYMBOL_NS_GPL(cxl_request_dpa, &quot;CXL&quot;);
+
 static int __cxl_dpa_alloc(struct cxl_endpoint_decoder *cxled, u64 size)
 {
 	struct cxl_memdev *cxlmd = cxled_to_memdev(cxled);
diff --git a/drivers/cxl/cxl.h b/drivers/cxl/cxl.h
index d1b010e5e1d0..2b1f7d687a0e 100644
--- a/drivers/cxl/cxl.h
+++ b/drivers/cxl/cxl.h
@@ -667,6 +667,7 @@ struct cxl_root *find_cxl_root(struct cxl_port *port);
 
 DEFINE_FREE(put_cxl_root, struct cxl_root *, if (_T) put_device(&amp;_T-&gt;port.dev))
 DEFINE_FREE(put_cxl_port, struct cxl_port *, if (!IS_ERR_OR_NULL(_T)) put_device(&amp;_T-&gt;dev))
+DEFINE_FREE(put_cxled, struct cxl_endpoint_decoder *, if (!IS_ERR_OR_NULL(_T)) put_device(&amp;_T-&gt;cxld.dev))
 DEFINE_FREE(put_cxl_root_decoder, struct cxl_root_decoder *, if (!IS_ERR_OR_NULL(_T)) put_device(&amp;_T-&gt;cxlsd.cxld.dev))
 DEFINE_FREE(put_cxl_region, struct cxl_region *, if (!IS_ERR_OR_NULL(_T)) put_device(&amp;_T-&gt;dev))
 
diff --git a/include/cxl/cxl.h b/include/cxl/cxl.h
index 783ad570a6eb..4802371db00e 100644
--- a/include/cxl/cxl.h
+++ b/include/cxl/cxl.h
@@ -7,6 +7,7 @@
 
 #include &lt;linux/node.h&gt;
 #include &lt;linux/ioport.h&gt;
+#include &lt;linux/range.h&gt;
 #include &lt;cxl/mailbox.h&gt;
 
 /**
@@ -276,4 +277,8 @@ struct cxl_root_decoder *cxl_get_hpa_freespace(struct cxl_memdev *cxlmd,
 					       unsigned long flags,
 					       resource_size_t *max);
 void cxl_put_root_decoder(struct cxl_root_decoder *cxlrd);
+struct cxl_endpoint_decoder *cxl_request_dpa(struct cxl_memdev *cxlmd,
+					     enum cxl_partition_mode mode,
+					     resource_size_t alloc);
+int cxl_dpa_free(struct cxl_endpoint_decoder *cxled);
 #endif /* __CXL_CXL_H__ */
-- 
2.34.1</pre>
</details>
<div class="review-comment-signals">Signals: new API implementation, code changes</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">alejandro.lucero-palau (author)</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-01">2026-02-01</a>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The author addressed a concern about interleaving granularity being set in user space, agreeing to factor out a common helper for kernel-driven region creation and acknowledging the need to restructure the code to handle this scenario.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">From: Alejandro Lucero &lt;alucerop@amd.com&gt;

Region creation based on Type3 devices is triggered from user space
allowing memory combination through interleaving.

In preparation for kernel driven region creation, that is Type2 drivers
triggering region creation backed with its advertised CXL memory, factor
out a common helper from the user-sysfs region setup forinterleave
granularity.

Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
Reviewed-by: Zhi Wang &lt;zhiw@nvidia.com&gt;
Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
Reviewed-by: Alison Schofield &lt;alison.schofield@intel.com&gt;
---
 drivers/cxl/core/region.c | 39 +++++++++++++++++++++++++--------------
 1 file changed, 25 insertions(+), 14 deletions(-)

diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
index ece1d3df7cf1..63c2aeb2ee1f 100644
--- a/drivers/cxl/core/region.c
+++ b/drivers/cxl/core/region.c
@@ -559,21 +559,14 @@ static ssize_t interleave_granularity_show(struct device *dev,
 	return sysfs_emit(buf, &quot;%d\n&quot;, p-&gt;interleave_granularity);
 }
 
-static ssize_t interleave_granularity_store(struct device *dev,
-					    struct device_attribute *attr,
-					    const char *buf, size_t len)
+static int set_interleave_granularity(struct cxl_region *cxlr, int val)
 {
-	struct cxl_root_decoder *cxlrd = to_cxl_root_decoder(dev-&gt;parent);
+	struct cxl_root_decoder *cxlrd = to_cxl_root_decoder(cxlr-&gt;dev.parent);
 	struct cxl_decoder *cxld = &amp;cxlrd-&gt;cxlsd.cxld;
-	struct cxl_region *cxlr = to_cxl_region(dev);
 	struct cxl_region_params *p = &amp;cxlr-&gt;params;
-	int rc, val;
+	int rc;
 	u16 ig;
 
-	rc = kstrtoint(buf, 0, &amp;val);
-	if (rc)
-		return rc;
-
 	rc = granularity_to_eig(val, &amp;ig);
 	if (rc)
 		return rc;
@@ -589,14 +582,32 @@ static ssize_t interleave_granularity_store(struct device *dev,
 	if (cxld-&gt;interleave_ways &gt; 1 &amp;&amp; val != cxld-&gt;interleave_granularity)
 		return -EINVAL;
 
-	ACQUIRE(rwsem_write_kill, rwsem)(&amp;cxl_rwsem.region);
-	if ((rc = ACQUIRE_ERR(rwsem_write_kill, &amp;rwsem)))
-		return rc;
-
+	lockdep_assert_held_write(&amp;cxl_rwsem.region);
 	if (p-&gt;state &gt;= CXL_CONFIG_INTERLEAVE_ACTIVE)
 		return -EBUSY;
 
 	p-&gt;interleave_granularity = val;
+	return 0;
+}
+
+static ssize_t interleave_granularity_store(struct device *dev,
+					    struct device_attribute *attr,
+					    const char *buf, size_t len)
+{
+	struct cxl_region *cxlr = to_cxl_region(dev);
+	int rc, val;
+
+	rc = kstrtoint(buf, 0, &amp;val);
+	if (rc)
+		return rc;
+
+	ACQUIRE(rwsem_write_kill, rwsem)(&amp;cxl_rwsem.region);
+	if ((rc = ACQUIRE_ERR(rwsem_write_kill, &amp;rwsem)))
+		return rc;
+
+	rc = set_interleave_granularity(cxlr, val);
+	if (rc)
+		return rc;
 
 	return len;
 }
-- 
2.34.1</pre>
</details>
<div class="review-comment-signals">Signals: acknowledged fix needed, agreed to restructure</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">alejandro.lucero-palau (author)</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-01">2026-02-01</a>
<span class="badge" style="color:#155724;background:#d4edda">Positive</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author addressed a concern about using the CXL API to get the Device Physical Address (DPA) and agreed to use it through an endpoint decoder.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">From: Alejandro Lucero &lt;alucerop@amd.com&gt;

Use cxl api for getting DPA (Device Physical Address) to use through an
endpoint decoder.

Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
Reviewed-by: Martin Habets &lt;habetsm.xilinx@gmail.com&gt;
Acked-by: Edward Cree &lt;ecree.xilinx@gmail.com&gt;
Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
---
 drivers/net/ethernet/sfc/efx_cxl.c | 9 +++++++++
 1 file changed, 9 insertions(+)

diff --git a/drivers/net/ethernet/sfc/efx_cxl.c b/drivers/net/ethernet/sfc/efx_cxl.c
index 1a4c1097c315..2cfd0a46225f 100644
--- a/drivers/net/ethernet/sfc/efx_cxl.c
+++ b/drivers/net/ethernet/sfc/efx_cxl.c
@@ -126,6 +126,14 @@ int efx_cxl_init(struct efx_probe_data *probe_data)
 			cxl_put_root_decoder(cxl-&gt;cxlrd);
 			return -ENOSPC;
 		}
+
+		cxl-&gt;cxled = cxl_request_dpa(cxl-&gt;cxlmd, CXL_PARTMODE_RAM,
+					     EFX_CTPIO_BUFFER_SIZE);
+		if (IS_ERR(cxl-&gt;cxled)) {
+			pci_err(pci_dev, &quot;CXL accel request DPA failed&quot;);
+			cxl_put_root_decoder(cxl-&gt;cxlrd);
+			return PTR_ERR(cxl-&gt;cxled);
+		}
 	}
 
 	probe_data-&gt;cxl = cxl;
@@ -141,6 +149,7 @@ void efx_cxl_exit(struct efx_probe_data *probe_data)
 		iounmap(probe_data-&gt;cxl-&gt;ctpio_cxl);
 		cxl_unregister_region(probe_data-&gt;cxl-&gt;efx_region);
 	} else {
+		cxl_dpa_free(probe_data-&gt;cxl-&gt;cxled);
 		cxl_put_root_decoder(probe_data-&gt;cxl-&gt;cxlrd);
 	}
 }
-- 
2.34.1</pre>
</details>
<div class="review-comment-signals">Signals: agreed, implemented</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">alejandro.lucero-palau (author)</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-01">2026-02-01</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">The author addressed a concern about type2 CXL devices using host-managed memory, explaining that it should not be available to other uses and adding code to skip device-dax registration for such regions.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">From: Alejandro Lucero &lt;alucerop@amd.com&gt;

By definition a type2 cxl device will use the host managed memory for
specific functionality, therefore it should not be available to other
uses.

Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
Reviewed-by: Davidlohr Bueso &lt;daves@stgolabs.net&gt;
Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
Reviewed-by: Ben Cheatham &lt;benjamin.cheatham@amd.com&gt;
---
 drivers/cxl/core/region.c | 7 +++++++
 1 file changed, 7 insertions(+)

diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
index 293e63dfef22..12df717cc881 100644
--- a/drivers/cxl/core/region.c
+++ b/drivers/cxl/core/region.c
@@ -4441,6 +4441,13 @@ static int cxl_region_probe(struct device *dev)
 	if (rc)
 		return rc;
 
+	/*
+	 * HDM-D[B] (device-memory) regions have accelerator specific usage.
+	 * Skip device-dax registration.
+	 */
+	if (cxlr-&gt;type == CXL_DECODER_DEVMEM)
+		return 0;
+
 	/*
 	 * From this point on any path that changes the region&#x27;s state away from
 	 * CXL_CONFIG_COMMIT is also responsible for releasing the driver.
-- 
2.34.1</pre>
</details>
<div class="review-comment-signals">Signals: clarification, explanation</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">alejandro.lucero-palau (author)</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-01">2026-02-01</a>
<span class="badge" style="color:#856404;background:#fff3cd">Needs Work</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author acknowledged that the CXL endpoint removal callback needs to be handled by disabling CXL-based PIO buffers, agreed to add this handling in a future patch.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">From: Alejandro Lucero &lt;alucerop@amd.com&gt;

A PIO buffer is a region of device memory to which the driver can write a
packet for TX, with the device handling the transmit doorbell without
requiring a DMA for getting the packet data, which helps reducing latency
in certain exchanges. With CXL mem protocol this latency can be lowered
further.

With a device supporting CXL and successfully initialised, use the cxl
region to map the memory range and use this mapping for PIO buffers.

Add the disabling of those CXL-based PIO buffers if the callback for
potential cxl endpoint removal by the CXL code happens.

Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
---
 drivers/net/ethernet/sfc/ef10.c       | 50 +++++++++++++++++++++++----
 drivers/net/ethernet/sfc/efx_cxl.c    | 33 ++++++++++++++----
 drivers/net/ethernet/sfc/net_driver.h |  2 ++
 drivers/net/ethernet/sfc/nic.h        |  3 ++
 4 files changed, 75 insertions(+), 13 deletions(-)

diff --git a/drivers/net/ethernet/sfc/ef10.c b/drivers/net/ethernet/sfc/ef10.c
index fcec81f862ec..2bb6d3136c7c 100644
--- a/drivers/net/ethernet/sfc/ef10.c
+++ b/drivers/net/ethernet/sfc/ef10.c
@@ -24,6 +24,7 @@
 #include &lt;linux/wait.h&gt;
 #include &lt;linux/workqueue.h&gt;
 #include &lt;net/udp_tunnel.h&gt;
+#include &quot;efx_cxl.h&quot;
 
 /* Hardware control for EF10 architecture including &#x27;Huntington&#x27;. */
 
@@ -106,7 +107,7 @@ static int efx_ef10_get_vf_index(struct efx_nic *efx)
 
 static int efx_ef10_init_datapath_caps(struct efx_nic *efx)
 {
-	MCDI_DECLARE_BUF(outbuf, MC_CMD_GET_CAPABILITIES_V4_OUT_LEN);
+	MCDI_DECLARE_BUF(outbuf, MC_CMD_GET_CAPABILITIES_V7_OUT_LEN);
 	struct efx_ef10_nic_data *nic_data = efx-&gt;nic_data;
 	size_t outlen;
 	int rc;
@@ -177,6 +178,12 @@ static int efx_ef10_init_datapath_caps(struct efx_nic *efx)
 			  efx-&gt;num_mac_stats);
 	}
 
+	if (outlen &lt; MC_CMD_GET_CAPABILITIES_V7_OUT_LEN)
+		nic_data-&gt;datapath_caps3 = 0;
+	else
+		nic_data-&gt;datapath_caps3 = MCDI_DWORD(outbuf,
+						      GET_CAPABILITIES_V7_OUT_FLAGS3);
+
 	return 0;
 }
 
@@ -919,6 +926,9 @@ static void efx_ef10_forget_old_piobufs(struct efx_nic *efx)
 static void efx_ef10_remove(struct efx_nic *efx)
 {
 	struct efx_ef10_nic_data *nic_data = efx-&gt;nic_data;
+#ifdef CONFIG_SFC_CXL
+	struct efx_probe_data *probe_data;
+#endif
 	int rc;
 
 #ifdef CONFIG_SFC_SRIOV
@@ -949,7 +959,12 @@ static void efx_ef10_remove(struct efx_nic *efx)
 
 	efx_mcdi_rx_free_indir_table(efx);
 
+#ifdef CONFIG_SFC_CXL
+	probe_data = container_of(efx, struct efx_probe_data, efx);
+	if (nic_data-&gt;wc_membase &amp;&amp; !probe_data-&gt;cxl_pio_in_use)
+#else
 	if (nic_data-&gt;wc_membase)
+#endif
 		iounmap(nic_data-&gt;wc_membase);
 
 	rc = efx_mcdi_free_vis(efx);
@@ -1140,6 +1155,9 @@ static int efx_ef10_dimension_resources(struct efx_nic *efx)
 	unsigned int channel_vis, pio_write_vi_base, max_vis;
 	struct efx_ef10_nic_data *nic_data = efx-&gt;nic_data;
 	unsigned int uc_mem_map_size, wc_mem_map_size;
+#ifdef CONFIG_SFC_CXL
+	struct efx_probe_data *probe_data;
+#endif
 	void __iomem *membase;
 	int rc;
 
@@ -1263,8 +1281,25 @@ static int efx_ef10_dimension_resources(struct efx_nic *efx)
 	iounmap(efx-&gt;membase);
 	efx-&gt;membase = membase;
 
-	/* Set up the WC mapping if needed */
-	if (wc_mem_map_size) {
+	if (!wc_mem_map_size)
+		goto skip_pio;
+
+	/* Set up the WC mapping */
+
+#ifdef CONFIG_SFC_CXL
+	probe_data = container_of(efx, struct efx_probe_data, efx);
+	if ((nic_data-&gt;datapath_caps3 &amp;
+	    (1 &lt;&lt; MC_CMD_GET_CAPABILITIES_V7_OUT_CXL_CONFIG_ENABLE_LBN)) &amp;&amp;
+	    probe_data-&gt;cxl_pio_initialised) {
+		/* Using PIO through CXL mapping? */
+		nic_data-&gt;pio_write_base = probe_data-&gt;cxl-&gt;ctpio_cxl +
+					   (pio_write_vi_base * efx-&gt;vi_stride +
+					    ER_DZ_TX_PIOBUF - uc_mem_map_size);
+		probe_data-&gt;cxl_pio_in_use = true;
+	} else
+#endif
+	{
+		/* Using legacy PIO BAR mapping */
 		nic_data-&gt;wc_membase = ioremap_wc(efx-&gt;membase_phys +
 						  uc_mem_map_size,
 						  wc_mem_map_size);
@@ -1279,12 +1314,13 @@ static int efx_ef10_dimension_resources(struct efx_nic *efx)
 			nic_data-&gt;wc_membase +
 			(pio_write_vi_base * efx-&gt;vi_stride + ER_DZ_TX_PIOBUF -
 			 uc_mem_map_size);
-
-		rc = efx_ef10_link_piobufs(efx);
-		if (rc)
-			efx_ef10_free_piobufs(efx);
 	}
 
+	rc = efx_ef10_link_piobufs(efx);
+	if (rc)
+		efx_ef10_free_piobufs(efx);
+
+skip_pio:
 	netif_dbg(efx, probe, efx-&gt;net_dev,
 		  &quot;memory BAR at %pa (virtual %p+%x UC, %p+%x WC)\n&quot;,
 		  &amp;efx-&gt;membase_phys, efx-&gt;membase, uc_mem_map_size,
diff --git a/drivers/net/ethernet/sfc/efx_cxl.c b/drivers/net/ethernet/sfc/efx_cxl.c
index 4d5f3974e51d..c13e1f2bf7ea 100644
--- a/drivers/net/ethernet/sfc/efx_cxl.c
+++ b/drivers/net/ethernet/sfc/efx_cxl.c
@@ -11,6 +11,7 @@
 #include &lt;cxl/pci.h&gt;
 #include &quot;net_driver.h&quot;
 #include &quot;efx_cxl.h&quot;
+#include &quot;efx.h&quot;
 
 #define EFX_CTPIO_BUFFER_SIZE	SZ_256M
 
@@ -138,14 +139,34 @@ int efx_cxl_init(struct efx_probe_data *probe_data)
 		cxl-&gt;efx_region = cxl_create_region(cxl-&gt;cxlrd, &amp;cxl-&gt;cxled, 1);
 		if (IS_ERR(cxl-&gt;efx_region)) {
 			pci_err(pci_dev, &quot;CXL accel create region failed&quot;);
-			cxl_put_root_decoder(cxl-&gt;cxlrd);
-			cxl_dpa_free(cxl-&gt;cxled);
-			return PTR_ERR(cxl-&gt;efx_region);
+			rc = PTR_ERR(cxl-&gt;efx_region);
+			goto err_region;
+		}
+
+		rc = cxl_get_region_range(cxl-&gt;efx_region, &amp;range);
+		if (rc) {
+			pci_err(pci_dev, &quot;CXL getting regions params failed&quot;);
+			goto err_map;
+		}
+
+		cxl-&gt;ctpio_cxl = ioremap(range.start, range.end - range.start + 1);
+		if (!cxl-&gt;ctpio_cxl) {
+			pci_err(pci_dev, &quot;CXL ioremap region (%pra) failed&quot;, &amp;range);
+			rc = -ENOMEM;
+			goto err_map;
 		}
 	}
 
 	probe_data-&gt;cxl = cxl;
+	probe_data-&gt;cxl_pio_initialised = true;
 	return 0;
+
+err_map:
+	cxl_unregister_region(cxl-&gt;efx_region);
+err_region:
+	cxl_put_root_decoder(cxl-&gt;cxlrd);
+	cxl_dpa_free(cxl-&gt;cxled);
+	return rc;
 }
 
 void efx_cxl_exit(struct efx_probe_data *probe_data)
@@ -153,9 +174,9 @@ void efx_cxl_exit(struct efx_probe_data *probe_data)
 	if (!probe_data-&gt;cxl)
 		return;
 
-	if (probe_data-&gt;cxl-&gt;hdm_was_committed) {
-		iounmap(probe_data-&gt;cxl-&gt;ctpio_cxl);
-	} else {
+	iounmap(probe_data-&gt;cxl-&gt;ctpio_cxl);
+
+	if (!probe_data-&gt;cxl-&gt;hdm_was_committed) {
 		cxl_dpa_free(probe_data-&gt;cxl-&gt;cxled);
 		cxl_put_root_decoder(probe_data-&gt;cxl-&gt;cxlrd);
 	}
diff --git a/drivers/net/ethernet/sfc/net_driver.h b/drivers/net/ethernet/sfc/net_driver.h
index 3964b2c56609..bea4eecdf842 100644
--- a/drivers/net/ethernet/sfc/net_driver.h
+++ b/drivers/net/ethernet/sfc/net_driver.h
@@ -1207,6 +1207,7 @@ struct efx_cxl;
  * @efx: Efx NIC details
  * @cxl: details of related cxl objects
  * @cxl_pio_initialised: cxl initialization outcome.
+ * @cxl_pio_in_use: PIO using CXL mapping
  */
 struct efx_probe_data {
 	struct pci_dev *pci_dev;
@@ -1214,6 +1215,7 @@ struct efx_probe_data {
 #ifdef CONFIG_SFC_CXL
 	struct efx_cxl *cxl;
 	bool cxl_pio_initialised;
+	bool cxl_pio_in_use;
 #endif
 };
 
diff --git a/drivers/net/ethernet/sfc/nic.h b/drivers/net/ethernet/sfc/nic.h
index 9fa5c4c713ab..c87cc9214690 100644
--- a/drivers/net/ethernet/sfc/nic.h
+++ b/drivers/net/ethernet/sfc/nic.h
@@ -152,6 +152,8 @@ enum {
  *	%MC_CMD_GET_CAPABILITIES response)
  * @datapath_caps2: Further Capabilities of datapath firmware (FLAGS2 field of
  * %MC_CMD_GET_CAPABILITIES response)
+ * @datapath_caps3: Further Capabilities of datapath firmware (FLAGS3 field of
+ * %MC_CMD_GET_CAPABILITIES response)
  * @rx_dpcpu_fw_id: Firmware ID of the RxDPCPU
  * @tx_dpcpu_fw_id: Firmware ID of the TxDPCPU
  * @must_probe_vswitching: Flag: vswitching has yet to be setup after MC reboot
@@ -186,6 +188,7 @@ struct efx_ef10_nic_data {
 	bool must_check_datapath_caps;
 	u32 datapath_caps;
 	u32 datapath_caps2;
+	u32 datapath_caps3;
 	unsigned int rx_dpcpu_fw_id;
 	unsigned int tx_dpcpu_fw_id;
 	bool must_probe_vswitching;
-- 
2.34.1</pre>
</details>
<div class="review-comment-signals">Signals: acknowledged fix needed</div>
</div>
</div>
<div class="thread-node depth-0">
<div class="review-comment">
<div class="review-comment-header">
<span class="review-author">alejandro.lucero-palau (author)</span>
<a class="date-chip" href="../2026-02-21_ollama_llama3.1-8b.html" title="First appeared in report for 2026-02-01">2026-02-01</a>
<span class="badge" style="color:#383d41;background:#e2e3e5">Neutral</span>
<span class="analysis-source-badge" style="color:#004085;background:#cce5ff" title="Analysis source: LLM">LLM</span>
</div>
<div class="review-comment-text">Author acknowledged that type2 support should allow accelerator drivers to create CXL regions from kernel code, explained how this would be achieved by adding functionality and integrating it with current memory expander support.</div>
<details class="raw-body-toggle">
<summary>Show original comment</summary>
<pre class="raw-body-text">From: Alejandro Lucero &lt;alucerop@amd.com&gt;

Creating a CXL region requires userspace intervention through the cxl
sysfs files. Type2 support should allow accelerator drivers to create
such cxl region from kernel code.

Adding that functionality and integrating it with current support for
memory expanders.

Based on https://lore.kernel.org/linux-cxl/168592159835.1948938.1647215579839222774.stgit@dwillia2-xfh.jf.intel.com/

Signed-off-by: Alejandro Lucero &lt;alucerop@amd.com&gt;
Reviewed-by: Jonathan Cameron &lt;Jonathan.Cameron@huawei.com&gt;
Reviewed-by: Dave Jiang &lt;dave.jiang@intel.com&gt;
---
 drivers/cxl/core/region.c | 131 ++++++++++++++++++++++++++++++++++++--
 include/cxl/cxl.h         |   3 +
 2 files changed, 127 insertions(+), 7 deletions(-)

diff --git a/drivers/cxl/core/region.c b/drivers/cxl/core/region.c
index 63c2aeb2ee1f..293e63dfef22 100644
--- a/drivers/cxl/core/region.c
+++ b/drivers/cxl/core/region.c
@@ -2944,6 +2944,14 @@ cxl_find_region_by_name(struct cxl_root_decoder *cxlrd, const char *name)
 	return to_cxl_region(region_dev);
 }
 
+static void drop_region(struct cxl_region *cxlr)
+{
+	struct cxl_root_decoder *cxlrd = to_cxl_root_decoder(cxlr-&gt;dev.parent);
+	struct cxl_port *port = cxlrd_to_port(cxlrd);
+
+	devm_release_action(port-&gt;uport_dev, __unregister_region, cxlr);
+}
+
 static ssize_t delete_region_store(struct device *dev,
 				   struct device_attribute *attr,
 				   const char *buf, size_t len)
@@ -4047,14 +4055,12 @@ static int __construct_region(struct cxl_region *cxlr,
 	return 0;
 }
 
-/* Establish an empty region covering the given HPA range */
-static struct cxl_region *construct_region(struct cxl_root_decoder *cxlrd,
-					   struct cxl_endpoint_decoder *cxled)
+static struct cxl_region *construct_region_begin(struct cxl_root_decoder *cxlrd,
+						 struct cxl_endpoint_decoder *cxled)
 {
 	struct cxl_memdev *cxlmd = cxled_to_memdev(cxled);
-	struct cxl_port *port = cxlrd_to_port(cxlrd);
 	struct cxl_dev_state *cxlds = cxlmd-&gt;cxlds;
-	int rc, part = READ_ONCE(cxled-&gt;part);
+	int part = READ_ONCE(cxled-&gt;part);
 	struct cxl_region *cxlr;
 
 	do {
@@ -4063,13 +4069,26 @@ static struct cxl_region *construct_region(struct cxl_root_decoder *cxlrd,
 				       cxled-&gt;cxld.target_type);
 	} while (IS_ERR(cxlr) &amp;&amp; PTR_ERR(cxlr) == -EBUSY);
 
-	if (IS_ERR(cxlr)) {
+	if (IS_ERR(cxlr))
 		dev_err(cxlmd-&gt;dev.parent,
 			&quot;%s:%s: %s failed assign region: %ld\n&quot;,
 			dev_name(&amp;cxlmd-&gt;dev), dev_name(&amp;cxled-&gt;cxld.dev),
 			__func__, PTR_ERR(cxlr));
+
+	return cxlr;
+}
+
+/* Establish an empty region covering the given HPA range */
+static struct cxl_region *construct_region(struct cxl_root_decoder *cxlrd,
+					   struct cxl_endpoint_decoder *cxled)
+{
+	struct cxl_port *port = cxlrd_to_port(cxlrd);
+	struct cxl_region *cxlr;
+	int rc;
+
+	cxlr = construct_region_begin(cxlrd, cxled);
+	if (IS_ERR(cxlr))
 		return cxlr;
-	}
 
 	rc = __construct_region(cxlr, cxlrd, cxled);
 	if (rc) {
@@ -4080,6 +4099,104 @@ static struct cxl_region *construct_region(struct cxl_root_decoder *cxlrd,
 	return cxlr;
 }
 
+DEFINE_FREE(cxl_region_drop, struct cxl_region *, if (_T) drop_region(_T))
+
+static struct cxl_region *
+__construct_new_region(struct cxl_root_decoder *cxlrd,
+		       struct cxl_endpoint_decoder **cxled, int ways)
+{
+	struct cxl_memdev *cxlmd = cxled_to_memdev(cxled[0]);
+	struct cxl_decoder *cxld = &amp;cxlrd-&gt;cxlsd.cxld;
+	struct cxl_region_params *p;
+	resource_size_t size = 0;
+	int rc, i;
+
+	struct cxl_region *cxlr __free(cxl_region_drop) =
+		construct_region_begin(cxlrd, cxled[0]);
+	if (IS_ERR(cxlr))
+		return cxlr;
+
+	guard(rwsem_write)(&amp;cxl_rwsem.region);
+
+	/*
+	 * Sanity check. This should not happen with an accel driver handling
+	 * the region creation.
+	 */
+	p = &amp;cxlr-&gt;params;
+	if (p-&gt;state &gt;= CXL_CONFIG_INTERLEAVE_ACTIVE) {
+		dev_err(cxlmd-&gt;dev.parent,
+			&quot;%s:%s: %s  unexpected region state\n&quot;,
+			dev_name(&amp;cxlmd-&gt;dev), dev_name(&amp;cxled[0]-&gt;cxld.dev),
+			__func__);
+		return ERR_PTR(-EBUSY);
+	}
+
+	rc = set_interleave_ways(cxlr, ways);
+	if (rc)
+		return ERR_PTR(rc);
+
+	rc = set_interleave_granularity(cxlr, cxld-&gt;interleave_granularity);
+	if (rc)
+		return ERR_PTR(rc);
+
+	scoped_guard(rwsem_read, &amp;cxl_rwsem.dpa) {
+		for (i = 0; i &lt; ways; i++) {
+			if (!cxled[i]-&gt;dpa_res)
+				return ERR_PTR(-EINVAL);
+			size += resource_size(cxled[i]-&gt;dpa_res);
+		}
+
+		rc = alloc_hpa(cxlr, size);
+		if (rc)
+			return ERR_PTR(rc);
+
+		for (i = 0; i &lt; ways; i++) {
+			rc = cxl_region_attach(cxlr, cxled[i], 0);
+			if (rc)
+				return ERR_PTR(rc);
+		}
+	}
+
+	rc = cxl_region_decode_commit(cxlr);
+	if (rc)
+		return ERR_PTR(rc);
+
+	p-&gt;state = CXL_CONFIG_COMMIT;
+
+	return no_free_ptr(cxlr);
+}
+
+/**
+ * cxl_create_region - Establish a region given an endpoint decoder
+ * @cxlrd: root decoder to allocate HPA
+ * @cxled: endpoint decoders with reserved DPA capacity
+ * @ways: interleave ways required
+ *
+ * Returns a fully formed region in the commit state and attached to the
+ * cxl_region driver.
+ */
+struct cxl_region *cxl_create_region(struct cxl_root_decoder *cxlrd,
+				     struct cxl_endpoint_decoder **cxled,
+				     int ways)
+{
+	struct cxl_region *cxlr;
+
+	mutex_lock(&amp;cxlrd-&gt;range_lock);
+	cxlr = __construct_new_region(cxlrd, cxled, ways);
+	mutex_unlock(&amp;cxlrd-&gt;range_lock);
+	if (IS_ERR(cxlr))
+		return cxlr;
+
+	if (device_attach(&amp;cxlr-&gt;dev) &lt;= 0) {
+		dev_err(&amp;cxlr-&gt;dev, &quot;failed to create region\n&quot;);
+		drop_region(cxlr);
+		return ERR_PTR(-ENODEV);
+	}
+
+	return cxlr;
+}
+EXPORT_SYMBOL_NS_GPL(cxl_create_region, &quot;CXL&quot;);
+
 static struct cxl_region *
 cxl_find_region_by_range(struct cxl_root_decoder *cxlrd, struct range *hpa)
 {
diff --git a/include/cxl/cxl.h b/include/cxl/cxl.h
index 4802371db00e..50acbd13bcf8 100644
--- a/include/cxl/cxl.h
+++ b/include/cxl/cxl.h
@@ -281,4 +281,7 @@ struct cxl_endpoint_decoder *cxl_request_dpa(struct cxl_memdev *cxlmd,
 					     enum cxl_partition_mode mode,
 					     resource_size_t alloc);
 int cxl_dpa_free(struct cxl_endpoint_decoder *cxled);
+struct cxl_region *cxl_create_region(struct cxl_root_decoder *cxlrd,
+				     struct cxl_endpoint_decoder **cxled,
+				     int ways);
 #endif /* __CXL_CXL_H__ */
-- 
2.34.1</pre>
</details>
<div class="review-comment-signals">Signals: acknowledged, explained</div>
</div>
</div>
</div>

    <footer>LKML Daily Activity Tracker</footer>
    <script>
    // When arriving via a date anchor (e.g. #2026-02-15 from a daily report),
    // scroll the anchor into view after a brief delay so layout is complete.
    (function () {
        var hash = window.location.hash;
        if (!hash) return;
        var target = document.getElementById(hash.slice(1));
        if (!target) return;
        setTimeout(function () {
            target.scrollIntoView({behavior: 'smooth', block: 'start'});
        }, 80);
    })();
    </script>
</body>
</html>