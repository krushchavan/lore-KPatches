{
  "thread_id": "aZhOnSVao9yFJML7@thinkstation",
  "subject": "[LSF/MM/BPF TOPIC] 64k (or 16k) base page size on x86",
  "url": "https://lore.kernel.org/all/aZhOnSVao9yFJML7@thinkstation/",
  "dates": {
    "2026-02-20": {
      "report_file": "2026-02-20.html",
      "developer": "Kiryl Shutsemau",
      "reviews": [
        {
          "author": "Kalesh Singh",
          "summary": "I think personality(2) may be too late? By the time a process invokes it, the initial userspace mappings (executable, linker for init, etc) are already established with the default granularity. To handle this, I've been using an early_param to enforce the larger VMA alignment system-wide right from boot. Perhaps, something for global enforcement (Kconfig/early param) and a prctl/personality flag for per-process opt in? This makes sense for maintaining ABI compatibility. Userspace allocators might want to optimize their layouts to match PG_SIZE while still being able to operate at PTE_SIZE when needed.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "preference expressed"
          ],
          "has_inline_review": true,
          "tags_given": [],
          "analysis_source": "heuristic",
          "raw_body": "On Fri, Feb 20, 2026 at 4:10 AM Kiryl Shutsemau <kas@kernel.org> wrote:\n>\n> On Thu, Feb 19, 2026 at 03:24:37PM -0800, Kalesh Singh wrote:\n> > On Thu, Feb 19, 2026 at 7:39 AM David Hildenbrand (Arm)\n> > <david@kernel.org> wrote:\n> > >\n> > > On 2/19/26 16:08, Kiryl Shutsemau wrote:\n> > > > No, there's no new hardware (that I know of). I want to explore what page size\n> > > > means.\n> > > >\n> > > > The kernel uses the same value - PAGE_SIZE - for two things:\n> > > >\n> > > >    - the order-0 buddy allocation size;\n> > > >\n> > > >    - the granularity of virtual address space mapping;\n> > > >\n> > > > I think we can benefit from separating these two meanings and allowing\n> > > > order-0 allocations to be larger than the virtual address space covered by a\n> > > > PTE entry.\n> > > >\n> > > > The main motivation is scalability. Managing memory on multi-terabyte\n> > > > machines in 4k is suboptimal, to say the least.\n> > > >\n> > > > Potential benefits of the approach (assuming 64k pages):\n> > > >\n> > > >    - The order-0 page size cuts struct page overhead by a factor of 16. From\n> > > >      ~1.6% of RAM to ~0.1%;\n> > > >\n> > > >    - TLB wins on machines with TLB coalescing as long as mapping is naturally\n> > > >      aligned;\n> > > >\n> > > >    - Order-5 allocation is 2M, resulting in less pressure on the zone lock;\n> > > >\n> > > >    - 1G pages are within possibility for the buddy allocator - order-14\n> > > >      allocation. It can open the road to 1G THPs.\n> > > >\n> > > >    - As with THP, fewer pages - less pressure on the LRU lock;\n> > > >\n> > > >    - ...\n> > > >\n> > > > The trade-off is memory waste (similar to what we have on architectures with\n> > > > native 64k pages today) and complexity, mostly in the core-MM code.\n> > > >\n> > > > == Design considerations ==\n> > > >\n> > > > I want to split PAGE_SIZE into two distinct values:\n> > > >\n> > > >    - PTE_SIZE defines the virtual address space granularity;\n> > > >\n> > > >    - PG_SIZE defines the size of the order-0 buddy allocation;\n> > > >\n> > > > PAGE_SIZE is only defined if PTE_SIZE == PG_SIZE. It will flag which code\n> > > > requires conversion, and keep existing code working while conversion is in\n> > > > progress.\n> > > >\n> > > > The same split happens for other page-related macros: mask, shift,\n> > > > alignment helpers, etc.\n> > > >\n> > > > PFNs are in PTE_SIZE units.\n> > > >\n> > > > The buddy allocator and page cache (as well as all I/O) operate in PG_SIZE\n> > > > units.\n> > > >\n> > > > Userspace mappings are maintained with PTE_SIZE granularity. No ABI changes\n> > > > for userspace. But we might want to communicate PG_SIZE to userspace to\n> > > > get the optimal results for userspace that cares.\n> > > >\n> > > > PTE_SIZE granularity requires a substantial rework of page fault and VMA\n> > > > handling:\n> > > >\n> > > >    - A struct page pointer and pgprot_t are not enough to create a PTE entry.\n> > > >      We also need the offset within the page we are creating the PTE for.\n> > > >\n> > > >    - Since the VMA start can be aligned arbitrarily with respect to the\n> > > >      underlying page, vma->vm_pgoff has to be changed to vma->vm_pteoff,\n> > > >      which is in PTE_SIZE units.\n> > > >\n> > > >    - The page fault handler needs to handle PTE_SIZE < PG_SIZE, including\n> > > >      misaligned cases;\n> > > >\n> > > > Page faults into file mappings are relatively simple to handle as we\n> > > > always have the page cache to refer to. So you can map only the part of the\n> > > > page that fits in the page table, similarly to fault-around.\n> > > >\n> > > > Anonymous and file-CoW faults should also be simple as long as the VMA is\n> > > > aligned to PG_SIZE in both the virtual address space and with respect to\n> > > > vm_pgoff. We might waste some memory on the ends of the VMA, but it is\n> > > > tolerable.\n> > > >\n> > > > Misaligned anonymous and file-CoW faults are a pain. Specifically, mapping\n> > > > pages across a page table boundary. In the worst case, a page is mapped across\n> > > > a PGD entry boundary and PTEs for the page have to be put in two separate\n> > > > subtrees of page tables.\n> > > >\n> > > > A naive implementation would map different pages on different sides of a\n> > > > page table boundary and accept the waste of one page per page table crossing.\n> > > > The hope is that misaligned mappings are rare, but this is suboptimal.\n> > > >\n> > > > mremap(2) is the ultimate stress test for the design.\n> > > >\n> > > > On x86, page tables are allocated from the buddy allocator and if PG_SIZE\n> > > > is greater than 4 KB, we need a way to pack multiple page tables into a\n> > > > single page. We could use the slab allocator for this, but it would\n> > > > require relocating the page-table metadata out of struct page.\n> > >\n> > > When discussing per-process page sizes with Ryan and Dev, I mentioned\n> > > that having a larger emulated page size could be interesting for other\n> > > architectures as well.\n> > >\n> > > That is, we would emulate a 64K page size on Intel for user space as\n> > > well, but let the OS work with 4K pages.\n> > >\n> > > We'd only allocate+map large folios into user space + pagecache, but\n> > > still allow for page tables etc. to not waste memory.\n> > >\n> > > So \"most\" of your allocations in the system would actually be at least\n> > > 64k, reducing zone lock contention etc.\n> > >\n> > >\n> > > It doesn't solve all the problems you wanted to tackle on your list\n> > > (e.g., \"struct page\" overhead, which will be sorted out by memdescs).\n> >\n> > Hi Kiryl,\n> >\n> > I'd be interested to discuss this at LSFMM.\n> >\n> > On Android, we have a separate but related use case: we emulate the\n> > userspace page size on x86, primarily to enable app developers to\n> > conduct compatibility testing of their apps for 16KB Android devices.\n> > [1]\n> >\n> > It mainly works by enforcing a larger granularity on the VMAs to\n> > emulate a userspace page size, somewhat similar to what David\n> > mentioned, while the underlying kernel still operates on a 4KB\n> > granularity. [2]\n> >\n> > IIUC the current design would not enfore the larger granularity /\n> > alignment for VMAs to avoid breaking ABI. However, I'd be interest to\n> > discuss whether it can be extended to cover this usecase as well.\n>\n> I don't want to break ABI, but might add a knob (maybe personality(2) ?)\n> for enforcement to see what breaks.\n\nI think personality(2) may be too late? By the time a process invokes\nit, the initial userspace mappings (executable, linker for init, etc)\nare already established with the default granularity.\n\nTo handle this, I've been using an early_param to enforce the larger\nVMA alignment system-wide right from boot.\n\nPerhaps, something for global enforcement (Kconfig/early param) and a\nprctl/personality flag for per-process opt in?\n\n>\n> In general, I would prefer to advertise a new value to userspace that\n> would mean preferred virtual address space granularity.\n\nThis makes sense for maintaining ABI compatibility. Userspace\nallocators might want to optimize their layouts to match PG_SIZE while\nstill being able to operate at PTE_SIZE when needed.\n\n-- Kalesh\n\n>\n> >\n> > [1]  https://developer.android.com/guide/practices/page-sizes#16kb-emulator\n> > [2] https://source.android.com/docs/core/architecture/16kb-page-size/getting-started-cf-x86-64-pgagnostic\n> >\n> > Thanks,\n> > Kalesh\n> >\n> >\n> >\n> >\n> > >\n> > > --\n> > > Cheers,\n> > >\n> > > David\n> > >\n>\n> --\n>   Kiryl Shutsemau / Kirill A. Shutemov\n",
          "reply_to": "",
          "message_date": "2026-02-20",
          "message_id": ""
        }
      ],
      "analysis_source": "heuristic"
    },
    "2026-02-19": {
      "report_file": "2026-02-20_ollama_llama3.1-8b.html",
      "developer": "Kiryl Shutsemau",
      "reviews": [
        {
          "author": "Pedro Falcato",
          "summary": "Reviewer Pedro Falcato questioned the relevance of the proposed patch, suggesting that memory management can be handled through transparent huge pages (mTHP) using /sys/kernel/mm/transparent_hugepage",
          "sentiment": "neutral",
          "sentiment_signals": [
            "questioning relevance",
            "alternative solution"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Doesn't this idea make less sense these days, with mTHP? Simply by toggling one\nof the entries in /sys/kernel/mm/transparent_hugepage.",
          "reply_to": "Kiryl Shutsemau",
          "message_date": "2026-02-19"
        },
        {
          "author": "Pedro Falcato",
          "summary": "Reviewer suggested enforcing a minimum allocation order globally on the page cache to address scalability issues, noting that some points are not addressed by existing work and requesting clarification on others.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes",
            "clarification needed"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "We could perhaps add a way to enforce a min_order globally on the page cache,\nas a way to address it.\n\nThere are some points there which aren't addressed by mTHP work in any way\n(1G THPs for one), others which are being addressed separately (memdesc work\ntrying to cut down on struct page overhead).\n\n(I also don't understand your point about order-5 allocation, AFAIK pcp will\ncache up to COSTLY_ORDER (3) and PMD order, but I'm probably not seeing the\nfull picture)\n\n\n-- \nPedro",
          "reply_to": "Kiryl Shutsemau",
          "message_date": "2026-02-19"
        },
        {
          "author": "David (Arm)",
          "summary": "Reviewer suggested emulating a larger page size (64K) for user space on x86 while still using 4K pages internally, reducing zone lock contention and other issues.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "When discussing per-process page sizes with Ryan and Dev, I mentioned \nthat having a larger emulated page size could be interesting for other \narchitectures as well.\n\nThat is, we would emulate a 64K page size on Intel for user space as \nwell, but let the OS work with 4K pages.\n\nWe'd only allocate+map large folios into user space + pagecache, but \nstill allow for page tables etc. to not waste memory.\n\nSo \"most\" of your allocations in the system would actually be at least \n64k, reducing zone lock contention etc.\n\n\nIt doesn't solve all the problems you wanted to tackle on your list \n(e.g., \"struct page\" overhead, which will be sorted out by memdescs).\n\n-- \nCheers,\n\nDavid",
          "reply_to": "Kiryl Shutsemau",
          "message_date": "2026-02-19"
        },
        {
          "author": "Kiryl Shutsemau (author)",
          "summary": "Author responded to Pedro Falcato's concern that mTHP (maximum THP) is not guaranteed to provide 64k pages, explaining that it's a best effort mechanism and fragmentation isn't an issue as long as there's free memory.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "mTHP is still best effort. This is way you don't need to care about\nfragmentation, you will get your 64k page as long as you have free\nmemory.",
          "reply_to": "Pedro Falcato",
          "message_date": "2026-02-19"
        },
        {
          "author": "Kiryl Shutsemau (author)",
          "summary": "The author addressed Pedro Falcato's concern about the efficiency of the page allocator by explaining that a higher base page size reduces the work required to merge/split buddy pages, making it cheaper for the allocator to serve large allocations.",
          "sentiment": "positive",
          "sentiment_signals": [
            "acknowledged the benefit of higher base page size"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "With higher base page size, page allocator doesn't need to do as much\nwork to merge/split buddy pages. So serving the same 2M as order-5 is\ncheaper than order-9.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
          "reply_to": "Pedro Falcato",
          "message_date": "2026-02-19"
        },
        {
          "author": "David (Arm)",
          "summary": "Reviewer David noted that the proposed change would lead to reduced page table entry (PTE) splitting and merging due to larger allocation sizes, which would naturally result in fewer PTEs being created.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "no clear technical objection or suggestion"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "I think the idea is that if most of your allocations (anon + pagecache) \nare 64k instead of 4k, on average, you'll just naturally do less merging \nsplitting.\n\n-- \nCheers,\n\nDavid",
          "reply_to": "Kiryl Shutsemau",
          "message_date": "2026-02-19"
        },
        {
          "author": "Kiryl Shutsemau (author)",
          "summary": "Author disagrees that emulation can help reduce zone lock contention, citing potential for increased contention due to mixed page sizes",
          "sentiment": "neutral",
          "sentiment_signals": [
            "disagreement",
            "uncertainty"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "I am not convinced emulation would help zone lock contention. I expect\ncontention to be higher if page allocator would see a mix of 4k and 64k\nrequests. It sounds like constant split/merge under the lock.",
          "reply_to": "David (Arm)",
          "message_date": "2026-02-19"
        },
        {
          "author": "Kiryl Shutsemau (author)",
          "summary": "Author acknowledged that serving 1G pages out of the buddy allocator is not feasible with a 4k order-0 allocation size, and expressed uncertainty about how to achieve viable 1G THPs without it.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "acknowledged a limitation",
            "expressed uncertainty"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "I don't think we can serve 1G pages out of buddy allocator with 4k\norder-0. And without it, I don't see how to get to a viable 1G THPs.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
          "reply_to": "David (Arm)",
          "message_date": "2026-02-19"
        },
        {
          "author": "David (Arm)",
          "summary": "Reviewer David (Arm) noted that if most allocations are larger than 64k, the benefits of splitting page size into two values may be diminished, as there would be less need for splitting and merging smaller allocations.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "If most your allocations are larger, then there isn't that much \nsplitting/merging.\n\nThere will be some for the < 64k allocations of course, but when all \nuser space+page cache is >= 64 then the split/merge + zone lock should \nbe heavily reduced.",
          "reply_to": "Kiryl Shutsemau",
          "message_date": "2026-02-19"
        },
        {
          "author": "David (Arm)",
          "summary": "Reviewer David (Arm) expressed skepticism about the proposed patch, suggesting that previous discussions and ideas from Zi Yan could be used to address the issue of larger page sizes on x86.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "skepticism",
            "lack of clear objection"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Zi Yan was one working on this, and I think we had ideas on how to make \nthat work in the long run.\n\n-- \nCheers,\n\nDavid",
          "reply_to": "Kiryl Shutsemau",
          "message_date": "2026-02-19"
        },
        {
          "author": "Dave Hansen",
          "summary": "Reviewer Dave Hansen questioned the memory savings of splitting PAGE_SIZE into PTE_SIZE and PG_SIZE, citing a kernel tree size analysis that showed a 64k page cache would consume ~5GB extra memory for a single kernel tree, suggesting that this approach may not be effective in reducing RAM usage.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "questioning the effectiveness of the proposed solution",
            "highlighting potential drawbacks"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "First of all, this looks like fun. Nice work! I'm not opposed at all in\nconcept to cleaning up things and doing the logical separation you\ndescribed to split buddy granularity and mapping granularity. That seems\nlike a worthy endeavor and some of the union/#define tricks look like a\nlikely viable way to do it incrementally.\n\nBut I don't think there's going to be a lot of memory savings in the\nend. Maybe this would bring the mem= hyperscalers back into the fold and\nhave them actually start using 'struct page' again for their VM memory.\nDunno.\n\nBut, let's look at my kernel directory and round the file sizes up to\n4k, 16k and 64k:\n\nfind .  -printf '%s\\n' | while read size; do echo\t\\\n\t\t$(((size + 0x0fff) & 0xfffff000))\t\\\n\t\t$(((size + 0x3fff) & 0xffffc000))\t\\\n\t\t$(((size + 0xffff) & 0xffff0000));\ndone\n\n... and add them all up:\n\n11,297,648 KB - on disk\n11,297,712 KB - in a 4k page cache\n12,223,488 KB - in a 16k page cache\n16,623,296 KB - in a 64k page cache\n\nSo a 64k page cache eats ~5GB of extra memory for a kernel tree (well,\n_my_ kernel tree). In other words, if you are looking for memory savings\non my laptop, you'll need ~300GB of RAM before 'struct page' overhead\noverwhelms the page cache bloat from a single kernel tree.\n\nThe whole kernel obviously isn't in the page cache all at the same time.\nThe page cache across the system is also obviously different than a\nkernel tree, but you get the point.\n\nThat's not to diminish how useful something like this might be,\nespecially for folks that are sensitive to 'struct page' overhead or\nallocator performance.\n\nBut, it will mostly be getting better performance at the _cost_ of\nconsuming more RAM, not saving RAM.",
          "reply_to": "Kiryl Shutsemau",
          "message_date": "2026-02-19"
        },
        {
          "author": "Kiryl Shutsemau (author)",
          "summary": "Author asks for clarification on whether the proposed page size change should also affect user-space ABI, specifically if all mappings should be 64k aligned.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarifying question"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Just to clarify, do you want it to be enforced on userspace ABI.\nLike, all mappings are 64k aligned?",
          "reply_to": "David (Arm)",
          "message_date": "2026-02-19"
        },
        {
          "author": "Kiryl Shutsemau (author)",
          "summary": "Author acknowledges that memory waste due to page table overhead is a solvable issue and proposes using slab allocation, indicating a planned fix.",
          "sentiment": "positive",
          "sentiment_signals": [
            "acknowledgment of an issue",
            "proposed solution"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Waste of memory for page table is solvable and pretty straight forward.\nMost of such cases can be solve mechanically by switching to slab.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
          "reply_to": "David (Arm)",
          "message_date": "2026-02-19"
        },
        {
          "author": "Dave Hansen",
          "summary": "Reviewer Dave Hansen noted that the patch does not provide a clear explanation for why 64k or 16k page sizes are being considered on x86, and requested more context before proceeding",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes",
            "lack of explanation"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "On 2/19/26 07:08, Kiryl Shutsemau wrote:\n...",
          "reply_to": "Kiryl Shutsemau",
          "message_date": "2026-02-19"
        },
        {
          "author": "Dave Hansen",
          "summary": "Reviewer noted that the patch introduces a large number of changes (874 insertions and 843 deletions) across various files in arch/x86 and mm, primarily due to renames, which may be overwhelming.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "large number of changes",
            "renames"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "A few notes about the diffstats:\n\n$ git diff v6.17..HEAD arch/x86 | diffstat | tail -1\n 105 files changed, 874 insertions(+), 843 deletions(-)\n$ git diff v6.17..HEAD mm | diffstat | tail -1\n 53 files changed, 1136 insertions(+), 1069 deletions(-)\n\nThe vast, vast majority of this seems to be the renames. Stuff like:",
          "reply_to": "Kiryl Shutsemau",
          "message_date": "2026-02-19"
        },
        {
          "author": "Dave Hansen",
          "summary": "Reviewer Dave Hansen noted that the patch requires auditing for logic changes and requested a clear separation between mechanical and logical updates.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested_changes"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "That stuff obviously needs to be audited but it's far less concerning\nthan the logic changes.\n\nSo just for review sanity, if you go forward with this, I'd very much\nappreciate a strong separation of the purely mechanical bits from any\nlogic changes.",
          "reply_to": "Kiryl Shutsemau",
          "message_date": "2026-02-19"
        },
        {
          "author": "Dave Hansen",
          "summary": "Reviewer Dave Hansen suggested that the patch should be gated behind a full tree conversion to ptdescs, as it is not feasible to implement without this change first.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "gating",
            "ptdesc"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Others mentioned this, but I think this essentially gates what you are\ndoing behind a full tree conversion over to ptdescs.\n\nThe most useful thing we can do with this series is look at it and\ndecide what _other_ things need to get done before the tree could\npossibly go in that direction, like ptdesc or a the disambiguation\nbetween PTE_SIZE and PG_SIZE that you've kicked off here.",
          "reply_to": "Kiryl Shutsemau",
          "message_date": "2026-02-19"
        },
        {
          "author": "Matthew Wilcox",
          "summary": "Reviewer Matthew Wilcox suggested an alternative approach to implementing larger page sizes by allocating the larger size and using it for multiple entries, expressing skepticism about the slab approach",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "skeptical",
            "alternative"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Have you looked at the s390/ppc implementations (yes, they're different,\nno, that sucks)?  slab seems like the wrong approach to me.\n\nThere's a third approach that I've never looked at which is to allocate\nthe larger size, then just use it for N consecutive entries.",
          "reply_to": "Kiryl Shutsemau",
          "message_date": "2026-02-19"
        },
        {
          "author": "Pedro Falcato",
          "summary": "Reviewer Pedro Falcato noted that the proposed patch would allow for 90%+ of allocations to be 64K, which he believes could yield a system where most allocations are 64K.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "no clear signal",
            "neutral comment"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Yep. That plus slab_min_order would hopefully yield a system where 90%+\n(depending on how your filesystem's buffer cache works) allocations are 64K.\n\n-- \nPedro",
          "reply_to": "David (Arm)",
          "message_date": "2026-02-19"
        },
        {
          "author": "Kiryl Shutsemau (author)",
          "summary": "Author acknowledged that struct page memory consumption is a problem, but noted that it's static and cannot be reclaimed, whereas page cache rounding overhead can be controlled by userspace",
          "sentiment": "neutral",
          "sentiment_signals": [
            "acknowledged the issue",
            "provided explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "That's fair.\n\nThe problem with struct page memory consumption is that it is static and\ncannot be reclaimed. You pay the struct page tax no matter what.\n\nPage cache rounding overhead can be large, but a motivated userspace can\nkeep it under control by avoiding splitting a dataset into many small\nfiles. And this memory is reclaimable.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
          "reply_to": "Dave Hansen",
          "message_date": "2026-02-19"
        },
        {
          "author": "Kiryl Shutsemau (author)",
          "summary": "Author acknowledged that packing of page tables is not required for correctness and plans to implement a proof-of-concept (PoC) without it, but needs to catch up on ptdescs first.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "acknowledged need to catch up",
            "planning PoC"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "I have not followed ptdescs closely. Need to catch up.\n\nFor PoC, I will just waste full order-0 page for page table. Packing is\nnot required for correctness.",
          "reply_to": "Dave Hansen",
          "message_date": "2026-02-19"
        },
        {
          "author": "Dave Hansen",
          "summary": "Reviewer Dave Hansen noted that the proposed change to separate PAGE_SIZE into PTE_SIZE and PG_SIZE would not impact the KPTI pgd allocation size, as it can still fit within a 128k page, making the change 'weird but functional'.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "NEUTRAL",
            "no clear signal"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Yeah, I guess padding it out is ugly but effective.\n\nI was trying to figure out how it would apply to the KPTI pgd because we\njust flip bit 12 to switch between user and kernel PGDs. But I guess the\n8k of PGDs in the current allocation will fit fine in 128k, so it's\nweird but functional.",
          "reply_to": "Kiryl Shutsemau",
          "message_date": "2026-02-19"
        },
        {
          "author": "Kiryl Shutsemau (author)",
          "summary": "Author acknowledges a need for further work on handling page faults and VMA alignment, but does not commit to a specific fix or timeline.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "acknowledges need for further work"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "I was the first thing that came to mind. I have not put much time into\nit",
          "reply_to": "Matthew Wilcox",
          "message_date": "2026-02-19"
        },
        {
          "author": "Kiryl Shutsemau (author)",
          "summary": "Author addresses Matthew Wilcox's concern about fragmentation when using 16k pages, explaining that it is not an issue because the parent page table only needs to be populated with 16 entries.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "clarification",
            "explanation"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "Yeah, that's a possible way. We would need to populate 16 page table\nentries of the parent page table. But you don't need to care about\nfragmentation within the page.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
          "reply_to": "Matthew Wilcox",
          "message_date": "2026-02-19"
        },
        {
          "author": "Kalesh Singh",
          "summary": "Reviewer noted that the patch does not handle page faults into file mappings correctly when PTE_SIZE is less than PG_SIZE, and suggested that the page fault handler needs to be modified to handle misaligned cases.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "On Thu, Feb 19, 2026 at 7:39 AM David Hildenbrand (Arm)\n<david@kernel.org> wrote:",
          "reply_to": "David (Arm)",
          "message_date": "2026-02-19"
        },
        {
          "author": "Kalesh Singh",
          "summary": "The reviewer notes that the current design does not enforce a larger granularity on VMAs to emulate a userspace page size, which is necessary for Android's use case of emulating 16KB devices on x86. They express interest in discussing whether this can be extended to cover their use case.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "requested discussion",
            "expressed interest"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Hi Kiryl,\n\nI'd be interested to discuss this at LSFMM.\n\nOn Android, we have a separate but related use case: we emulate the\nuserspace page size on x86, primarily to enable app developers to\nconduct compatibility testing of their apps for 16KB Android devices.\n[1]\n\nIt mainly works by enforcing a larger granularity on the VMAs to\nemulate a userspace page size, somewhat similar to what David\nmentioned, while the underlying kernel still operates on a 4KB\ngranularity. [2]\n\nIIUC the current design would not enfore the larger granularity /\nalignment for VMAs to avoid breaking ABI. However, I'd be interest to\ndiscuss whether it can be extended to cover this usecase as well.\n\n[1]  https://developer.android.com/guide/practices/page-sizes#16kb-emulator\n[2] https://source.android.com/docs/core/architecture/16kb-page-size/getting-started-cf-x86-64-pgagnostic\n\nThanks,\nKalesh",
          "reply_to": "David (Arm)",
          "message_date": "2026-02-19"
        },
        {
          "author": "Zi Yan",
          "summary": "Reviewer suggested adding a super pageblock concept that consists of N consecutive pageblocks to enable anti-fragmentation at larger granularity (e.g., 1GB) and create free pages.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "debate",
            "debatable"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Right. The idea is to add super pageblock (or whatever name), which consists of N consecutive\npageblocks, so that anti fragmentation can work at larger granularity, e.g., 1GB, to create\nfree pages. Whether 1GB free pages from memory compaction need to go into buddy allocator\nor not is debatable.\n\n--\nBest Regards,\nYan, Zi",
          "reply_to": "David (Arm)",
          "message_date": "2026-02-19"
        },
        {
          "author": "Liam Howlett",
          "summary": "Reviewer Liam Howlett noted that increasing page size may not be beneficial for systems under memory pressure, as it can lead to increased CPU usage and reduced primary workload performance, especially on multi-workload machines.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "requested changes"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "But we are in reclaim a lot more these days.  As I'm sure you are aware,\nwe are trying to maximize the resources (both cpu and ram) of any\nmachine powered on.  Entering reclaim will consume the cpu time and will\naffect other tasks.\n\nEspecially with multiple workload machines, the tendency is to have a\nprimary focus with the lower desired work being killed, if necessary.\nReducing the overhead just means more secondary tasks, or a bigger\nfootprint of the ones already executing.\n\nIncreasing the memory pressure will degrade the primary workload more\nfrequently, even if we recover enough to avoid OOMing the secondary.\n\nWhile in the struct page tax world, the secondary task would be killed\nafter a shorter (and less frequently executed) reclaim comes up short.\nSo, I would think that we would be degrading the primary workload in an\nattempt to keep the secondary alive?  Maybe I'm over-simplifying here?\n\nNear the other end of the spectrum, we have chromebooks that are\nconstantly in reclaim, even with 4k pages.  I guess these machines would\nbe destine to maintain the same page size they use today.  That is, this\nsolution for the struct page tax is only useful if you have a lot of\nmemory.  But then again, that's where the bookkeeping costs become hard\nto take.\n\nThanks,\nLiam",
          "reply_to": "Kiryl Shutsemau",
          "message_date": "2026-02-19"
        }
      ],
      "analysis_source": "llm-per-reviewer"
    },
    "2026-02-23": {
      "report_file": "2026-02-20_ollama_llama3.1-8b.html",
      "developer": "Kiryl Shutsemau",
      "reviews": [
        {
          "author": "David (Arm)",
          "summary": "Reviewer David noted that the patch requires consideration of potential issues with existing binaries and libraries, which may need to be recompiled.",
          "sentiment": "needs_work",
          "sentiment_signals": [
            "potential ABI changes",
            "recompilation requirements"
          ],
          "has_inline_review": false,
          "tags_given": [
            "Reviewed-by"
          ],
          "analysis_source": "llm",
          "raw_body": "Right, I assume that they will have to be thought about that, and \npossibly, some binaries/libraries recompiled.\n\n-- \nCheers,\n\nDavid",
          "reply_to": "Kalesh Singh",
          "message_date": "2026-02-23"
        },
        {
          "author": "Kiryl Shutsemau (author)",
          "summary": "Author acknowledges that the x86-64 SysV ABI allows for 64k page size, but notes it doesn't work in practice and emphasizes the importance of backward compatibility.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "acknowledgment",
            "emphasis on backward compatibility"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "I think backward compatibility is important and I believe we can get\nthere without ABI break. And optimize from there.\n\nBTW, x86-64 SysV ABI allows for 64k page size:\n\n\tSystems are permitted to use any power-of-two page size between\n\t4KB and 64KB, inclusive.\n\nBut it doesn't work in practice.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
          "reply_to": "David (Arm)",
          "message_date": "2026-02-23"
        },
        {
          "author": "Kiryl Shutsemau (author)",
          "summary": "Author acknowledged that the patch may not be suitable for all use cases, specifically desktops, and is open to exploring alternative page sizes like 16k.",
          "sentiment": "neutral",
          "sentiment_signals": [
            "acknowledged limitations",
            "open to alternatives"
          ],
          "has_inline_review": false,
          "tags_given": [],
          "analysis_source": "llm",
          "raw_body": "I have not invested much time into investigating this.\n\nI intentionally targeted compatible version assuming it will be better\nreceived by upstream. I want it to be usable outside specially cured\nuserspace. 64k might not be good fit for a desktop, but 16k can be a\ndifferent story.\n\n-- \n  Kiryl Shutsemau / Kirill A. Shutemov",
          "reply_to": "David (Arm)",
          "message_date": "2026-02-23"
        }
      ],
      "analysis_source": "llm-per-reviewer"
    }
  }
}